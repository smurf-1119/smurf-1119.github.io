<!DOCTYPE html>

<html lang="zh-CN">

<head>
  
  <meta name="baidu-site-verification" content="code-J1Qg17G6wT" />
  <title>Transfer learning for CV - Smurf</title>
  <meta charset="UTF-8">
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
  
  

    <!-- Site Verification -->
    <meta name="baidu-site-verification" content="code-J1Qg17G6wT" />

  <link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/tangyuxian/blog_image@master/head/head.jpg" type="image/png" />
  <meta name="description" content="Transfer learning for CV">
<meta property="og:type" content="article">
<meta property="og:title" content="Transfer learning for CV">
<meta property="og:url" content="http://example.com/2021/08/15/cv/13.%20Transfer%20learning%20for%20CV/index.html">
<meta property="og:site_name" content="Smurf">
<meta property="og:description" content="Transfer learning for CV">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011223255.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234434.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234563.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234349.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234270.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234540.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234138.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234958.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234993.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234362.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234965.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235410.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235317.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235498.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235237.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235574.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235084.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235138.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235858.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235837.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235613.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235202.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235279.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235369.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236437.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236159.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236434.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236731.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236530.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236277.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236781.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236320.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236211.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236473.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236855.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236579.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236931.png">
<meta property="og:image" content="http://example.com/2021/08/15/cv/13.%20Transfer%20learning%20for%20CV/img/image-20211217110639386.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236965.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236311.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236991.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237180.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237040.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237276.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237200.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237155.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237826.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237436.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237884.png">
<meta property="og:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237944.png">
<meta property="article:published_time" content="2021-08-14T16:00:00.000Z">
<meta property="article:modified_time" content="2022-02-01T04:37:41.703Z">
<meta property="article:author" content="Smurf">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011223255.png">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/combine/npm/highlight.js@9.15.8/styles/atom-one-dark.css,gh/theme-nexmoe/hexo-theme-nexmoe@latest/source/lib/mdui_043tiny/css/mdui.css,gh/theme-nexmoe/hexo-theme-nexmoe@latest/source/lib/iconfont/iconfont.css,gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css?v=233" crossorigin>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css">
  
    <link rel="stylesheet" href="//at.alicdn.com/t/font_2421060_cksn56jaae6.css">
  
  <link rel="stylesheet" href="/css/style.css?v=1644335087698">
  <script type="text/javascript" src="https://cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.js"></script>
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="mdui-drawer-body-left">
  
  <div id="nexmoe-background">
    <div class="nexmoe-bg" style="background-image: url(https://cdn.jsdelivr.net/gh/tangyuxian/blog_image@master/background/xiaomai.jpg)"></div>
    <div class="nexmoe-small" style="background-image: url(https://cdn.jsdelivr.net/gh/tangyuxian/blog_image@master/background/lihui.png)"></div>
    <div class="mdui-appbar mdui-shadow-0">
      <div class="mdui-toolbar">
        <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon mdui-ripple"><i class="mdui-icon nexmoefont icon-menu"></i></a>
        <div class="mdui-toolbar-spacer"></div>
        <!--<a href="javascript:;" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">search</i></a>-->
        <a href="/" title="Smurf" class="mdui-btn mdui-btn-icon"><img src="https://cdn.jsdelivr.net/gh/tangyuxian/blog_image@master/head/head.jpg" alt="Smurf"></a>
       </div>
    </div>
  </div>
  <div id="nexmoe-header">
      <div class="nexmoe-drawer mdui-drawer" id="drawer">
    <div class="nexmoe-avatar mdui-ripple">
        <a href="/" title="Smurf">
            <img src="https://cdn.jsdelivr.net/gh/tangyuxian/blog_image@master/head/head.jpg" alt="Smurf" alt="Smurf">
        </a>
    </div>
    <div class="nexmoe-count">
        <div class="nexmoe-count-item"><span>文章</span>50 <div class="item-radius"></div><div class="item-radius item-right"></div> </div>
        <div class="nexmoe-count-item"><span>标签</span>0<div class="item-radius"></div><div class="item-radius item-right"></div></div>
        <div class="nexmoe-count-item"><span>分类</span>6<div class="item-radius"></div><div class="item-radius item-right"></div></div>
    </div>
    <div class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}">
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页">
            <i class="mdui-list-item-icon nexmoefont icon-meishi"></i>
            <div class="mdui-list-item-content">
                回到首页
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/archives.html" title="文章归档">
            <i class="mdui-list-item-icon nexmoefont icon-hanbao1"></i>
            <div class="mdui-list-item-content">
                文章归档
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/about.html" title="关于糖糖">
            <i class="mdui-list-item-icon nexmoefont icon-jiubei1"></i>
            <div class="mdui-list-item-content">
                关于糖糖
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/friend.html" title="我的朋友">
            <i class="mdui-list-item-icon nexmoefont icon-cola"></i>
            <div class="mdui-list-item-content">
                我的朋友
            </div>
        </a>
        
    </div>
    <aside id="nexmoe-sidebar">
  
  
<!-- 站内搜索 -->

<div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-search" >
        <form id="search-form">
            <label><input type="text" id="local-search-input" name="q" results="0" placeholder="站内搜索" class="input form-control" autocomplete="off" autocorrect="off"/></label>
            <!-- 清空/重置搜索框 -->
            <i class="fa fa-times" onclick="resetSearch()"></i>
        </form>
    </div>
    <div id="local-search-result"></div> <!-- 搜索结果区 -->
    <!-- <p class='no-result'></p> 无匹配时显示，注意在 CSS 中设置默认隐藏 -->
</div>


  
  <div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-social">
        <a class="mdui-ripple" href="http://wpa.qq.com/msgrd?v=3&uin=1250782604&site=qq&menu=yes" target="_blank" mdui-tooltip="{content: 'QQ'}" style="color: rgb(64, 196, 255);background-color: rgba(64, 196, 255, .1);">
            <i class="nexmoefont icon-QQ"></i>
        </a><a class="mdui-ripple" href="mailto:tangyuxian@vip.qq.com" target="_blank" mdui-tooltip="{content: 'mail'}" style="color: rgb(249,8,8);background-color: rgba(249,8,8,.1);">
            <i class="nexmoefont icon-mail-fill"></i>
        </a><a class="mdui-ripple" href="https://www.cnblogs.com/lovetangyuxian/" target="_blank" mdui-tooltip="{content: '博客园'}" style="color: rgb(66, 214, 29);background-color: rgba(66, 214, 29, .1);">
            <i class="nexmoefont icon-bokeyuan"></i>
        </a><a class="mdui-ripple" href="https://github.com/tangyuxian/" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color: rgb(25, 23, 23);background-color: rgba(25, 23, 23, .15);">
            <i class="nexmoefont icon-github"></i>
        </a><a class="mdui-ripple" href="https://gitee.com/tangyuxian" target="_blank" mdui-tooltip="{content: 'gitee'}" style="color: rgb(255, 255, 255);background-color: rgb(199,29,35);">
            <i class="nexmoefont icon-mayun"></i>
        </a>
    </div>
</div>
  
  
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">文章分类</h3>
    <div class="nexmoe-widget">

      <ul class="category-list">

        


        

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/CV/">CV</a>
          <span class="category-list-count">17</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/ImageProcessing/">ImageProcessing</a>
          <span class="category-list-count">2</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/KnowledgeEngineering/">KnowledgeEngineering</a>
          <span class="category-list-count">15</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/blog/">blog</a>
          <span class="category-list-count">1</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/gitskills/">gitskills</a>
          <span class="category-list-count">2</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/nlp/">nlp</a>
          <span class="category-list-count">13</span>
        </li>

        
      </ul>

    </div>
  </div>


  
  
  
  
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">文章归档</h3>
    <div class="nexmoe-widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a><span class="archive-list-count">47</span></li></ul>
    </div>
  </div>


<style>
.nexmoe-widget .archive-list-count{
	position : absolute;
	right: 15px;
	top:9px;
	color: #DDD;
}
</style>

  
</aside>
    <div class="nexmoe-copyright">
        &copy; 2022 Smurf
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
        & <a href="https://github.com/tangyuxian/hexo-theme-tangyuxian" target="_blank">Tangyuxian</a><br/>
        <a href="http://beian.miit.gov.cn" target="_blank">辽ICP备2021002341号</a><br/>
        
        <div style="font-size: 12px">
            <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            本站总访问量  <a id="busuanzi_value_site_pv"></a> 次<br />
            本站访客数<a id="busuanzi_value_site_uv"></a>人次
        </div>
        
        
    </div>

</div><!-- .nexmoe-drawer -->

  </div>
  <div id="nexmoe-content">
    <div class="nexmoe-primary">
        <div class="nexmoe-post">
    
        <div class="nexmoe-post-cover"
             style="padding-bottom: 24.305555555555554%;">
            <img data-src="https://cdn.jsdelivr.net/gh/tangyuxian/blog_image@master/background/xiaomai.jpg" data-sizes="auto" alt="Transfer learning for CV" class="lazyload">
            <h1>Transfer learning for CV</h1>
        </div>
    

        <div class="nexmoe-post-meta nexmoe-rainbow" style="margin:10px 0!important;">
    <a><i class="nexmoefont icon-calendar-fill"></i>2021年08月15日</a>
    <a><i class="nexmoefont icon-areachart"></i>1.6k 字</a>
    <a><i class="nexmoefont icon-time-circle-fill"></i>大概 8 分钟</a>
</div>

        <div class="nexmoe-post-right">
            
                <div class="nexmoe-fixed">
                    <div class="nexmoe-valign">
                        <div class="nexmoe-toc">
                            
                            
                                <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Transfer-learning-for-CV"><span class="toc-number">1.</span> <span class="toc-text">1. Transfer learning for CV</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Why"><span class="toc-number">2.</span> <span class="toc-text">1.1 Why?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Traditional-vs-Transfer-Learning"><span class="toc-number">3.</span> <span class="toc-text">1.2 Traditional vs. Transfer Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-Conservative-Training"><span class="toc-number">4.</span> <span class="toc-text">1.3 Conservative Training</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-Layer-Transfer"><span class="toc-number">5.</span> <span class="toc-text">1.4 Layer Transfer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-Neural-Network-Layers-General-to-Specific"><span class="toc-number">6.</span> <span class="toc-text">1.5 Neural Network Layers: General to Specific</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-6-Multitask-Learning"><span class="toc-number">7.</span> <span class="toc-text">1.6 Multitask Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-7-Progressive-Neural-Networks"><span class="toc-number">8.</span> <span class="toc-text">1.7 Progressive Neural Networks</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Domain-adversarial-training"><span class="toc-number"></span> <span class="toc-text">2. Domain-adversarial training</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Task-description-domain-adaptation"><span class="toc-number">1.</span> <span class="toc-text">2.1 Task description: domain adaptation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Discrepancy-based-approaches"><span class="toc-number">2.</span> <span class="toc-text">2.2 Discrepancy-based approaches</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Adversarial-based-approaches"><span class="toc-number">3.</span> <span class="toc-text">2.3 Adversarial-based approaches</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-Adversarial-based-approaches"><span class="toc-number">4.</span> <span class="toc-text">2.4 Adversarial-based approaches</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-Reconstruction-based-approaches"><span class="toc-number">5.</span> <span class="toc-text">2.5 Reconstruction-based approaches</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-Knowledge-distillation"><span class="toc-number">6.</span> <span class="toc-text">2.6 Knowledge distillation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Self-supervised-learning"><span class="toc-number"></span> <span class="toc-text">3. Self-supervised learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Motivation"><span class="toc-number">1.</span> <span class="toc-text">3.1  Motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Self-supervised-pretext-tasks"><span class="toc-number">2.</span> <span class="toc-text">3.2 Self-supervised pretext tasks</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-Self-supervised-learning-workflow-I"><span class="toc-number">2.1.</span> <span class="toc-text">3.2.1 Self-supervised learning workflow (I)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-Self-supervised-learning-workflow-II"><span class="toc-number">2.2.</span> <span class="toc-text">3.2.2 Self-supervised learning workflow (II)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-3-Self-supervisedvs-unsupervisedlearning"><span class="toc-number">2.3.</span> <span class="toc-text">3.2.3 Self-supervisedvs. unsupervisedlearning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-Self-supervisedvs-Generative-learning"><span class="toc-number">3.</span> <span class="toc-text">3.3 Self-supervisedvs. Generative learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-Types-of-self-supervised-learning"><span class="toc-number">4.</span> <span class="toc-text">3.4 Types of self-supervised learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-Self-Supervision-as-data-prediction"><span class="toc-number">5.</span> <span class="toc-text">3.5 Self-Supervision as data prediction</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-1Colorization"><span class="toc-number">5.1.</span> <span class="toc-text">3.5.1Colorization</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-Self-supervision-by-transformation-prediction"><span class="toc-number">6.</span> <span class="toc-text">3.6 Self-supervision by transformation prediction</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-1-Context-prediction-Details"><span class="toc-number">6.1.</span> <span class="toc-text">3.6.1 Context prediction: Details</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-2-Jigsaw-puzzle-solving"><span class="toc-number">6.2.</span> <span class="toc-text">3.6.2 Jigsaw puzzle solving</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Details"><span class="toc-number">6.3.</span> <span class="toc-text">Details</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-3-Rotation-prediction"><span class="toc-number">6.4.</span> <span class="toc-text">3.6.3 Rotation prediction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-Contrastive-methods"><span class="toc-number">7.</span> <span class="toc-text">3.7 Contrastive methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-8-SimCLR-A-Simple-Framework-for-Contrastive-Learning"><span class="toc-number">8.</span> <span class="toc-text">3.8 SimCLR: A Simple Framework for Contrastive Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-8-1-SimCLRdesign-choices-projection-head"><span class="toc-number">8.1.</span> <span class="toc-text">3.8.1 SimCLRdesign choices: projection head</span></a></li></ol></li></ol>
                            
                        </div>
                    </div>
                </div>
            
        </div>

        <article>
            <p>Transfer learning for CV、self-supervised learning</p>
<span id="more"></span>
<h3 id="1-Transfer-learning-for-CV"><a href="#1-Transfer-learning-for-CV" class="headerlink" title="1. Transfer learning for CV"></a>1. Transfer learning for CV</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011223255.png" alt="image-20211217101408721" class="lazyload"></p>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234434.png" alt="image-20211217095438486" class="lazyload"></p>
<h3 id="1-1-Why"><a href="#1-1-Why" class="headerlink" title="1.1 Why?"></a>1.1 Why?</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234563.png" alt="image-20211217095600777" class="lazyload"></p>
<h3 id="1-2-Traditional-vs-Transfer-Learning"><a href="#1-2-Traditional-vs-Transfer-Learning" class="headerlink" title="1.2 Traditional vs. Transfer Learning"></a>1.2 Traditional vs. Transfer Learning</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234349.png" alt="image-20211217095835039" class="lazyload"></p>
<ul>
<li><p>由源数据学到一些共用的知识，在进行微调</p>
</li>
<li><p>Traditional machine learning:</p>
<ul>
<li>learn a system for a task, respectively</li>
</ul>
</li>
<li><p>Transfer learning:</p>
<ul>
<li>transfer the knowledge form the source model for the target task</li>
</ul>
</li>
<li><p>Task description</p>
</li>
<li>Source data: $(x^s, y^s)$  A large amount</li>
<li>Target data: $(x^t, y^t)$​  Very little<ul>
<li>One-shot learning: only a few examples in target domain</li>
</ul>
</li>
<li>Example: (supervised) speaker adaption<ul>
<li>Source data: audio data and transcriptions from many speakers</li>
<li>Target data: audio data and its transcriptions of specific user</li>
</ul>
</li>
<li>Idea: training a model by source data, then fine-tune the model by target data<ul>
<li>Challenge: only limited target data, so be careful about overfitting</li>
</ul>
</li>
</ul>
<h3 id="1-3-Conservative-Training"><a href="#1-3-Conservative-Training" class="headerlink" title="1.3 Conservative Training"></a>1.3 Conservative Training</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234270.png" alt="image-20211217100456443" class="lazyload"></p>
<ul>
<li>学习率调的很低</li>
</ul>
<h3 id="1-4-Layer-Transfer"><a href="#1-4-Layer-Transfer" class="headerlink" title="1.4 Layer Transfer"></a>1.4 Layer Transfer</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234540.png" alt="image-20211217100528414" class="lazyload"></p>
<ul>
<li>Which layer can be transferred (copied)?<ul>
<li>Speech: usually copy the last few layers</li>
<li>Image: usually copy the first few layers</li>
</ul>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234138.png" alt="image-20211217100601426" class="lazyload"></p>
<h3 id="1-5-Neural-Network-Layers-General-to-Specific"><a href="#1-5-Neural-Network-Layers-General-to-Specific" class="headerlink" title="1.5 Neural Network Layers: General to Specific"></a>1.5 Neural Network Layers: General to Specific</h3><ul>
<li>Bottom/first/earlier layers: general learners<ul>
<li><strong>Low-level notions of edges, visual shapes</strong></li>
</ul>
</li>
<li>Top/last/later layers: specific learners<ul>
<li><strong>High-level features such as eyes, feathers</strong></li>
</ul>
</li>
</ul>
<h3 id="1-6-Multitask-Learning"><a href="#1-6-Multitask-Learning" class="headerlink" title="1.6 Multitask Learning"></a>1.6 Multitask Learning</h3><ul>
<li>The multi-layer structure makes NN suitable for multitask learning<ul>
<li>任务相关则可以共享部分参数</li>
</ul>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234958.png" alt="image-20211217101104901" class="lazyload"></p>
<h3 id="1-7-Progressive-Neural-Networks"><a href="#1-7-Progressive-Neural-Networks" class="headerlink" title="1.7 Progressive Neural Networks"></a>1.7 Progressive Neural Networks</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234993.png" alt="image-20211217101220837" class="lazyload"></p>
<ul>
<li>不考虑任务相关性</li>
<li>只进行特征共享，但是不共享参数</li>
</ul>
<h2 id="2-Domain-adversarial-training"><a href="#2-Domain-adversarial-training" class="headerlink" title="2. Domain-adversarial training"></a>2. Domain-adversarial training</h2><h3 id="2-1-Task-description-domain-adaptation"><a href="#2-1-Task-description-domain-adaptation" class="headerlink" title="2.1 Task description: domain adaptation"></a>2.1 Task description: domain adaptation</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234362.png" alt="image-20211217101502380" class="lazyload"></p>
<ul>
<li>How to remove the domain shift?</li>
<li>How to bridge the domain gap?</li>
<li>The domain can be a general concept:<ul>
<li>Datasets: transfer from an “easy” dataset to a “hard” one</li>
<li>Modalities: transfer from RGB to depth, infrared images, point cloud……</li>
</ul>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011234965.png" alt="image-20211217101627652" class="lazyload"></p>
<ul>
<li>Remove the domain shift</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235410.png" alt="image-20211217101731118" class="lazyload"></p>
<h3 id="2-2-Discrepancy-based-approaches"><a href="#2-2-Discrepancy-based-approaches" class="headerlink" title="2.2 Discrepancy-based approaches"></a>2.2 Discrepancy-based approaches</h3><ul>
<li><p>我们希望两者数据越接近越好，这样在源数据训练可以迁移到目标数据</p>
</li>
<li><p>Idea: minimize the domain distance in a feature space</p>
</li>
<li>Works focus on designing a reasonable distance</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235317.png" alt="image-20211217101914275" class="lazyload"></p>
<ul>
<li>Example: Metric learning based</li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
&D_{t s}^{(m)}\left(\mathcal{X}_{t}, \mathcal{X}_{s}\right)= 
\quad\left\|\frac{1}{N_{l}} \sum_{i=1}^{N_{t}} f^{(m)}\left(\mathbf{x}_{t i}\right)-\frac{1}{N_{s}} \sum_{i=1}^{N_{z}} f^{(m)}\left(\mathbf{x}_{s i}\right)\right\|^{2}
\end{aligned}</script><h3 id="2-3-Adversarial-based-approaches"><a href="#2-3-Adversarial-based-approaches" class="headerlink" title="2.3 Adversarial-based approaches"></a>2.3 Adversarial-based approaches</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235498.png" alt="image-20211217102042921" class="lazyload"></p>
<ul>
<li>我们希望找到一个特征空间可以使他们的特征领域可以混在一起</li>
</ul>
<h3 id="2-4-Adversarial-based-approaches"><a href="#2-4-Adversarial-based-approaches" class="headerlink" title="2.4 Adversarial-based approaches"></a>2.4 Adversarial-based approaches</h3><ul>
<li>Method 1: Domain-adversarial training</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235237.png" alt="image-20211217102311355" class="lazyload"></p>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235574.png" alt="image-20211217102408991" class="lazyload"></p>
<ul>
<li>不同于GAN，GAN的分类器希望能分开fake数据，而对抗学习希望分类器越分不开越好</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235084.png" alt="image-20211217102417938" class="lazyload"></p>
<ul>
<li>所以我们对于domain classifier不能使用梯度下降，而应该使用梯度反向</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235138.png" alt="image-20211217102659257" class="lazyload"></p>
<ul>
<li>Method 2: GAN-based methods</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235858.png" alt="image-20211217103006920" class="lazyload"></p>
<h3 id="2-5-Reconstruction-based-approaches"><a href="#2-5-Reconstruction-based-approaches" class="headerlink" title="2.5 Reconstruction-based approaches"></a>2.5 Reconstruction-based approaches</h3><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235837.png" alt="image-20211217103149535" class="lazyload"></p>
<ul>
<li>The data reconstruction of source or target samples is an auxiliary task that simultaneously focuses on creating a shared representation between the two domains and keeping the individual characteristics of each domain.</li>
</ul>
<h3 id="2-6-Knowledge-distillation"><a href="#2-6-Knowledge-distillation" class="headerlink" title="2.6 Knowledge distillation"></a>2.6 Knowledge distillation</h3><ul>
<li>Distill the knowledge from a larger deep neural network into a small network</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235613.png" alt="image-20211217103249019" class="lazyload"></p>
<ul>
<li>Response-based knowledge<ul>
<li>Use the neural response of the last output layer of the teacher model to transfer.</li>
<li>Directly mimic the final prediction of the teacher model.</li>
<li>Simple yet effective</li>
</ul>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235202.png" alt="image-20211217103307255" class="lazyload"></p>
<ul>
<li><p>大型网络与轻型网络分类越相近，越好</p>
</li>
<li><p>Feature-based knowledge</p>
<ul>
<li>Extend the transfer point from the last layer to intermediate layers</li>
<li>A good extension of response-based knowledge, especially for the training of thinner and deeper networks.</li>
<li>Generalize feature maps to attention maps</li>
</ul>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235279.png" alt="image-20211217103432014" class="lazyload"></p>
<ul>
<li>Relation-based knowledge<ul>
<li>Both response-based and feature-based knowledge use the outputs of specific layers in the teacher model.</li>
<li>Relation-based knowledge further explores the relationships between different layers or data samples.</li>
</ul>
</li>
<li>考虑不同的特征分布</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011235369.png" alt="image-20211217103528450" class="lazyload"></p>
<ul>
<li>Extension: Cross-modal distillation<ul>
<li>The data or labels for some modalities might not beavailable during training or testing</li>
</ul>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236437.png" alt="image-20211217104141848" class="lazyload"></p>
<h2 id="3-Self-supervised-learning"><a href="#3-Self-supervised-learning" class="headerlink" title="3. Self-supervised learning"></a>3. Self-supervised learning</h2><h3 id="3-1-Motivation"><a href="#3-1-Motivation" class="headerlink" title="3.1  Motivation"></a>3.1  Motivation</h3><ul>
<li><p>Recall the idea of transfer learning: start with general-purpose feature representation pre-trained on a large, diverse dataset and adapt it to specialized tasks</p>
</li>
<li><p>Challenge: overcoming reliance on supervised pre-training</p>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236159.png" alt="image-20211217104304133" class="lazyload"></p>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236434.png" alt="image-20211217104341902" class="lazyload"></p>
<h3 id="3-2-Self-supervised-pretext-tasks"><a href="#3-2-Self-supervised-pretext-tasks" class="headerlink" title="3.2 Self-supervised pretext tasks"></a>3.2 Self-supervised pretext tasks</h3><ul>
<li>Self-supervised learning methods solve “pretext” tasks that producegood features for downstream tasks.<ul>
<li>Learn with supervised learning objectives, e.g., classification, regression.</li>
<li>Labels of these pretext tasks are generated automatically</li>
</ul>
</li>
<li>Example: learn to predict image transformations / complete corrupted images</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236731.png" alt="image-20211217104525627" class="lazyload"></p>
<h4 id="3-2-1-Self-supervised-learning-workflow-I"><a href="#3-2-1-Self-supervised-learning-workflow-I" class="headerlink" title="3.2.1 Self-supervised learning workflow (I)"></a>3.2.1 Self-supervised learning workflow (I)</h4><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236530.png" alt="image-20211217105043956" class="lazyload"></p>
<ul>
<li>Learn good feature extractors from self-supervised pretext tasks, e.g., predicting image rotations</li>
</ul>
<h4 id="3-2-2-Self-supervised-learning-workflow-II"><a href="#3-2-2-Self-supervised-learning-workflow-II" class="headerlink" title="3.2.2 Self-supervised learning workflow (II)"></a>3.2.2 Self-supervised learning workflow (II)</h4><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236277.png" alt="image-20211217105152186" class="lazyload"></p>
<ul>
<li>Attach a shallow network on the feature extractor; train the shallow<br>network on the target task with small amount of labeled data</li>
<li>Evaluate the learned feature encoders on downstream target tasks</li>
</ul>
<h4 id="3-2-3-Self-supervisedvs-unsupervisedlearning"><a href="#3-2-3-Self-supervisedvs-unsupervisedlearning" class="headerlink" title="3.2.3 Self-supervisedvs. unsupervisedlearning"></a>3.2.3 Self-supervisedvs. unsupervisedlearning</h4><ul>
<li>The terms are sometimes used interchangeably in the literature, but self-supervised learning is a particular kind ofunsupervised learning</li>
<li><p><strong>Unsupervised learning:</strong> any kind of learning without labels</p>
<ul>
<li>Clustering and quantization</li>
<li>Dimensionality reduction, manifold learning</li>
<li>Density estimation<br>…</li>
</ul>
</li>
<li><p><strong>Self-supervised learning:</strong> the learner “makes up” labels from the data and then solves a supervised task</p>
</li>
</ul>
<h3 id="3-3-Self-supervisedvs-Generative-learning"><a href="#3-3-Self-supervisedvs-Generative-learning" class="headerlink" title="3.3 Self-supervisedvs. Generative learning"></a>3.3 Self-supervisedvs. Generative learning</h3><ul>
<li><p>Both aim to learn from data without manual label annotation.</p>
</li>
<li><p><strong>Generative learning</strong> aims to model data distribution, e.g., generating realistic images.</p>
<ul>
<li>希望能生成和真实越相近越好的图片，更注重细节</li>
</ul>
</li>
<li><p><strong>Self-supervised learning</strong> aims to learn high-level semantic features with pretext tasks</p>
<ul>
<li>只学习高阶语义信息</li>
</ul>
</li>
</ul>
<h3 id="3-4-Types-of-self-supervised-learning"><a href="#3-4-Types-of-self-supervised-learning" class="headerlink" title="3.4 Types of self-supervised learning"></a>3.4 Types of self-supervised learning</h3><ul>
<li>预测遮挡，预测上色，预测未来</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236781.png" alt="image-20211217105924241" class="lazyload"></p>
<ul>
<li>预测拼图</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236320.png" alt="image-20211217110002112" class="lazyload"></p>
<ul>
<li>对比学习</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236211.png" alt="image-20211217110018571" class="lazyload"></p>
<h3 id="3-5-Self-Supervision-as-data-prediction"><a href="#3-5-Self-Supervision-as-data-prediction" class="headerlink" title="3.5 Self-Supervision as data prediction"></a>3.5 Self-Supervision as data prediction</h3><h4 id="3-5-1Colorization"><a href="#3-5-1Colorization" class="headerlink" title="3.5.1Colorization"></a>3.5.1Colorization</h4><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236473.png" alt="image-20211217110111322" class="lazyload"></p>
<ul>
<li><p>要考虑固有颜色的歧义性，只要上色会在自然界出现，就不判错</p>
</li>
<li><p>Colorization: Training data generation</p>
<ul>
<li>数据灰度化</li>
</ul>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236855.png" alt="image-20211217110200700" class="lazyload"></p>
<ul>
<li>用ab作为监督信息</li>
<li>对ab空间进行量化，从而预测一个分布，最终考虑到了颜色的歧义性</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236579.png" alt="image-20211217110310161" class="lazyload"></p>
<h3 id="3-6-Self-supervision-by-transformation-prediction"><a href="#3-6-Self-supervision-by-transformation-prediction" class="headerlink" title="3.6 Self-supervision by transformation prediction"></a>3.6 Self-supervision by transformation prediction</h3><ul>
<li>Pretext task:randomly sample a patch and one of 8 neighbors，Guess the spatial relationship between the patches</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236931.png" alt="image-20211217110648572" class="lazyload"></p>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="img/image-20211217110639386.png" alt="image-20211217110639386" class="lazyload"></p>
<h4 id="3-6-1-Context-prediction-Details"><a href="#3-6-1-Context-prediction-Details" class="headerlink" title="3.6.1 Context prediction: Details"></a>3.6.1 Context prediction: Details</h4><ul>
<li>切割时留有gap，防止学到这些边缘</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236965.png" alt="image-20211217111005476" class="lazyload"></p>
<h4 id="3-6-2-Jigsaw-puzzle-solving"><a href="#3-6-2-Jigsaw-puzzle-solving" class="headerlink" title="3.6.2 Jigsaw puzzle solving"></a>3.6.2 Jigsaw puzzle solving</h4><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236311.png" alt="image-20211217111210571" class="lazyload"></p>
<ul>
<li>不同于预测位置，而是考虑九个块整体的一个顺序</li>
</ul>
<h4 id="Details"><a href="#Details" class="headerlink" title="Details"></a>Details</h4><ul>
<li>防止过拟合，只考虑64种组合，其hamming loss较大</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011236991.png" alt="image-20211217111411606" class="lazyload"></p>
<h4 id="3-6-3-Rotation-prediction"><a href="#3-6-3-Rotation-prediction" class="headerlink" title="3.6.3 Rotation prediction"></a>3.6.3 Rotation prediction</h4><ul>
<li>Pretext task: recognize image rotation (0, 90, 180, 270 degrees)</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237180.png" alt="image-20211217111451479" class="lazyload"></p>
<ul>
<li>During training, feed in all four rotated versions of an image in the same mini-batch</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237040.png" alt="image-20211217111502032" class="lazyload"></p>
<h3 id="3-7-Contrastive-methods"><a href="#3-7-Contrastive-methods" class="headerlink" title="3.7 Contrastive methods"></a>3.7 Contrastive methods</h3><ul>
<li>Encourage representations of transformed versions of the same image to be the same and different images to be different<ul>
<li>希望同种信息越相近越好，不同种数据越不相近越好</li>
</ul>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237276.png" alt="image-20211217111650163" class="lazyload"></p>
<ul>
<li>Encourage representations of transformed versions of the same image to be the same and different images to be different</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237200.png" alt="image-20211217111745082" class="lazyload"></p>
<ul>
<li>Given: query point $x$, positive samples $x^{+}$, negative samples $x^{-}$<ul>
<li>Positives are typically transformed versions of $x$, negatives are random examples from the same mini-batch or memory bank</li>
</ul>
</li>
<li>Key idea: learn representation to make $x$ similar to $x^{+}$, dissimilar from $x^{-}$(similarity is measured by dot product of normalized features)</li>
<li>Given 1 positive sample and $N$ - 1 negative samples, Contrastive loss:</li>
</ul>
<script type="math/tex; mode=display">
l\left(x, x^{+}\right)=-\log \frac{\exp \left(f(x)^{T} f\left(x^{+}\right) / \tau\right)}{\frac{\exp \left(f(x)^{T} f\left(x^{+}\right) / \tau\right)}{\text { Score for the positive }}+\frac{\sum_{j=1}^{N} \exp \left(f(x)^{T} f\left(x_{j}^{-}\right) / \tau\right)}{\text { pair }}}</script><ul>
<li>This seems familiar as cross entropy loss for a N-way Softmaxclassifier!<br>Try to find the positive samples from the Nsamples.</li>
<li>$\tau$​​ is the <strong>temperature hyperparameter</strong>(determines how concentrated the softmaxis)</li>
<li>我们希望温度参数越小越好，这样预测越集中</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237155.png" alt="image-20211217112207576" class="lazyload"></p>
<h3 id="3-8-SimCLR-A-Simple-Framework-for-Contrastive-Learning"><a href="#3-8-SimCLR-A-Simple-Framework-for-Contrastive-Learning" class="headerlink" title="3.8 SimCLR: A Simple Framework for Contrastive Learning"></a>3.8 SimCLR: A Simple Framework for Contrastive Learning</h3><ul>
<li><p>Generate positive samples through data augmentation.</p>
</li>
<li><p>Use a projection network 𝒉𝒉(·)to project features to a space where contrastive learning is applied</p>
</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237826.png" alt="image-20211217112348651" class="lazyload"></p>
<ul>
<li>SimCLR：Evaluation</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237436.png" alt="image-20211217112414759" class="lazyload"></p>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237884.png" alt="image-20211217113153614" class="lazyload"></p>
<ul>
<li>Train feature encoder on <strong>ImageNet</strong> (entire training set)<br>using SimCLR.</li>
<li>Freeze feature encoder, train a linear classifier on top with<br>labeled data.</li>
</ul>
<h4 id="3-8-1-SimCLRdesign-choices-projection-head"><a href="#3-8-1-SimCLRdesign-choices-projection-head" class="headerlink" title="3.8.1 SimCLRdesign choices: projection head"></a>3.8.1 SimCLRdesign choices: projection head</h4><p><img data-fancybox="gallery" data-sizes="auto" data-src="https://gitee.com/zhu-qipeng/blogImage/raw/master/blogImage/202202011237944.png" alt="image-20211217113314855" class="lazyload"></p>
<ul>
<li>Linear / non-linear projection heads improve representation learning.<br>A possible explanation:<ul>
<li>representation space 𝒛𝒛is trained to be invariant to data transformation</li>
<li>contrastive learning objective may discard useful information for downstream tasks</li>
<li>by leveraging the projection head 𝒈(ᐧ), more information can be preserved in the 𝒉 representation space</li>
</ul>
</li>
</ul>

        </article>

        
            
  <div class="nexmoe-post-copyright">
    <strong>本文作者：</strong>Smurf<br>
    
    <strong>本文链接：</strong><a href="http://example.com/2021/08/15/cv/13.%20Transfer%20learning%20for%20CV/" title="http:&#x2F;&#x2F;example.com&#x2F;2021&#x2F;08&#x2F;15&#x2F;cv&#x2F;13.%20Transfer%20learning%20for%20CV&#x2F;" target="_blank" rel="noopener">http:&#x2F;&#x2F;example.com&#x2F;2021&#x2F;08&#x2F;15&#x2F;cv&#x2F;13.%20Transfer%20learning%20for%20CV&#x2F;</a><br>

    
      <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可
    
  </div>


        

        <div class="nexmoe-post-meta nexmoe-rainbow">
    
        <a class="nexmoefont icon-appstore-fill -link" href="/categories/CV/">CV</a>
    
    
</div>

    <div class="nexmoe-post-footer">
        <section class="nexmoe-comment">
    <div class="valine"></div>
<script src='https://cdn.jsdelivr.net/npm/valine@1.3.9/dist/Valine.min.js'></script>
<script>
    // 使用方法 https://valine.js.org/quickstart.html
    new Valine({
        el: '.valine',
        appId: 'r5zxC0st0DDjPA9auXzMV7HY-gzGzoHsz',
        appKey: '3bqCsovpyfTPHUzTHovd3V3V'
    })
</script>
</section>
    </div>
</div>


        <div class="nexmoe-post-right">
          
            <div class="nexmoe-fixed">
              <div class="nexmoe-tool">
                <a href="#" aria-label="回到顶部" title="top"><button class="mdui-fab mdui-ripple"><i class="nexmoefont icon-caret-top"></i></button></a>
              </div>
            </div>
          
        </div>
    </div>
  </div>
  <div id="nexmoe-pendant">
    <div class="nexmoe-drawer mdui-drawer nexmoe-pd" id="drawer">
        
            <div class="nexmoe-pd-item">
                <div class="clock">
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="memory"></div>
        <div class="needle" id="hours"></div>
        <div class="needle" id="minutes"></div>
        <div class="needle" id="seconds"></div>
        <div class="clock_logo">

        </div>

    </div>
<style>
    .clock {
        background-color: #ffffff;
        width: 70vw;
        height: 70vw;
        max-width: 70vh;
        max-height: 70vh;
        border: solid 2.8vw #242424;
        position: relative;
        overflow: hidden;
        border-radius: 50%;
        box-sizing: border-box;
        box-shadow: 0 1.4vw 2.8vw rgba(0, 0, 0, 0.8);
        zoom:0.2
    }

    .memory {
        position: absolute;
        top: 50%;
        left: 50%;
        transform-origin: center;
    }

    .memory:nth-child(1) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(0deg) translateY(-520%);
    }

    .memory:nth-child(2) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(6deg) translateY(-1461%);
    }

    .memory:nth-child(3) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(12deg) translateY(-1461%);
    }

    .memory:nth-child(4) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(18deg) translateY(-1461%);
    }

    .memory:nth-child(5) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(24deg) translateY(-1461%);
    }

    .memory:nth-child(6) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(30deg) translateY(-520%);
    }

    .memory:nth-child(7) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(36deg) translateY(-1461%);
    }

    .memory:nth-child(8) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(42deg) translateY(-1461%);
    }

    .memory:nth-child(9) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(48deg) translateY(-1461%);
    }

    .memory:nth-child(10) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(54deg) translateY(-1461%);
    }

    .memory:nth-child(11) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(60deg) translateY(-520%);
    }

    .memory:nth-child(12) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(66deg) translateY(-1461%);
    }

    .memory:nth-child(13) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(72deg) translateY(-1461%);
    }

    .memory:nth-child(14) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(78deg) translateY(-1461%);
    }

    .memory:nth-child(15) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(84deg) translateY(-1461%);
    }

    .memory:nth-child(16) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(90deg) translateY(-520%);
    }

    .memory:nth-child(17) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(96deg) translateY(-1461%);
    }

    .memory:nth-child(18) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(102deg) translateY(-1461%);
    }

    .memory:nth-child(19) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(108deg) translateY(-1461%);
    }

    .memory:nth-child(20) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(114deg) translateY(-1461%);
    }

    .memory:nth-child(21) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(120deg) translateY(-520%);
    }

    .memory:nth-child(22) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(126deg) translateY(-1461%);
    }

    .memory:nth-child(23) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(132deg) translateY(-1461%);
    }

    .memory:nth-child(24) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(138deg) translateY(-1461%);
    }

    .memory:nth-child(25) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(144deg) translateY(-1461%);
    }

    .memory:nth-child(26) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(150deg) translateY(-520%);
    }

    .memory:nth-child(27) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(156deg) translateY(-1461%);
    }

    .memory:nth-child(28) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(162deg) translateY(-1461%);
    }

    .memory:nth-child(29) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(168deg) translateY(-1461%);
    }

    .memory:nth-child(30) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(174deg) translateY(-1461%);
    }

    .memory:nth-child(31) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(180deg) translateY(-520%);
    }

    .memory:nth-child(32) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(186deg) translateY(-1461%);
    }

    .memory:nth-child(33) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(192deg) translateY(-1461%);
    }

    .memory:nth-child(34) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(198deg) translateY(-1461%);
    }

    .memory:nth-child(35) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(204deg) translateY(-1461%);
    }

    .memory:nth-child(36) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(210deg) translateY(-520%);
    }

    .memory:nth-child(37) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(216deg) translateY(-1461%);
    }

    .memory:nth-child(38) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(222deg) translateY(-1461%);
    }

    .memory:nth-child(39) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(228deg) translateY(-1461%);
    }

    .memory:nth-child(40) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(234deg) translateY(-1461%);
    }

    .memory:nth-child(41) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(240deg) translateY(-520%);
    }

    .memory:nth-child(42) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(246deg) translateY(-1461%);
    }

    .memory:nth-child(43) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(252deg) translateY(-1461%);
    }

    .memory:nth-child(44) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(258deg) translateY(-1461%);
    }

    .memory:nth-child(45) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(264deg) translateY(-1461%);
    }

    .memory:nth-child(46) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(270deg) translateY(-520%);
    }

    .memory:nth-child(47) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(276deg) translateY(-1461%);
    }

    .memory:nth-child(48) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(282deg) translateY(-1461%);
    }

    .memory:nth-child(49) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(288deg) translateY(-1461%);
    }

    .memory:nth-child(50) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(294deg) translateY(-1461%);
    }

    .memory:nth-child(51) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(300deg) translateY(-520%);
    }

    .memory:nth-child(52) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(306deg) translateY(-1461%);
    }

    .memory:nth-child(53) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(312deg) translateY(-1461%);
    }

    .memory:nth-child(54) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(318deg) translateY(-1461%);
    }

    .memory:nth-child(55) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(324deg) translateY(-1461%);
    }

    .memory:nth-child(56) {
        background-color: #424242;
        width: 2%;
        height: 8%;
        transform: translate(-50%, -50%) rotate(330deg) translateY(-520%);
    }

    .memory:nth-child(57) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(336deg) translateY(-1461%);
    }

    .memory:nth-child(58) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(342deg) translateY(-1461%);
    }

    .memory:nth-child(59) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(348deg) translateY(-1461%);
    }

    .memory:nth-child(60) {
        background-color: #949494;
        width: 1%;
        height: 3%;
        transform: translate(-50%, -50%) rotate(354deg) translateY(-1461%);
    }

    .needle {
        position: absolute;
        top: 50%;
        left: 50%;
        transform-origin: center;
    }

    .needle#hours {
        background-color: #1f1f1f;
        width: 4%;
        height: 30%;
        transform-origin: center 75%;
        transform: translate(-50%, -75%);
    }

    .needle#hours.moving {
        transition: transform 150ms ease-out;
    }

    .needle#hours:after {
        content: '';
        background-color: #1f1f1f;
        width: 4vw;
        height: 4vw;
        max-width: 4vh;
        max-height: 4vh;
        display: block;
        position: absolute;
        top: 75%;
        left: 50%;
        box-sizing: border-box;
        border-radius: 50%;
        transform: translate(-50%, -50%);
    }

    .needle#minutes {
        background-color: #1f1f1f;
        width: 2%;
        height: 45%;
        transform-origin: center 75%;
        transform: translate(-50%, -75%);
    }

    .needle#minutes.moving {
        transition: transform 150ms ease-out;
    }

    .needle#minutes:after {
        content: '';
        background-color: #1f1f1f;
        width: 4vw;
        height: 4vw;
        max-width: 4vh;
        max-height: 4vh;
        display: block;
        position: absolute;
        top: 75%;
        left: 50%;
        box-sizing: border-box;
        border-radius: 50%;
        transform: translate(-50%, -50%);
    }

    .needle#seconds {
        background-color: #cb2f2f;
        width: 1%;
        height: 50%;
        transform-origin: center 75%;
        transform: translate(-50%, -75%);
    }

    .needle#seconds.moving {
        transition: transform 150ms ease-out;
    }

    .needle#seconds:after {
        content: '';
        background-color: #cb2f2f;
        width: 2.5vw;
        height: 2.5vw;
        max-width: 2.5vh;
        max-height: 2.5vh;
        display: block;
        position: absolute;
        top: 75%;
        left: 50%;
        box-sizing: border-box;
        border-radius: 50%;
        transform: translate(-50%, -50%);
    }
    .clock_logo{
        width: 10vw;
        height: 10vw;
        max-width: 10vh;
        max-height: 10vh;
        position: absolute;
        top: 50%;
        left: 50%;
        box-sizing: border-box;
        border-radius: 50%;
        transform: translate(-50%, -50%);
        background-size: 100% 100%;
        background-repeat: no-repeat;
    }
    @media (min-width: 100vh) {
        .clock {
            border: solid 2.8vh #242424;
            box-shadow: 0 1.4vh 2.8vh rgba(0, 0, 0, 0.8);
        }
    }

</style>





            </div>
        
            <div class="nexmoe-pd-item">
                <div class="qweather" >
    <div id="he-plugin-standard"></div>
    <div class="qweather-logo">

    </div>

</div>
<style>
    .qweather{
        position: relative;
    }
    .qweather-logo{
        position: absolute;
        right: 0;
        top: -15px;
        width: 40px;
        height: 40px;
        background-size: 100% 100%;
        background-repeat: no-repeat;
    }
</style>
<script>
  WIDGET = {
    "CONFIG": {
      "layout": "2",
      "width": "260",
      "height": "220",
      "background": "5",
      "dataColor": "e67249",
      "borderRadius": "15",
      "key": "f74d1e1690e6432d801e97fa2f05a162"
    }
  }
</script>
<script src="https://widget.qweather.net/standard/static/js/he-standard-common.js?v=2.0"></script>

            </div>
        
</div>
<style>
    .nexmoe-pd {
        left: auto;
        top: 40px;
        right: 0;
    }
    .nexmoe-pd-item{
       display: flex;
        justify-content: center;
        margin-bottom: 30px;
    }
</style>

  </div>
  <script src="https://cdn.jsdelivr.net/combine/npm/lazysizes@5.1.0/lazysizes.min.js,gh/highlightjs/cdn-release@9.15.8/build/highlight.min.js,npm/mdui@0.4.3/dist/js/mdui.min.js?v=1"></script>
<script>
	hljs.initHighlightingOnLoad();
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>


<script src="/js/app.js?v=1644335087700"></script>

<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js"></script>
<script>
	$(".justified-gallery").justifiedGallery({
		rowHeight: 160,
		margins: 10,
	});
</script>

  





<!-- hexo injector body_end start -->
<script src="/js/clock.js"></script>

<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script>

<script src="/lib/codeBlock/codeBlockFuction.js"></script>

<script src="/lib/codeBlock/codeLang.js"></script>

<script src="/lib/codeBlock/codeCopy.js"></script>

<script src="/lib/codeBlock/codeShrink.js"></script>

<link rel="stylesheet" href="/lib/codeBlock/matery.css">

<script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.js"></script>

<script src="/js/search.js"></script>

<script src="/js/webapp.js"></script>
<!-- hexo injector body_end end --></body>
</html>

<script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/250cb4aa.js","daovoice")</script>
<script>
  daovoice('init', {
    app_id: "250cb4aa"
  });
  daovoice('update');
</script>

