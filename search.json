[{"title":"blog tutorio","url":"/2022/02/08/blog_tutorio/","content":"hexo build up\n\n\né€šè¿‡Hexoåœ¨Githubä¸Šæ­å»ºåšå®¢æ•™ç¨‹ - ç®€ä¹¦ (jianshu.com)\nhexoå²ä¸Šæœ€å…¨æ­å»ºæ•™ç¨‹_Fangzhçš„æŠ€æœ¯åšå®¢-CSDNåšå®¢_hexo\n\n","categories":["blog"]},{"title":"CNN","url":"/2021/08/15/cv/11.%20CNN/","content":"CNN\n\n1. Why CNN for Image?\nå‚æ•°è¿‡å¤šï¼Œæˆ‘ä»¬å¯ä»¥å‡å°‘å…¨è¿æ¥ç¥ç»å…ƒã€å…±äº«å‚æ•°ã€å·ç§¯\n\n\n\nSome patterns are much smaller than the whole image\nç¥ç»å…ƒä¸éœ€è¦çœ‹æ•´å¼ å›¾ç‰‡ï¼Œè€Œåªéœ€è¦çœ‹ä¸€å°éƒ¨åˆ†\n\n\n\n\n\nThe same patterns appear in different regions.\nå¯¹äºé‡å¤å‡ºç°çš„æ¨¡å¼å¯ä»¥å…±äº«å‚æ•°\n\n\n\n\n\nSubsampling the pixels will not change the object\né™é‡‡æ ·ä¸å½±å“å›¾åƒè¯­ä¹‰\n\n\n\n\n\nWe can subsample the pixels to make image smaller\nLess parameters for the network to process the image\n\n\n\n1.2 The whole CNN\n\n\n\nå·ç§¯æ˜¯å±€éƒ¨åŒºåŸŸçš„åŠ æƒå’Œï¼Œåšå·ç§¯æ—¶å¤§å°ç›¸åŒå°±å…±äº«å‚æ•°äº†\nè€Œmaxpoolingç›¸å½“äºé™é‡‡æ ·\n\n1.3  CNN Convolution\n\nç”±äºè¿‡äºä¸€ä¸ªè¾“å‡ºé€šé“çš„å·ç§¯æ ¸éƒ½å¯ä»¥å­¦ä¹ ä¸€ç§æ¨¡å¼ï¼Œè¿™ç›¸å½“äºå°±æ˜¯å…±äº«å‚æ•°\n\n\n\nDo the same process for every filter\n\n\n\nCNN Zero Padding\n\n\n\nCNN Colorful image\n\n\n\nConvolution v.s. Fully Connected\nå‡å°‘äº†å¾ˆå¤šå‚æ•°\nè¾“å‡ºå¤šä¸ªfeature mapï¼Œè¯´æ˜å…¶å¢åŠ æ›´å¤šçš„éçº¿æ€§å˜æ¢ï¼Œå¢å¼ºç½‘ç»œçš„è¡¨å¾èƒ½åŠ›\n\n\n\n\n\nCNN Max Pooling\n\n\n\nå¢åŠ éçº¿æ€§ï¼Œä»¥åŠå‡å°‘å‚æ•°\n\n\n\n\nFlatten\nConvolutional Neural Network\nWhat does CNN learn?\nWhat is the essential difficulty?\næ·±åº¦å­¦ä¹ è§£å†³è¯­ä¹‰é¸¿æ²Ÿï¼šæå–é«˜é˜¶è¯­ä¹‰æ¨¡å¼ã€ä¸å—å…‰ç…§ã€æ—‹è½¬ç­‰å½±å“\n\n\nWhat can CNN do for computer vision?Before deep learning was born\nFeature extraction example #1\nFeature name: Local Binary Pattern (LBP)\n\nUse center pixel value to threshold the 3x3 neighborhood\n\nResult in binary number\n\nHistogram of the labels is used as a texture descriptor\n\n\n\nFeature extraction example #2\nFeature name: Scale invariant feature transform (SIFT)\n\nDivide the 16x16 window into a 4x4 grid of cells\n\nCompute an orientation histogram for each cell\n\n16 cells x 8 orientations = 128 dimensional descriptor\n\n\n\nWhatâ€™s wrong with traditional features?\n\nImage classification with deep learning\nFour typical image classification nets\nImage classification with deep learning\nAlexNet\n\n\n\n\nCharacters of AlexNet\nTrained by two GPUs\n\nData augmentation\n\nClipping / flipping / â€¦\n\nUsing ReLU rather than sigmoid function\n\nOverlapped pooling\n\nDropout in full connection layers\n\n\n\nVGG\n\n\n\nQ: Why use smaller filters? (3x3 conv)\n\n\n\nå¤§çš„å·ç§¯æ ¸å¯ä»¥åˆ†è§£æˆå°çš„å·ç§¯æ ¸ï¼Œç½‘ç»œåŠ æ·±ï¼Œè·å¾—æ›´å¤§æ„Ÿå—é‡ï¼Œå‡å°‘å‚æ•°ï¼Œé€Ÿåº¦åŠ å¿«\nä¸¤ä¸ªconv 33 ç›¸å½“äº5\\5ï¼Œä¸‰ä¸ªç›¸å½“äº7*7ï¼Œï¼ˆ2*3+1ï¼‰\n\nGoogLENet\n\n\n\n\nå°ºåº¦ä¿¡æ¯æ›´ä¸°å¯Œï¼Œé˜²æ­¢ä¸¢å¤±ä¿¡æ¯\nå¢åŠ æ¯ä¸€å±‚å­¦åˆ°çš„æ¨¡å¼\n\n\n\n\nWhy not going much deeper?\n\n\n\n\nResNet\nå­¦ä¹ åˆ°çš„å‡½æ•°å˜ä¸ºæ®‹å·®ï¼šF(x)-x\n\n\n\n\n\n\nç“¶é¢ˆæ®‹å·®å—ï¼šä½¿å¾—è®¡ç®—é‡å˜å°‘\n\n\n\nå¥½å¤„ï¼šä¿è¯å‰å‘ä¿¡æ¯ä¼ æ’­çš„æµç•…æ€§ã€å…¶æ¬¡ä¿è¯æ¢¯åº¦å›ä¼ çš„ç¨³å®šæ€§\n\n\nFrom classification to segmentation\n\nConverting the segmentation problem to classification\næŠŠä¸€ä¸ªçª—å£æ‰£æˆå°å—å»å·ç§¯\n\n\n\n\n\nåˆ—ä¸¾æ‰€æœ‰æ»‘åŠ¨çª—å£å»å·ç§¯åˆ†ç±»\nè¿™æ ·ä¼šå¯¼è‡´å‚æ•°çˆ†ç‚¸\n\n\n\n\nDownsampling and Upsampling\n\nå…ˆä¸‹é‡‡æ ·ï¼Œä½¿å¾—å‚æ•°å˜å°‘ï¼Œå†ä¸Šé‡‡æ ·è¿˜åŸåˆ†ç±»ç»“æœ\n\nReview: Unpooling\n\nè®°ä½poolingçš„æ‰€æœ‰ä½ç½®ï¼Œç„¶ååpoolingï¼Œé™¤äº†æœ€å¤§å€¼çš„ä½ç½®ï¼Œå…¶ä»–æ ‡ä¸ºé›¶\n\n\n\n\n\nReview: Deconvolution\næœ«å°¾è¡¥é›¶å³å¯\n\n\n\n\nObject detection\n\nPredict bounding boxes, class labels, and confidence scores\nFor each detection, determine whether it is true or false\n\nBasic idea to detection: Sliding windows\n\n\n\né€šè¿‡è®¾è®¡ä¸€äº›åˆ¤æ–­çš„å‡†åˆ™ï¼Œæ‰¾ä¸€äº›ç½®ä¿¡åº¦æœ€é«˜çš„æ¡†ä¿ç•™ä¸‹æ¥\n\n\nR-CNN: Region proposals + CNN features\nRegional-based Convolutional Neural Network (R-CNN)\n\n\n\n\nFast R-CNN\n\n\nRoI pooling goal\nâ€œCrop and resampleâ€ a fixed size feature representing a region of interest out of the feature map\n\nUse nearest neighbor interpolation of coordinates, max pooling\n\næŠŠåŸå§‹å›¾ç‰‡çš„å€™é€‰æ¡†æ˜ å°„åˆ°feature mapä¸Šå»\n\n\n\n\nFor each RoI , predicts probabilities for c+1 classes (with background) and four bounding box offsets for c classes\n\n\nFast R-CNN training\nBounding box regression\nFaster R CNN\n\nSlide a small window (3x3) over the conv5 layer\nPredict object/no object\nRegress bounding box coordinates with reference to anchors (3 scales x 3 aspect ratios)\n\n\nä¸€å¼€å§‹æ˜¯è°ƒæ•´æ¯ä¸ªå€™é€‰æ¡†ï¼Œè€Œæœ€åæ˜¯åªå¯¹ä¸€äº›æ¡†è¿›è¡Œè®¡ç®—loss\n\n\n\nYOLOStreamlined detection architectures\nThe Faster R CNN pipeline separates proposal generation and regionclassification:\n\n\n\nIs it possible do detection in one shot?\n\n\n\nIdea: No bounding box proposals. Predict a class and a box for every location in a grid.\n\n\n\n\nDivide the image into 7x7 cells.\nEach cell trains a detector.\nThe detector needs to predict the objectâ€™s class distributions.\nThe detector also predicts bounding boxes and confidencescores.\n\nObjective function\n\nä¸ºäº†è®©å°çš„æ¡†çš„é•¿å®½å¯¹lossçš„å½±å“æ›´å¤§ä¸€ç‚¹\n\n\n\n\n\nLocalization accuracy suffers compared to Fast(er) R CNN due to coarser features, errors on small boxes\n7x speedup over Faster R CNN (45 155 FPS vs. 7 18 FPS)\n\n\n","categories":["CV"]},{"title":"review","url":"/2021/08/15/cv/14.%20review/","content":"review\n\n1.  Course Outline\n2.  What is computer vision\nComputer vision is a field of artificial intelligence (AI)that enables computers and systems to derive meaningful information from digital images, videos and other visual inputs â€”and take actions or make recommendations based on that information.   â€”IBM\nåˆ©ç”¨è®¡ç®—æœºç³»ç»Ÿä»æ•°å­—å›¾åƒã€è§†é¢‘å’Œå…¶ä»–å¯è§†åŒ–è¾“å…¥æå–æœ‰æ„ä¹‰çš„ä¿¡æ¯ï¼Œå¹¶åŸºäºè¿™äº›ä¿¡æ¯åšå‡ºå†³ç­–\n\n\n\nKey point 1: human visual system\nèƒ½å¤Ÿæ¨¡æ‹Ÿäºº\nåŒç›®-&gt;ä¸‰ç»´é‡æ„\nå¤šå°ºåº¦ç‰¹æ€§-&gt;sift\næ³¨æ„åŠ›æœºåˆ¶-&gt;opç®—æ³•ã€ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶FCNN\nå¹¶è¡Œå¤„ç†-&gt;å¤šå°ºåº¦å¤šç‰¹å¾èåˆ\n\n\nPhilosophies learn from the human visual system for computer vision systems.\nHierarchical :Multi-scale fusion\nMeaning\n\n\nApplications:\nHandcrafted features, e.g., SIFT, HOG..â€¦.\nDeep learning architectures, e.g., segmentationâ€¦.\n\n\nAttention mechanism\nMeaning\nApplications: various CNNs\n\n\n\n3. Key point 2: computer vision system (CVS)\nç³»ç»Ÿåˆ†æ\n\nRelated domain knowledge when you construct a CVS.Examples: a self-driving system, a video surveillance systemâ€¦â€¦\n\nå¤©æ°”é¢„æŠ¥\n\näº‘å›¾ï¼šæ ¹æ®å›¾åƒä»¥åŠè¿‡å¾€å¤©æ°”é¢„æµ‹æœªæ¥å¤©æ°”ã€ç”¨åˆ°å›¾åƒå¤„ç†ã€ä¿¡æ¯ã€å¤©æ°”å­¦ã€æ·±åº¦å­¦ä¹ \n\n\n\n\n4. Key point 3: CVS in our daily lives\näººè„¸è¯†åˆ«ï¼šVGmodel RCNN \nè€—æ—¶ã€å‡†ç¡®ç‡ä½\n\n\næŒ‡çº¹è¯†åˆ«ã€èº«ä»½è¯è¯†åˆ«\n\nVarious applications\n\nåˆ†æè®¡ç®—æœºè§†è§‰åº”ç”¨ï¼Œåˆ†æç®—æ³•ä¼˜åŠ£\n\n\n\n5. Key point 4: challenges\nAnalyze the challenges with real-life CV systems\n\n\n\nå°ºåº¦ï¼šå°ºåº¦é‡‘å­—å¡”\nå…‰çº¿ï¼šè¾¹ç¼˜ã€è§’ç‚¹\nåˆ’å½’ä¸ºcellï¼Œå¢åŠ å…‰ç…§é²æ£’æ€§\n\n\nè§†è§’\né®æŒ¡ï¼šç‰¹å¾ç‚¹æ£€æµ‹ã€å±€éƒ¨ç‰¹å¾åº”å¯¹é®æŒ¡\nå½¢å˜ï¼šåˆ†å¼€è€ƒè™‘\n\n\n6. Image filtering\nå¹³æ»‘æ»¤æ³¢ç§»é™¤é«˜é¢‘ç‰¹å¾\né«˜æ–¯æ»¤æ³¢ï¼šé«˜æ–¯æ ¸å¯åˆ†ï¼Œé™ä½è®¡ç®—é‡\n\nä¸¤ä¸ªçš„$\\sigma$å…³ç³»\n\n\nè¡¥é›¶å…³ç³»\n\nComputing\n\nProperties:\n\nRemove â€œhigh-frequencyâ€ components from the image\nConvolution with self is another Gaussian\nSo can smooth with small-Ïƒ kernel, repeat, and get same result as larger-Ïƒ kernel would have\nConvolving two times with Gaussian kernel with std. dev. Ïƒ is same as convolving once with kernel with std. dev. Ïƒâˆš2\n\n\nSeparable kernel\nFactors into product of two 1D Gaussians\n\n\nPadding on the edge: methods and problems\nWhat is the complexity of filtering an nÃ—nimage with an mÃ—mkernel?\nWhat if the kernel is separable?\nO(n2m2)\nO(n2m)\n\n\n\n\n\n\n\n6.2 Key point 2: Separability\n6.3 Key point 3: Image filtering -noise\nSalt and pepper noise:Contains random occurrencesof black and white pixels\nImpulse noise:Contains random occurrencesof white pixels\nGaussian noise:Variations in intensity drawn from a Gaussian normal distribution\n\n\n\nä¸­å€¼æ»¤æ³¢åˆ©äºå¤„ç†æ¤’ç›å™ªå£°ï¼Œå®¹æ˜“æ»¤å»è¿‡ä½æˆ–è¿‡é«˜çš„å¼‚å¸¸å€¼\nåˆ©äºä¿æŠ¤è¾¹ç¼˜\nä¸å¥½æ˜¯éçº¿æ€§ã€ä¸èƒ½å†™æˆå·ç§¯\n\n\né«˜æ–¯æ»¤æ³¢åˆ©äºå»é™¤é«˜æ–¯å™ªå£°\nå¯èƒ½ä¼šæŠŠè¾¹ç¼˜æ¨¡ç³Šæ‰\n\n\n\n\n6.4 Key point 4: Sharpening\nUnderstand the process and parameter influence\nWhat does blurring take away?\n\n\n\n\n\nLetâ€™s add it back:\n\n\n7. Edge detection7.1 Key point 1: Image gradient\n7.2 Key point 2: Edge filters\nDesign philosophy and their functions\n\nCompute\n\n\n\n7.3 Key point 3: Canny edge detector\nSteps and their motivations\n\nParameter choice and reasons\n\n\n\nFilter image with derivative of Gaussian\nFind magnitude and orientation of gradient\nNon-maximum suppression:-Thin wide â€œridgesâ€ down to single pixel width\nLinking and thresholding (hysteresis):-Define two thresholds: low and high-Use the high threshold to start edge curves and the low threshold to continue them\n\n8. Local features -corner8.1 Key point 1: Corner Detection -Basic Idea\nWe should easily recognize the point by looking through a small window\nShifting a window in any direction should give a large change in intensity\n\n8.2 Key point 1: Harris detector\n\n\nStep3: Compute corner response function R and judge it is a corner or edge or â€¦.\n\n8.3 Key point 2: Harris detector â€“Properties\n9.1 Key point 1: Scale space/SIFT\n9.2 Key point 4: HOG -steps and motivations\næ€ä¹ˆç®—\n\nBlocks and cells:\n\nEach block contains 2Ã—2 cells\nEach cell is with 8Ã—8 pixels\nEach blockï¼š16Ã—16 pixels\nNeighboring blocks are with 50% overlap.\nFor a 64Ã—128 image, it cantains7Ã—15 = 105 blocks in total\n\n\n\n\n9.3 Key point 5: HOG for Detection\nå·ç§¯ã€hogç‰¹å¾ã€ä¸‰ç»´\n10. Key point 1: RANSAC for line fitting\n\n\n\nå‚æ•°é€‰æ‹©\n\n\n11. K-means: pros and cons\n\nNormalized cutï¼šä¸ºä»€ä¹ˆä¸ä¸€æ ·\n\n\n\nKey point 1: Viola-Jones face detector\n\nVisual vocabularies: Issues\nHow to choose vocabulary size?â€¢Too small: visual words not representative of all patchesâ€¢Too large: quantization artifacts, overfittingâ€¢Why BOW?â€¢Efficiencyâ€¢BOW have been useful in matching an image to a large database\n\n\n\nKey point 2: Pedestrian detection with HOG\n\nTrain a pedestrian template using a linear support vector machine\n\nAt test time, convolve feature map with template\nFind local maxima of response\nFor multi-scale detection, repeat over multiple levels of a HOG pyramid\n\n\nStrengthsWorks very well for non deformable objects with canonical orientations: faces, cars, pedestriansFast detectionWeaknessesNot so well for highly deformable objects or â€œstuffâ€Not robust to occlusionRequires lots of training data\nMotion and Tracking\nKey point 1: Optical flow\n2D transformations\n\n\n\n6ä¸ªè‡ªç”±åº¦\nCamera model World\n\n\n\n\n\n\n\n\nç›®æ ‡æ£€æµ‹ï¼šä¼ ç»Ÿæ–¹æ³•ã€ç°åœ¨æ–¹æ³•\nRCNNæ¼”å˜è¿‡ç¨‹ï¼ŒåŒºåˆ«ï¼Œç›®çš„ï¼Œä¸ºä»€ä¹ˆæ›´å¿«äº†\n\n\n\ntransfer learning\n\n","categories":["CV"]},{"title":"Transfer learning for CV","url":"/2021/08/15/cv/13.%20Transfer%20learning%20for%20CV/","content":"Transfer learning for CVã€self-supervised learning\n\n1. Transfer learning for CV\n\n1.1 Why?\n1.2 Traditional vs. Transfer Learning\n\nç”±æºæ•°æ®å­¦åˆ°ä¸€äº›å…±ç”¨çš„çŸ¥è¯†ï¼Œåœ¨è¿›è¡Œå¾®è°ƒ\n\nTraditional machine learning:\n\nlearn a system for a task, respectively\n\n\nTransfer learning:\n\ntransfer the knowledge form the source model for the target task\n\n\nTask description\n\nSource data: $(x^s, y^s)$  A large amount\nTarget data: $(x^t, y^t)$â€‹  Very little\nOne-shot learning: only a few examples in target domain\n\n\nExample: (supervised) speaker adaption\nSource data: audio data and transcriptions from many speakers\nTarget data: audio data and its transcriptions of specific user\n\n\nIdea: training a model by source data, then fine-tune the model by target data\nChallenge: only limited target data, so be careful about overfitting\n\n\n\n1.3 Conservative Training\n\nå­¦ä¹ ç‡è°ƒçš„å¾ˆä½\n\n1.4 Layer Transfer\n\nWhich layer can be transferred (copied)?\nSpeech: usually copy the last few layers\nImage: usually copy the first few layers\n\n\n\n\n1.5 Neural Network Layers: General to Specific\nBottom/first/earlier layers: general learners\nLow-level notions of edges, visual shapes\n\n\nTop/last/later layers: specific learners\nHigh-level features such as eyes, feathers\n\n\n\n1.6 Multitask Learning\nThe multi-layer structure makes NN suitable for multitask learning\nä»»åŠ¡ç›¸å…³åˆ™å¯ä»¥å…±äº«éƒ¨åˆ†å‚æ•°\n\n\n\n\n1.7 Progressive Neural Networks\n\nä¸è€ƒè™‘ä»»åŠ¡ç›¸å…³æ€§\nåªè¿›è¡Œç‰¹å¾å…±äº«ï¼Œä½†æ˜¯ä¸å…±äº«å‚æ•°\n\n2. Domain-adversarial training2.1 Task description: domain adaptation\n\nHow to remove the domain shift?\nHow to bridge the domain gap?\nThe domain can be a general concept:\nDatasets: transfer from an â€œeasyâ€ dataset to a â€œhardâ€ one\nModalities: transfer from RGB to depth, infrared images, point cloudâ€¦â€¦\n\n\n\n\n\nRemove the domain shift\n\n\n2.2 Discrepancy-based approaches\næˆ‘ä»¬å¸Œæœ›ä¸¤è€…æ•°æ®è¶Šæ¥è¿‘è¶Šå¥½ï¼Œè¿™æ ·åœ¨æºæ•°æ®è®­ç»ƒå¯ä»¥è¿ç§»åˆ°ç›®æ ‡æ•°æ®\n\nIdea: minimize the domain distance in a feature space\n\nWorks focus on designing a reasonable distance\n\n\n\nExample: Metric learning based\n\n\n\\begin{aligned}\n&D_{t s}^{(m)}\\left(\\mathcal{X}_{t}, \\mathcal{X}_{s}\\right)= \n\\quad\\left\\|\\frac{1}{N_{l}} \\sum_{i=1}^{N_{t}} f^{(m)}\\left(\\mathbf{x}_{t i}\\right)-\\frac{1}{N_{s}} \\sum_{i=1}^{N_{z}} f^{(m)}\\left(\\mathbf{x}_{s i}\\right)\\right\\|^{2}\n\\end{aligned}2.3 Adversarial-based approaches\n\næˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ä¸€ä¸ªç‰¹å¾ç©ºé—´å¯ä»¥ä½¿ä»–ä»¬çš„ç‰¹å¾é¢†åŸŸå¯ä»¥æ··åœ¨ä¸€èµ·\n\n2.4 Adversarial-based approaches\nMethod 1: Domain-adversarial training\n\n\n\n\nä¸åŒäºGANï¼ŒGANçš„åˆ†ç±»å™¨å¸Œæœ›èƒ½åˆ†å¼€fakeæ•°æ®ï¼Œè€Œå¯¹æŠ—å­¦ä¹ å¸Œæœ›åˆ†ç±»å™¨è¶Šåˆ†ä¸å¼€è¶Šå¥½\n\n\n\næ‰€ä»¥æˆ‘ä»¬å¯¹äºdomain classifierä¸èƒ½ä½¿ç”¨æ¢¯åº¦ä¸‹é™ï¼Œè€Œåº”è¯¥ä½¿ç”¨æ¢¯åº¦åå‘\n\n\n\nMethod 2: GAN-based methods\n\n\n2.5 Reconstruction-based approaches\n\nThe data reconstruction of source or target samples is an auxiliary task that simultaneously focuses on creating a shared representation between the two domains and keeping the individual characteristics of each domain.\n\n2.6 Knowledge distillation\nDistill the knowledge from a larger deep neural network into a small network\n\n\n\nResponse-based knowledge\nUse the neural response of the last output layer of the teacher model to transfer.\nDirectly mimic the final prediction of the teacher model.\nSimple yet effective\n\n\n\n\n\nå¤§å‹ç½‘ç»œä¸è½»å‹ç½‘ç»œåˆ†ç±»è¶Šç›¸è¿‘ï¼Œè¶Šå¥½\n\nFeature-based knowledge\n\nExtend the transfer point from the last layer to intermediate layers\nA good extension of response-based knowledge, especially for the training of thinner and deeper networks.\nGeneralize feature maps to attention maps\n\n\n\n\n\nRelation-based knowledge\nBoth response-based and feature-based knowledge use the outputs of specific layers in the teacher model.\nRelation-based knowledge further explores the relationships between different layers or data samples.\n\n\nè€ƒè™‘ä¸åŒçš„ç‰¹å¾åˆ†å¸ƒ\n\n\n\nExtension: Cross-modal distillation\nThe data or labels for some modalities might not beavailable during training or testing\n\n\n\n\n3. Self-supervised learning3.1  Motivation\nRecall the idea of transfer learning: start with general-purpose feature representation pre-trained on a large, diverse dataset and adapt it to specialized tasks\n\nChallenge: overcoming reliance on supervised pre-training\n\n\n\n\n3.2 Self-supervised pretext tasks\nSelf-supervised learning methods solve â€œpretextâ€ tasks that producegood features for downstream tasks.\nLearn with supervised learning objectives, e.g., classification, regression.\nLabels of these pretext tasks are generated automatically\n\n\nExample: learn to predict image transformations / complete corrupted images\n\n\n3.2.1 Self-supervised learning workflow (I)\n\nLearn good feature extractors from self-supervised pretext tasks, e.g., predicting image rotations\n\n3.2.2 Self-supervised learning workflow (II)\n\nAttach a shallow network on the feature extractor; train the shallownetwork on the target task with small amount of labeled data\nEvaluate the learned feature encoders on downstream target tasks\n\n3.2.3 Self-supervisedvs. unsupervisedlearning\nThe terms are sometimes used interchangeably in the literature, but self-supervised learning is a particular kind ofunsupervised learning\nUnsupervised learning: any kind of learning without labels\n\nClustering and quantization\nDimensionality reduction, manifold learning\nDensity estimationâ€¦\n\n\nSelf-supervised learning: the learner â€œmakes upâ€ labels from the data and then solves a supervised task\n\n\n3.3 Self-supervisedvs. Generative learning\nBoth aim to learn from data without manual label annotation.\n\nGenerative learning aims to model data distribution, e.g., generating realistic images.\n\nå¸Œæœ›èƒ½ç”Ÿæˆå’ŒçœŸå®è¶Šç›¸è¿‘è¶Šå¥½çš„å›¾ç‰‡ï¼Œæ›´æ³¨é‡ç»†èŠ‚\n\n\nSelf-supervised learning aims to learn high-level semantic features with pretext tasks\n\nåªå­¦ä¹ é«˜é˜¶è¯­ä¹‰ä¿¡æ¯\n\n\n\n3.4 Types of self-supervised learning\né¢„æµ‹é®æŒ¡ï¼Œé¢„æµ‹ä¸Šè‰²ï¼Œé¢„æµ‹æœªæ¥\n\n\n\né¢„æµ‹æ‹¼å›¾\n\n\n\nå¯¹æ¯”å­¦ä¹ \n\n\n3.5 Self-Supervision as data prediction3.5.1Colorization\n\nè¦è€ƒè™‘å›ºæœ‰é¢œè‰²çš„æ­§ä¹‰æ€§ï¼Œåªè¦ä¸Šè‰²ä¼šåœ¨è‡ªç„¶ç•Œå‡ºç°ï¼Œå°±ä¸åˆ¤é”™\n\nColorization: Training data generation\n\næ•°æ®ç°åº¦åŒ–\n\n\n\n\n\nç”¨abä½œä¸ºç›‘ç£ä¿¡æ¯\nå¯¹abç©ºé—´è¿›è¡Œé‡åŒ–ï¼Œä»è€Œé¢„æµ‹ä¸€ä¸ªåˆ†å¸ƒï¼Œæœ€ç»ˆè€ƒè™‘åˆ°äº†é¢œè‰²çš„æ­§ä¹‰æ€§\n\n\n3.6 Self-supervision by transformation prediction\nPretext task:randomly sample a patch and one of 8 neighborsï¼ŒGuess the spatial relationship between the patches\n\n\n\n3.6.1 Context prediction: Details\nåˆ‡å‰²æ—¶ç•™æœ‰gapï¼Œé˜²æ­¢å­¦åˆ°è¿™äº›è¾¹ç¼˜\n\n\n3.6.2 Jigsaw puzzle solving\n\nä¸åŒäºé¢„æµ‹ä½ç½®ï¼Œè€Œæ˜¯è€ƒè™‘ä¹ä¸ªå—æ•´ä½“çš„ä¸€ä¸ªé¡ºåº\n\nDetails\né˜²æ­¢è¿‡æ‹Ÿåˆï¼Œåªè€ƒè™‘64ç§ç»„åˆï¼Œå…¶hamming lossè¾ƒå¤§\n\n\n3.6.3 Rotation prediction\nPretext task: recognize image rotation (0, 90, 180, 270 degrees)\n\n\n\nDuring training, feed in all four rotated versions of an image in the same mini-batch\n\n\n3.7 Contrastive methods\nEncourage representations of transformed versions of the same image to be the same and different images to be different\nå¸Œæœ›åŒç§ä¿¡æ¯è¶Šç›¸è¿‘è¶Šå¥½ï¼Œä¸åŒç§æ•°æ®è¶Šä¸ç›¸è¿‘è¶Šå¥½\n\n\n\n\n\nEncourage representations of transformed versions of the same image to be the same and different images to be different\n\n\n\nGiven: query point $x$, positive samples $x^{+}$, negative samples $x^{-}$\nPositives are typically transformed versions of $x$, negatives are random examples from the same mini-batch or memory bank\n\n\nKey idea: learn representation to make $x$ similar to $x^{+}$, dissimilar from $x^{-}$(similarity is measured by dot product of normalized features)\nGiven 1 positive sample and $N$ - 1 negative samples, Contrastive loss:\n\n\nl\\left(x, x^{+}\\right)=-\\log \\frac{\\exp \\left(f(x)^{T} f\\left(x^{+}\\right) / \\tau\\right)}{\\frac{\\exp \\left(f(x)^{T} f\\left(x^{+}\\right) / \\tau\\right)}{\\text { Score for the positive }}+\\frac{\\sum_{j=1}^{N} \\exp \\left(f(x)^{T} f\\left(x_{j}^{-}\\right) / \\tau\\right)}{\\text { pair }}}\nThis seems familiar as cross entropy loss for a N-way Softmaxclassifier!Try to find the positive samples from the Nsamples.\n$\\tau$â€‹â€‹ is the temperature hyperparameter(determines how concentrated the softmaxis)\næˆ‘ä»¬å¸Œæœ›æ¸©åº¦å‚æ•°è¶Šå°è¶Šå¥½ï¼Œè¿™æ ·é¢„æµ‹è¶Šé›†ä¸­\n\n\n3.8 SimCLR: A Simple Framework for Contrastive Learning\nGenerate positive samples through data augmentation.\n\nUse a projection network ğ’‰ğ’‰(Â·)to project features to a space where contrastive learning is applied\n\n\n\n\nSimCLRï¼šEvaluation\n\n\n\n\nTrain feature encoder on ImageNet (entire training set)using SimCLR.\nFreeze feature encoder, train a linear classifier on top withlabeled data.\n\n3.8.1 SimCLRdesign choices: projection head\n\nLinear / non-linear projection heads improve representation learning.A possible explanation:\nrepresentation space ğ’›ğ’›is trained to be invariant to data transformation\ncontrastive learning objective may discard useful information for downstream tasks\nby leveraging the projection head ğ’ˆ(á§), more information can be preserved in the ğ’‰ representation space\n\n\n\n","categories":["CV"]},{"title":"Edge Detection","url":"/2021/08/15/cv/3.1%20Edge%20Detection/","content":"Edge Detection\n\nConvolution1. calculate\n\nMeaning\nä¿å­˜ä¸å˜\n\n\n\nå‘å³ç§»åŠ¨\n\n\n\nå¹³æ»‘\n\n\n\nå›¾åƒé”åŒ–\n\n\n\n\nSharpening filter: Accentuates differences with local average \né”åŒ–è¿‡æ»¤å™¨ï¼šçªå‡ºä¸å±€éƒ¨å¹³å‡å€¼çš„å·®å¼‚\n\n\n\n\nè®¡ç®—ç»“æœå¤§å°\npadding\nzero â€œpaddingâ€\n\nedge value replication\n\nmirror extension\n\nmore (beyond the scope of this\n\n\nSmoothing with box filter revisited\nä½¿ç”¨å¹³æ»‘æ»¤æ³¢å™¨ä¼šå¯¼è‡´è¾¹ç¼˜æ¶ˆå¤±\nä¸ºäº†æ¶ˆé™¤è¾¹ç¼˜æ•ˆåº”ï¼Œå¯¹é‚»åŸŸçš„æƒé‡è´¡çŒ®ï¼Œæ ¹æ®åƒç´ ä¸ä¸­å¿ƒçš„æ¥è¿‘ç¨‹åº¦ç¡®å®šåƒç´ ã€‚\n\n\nGaussian Kernel\n\nè®°å¾—å½’ä¸€åŒ–ï¼Œä¸€èˆ¬æ¥è¯´$\\sigma$çš„å¤§å°å†³å®šäº†é«˜æ–¯æ ¸çš„å¤§å°ï¼Œæ‰€ä»¥æ ‡å‡†å·®ğœ: ç¡®å®šå¹³æ»‘çš„èŒƒå›´\nä½œç”¨ï¼šä»å›¾åƒä¸­åˆ é™¤â€œé«˜é¢‘â€åˆ†é‡ï¼ˆä½é€šæ»¤æ³¢å™¨ï¼‰\n\nä¸è‡ªèº«çš„å·ç§¯æ˜¯å¦ä¸€ç§é«˜æ–¯å‡½æ•°\n\næ‰€ä»¥å¯ä»¥ç”¨å°çš„å¹³æ»‘ğœå†…æ ¸ï¼Œé‡å¤ä¸è‡ªèº«å·ç§¯ï¼Œå¯ä»¥å¾—åˆ°å’Œå¤§å·ç§¯æ ¸å·ç§¯ç›¸åŒçš„ç»“æœ\nå·ç§¯ä¸¤æ¬¡çš„é«˜æ–¯æ ¸ç›¸å½“äºæ ‡å‡†å·®å˜ä¸º$\\frac{\\sigma}{\\sqrt{2}}$â€‹\n\n\n\nSeparable kernel\n2Dé«˜æ–¯æ ¸å…·æœ‰å¯åˆ†æ€§ï¼Œå¯ä»¥åˆ†ä¸ºä¸¤ä¸ªä¸€ç»´å·ç§¯æ ¸\n\n\nG(x, y)=\\frac{1}{2 \\pi \\sigma^{2}} \\exp ^{-\\frac{x^{2}+y^{2}}{2 \\sigma^{2}}}=\\left(\\frac{1}{2 \\pi \\sigma} \\exp ^{-\\frac{x^{2}}{2 \\sigma^{2}}}\\right)\\left(\\frac{1}{2 \\pi \\sigma} \\exp ^{-\\frac{y^{2}}{2 \\sigma^{2}}}\\right)\n\nWhat is the complexity of filtering an $ğ‘›Ã—ğ‘›$ image with an $ğ‘šÃ—ğ‘š$â€‹â€‹ kernel?\n$O(n^2m^2)$\nWhat if the kernel is separable?\n$O(n^2m)$\n\n(Cross) correlation\nProperties\nCommutative property:\nf * * h=h * * f\nAssociative property:\n\\left(f * * h_{1}\\right) * * h_{2}=f * *\\left(h_{1} * * h_{2}\\right)\nDistributive property:\nf * *\\left(h_{1}+h_{2}\\right)=\\left(f * * h_{1}\\right)+\\left(f * * h_{2}\\right)\nThe order doesnâ€™t matter! $\\quad h_{1}   h_{2}=h_{2}   h_{1}$\n\nShift property:\n\nf[n, m] * * \\delta_{2}\\left[n-n_{0}, m-m_{0}\\right]=f\\left[n-n_{0}, m-m_{0}\\right]\nShift-invariance:\n\n\n\\begin{gathered}\ng[n, m]=f[n, m] * h[n, m] \\\\\n\\Longrightarrow f\\left[n-l_{1}, m-l_{1}\\right] * h\\left[n-l_{2}, m-l_{2}\\right] \\\\\n=g\\left[n-l_{1}-l_{2}, m-l_{1}-l_{2}\\right]\n\\end{gathered}Convolution vs. (Cross) Correlation\nA convolution is an integral that expresses the amount of overlap of one function as it is shifted over another function.\nconvolution is a filtering operation\n\n\nCorrelation compares the similarity of two sets of data. Correlation computes a measure of similarity of two input signals as they are shifted by one another. The correlation result reaches a maximum at the time when the two signals match best.\ncorrelation is a measure of relatedness of two signals\n\n\n\nEdge Detection1. Edges1.1 Def\nsignificant local changes of intensity (discontinuities) in an image. å›¾åƒä¸­å¼ºåº¦çš„æ˜¾ç€å±€éƒ¨å˜åŒ–ï¼ˆä¸è¿ç»­æ€§ï¼‰\n\n1.2 Origins of edges\ndiscontinuity in depth æ·±åº¦ä¸è¿ç»­\nsurface normal/color/texture discontinuity è¡¨é¢æ³•çº¿\\é¢œè‰²\\çº¹ç†ä¸è¿ç»­\nspecularity /shadows ç”±äºå…‰ç…§çš„é˜´å½±\n\n2. Image gradient2.1 The gradient of an image\n\\nabla f=\\left[\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}\\right]\n\\theta=\\tan ^{-1}\\left(\\frac{\\partial f}{\\partial y} / \\frac{\\partial f}{\\partial x}\\right)\n\\|\\nabla f\\|=\\sqrt{\\left(\\frac{\\partial f}{\\partial x}\\right)^{2}+\\left(\\frac{\\partial f}{\\partial y}\\right)^{2}}\n\næ¢¯åº¦å‚ç›´äºå›¾ç‰‡è¾¹ç¼˜\n\n\n3. Effects of noise\n\nå¦‚æœä¿¡å·ä¸­æœ‰å™ªå£°ï¼Œè¾¹ç¼˜çš„ç‰¹å¾å¯èƒ½ä¼šæ·¹æ²¡åœ¨å™ªå£°ä¸­ï¼Œä»è€Œæ— æ³•é€šè¿‡æ±‚æ¢¯åº¦çš„æ–¹æ³•ï¼Œå¯¹è¾¹ç¼˜è¿›è¡Œå®šä½ã€‚\næ‰€ä»¥ï¼Œå®é™…ä¸Šæˆ‘ä»¬ç»å¸¸å…ˆå¯¹ä¿¡å·åšå¹³æ»‘å¤„ç†ï¼Œç„¶åå†æ±‚å¯¼ã€‚\n\n\n4. Sobel Operator4.1 ç®—æ³•ä»‹ç»\nUses two 3 3Ã—3 kernels which are convolved with the original image to calculate approximations of the derivatives\nOne for horizontal changes, and one for vertical\n\n\n\\mathbf{G}_{x}=\\left[\\begin{array}{ccc}\n+1 & 0 & -1 \\\\\n+2 & 0 & -2 \\\\\n+1 & 0 & -1\n\\end{array}\\right] \\quad \\mathbf{G}_{y}=\\left[\\begin{array}{ccc}\n+1 & +2 & +1 \\\\\n0 & 0 & 0 \\\\\n-1 & -2 & -1\n\\end{array}\\right]\nSmoothing + differentiationï¼šå¹³æ»‘å¤„ç†ï¼‹å¾®åˆ†\n\n\n\\begin{aligned}\n&\\mathbf{G}_{x}=\\left[\\begin{array}{ccc}\n+1 & 0 & -1 \\\\\n+2 & 0 & -2 \\\\\n+1 & 0 & -1\n\\end{array}\\right]=\\left[\\begin{array}{l}\n1 \\\\\n2 \\\\\n1\n\\end{array}\\right]\\left[\\begin{array}{lll}\n+1 & 0 & -1\n\\end{array}\\right]\\\\\n&\\text { Gaussian smoothing differentiation }\n\\end{aligned}\nä¹‹æ‰€ä»¥$[1 2 1]^t$å¯ä»¥çœ‹ä½œä¸ºé«˜æ–¯æ ¸ï¼Œè¿™æ˜¯å› ä¸ºå…¶æ•°å€¼å‘ˆç°ç±»ä¼¼é«˜æ–¯åˆ†å¸ƒçš„æ•ˆæœï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æ•°å­¦æ‰‹æ®µéªŒè¯ã€‚\n\nMagnitude: æ¨¡å€¼\n\n\n\n\\mathbf{G}=\\sqrt{\\mathbf{G}_{x}^{2}+\\mathbf{G}_{y}^{2}}\nAngle or direction of the gradient: æ–¹å‘\n\n\n\\Theta=\\operatorname{atan}\\left(\\frac{\\mathbf{G}_{y}}{\\mathbf{G}_{x}}\\right)4.2 Sobel Filter Problems\n\nPoor Localization (Trigger response in multiple adjacent pixels)ï¼šå®šä½ä¸å¤Ÿå‡†ç¡®ï¼Œè¾¹ç¼˜å¯èƒ½å¾ˆç²—\nThresholding value favors certain directions over others\nCan miss oblique edges more than horizontal or vertical edges å¯èƒ½ä¸¢å¤±é™¤äº†æ°´å¹³ä»¥åŠå‚ç›´çš„è¾¹ç¼˜\nFalse negatives æœ€ç»ˆé€ æˆæŠŠè¾¹ç¼˜è¯†åˆ«ä¸ºä¸æ˜¯è¾¹ç¼˜\n\n\n\n4.3 Other approximations of derivative filters4.3.1 Prewitt:\nG_{x}=\\left[\\begin{array}{lll}\n-1 & 0 & 1 \\\\\n-1 & 0 & 1 \\\\\n-1 & 0 & 1\n\\end{array}\\right] \\quad G_{y}=\\left[\\begin{array}{ccc}\n1 & 1 & 1 \\\\\n0 & 0 & 0 \\\\\n-1 & -1 & -1\n\\end{array}\\right]\\\né™¤äº†è€ƒè™‘ä¸­å¿ƒåƒç´ å·¦å³é‚»è¿‘çš„åƒç´ å€¼ï¼Œè¿˜è€ƒè™‘äº†å…¶å¯¹è§’çš„é¢†åŸŸåƒç´ ã€‚\n\n4.3.2 Roberts:\nG_{x}=\\left[\\begin{array}{cc}\n0 & 1 \\\\\n-1 & 0\n\\end{array}\\right] \\quad G_{y}=\\left[\\begin{array}{cc}\n1 & 0 \\\\\n0 & -1\n\\end{array}\\right]\n$G_x$ç”¨äºæ£€æµ‹135Â°çš„è¾¹ç¼˜ï¼Œ$G_y$ç”¨äºæ£€æµ‹45Â°çš„è¾¹ç¼˜ã€‚\n\n5. Canny edge detector\nThis is probably the most widely used edge detector in computer vision\n\n5.1 Derivative of Gaussian filter\n\\frac{d}{d x}(f * g)=f * \\frac{d}{d x} g\nå¯¹äºé«˜æ–¯å¹³æ»‘æ ¸è€Œè¨€æ‰€æœ‰å…ƒç´ éƒ½æ˜¯æ­£çš„ï¼Œå¯¹äºé«˜æ–¯åå¯¼æ ¸è€Œè¨€æœ‰å¯èƒ½å­˜åœ¨éæ­£çš„å…ƒç´ ã€‚\n\nå¯¹äºé«˜æ–¯å¹³æ»‘æ ¸è€Œè¨€ï¼Œå…¶å…ƒç´ ä¹‹å’Œä¸º1ï¼›å¯¹äºé«˜æ–¯åå¯¼æ ¸è€Œè¨€ï¼Œå…¶æ‰€æœ‰å…ƒç´ ä¹‹å’Œä¸º0ï¼ˆå¥‡å‡½æ•°ï¼‰ã€‚\n\n\n5.2 Problems of Gaussian filter5.2.3 ç»†èŠ‚è¿‡å¤š\n\næˆ‘ä»¬å¯ä»¥å‘ç°é«˜æ–¯åå¯¼æ ¸å¯èƒ½æ£€æµ‹å‡ºè®¸å¤šæˆ‘ä»¬ä¸éœ€è¦çš„ç»†èŠ‚ã€‚æ‰€ä»¥æˆ‘ä»¬å°è¯•å°†é«˜æ–¯åå¯¼æ ¸çš„ç»“æœå†è¾“å…¥ä¸€ä¸ªé˜ˆå€¼æ ¸ï¼ˆTresholdingb Kernelï¼‰ï¼Œæ»¤å»ä¸ç”¨çš„è¾¹ç¼˜ã€‚\n\n5.2.4 è¾¹ç¼˜è¿‡ç²—\n\n\nè¿™æ˜¯å› ä¸ºï¼Œæˆ‘ä»¬åŸæœ¬çš„è¾¹ç¼˜å–çš„æ˜¯æ¢¯åº¦çš„æœ€å¤§å€¼ï¼Œä½†æ˜¯é˜ˆå€¼çš„æ–¹æ³•å–çš„æ˜¯é˜ˆå€¼ä»¥ä¸Šçš„æ•´ä¸ªéƒ¨åˆ†ã€‚\n\n\n5.2.5 Non-maximum suppression\nä¸ºäº†è§£å†³è¾¹ç¼˜è¿‡ç²—çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨Non-maximumçš„æ–¹æ³•ï¼š\n\n\n\næ²¿ç€è¾¹ç¼˜çš„æ¢¯åº¦æ–¹å‘ï¼Œæ¯æ¬¡è®°å½•é‚»è¿‘åƒç´ æœ€å¤§çš„ä¸€ä¸ªå€¼ï¼Œä¸€èˆ¬åœ°ï¼Œå¦‚æœå½“å‰åƒç´ æ¢¯åº¦æ–¹å‘ä¸å­˜åœ¨é‚»è¿‘åƒç´ ï¼Œåˆ™è€ƒè™‘ç”¨åƒç´ æ’å€¼åœ°æ–¹æ³•ï¼Œå……å½“å…¶é‚»è¿‘åƒç´ ã€‚æœ€ç»ˆä½¿å¾—æ•´ä¸ªè¾¹ç¼˜çš„å®½åº¦ä¸º1\n\n\n5.2.6 è¾¹ç¼˜æ¶ˆå¤±ï¼ˆFN problemï¼‰\n5.2.7 Hysteresis thresholding\nAvoid streaking near threshold value é¿å…åœ¨é˜ˆå€¼é™„è¿‘çš„è¾¹ç¼˜ä¸¢å¤±\n\nDefine two thresholds: Low and High\n\nIf less than Low, not an edge\n\nIf greater than High, strong edge\n\nIf between Low and High, weak edge\n\n\n\n\n\né¦–å…ˆèƒ½å¤Ÿæ£€æµ‹å‡ºå¼ºè¾¹ç¼˜çš„åƒç´ ï¼Œä»¥åŠå¼±è¾¹ç¼˜çš„åƒç´ ï¼š\n\næ¥ç€ï¼Œæˆ‘ä»¬è®©å¼ºè¾¹ç¼˜çš„åƒç´ ä¸æ–­ä¸å‘¨å›´åƒç´ è¿›è¡Œæ¯”è¾ƒï¼Œæ€»æ˜¯å–æœ€æ¥è¿‘çš„é‚»å±…è¿›è¡Œå»¶ç”³ï¼›åŒç†ï¼Œå¼±è¾¹ç¼˜ä¹Ÿè¿›è¡Œå»¶ç”³ï¼Œè‹¥å¼ºè¾¹ç¼˜æœ€ç»ˆå¯ä»¥å’Œå¼ºè¾¹ç¼˜è¿æ¥èµ·æ¥ï¼Œåˆ™ä¿ç•™è¯¥å¼±è¾¹ç¼˜ï¼Œåä¹‹åˆ™å¿½ç•¥è¯¥å¼±è¾¹ç¼˜ã€‚\n\n\n5.3 Summary\nFilter image with ğ‘¥,ğ‘¦derivatives of Gaussian ä½¿ç”¨x,yæ–¹å‘çš„é«˜æ–¯åå¯¼æ ¸è¿›è¡Œæ»¤æ³¢\nFind magnitude and orientation of gradient æ‰¾åˆ°è¾¹ç¼˜çš„æ¢¯åº¦å¤§å°ä»¥åŠæ¢¯åº¦æ–¹å‘\nNon maximum suppression:\nThin multi pixel wide ridges down to single pixel width å°†å¤šåƒç´ çš„è¾¹ç¼˜é™è‡³å•åƒç´ \n\n\nThresholding and linking (hysteresis): è®¾ç½®é«˜ä½é˜ˆå€¼ï¼Œæ»¤å»ä¸å¿…è¦çš„ç»†èŠ‚åŒæ—¶ï¼Œä¿ç•™é˜ˆå€¼é™„è¿‘åŠä»¥ä¸Šçš„è¾¹ç¼˜\nDefine two thresholds: low and high\nUse the high threshold to start edge curves and the low threshold to continue them\n\n\n\n\n5.4 Effect of $\\sigma$ Gaussian kernel spread/size)\n\n\n$\\sigma$è¶Šå°ï¼Œçª—å£è¶Šå°ï¼ˆç”±äº$3\\sigma$åŸåˆ™ï¼‰ï¼Œèƒ½æ£€æµ‹å‡ºæ›´å¤šçš„ç»†èŠ‚ï¼Œé€‚åˆäººè„¸æ£€æµ‹ï¼›\n$\\sigma$è¶Šå¤§ï¼Œçª—å£è¶Šå¤§ï¼ˆç”±äº$3\\sigma$â€‹åŸåˆ™ï¼‰ï¼Œèƒ½æ£€æµ‹å‡ºæ›´å°‘çš„ç»†èŠ‚ï¼Œæ›´æ³¨é‡æ•´ä½“è½®å»“ï¼Œé€‚åˆè¡Œäººæ£€æµ‹ã€‚\n\n5.4 Concluding remarks\nAdvantages:\nConceptually simple. æ¦‚å¿µç®€å•\nEasy implementation æ˜“äºå®æ–½\nHandles missing and occluded data very gracefully. æ˜“äºè§£å†³ç¼ºå¤±å€¼\nCan be adapted to many types of forms, not just lines å¯ä»¥é€‚åº”å¤šç§å½¢å¼\n\n\nDisadvantages:\nComputationally complex for objects with many parameters. å‚æ•°è¿‡å¤šï¼Œè®¡ç®—å¤æ‚\nLooks for only one single type of object \nCan be â€œfooledâ€ by â€œapparent linesâ€.  å¯èƒ½è¢«â€œæ˜æ˜¾çš„çº¿æ¡â€è¿·æƒ‘ï¼Œæ¯”å¦‚å…±çº¿\nThe length and the position of a line segment cannot be determined.\nCo linear line segments cannot be separated.\n\n\n\n","categories":["CV"]},{"title":"Seam Carving","url":"/2021/08/15/cv/3.3%20Seam%20Carving/","content":"Seam Carving\n\n1. DefProblem statement:\n\nInput Image $ğ¼_{ğ‘›Ã—ğ‘š}$ and new size ğ‘›â€²Ã—ğ‘šâ€²\n\nOutput Image ğ¼â€²of size ğ‘›â€²Ã—ğ‘šâ€²which will be â€œ good representative â€ of the original image ğ¼\nå³ï¼šå¯¹å›¾åƒè¿›è¡Œç¼©æ”¾çš„åŒæ—¶å¸Œæœ›è¾“å‡ºå›¾åƒå¯¹å†…å®¹æœ‰å¥½çš„å±•ç¤º\n\n\n2. General Retargeting Framework\n\nAssume $m \\times n \\rightarrow m \\times nâ€™, nâ€™&lt;n$â€‹â€‹â€‹ (summarization)\nBasic Idea: remove unimportant pixels from the image ç§»é™¤ä¸é‡è¦çš„åƒç´ å‡ºå»\nUnimportant = pixels with less â€œenergyâ€ ä¸é‡è¦æŒ‡çš„æ˜¯èƒ½é‡è¾ƒä½\n\n\n\n\nE_{1}(\\mathbf{I})=\\left|\\frac{\\partial}{\\partial x} \\mathbf{I}\\right|+\\left|\\frac{\\partial}{\\partial y} \\mathbf{I}\\right|\nIntuition for gradient based energy:\nPreserve strong contours\nHuman vision more sensitive to edges so try remove content from smoother areas\nSimple enough for producing some nice results\n\n\n\n3. A Seam3.1 Def\nA connected path of pixels from top to bottom (or left to right).å¯ä»¥ç†è§£ä¸ºä¸€ä¸ªåƒç´ çš„å…«é¢†åŸŸåƒç´ ç‚¹4\n\n\n\\begin{aligned}\n&\\mathrm{s}^{\\mathrm{x}}=\\left\\{s_{i}^{x}\\right\\}_{i=1}^{n}=\\{(x(i), i)\\}_{i=1}^{n}, \\text { s.t. } \\forall i,|x(i)-x(i-1)| \\leq 1 \n\\end{aligned}\n\\begin{aligned}\n&\\mathrm{~s}^{\\mathrm{y}}=\\left\\{s_{j}^{y}\\right\\}_{j=1}^{m}=\\{(j, y(j))\\}_{j=1}^{m}, \\text { s.t. } \\forall j|y(j)-y(j-1)| \\leq 1\n\\end{aligned}\n3.2 Finding the Seam?\n\n3.3 The Optimal Seam\nThe recursion relation\n\n\n\\mathbf{M}(i, j)=E(i, j)+\\min (\\mathbf{M}(i-1, j-1), \\mathbf{M}(i-1, j), \\mathbf{M}(i-1, j+1))\nCan be solved efficiently using dynamic programming in $O(s\\times n\\times m)$\n\n3.4 Dynamic Programming3.4.1 Recursion\nğ‘€(ğ‘–,ğ‘—)= minimal cost of a seam going through (ğ‘–,ğ‘—) å…ˆè®¡ç®—æ•´å¼ å›¾çš„èƒ½é‡ï¼Œè®¡ç®—çš„æ–¹æ³•ä¸ºè¯¥åƒç´ ç‚¹è¿‡å»çš„é¢†åŸŸåƒç´ ä¸­èƒ½é‡çš„æœ€å°å€¼åŠ ä¸Šè‡ªèº«çš„èƒ½é‡ã€‚\n\n\n\n\næœ€ç»ˆï¼š\n\n\n3.4.2 Backtrack\nBacktrack (can store choices along the path, but do not have to)\nåœ¨æœ€åä¸€å±‚æ‰¾æœ€å°çš„ä¸€ä¸ªèƒ½é‡çš„åƒç´ ç‚¹\nç„¶åå›æº¯ï¼Œæ‰¾è¯¥åƒç´ ä¸Šä¸‰é¢†åŸŸä¸­èƒ½é‡æœ€å°çš„åƒç´ \nç›´åˆ°éå†åˆ°ç¬¬ä¸€è¡Œç»“æŸã€‚\n\n\n\n\n3.4.3 ä¼ªä»£ç \n3.5 æ•ˆæœ\n\nQ: Will the result be the same if the image is flipped upside down?\nA: Yes (up to numerical stability)\n\n\nQ: What happens to the overall energy in the image during seam carving?\nå˜å¤§\n\n\næ‰€ä»¥å½“æˆ‘ä»¬resizeå›¾åƒåï¼Œå¯¹äºæ•´ä¸ªå›¾åƒçš„å¹³å‡èƒ½é‡åº”è¯¥å˜å¤§\n\n\n\næ¯”è¾ƒï¼š\n\n\n\næˆ‘ä»¬å¯ä»¥å‘ç°seamçš„æ•ˆæœæœ€å¥½\n\n3.6 Both Dimensions?\n$m \\times n \\rightarrow mâ€™ \\times nâ€™, nâ€™&lt;n, mâ€™&lt;m$\n\n\n\nThe recursion relation:\n\n\n\\begin{aligned}\n&\\min _{\\mathbf{s}^{\\mathbf{x}}, \\mathbf{s}^{y}, \\alpha} \\sum_{i=1}^{k} E\\left(\\alpha_{i} \\mathbf{s}_{\\mathbf{i}}^{\\mathbf{x}}+\\left(1-\\alpha_{i}\\right) \\mathbf{s}_{\\mathbf{i}}^{\\mathbf{y}}\\right)\n\\end{aligned}\n\\begin{aligned}\n&r=n-n^{\\prime} \\quad c=m-m^{\\prime} \\quad \\mathrm{k}=r+c\n\\end{aligned}\nTransport map :\n\n\n\\begin{aligned}\n\\mathbf{T}(r, c)=\\min \\left(\\mathbf{T}(r-1, c)+E(\\mathbf{s}^{\\mathbf{x}}(\\mathbf{I}_{\\mathbf{n}-\\mathbf{r}-1 \\times \\mathbf{m}-\\mathbf{c}}\\right)),\n\\\\\n\\left.\\mathbf{T}(r, c-1)+E\\left(\\mathbf{s}^{\\mathbf{y}}\\left(\\mathbf{I}_{\\mathbf{n}-\\mathbf{r} \\times \\mathbf{m}-\\mathbf{c}-\\mathbf{1}}\\right)\\right)\\right)\n\\end{aligned}\nå…¶ç‰©ç†å«ä¹‰å°±æ˜¯ï¼Œ\n\n\n","categories":["CV"]},{"title":"Edge Preserving","url":"/2021/08/15/cv/3.2%20Edge%20Preserving/","content":"Edge Preserving\n1. Bilateral filteråŒè¾¹æ»¤æ³¢ç®—æ³•åŸç†åŠä»£ç ä»‹ç»_leonardohaigçš„åšå®¢-CSDNåšå®¢_è”åˆåŒè¾¹æ»¤æ³¢ä¸Šé‡‡æ ·ç®—æ³•åŸç†\n1.1 ç®—æ³•è§£æ\n\nå€¼åŸŸæ ¸r,è¡¨ç¤ºé‚»åŸŸå†…æŸç‚¹(k,l)çš„ç°åº¦å€¼f(k,l)ä¸ä¸­å¿ƒç‚¹(i,j)ç°åº¦å€¼f(i,j)çš„å·®çš„ç»å¯¹å€¼:\nå¯ä»¥çœ‹åˆ°å€¼åŸŸæ ¸ç”¨æ¥è¡¨å¾é‚»åŸŸå†…åƒç´ çš„ç›¸ä¼¼ç¨‹åº¦(æ¥è¿‘ç¨‹åº¦)\n\n\n\n\nG_r(P_i-P_j)=r(i, j, k, l)=\\exp \\left(-\\frac{\\|f(i, j)-f(k, l)\\|^{2}}{2 \\sigma_{r}^{2}}\\right)\nç©ºé—´åŸŸæ ¸d,è¡¨ç¤ºé‚»åŸŸå†…æŸç‚¹(k,l)ä¸ä¸­å¿ƒç‚¹(i,j)çš„æ¬§å¼è·ç¦»: è¿™å°±æ˜¯é«˜æ–¯æ»¤æ³¢æ ¸\n\n\nG_s(x_i-x_j)=d(i, j, k, l)=\\exp \\left(-\\frac{(i-k)^{2}+(j-l)^{2}}{2 \\sigma_{d}^{2}}\\right)\næƒé‡ç³»æ•°ä¸ºç©ºé—´åŸŸæ ¸å’Œå€¼åŸŸæ ¸çš„ä¹˜ç§¯:\n\n\n\\begin{gathered}\nw(i, j, k, l)=d(i, j, k, l) * r(i, j, k, l)= \\\\\n\\exp \\left(-\\frac{(i-k)^{2}+(j-l)^{2}}{2 \\sigma_{d}^{2}}-\\frac{\\|f(i, j)-f(k, l)\\|^{2}}{2 \\sigma_{r}^{2}}\\right)\n\\end{gathered}\nåŒè¾¹æ»¤æ³¢ä¸­(i,j)ä½ç½®çš„åƒç´ å€¼g(i,j)ä¾èµ–äºé‚»åŸŸå†…åƒç´ å€¼fä¸å…¶æƒé‡wçš„åŠ æƒç»„åˆ(k,lè¡¨ç¤ºé‚»åŸŸåƒç´ ä½ç½®)ï¼š\n\n\ng(i, j)=\\frac{\\sum_{k, l} f(k, l) w(i, j, k, l)}{\\sum_{k, l} w(i, j, k, l)}\nå¯¹äºé«˜æ–¯æ»¤æ³¢ï¼Œç¦»ä¸­å¿ƒåƒç´ è·ç¦»è¶Šè¿‘ï¼Œæƒé‡è¶Šå¤§ï¼ˆç‰©ç†è·ç¦»ï¼‰\nå¯¹äºå€¼åŸŸæ»¤æ³¢ï¼Œç°åº¦å€¼ç›¸å·®å¤§çš„ç‚¹æƒé‡è¶Šå°ï¼Œæ‰€ä»¥æœ€ç»ˆè¾¹ç¼˜äº¤ç•Œå¤„çš„æƒé‡æ¥è¿‘äºé›¶ï¼Œè€Œéè¾¹ç¼˜å¤„ï¼Œç”±äºç°åº¦å€¼ç›¸å·®å°ï¼Œæ‰€ä»¥æƒé‡è¾ƒå¤§ï¼Œä¸å¯èƒ½ä¸ºè¾¹ç¼˜ã€‚\nå½“ä¸¤è€…ç›¸ä¹˜ï¼Œæœ€ç»ˆå¯ä»¥åšåˆ°æ—¢æ¶ˆé™¤å™ªéŸ³ï¼Œåˆå·§å¦™ä¿ç•™äº†è¾¹ç¼˜ã€‚\n\n1.2 ç®—æ³•æ¡ˆä¾‹\n\nå…¶å¯ä»¥çœ‹ä½œæ˜¯10Ã—10çš„ä¸€å¼ å›¾åƒï¼Œå›¾ä¸­çš„æ•°å­—è¡¨ç¤ºæ¯ä¸ªç‚¹çš„åƒç´ å€¼ã€‚åœ¨å›¾ä¸­å­˜åœ¨ä¸€ä¸ª5Ã—5å¤§å°çš„æ»‘åŠ¨çª—å£ï¼Œæˆ‘ä»¬éœ€è¦æ±‚å‡ºä¸­å¿ƒç‚¹ç°åº¦å€¼146çš„æ–°åƒç´ å€¼ã€‚\n\nè¾¹ç¼˜å¤åˆ¶/è¾¹ç•Œå¡«å……(ä¸å¤šè¯´)\né¦–å…ˆéå†æ•´ä¸ªçª—å£ï¼Œç¬¬ä¸€ä¸ªéå†åˆ°çš„ç‚¹æ˜¯165ï¼Œé‚£ä¹ˆä¸­å¿ƒç‚¹ä¸è¯¥ç‚¹çš„ç©ºé—´åŸŸè®¡ç®—ç»“æœä¸ºï¼š\n\n\n\nå†è®¡ç®—ä¸­å¿ƒç‚¹ä¸è¯¥ç‚¹çš„åƒç´ åŸŸç»“æœï¼š\n\n\n\n\nâ€‹            å½“Ïƒs=5ä¸Ïƒr=20æ—¶ï¼ŒGÏƒs = 0.8521ï¼ŒGÏƒr = 0.6368ã€‚\nâ€‹          3. æ¥ç€éå†æ•´ä¸ªçª—å£ï¼Œå°†çª—å£å†…æ¯ä¸ªåƒç´ ç‚¹éƒ½ä¸ä¸­å¿ƒç‚¹å»ºç«‹è”ç³»ï¼Œæ±‚å‡ºå®ƒä»¬çš„GÏƒsä¸GÏƒrçš„å€¼ï¼Œå°†GÏƒsä¸GÏƒr             ç›¸ä¹˜å³å¾—åˆ°æ¯ä¸ªç‚¹å¯¹åº”çš„æƒé‡Wpï¼Œå³Wp = GÏƒs Ã— GÏƒrã€‚\nâ€‹            åœ¨éå†ç»“æŸåï¼Œç”¨æ¯ä¸ªç‚¹çš„Wpä¹˜ä¸Šè¯¥ç‚¹çš„åƒç´ å€¼I(i,j)ï¼Œå¹¶æ±‚å’Œï¼Œè¿™æ˜¯ä½œä¸ºåˆ†å­ã€‚å°†æ¯ä¸ªç‚¹çš„Wpç›¸åŠ ï¼Œä½œä¸º            åˆ†æ¯ï¼Œä¸¤è€…ç›¸é™¤ï¼Œå³å¾—åˆ°éœ€è¦çš„æ–°è¾“å‡ºå›¾åƒçš„ä¸­å¿ƒç‚¹ï¼ˆiï¼Œjï¼‰çš„åƒç´ å€¼ã€‚\n1.3 opencv ä»£ç å®ç°CV_EXPORTS_W void bilateralFilter( InputArray src, OutputArray dst, int d,                                   double sigmaColor, double sigmaSpace,                                   int borderType = BORDER_DEFAULT );//ç¬¬ä¸€ä¸ªå‚æ•°ï¼ŒInputArrayç±»å‹çš„srcï¼Œè¾“å…¥å›¾åƒï¼Œå³æºå›¾åƒï¼Œéœ€è¦ä¸º8ä½æˆ–è€…æµ®ç‚¹å‹å•é€šé“ã€ä¸‰é€šé“çš„å›¾åƒã€‚//ç¬¬äºŒä¸ªå‚æ•°ï¼ŒOutputArrayç±»å‹çš„dstï¼Œå³ç›®æ ‡å›¾åƒï¼Œéœ€è¦å’Œæºå›¾ç‰‡æœ‰ä¸€æ ·çš„å°ºå¯¸å’Œç±»å‹ã€‚//ç¬¬ä¸‰ä¸ªå‚æ•°ï¼Œintç±»å‹çš„dï¼Œè¡¨ç¤ºåœ¨è¿‡æ»¤è¿‡ç¨‹ä¸­æ¯ä¸ªåƒç´ é‚»åŸŸçš„ç›´å¾„ã€‚å¦‚æœè¿™ä¸ªå€¼æˆ‘ä»¬è®¾å…¶ä¸ºéæ­£æ•°ï¼Œé‚£ä¹ˆOpenCVä¼šä»ç¬¬äº”ä¸ªå‚æ•°sigmaSpaceæ¥è®¡ç®—å‡ºå®ƒæ¥ã€‚//ç¬¬å››ä¸ªå‚æ•°ï¼Œdoubleç±»å‹çš„sigmaColorï¼Œé¢œè‰²ç©ºé—´æ»¤æ³¢å™¨çš„sigmaå€¼ã€‚è¿™ä¸ªå‚æ•°çš„å€¼è¶Šå¤§ï¼Œå°±è¡¨æ˜è¯¥åƒç´ é‚»åŸŸå†…æœ‰æ›´å®½å¹¿çš„é¢œè‰²ä¼šè¢«æ··åˆåˆ°ä¸€èµ·ï¼Œäº§ç”Ÿè¾ƒå¤§çš„åŠç›¸ç­‰é¢œè‰²åŒºåŸŸã€‚//ç¬¬äº”ä¸ªå‚æ•°ï¼Œdoubleç±»å‹çš„sigmaSpaceåæ ‡ç©ºé—´ä¸­æ»¤æ³¢å™¨çš„sigmaå€¼ï¼Œåæ ‡ç©ºé—´çš„æ ‡æ³¨æ–¹å·®ã€‚ä»–çš„æ•°å€¼è¶Šå¤§ï¼Œæ„å‘³ç€è¶Šè¿œçš„åƒç´ ä¼šç›¸äº’å½±å“ï¼Œä»è€Œä½¿æ›´å¤§çš„åŒºåŸŸè¶³å¤Ÿç›¸ä¼¼çš„é¢œè‰²è·å–ç›¸åŒçš„é¢œè‰²ã€‚å½“d&gt;0ï¼ŒdæŒ‡å®šäº†é‚»åŸŸå¤§å°ä¸”ä¸sigmaSpaceæ— å…³ã€‚å¦åˆ™ï¼Œdæ­£æ¯”äºsigmaSpaceã€‚//ç¬¬å…­ä¸ªå‚æ•°ï¼Œintç±»å‹çš„borderTypeï¼Œç”¨äºæ¨æ–­å›¾åƒå¤–éƒ¨åƒç´ çš„æŸç§è¾¹ç•Œæ¨¡å¼ã€‚æ³¨æ„å®ƒæœ‰é»˜è®¤å€¼BORDER_DEFAULTã€‚\n2. Joint Bilateral filterè”åˆåŒè¾¹æ»¤æ³¢å™¨ï¼ˆjoint bilateral filter)ã€OpenCVã€‘_ShaderJoy çš„å…´è¶£æŠ€æœ¯æ‚è´§é“º-CSDNåšå®¢\n2.1 ç®€ä»‹\n\nå‰é¢ä»‹ç»äº†åŒè¾¹æ»¤æ³¢å™¨ï¼ˆbilateral filter,LBFï¼‰ï¼Œç„¶è€ŒBFçš„æƒå€¼æ˜¯ä¸ç¨³å®šçš„ï¼Œå› æ­¤åœ¨è¾¹ç¼˜é™„è¿‘ä¼šå‡ºç°ä¸€äº›ç¿»è½¬ã€‚æ­¤å¤–BFè®¡ç®—å¤æ‚åº¦æ˜¯O(r^2)ï¼›ä¸ºäº†æ”¹å–„BFæƒå€¼çš„ç¨³å®šæ€§ï¼Œå¼•å…¥äº†è”åˆåŒè¾¹æ»¤æ³¢å™¨ï¼ˆjoint bilateral filter ,LBF)ã€‚ä¸¤è€…ä¹‹é—´çš„å·®åˆ«å°±æ˜¯JBFç”¨äº†ä¸€ä¸ªå¯¼å‘å›¾ä½œä¸ºå€¼åŸŸæƒé‡çš„è®¡ç®—ä¾æ®ã€‚ä¸‹é¢æˆ‘ä»¬é€šè¿‡æ•°å­¦å…¬å¼å±•ç¤ºäºŒè€…çš„ä¸åŒï¼š\n\nå…ˆçœ‹BFçš„ï¼Œå¦‚ï¼ˆ1ï¼‰æ‰€ç¤ºï¼Œ\n\n\n\nJ_{p}=\\frac{1}{k_{p}} \\sum_{g \\in \\Omega} I_{q} f(\\|p-q\\|) g\\left(\\left\\|I_{p}-I_{q}\\right\\|\\right),\nå†æ¬¡è§£é‡Šä¸€ä¸‹å…¬å¼ä¸­çš„ç¬¦å·æ„ä¹‰ï¼Œå…¶ä¸­Iè¡¨ç¤ºè¾“å…¥å›¾åƒï¼Œpã€qè¡¨ç¤ºåƒç´ åœ¨å›¾åƒä¸­çš„åæ ‡ï¼ŒIpè¡¨ç¤ºå¯¹åº”ä½ç½®çš„åƒç´ å€¼ï¼ŒJè¡¨ç¤ºè¾“å‡ºï¼Œ fã€gæ˜¯æƒé‡åˆ†å¸ƒå‡½æ•°ï¼Œä¸€èˆ¬ä¸ºé«˜æ–¯å‡½æ•°ã€‚è¿™ç§æ»¤æ³¢çš„ç»“æœå°±æ˜¯å‘¨è¾¹åƒç´ çš„æƒå€¼ä¸ä»…å’Œè·ç¦»æœ‰å…³è¿˜å’Œé‚£ä¸ªä½ç½®çš„åƒç´ å€¼æœ‰å…³ã€‚\nå†çœ‹JBFï¼Œå¦‚ï¼ˆ2ï¼‰æ‰€ç¤ºï¼Œ\n\n\n\nJ_{p}=\\frac{1}{k_{p}} \\sum_{a \\in 0} I_{q} f(\\|p-q\\|) g\\left(\\left\\|\\tilde{I}_{p}-\\tilde{I}_{q}\\right\\|\\right)\nå¦‚æœåœ¨å€¼åŸŸçš„æƒé‡è®¡ç®—è¿‡ç¨‹å¼•å…¥å¦å¤–ä¸€å¹…å›¾åƒï¼Œå¦‚ä¸‹å¼ï¼Œåˆ™ç§°ä¹‹ä¸ºè”åˆåŒè¾¹æ»¤æ³¢ã€‚ $\\tilde{I}$â€‹â€‹ å°±æ˜¯å¼•å…¥çš„å¦å¤–ä¸€å¹…å›¾åƒã€‚è¯¥å›¾åƒ å¿…é¡»ä¸å¾…å¤„ç†çš„å›¾åƒç›¸ä¼¼ã€‚\nè”åˆåŒè¾¹æ»¤æ³¢ä¸Šé‡‡æ ·æŠ€æœ¯ä¹Ÿå¾ˆç®€å•ï¼Œä¸€ç§ä¾¿äºç†è§£çš„ä¹Ÿä¾¿äºå†™ä»£ç çš„æ–¹å¼å°±æ˜¯æŠŠä¸‹é‡‡æ ·å¹¶è¿›è¡Œå¤„ç†è¿‡åçš„å°å›¾æŒ‰ç…§æœ€è¿‘é‚»æ’å€¼çš„æ–¹å¼æ”¾å¤§åˆ°åŸå›¾å¤§å°ï¼Œç„¶åå†ç”¨åŸå›¾çš„æ•°æ®å’Œè¿™ä¸ªæ”¾å¤§çš„ç»“æœè¿›è¡Œè”åˆåŒè¾¹æ»¤æ³¢å¤„ç† ã€‚\n\n2.2 ä»£ç å®ç°ï¼šfunction B = jbfltGray(D,C,w,sigma_d,sigma_r)%    D should be a double precision matrix of size NxMx1 (i.e., grayscale)  with normalized values in the %    closed interval [0,1]. %    C should be similar to D, from which the weights are calculated, with normalized values in the%   closed interval [0,1]. % Pre-compute Gaussian distance weights.[X,Y] = meshgrid(-w:w,-w:w);G = exp(-(X.^2+Y.^2)/(2*sigma_d^2));% Apply bilateral filter.dim = size(D);B = zeros(dim);for i = 1:dim(1)   for j = 1:dim(2)               % Extract local region.         iMin = max(i-w,1);         iMax = min(i+w,dim(1));         jMin = max(j-w,1);         jMax = min(j+w,dim(2));         I = D(iMin:iMax,jMin:jMax);          % To compute weights from the color image         J = C(iMin:iMax,jMin:jMax);         % Compute Gaussian intensity weights according to the color image         H = exp(-(J-C(i,j)).^2/(2*sigma_r^2));         % Calculate bilateral filter response.         F = H.*G((iMin:iMax)-i+w+1,(jMin:jMax)-j+w+1);         B(i,j) = sum(F(:).*I(:))/sum(F(:));      endend\nOpenCV 3.x.xçš„æ‰©å±•æ¨¡å—ï¼ˆximgproc. Extended Image Processingï¼‰ ä¹Ÿæ·»åŠ äº†JBFçš„ API ï¼š\n\n#include &quot;stdafx.h&quot;#include &lt;opencv2/opencv.hpp&gt;#include &lt;ximgproc.hpp&gt; int main()&#123;\tcv::Mat src = cv::imread(&quot;data/dp.png&quot;, 1); // åŸå§‹å¸¦å™ªå£°çš„æ·±åº¦å›¾\tcv::Mat joint = cv::imread(&quot;data/teddy.png&quot;, 0); \tcv::Mat dst;\tint64 begin = cvGetTickCount();\tcv::ximgproc::jointBilateralFilter(joint, src, dst, -1, 3, 9);\tint64 end = cvGetTickCount(); \tfloat time = (end - begin) / (cvGetTickFrequency() * 1000.);\tprintf(&quot;time = %fms\\n&quot;, time); \timshow(&quot;src&quot;, src);\timshow(&quot;joint&quot;, joint);\timshow(&quot;jointBilateralFilter&quot;, dst);\tcv::waitKey(0);      return 0;&#125;\n2.3 æ•ˆæœ\n2.4 è¯„ä»·Advantagesï¼š\nPreserve edges in the smoothing process å¯ä»¥åœ¨å¹³æ»‘å¤„ç†åä»ä¿ç•™è¾¹ç¼˜\nSimple and intuitive ç®€å•ç›´è§‚\n\nProblemsï¼š\nComplexity\n\nBrute force: $O(r^2)$\nDistributive histogram: $O(log r)$\nIntegral histogram: $O(1)$\n\n\nGradient distortion: æ¢¯åº¦ç¿»è½¬\n\nPreserves edges, but not gradients\nç”±äºé«˜æ–¯æ»¤æ³¢å¯¹è¾¹ç¼˜æ•æ„Ÿï¼Œå®¹æ˜“å¯¹è¾¹ç¼˜éƒ¨åˆ†çš„åƒç´ å€¼é€ æˆå¾ˆå¤§çš„å˜åŒ–ï¼Œè¿™å°±å¯¼è‡´è¾¹ç¼˜éƒ¨åˆ†å¯èƒ½æœ‰æ¢¯åº¦ç¿»è½¬çš„ç°è±¡\n\n\n\n\n3. Guided filter3.1 ç®—æ³•è§£æ\n\nè¿™é‡Œè¦è¯´çš„å¼•å¯¼æ»¤æ³¢ï¼ŒæŸåƒç´ ç‚¹çš„è¾“å‡ºç»“æœä¸ºï¼š\n\n\nq_{i}=a_{k} I_{i}+b_{k}, \\forall i \\in \\omega_{k}\nå…¶ä¸­ï¼Œq ä¸ºè¾“å‡ºå›¾åƒï¼ŒI ä¸ºå¼•å¯¼å›¾åƒï¼Œa å’Œ b æ˜¯å½“çª—å£ä¸­å¿ƒä½äº k æ—¶è¯¥çº¿æ€§å‡½æ•°çš„ä¸å˜ç³»æ•°ã€‚å¯¹äºç»™å®škä¸ªçª—å£ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾å¯¹äºkä¸ªçª—å£è¦†ç›–åˆ°å¼•å¯¼å›¾åƒçš„æ¯ä¸ªåƒç´ éƒ½å’Œè¾“å‡ºå›¾åƒå¯¹åº”çš„åƒç´ ç‚¹æœ‰ä¸€ä¸ªçº¿æ€§æ˜ å°„çš„å…³ç³»ï¼Œå…¶ä¸­å¯¹äºæ¯ä¸€ä¸ªçª—å£ï¼Œå…¶çº¿æ€§çš„å‚æ•°æ˜¯æ˜¯ä¸€æ ·çš„ã€‚\n$n_i$ä¸ºå™ªå£°ï¼Œpæ˜¯qå—åˆ°å™ªå£°næ±¡æŸ“çš„é€€åŒ–å›¾åƒ\n\n\nn_i = p_i-q_i\nä»·å€¼å‡½æ•°å¦‚ä¸‹ï¼š\n\n\nE\\left(a_{k}, b_{k}\\right)=\\sum_{i \\in \\omega_{k}}\\left(\\left(a_{k} I_{i}+b_{k}-p_{i}\\right)^{2}+\\varepsilon a_{k}^{2}\\right)\nå³ï¼š\n\n\n\\min _{(a, b)} \\sum_{i}\\left(a I_{i}+b-p_{i}\\right)^{2}+\\varepsilon a^{2}\nç¬¬äºŒé¡¹ä¸ºæ­£åˆ™é¡¹ï¼Œç”¨äºé™åˆ¶açš„å¤§å°ï¼Œ$\\epsilon$ä¸ºè¶…å‚ã€‚ç±»ä¼¼äºæœ€ä¸‹äºŒä¹˜æ³•æ±‚è§£ï¼Œå¼ï¼ˆ9ï¼‰çš„è§£ä¸ºï¼š\n\n\n\\begin{aligned}\na_{k} &=\\frac{\\frac{1}{|\\omega|} \\sum_{i \\in \\omega_{k}} I_{i} p_{i}-\\mu_{k} \\bar{p}_{k}}{\\sigma_{k}^{2}+\\varepsilon } \n\\end{aligned}\n\\begin{aligned}\nb_{k} &=\\bar{p}_{k}-a_{k} \\mu_{k}\n\\end{aligned}\nè¿™é‡Œçš„$p_i$æŒ‡çš„æ˜¯å¯¹äºåŸå›¾åƒå¯¹åº”çš„ç¬¬$i$ä¸ªåƒç´ ï¼Œ$\\mu_k$è¡¨ç¤ºå¯¹åº”ç¬¬kä¸ªçª—å£å¼•å¯¼å›¾åƒçš„æ‰€æœ‰åƒç´ å€¼çš„å‡å€¼ï¼Œ$\\bar{p_k}$æŒ‡çš„æ˜¯å¯¹äºè¯¥çª—å£è¦†ç›–åŸå›¾åƒæ‰€æœ‰åƒç´ çš„å‡å€¼ï¼Œ$\\sigma^2_k$æŒ‡çš„æ˜¯å¯¹äºç¬¬kä¸ªçª—å£å¼•å¯¼å›¾åƒä¸Šåƒç´ å€¼çš„æ–¹å·®ï¼Œ$\\varepsilon$â€‹æ˜¯è¶…å‚ã€‚\næœ€åå–å‡å€¼å¯ä»¥å¾—åˆ°å¼ï¼ˆ7ï¼‰çš„ç»“æœä¸ºï¼š\n\n\n\\begin{aligned}\nq_{i} &=\\frac{1}{|\\omega|} \\sum_{k: i \\in \\omega_{k} \\ldots t_{p i a 0 x u e}}\\left(a_{k} I_{i}+b_{k}\\right) \\\\\n&=\\bar{a}_{i} I_{i}+\\bar{b}_{i}\n\\end{aligned}\nå…¶ä¸­ï¼Œ$\\bar{a}_{i}=\\frac{1}{|\\omega|} \\sum_{k \\in \\omega_{i} } a_{k},  \\bar{b}_{i}=\\frac{1}{|\\omega|} \\sum_{k \\in \\omega_{i}} b_{k}$â€‹â€‹â€‹ï¼Œå…¶ç‰©ç†å«ä¹‰æ˜¯å¯¹äºç»è¿‡ç¬¬$i$ä¸ªåƒç´ çš„æ‰€æœ‰çª—å£å¯¹$a_k, b_k$â€‹â€‹â€‹è¿›è¡Œå¹³å‡ã€‚\nå³ï¼š\n\n\n\\begin{aligned}\na_{k} &=\\frac{\\operatorname{cov}_{k}(I, p)}{\\operatorname{var}_{k}(I)+\\varepsilon} \\\\\nb_{k} &=\\bar{p}_{k}-a \\bar{I}_{k} \\\\\nq_{i} &=\\frac{1}{|\\omega|} \\sum_{k \\mid \\in \\omega_{k}}\\left(a_{k} I_{i}+b_{k}\\right) \\\\\n&=\\bar{a}_{i} I_{i}+\\bar{b}_{i}\n\\end{aligned}3.2 æ€»ç»“\næ€»ç»“ï¼šå¯¼å¼•å›¾åƒIä¸ q ä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»ï¼Œè¿™æ ·è®¾å®šå¯ä»¥ä½¿å¯¼å¼•å›¾åƒæä¾›çš„ä¿¡æ¯ä¸»è¦ç”¨äºæŒ‡ç¤ºå“ªäº›æ˜¯è¾¹ç¼˜ã€‚å¦‚æœå¯¼å¼•å›¾å‘Šè¯‰æˆ‘ä»¬è¿™é‡Œæ˜¯è¾¹ç¼˜ï¼Œæœ€ç»ˆçš„ç»“æœå°±è®¾æ³•ä¿ç•™è¿™äº›è¾¹ç¼˜ä¿¡æ¯ã€‚æ‰€ä»¥ï¼Œå¼•å¯¼æ»¤æ³¢çš„å‰ææ¡ä»¶æ˜¯ï¼šå½“Iå’Œqæ»¡è¶³çº¿æ€§å…³ç³»æ‰æœ‰æ„ä¹‰ã€‚\n\n\n\nå…¶æœ€ç»ˆç»“æœå¯ä»¥ç†è§£ä¸ºï¼Œå¯¹äºæ¯ä¸ªè¾“å‡ºçš„åƒç´ ä¸ºï¼šå¯¹å¼•å¯¼å›¾åƒå¯¹åº”çš„åƒç´ çš„ä¸€ä¸ªå˜æ¢çš„å‡å€¼ã€‚\nå¯¹äºç¬¬kä¸ªç»è¿‡è¯¥åƒç´ çš„çª—å£ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°å¯¹åº”çš„ä¸€ä¸ªçº¿æ€§å˜æ¢ï¼Œä»è€Œå¾—åˆ°å¯¹åº”çš„è¾“å‡ºåƒç´ å€¼ï¼›\néå†è¿™ä¹ˆå¤šä¸ªçª—å£çš„å˜æ¢åï¼Œæˆ‘ä»¬åœ¨æ±‚ä¸€ä¸ªå‡å€¼ï¼Œæœ€ç»ˆå°±ä¼šå¾—åˆ°æˆ‘ä»¬æƒ³è¦çš„ç­”æ¡ˆ\nè¿™é‡Œçš„$\\bar{a_i}$å’Œ$\\bar{b_i}$å¯ä»¥ç†è§£ä¸ºç»è¿‡ç¬¬$i$ä¸ªåƒç´ çª—å£çš„ç³»æ•°çš„å‡å€¼\n\n3.3 ä¸ºä½•å¯è¡Œ3.3.1 Def\n\\begin{aligned}\na_{k} &=\\frac{\\operatorname{cov}_{k}(I, p)}{\\operatorname{var}_{k}(I)+\\varepsilon} \\\\\nb_{k} &=\\bar{p}_{k}-a \\bar{I}_{k} \\\\\nq_{i} &=\\frac{1}{|\\omega|} \\sum_{k \\mid \\in \\omega_{k}}\\left(a_{k} I_{i}+b_{k}\\right) \\\\\n&=\\bar{a}_{i} I_{i}+\\bar{b}_{i}\n\\end{aligned}å³ï¼š\n\n\\begin{aligned}\na &=\\frac{\\operatorname{cov}(I, p)}{\\operatorname{var}(I)+\\varepsilon} \\\\\nb &=\\bar{p}-a \\bar{I}\n\\end{aligned}\n$\\varepsilon$å¯ä»¥è§†ä¸ºè¾¹ç¼˜ä¿ç•™ç¨‹åº¦çš„è¯„åˆ¤â€‹\n\n3.3.2 Smoothing\n\nå…¶æ„ä¹‰æ˜¯ï¼Œå¦‚æœè¦å¯¹å›¾åƒè¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œåªéœ€å¢å¤§$\\varepsilon$ï¼Œè¿™æ ·å°±ä¼šä½¿å¾—éƒ½$\\begin{gathered}a \\approx 0 , b \\approx \\bar{p} \\end{gathered}$ åˆ™è¾“å‡ºå›¾åƒçš„åƒç´ è¿‘ä¼¼ä¸ºé«˜æ–¯è¿‡æ»¤åçš„è¾“å‡ºå›¾åƒï¼Œæˆ–è€…è¯´æ­¤æ—¶ç”±äºæ˜¯éè¾¹ç¼˜å¤„ï¼Œæ‰€ä»¥å˜åŒ–å¾ˆå°ï¼Œæ–¹å·®å’Œå·ç§¯è‡ªç„¶å¾ˆå°ï¼Œä¼šè¿œå°äºä¸€ä¸ªé˜ˆå€¼ï¼Œè¿™ä¸ªé˜ˆå€¼å°±æ˜¯$\\varepsilon$â€‹ã€‚\nå¯¹äº$\\bar{p}_k$æŒ‡çš„æ˜¯å¯¹äºç¬¬kä¸ªçª—å£åœ¨åŸå›¾åƒè¦†ç›–çš„æ‰€æœ‰åƒç´ å€¼çš„å‡å€¼ï¼Œ$\\overline{\\bar{p}}$åˆ™ä¸ºå¯¹äºè¿™æ ·kä¸ªçª—å£å¾—å‡ºçš„$\\bar{p}_k$çš„å‡å€¼åŒ–ï¼Œå…¶å®ç»“æœå°±ç›¸å½“äºåšäº†æ»¤æ³¢ã€‚â€‹\n\n3.3.3 edge-preserving\n\nç”±äº$\\bar{a}$å’Œ$\\bar{b}$æ˜¯å¸¸æ•°ï¼Œæ‰€ä»¥æ±‚æ¢¯åº¦æ˜¯é›¶ï¼Œè¿™é‡Œè¡¨ç¤ºäº†å¯¹äºè¾“å‡ºå›¾åƒæ¯ä¸€ä¸ªåƒç´ çš„æ¢¯åº¦å€¼å¯ä»¥ç†è§£ä¸ºå¼•å¯¼å›¾åƒæ¢¯åº¦å€¼çš„å¢ç›Šæˆ–è€…è¡°è½ã€‚\nåœ¨è¿™é‡Œï¼Œä¹Ÿè¯´æ˜äº†è¶…å‚$\\varepsilon$â€‹å¯ä»¥æ§åˆ¶açš„å¤§å°ï¼Œä»è€Œæ§åˆ¶è¾“å‡ºå›¾åƒçš„åƒç´ å€¼æ¢¯åº¦ï¼Œæˆ‘ä»¬çŸ¥é“è¾¹ç¼˜å¤„çš„åƒç´ å€¼æ¢¯åº¦ä¼šæ˜æ˜¾å¤§äºå‘¨å›´ï¼Œè¿™å°±æ„å‘³ç€è¶…å‚å®è´¨æ˜¯åœ¨å¢å¼ºè¾“å‡ºå›¾åƒçš„è¾¹ç¼˜\n\n\n\næˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œ$\\varepsilon$â€‹è¶Šå°ï¼Œè¾¹ç¼˜è¶Šæ˜æ˜¾ï¼Œå½“ç„¶è¶Šå¤§ï¼Œåˆ™è¶Šæ¨¡ç³Šã€‚â€‹\n\n3.4 ä¸BFå¯¹æ¯”\n\nç”±äºå¼•å¯¼å›¾åƒå’Œè¾“å‡ºå›¾åƒçš„æ¢¯åº¦å€¼å…·æœ‰çº¿æ€§å…³ç³»ï¼Œæ‰€ä»¥ä¸ä¼šåœ¨è¾¹ç¼˜å¤„å‡ºç°æ¢¯åº¦ç¿»è½¬çš„ç°è±¡ï¼Œç›¸åï¼Œå…¶ä¼šå¯¹è¾¹ç¼˜å¤„è¿›è¡Œå¢ç›Šã€‚\n\n","categories":["CV"]},{"title":"Histogram of Oriented Gradients","url":"/2021/08/15/cv/4.2%20HoG/","content":"Histogram of Oriented Gradients\n\n1. Some Challenges\nFind robust feature set that allows object form to be discriminated.\n\nChallenges:\n\nWide range of pose and large variations in appearances æˆ‘ä»¬æƒ³å¾—åˆ°æ¯”è¾ƒæœ‰åˆ¤åˆ«åŠ›çš„ç‰¹å¾ï¼Œä»–çš„å½¢æ€ä¼šå‘ç”Ÿæ¯”è¾ƒå¤§çš„å˜åŒ–\nCluttered backgrounds under different illumination èƒŒæ™¯è½¦çš„å˜åŒ–ï¼Œé£å¹æ ‘çš„å˜åŒ–ï¼Œå…‰ç…§çš„å˜åŒ–\nâ€œSpeedâ€ for mobile vision å¸Œæœ›å®æ—¶æ£€æµ‹ï¼Œå¯¹é€Ÿåº¦æœ‰å¾ˆé«˜çš„è¦æ±‚\n\n\n\n\n\nLocal object appearance and shape can often be characterized rather well by the distribution of local intensity gradients or edge directions.å±€éƒ¨æ¢¯åº¦å¢å¼ºæˆ–è€…è¾¹ç¼˜æ£€æµ‹\n\n2. Histogram of Oriented Gradients\nDividing the image window into small spatial regions (cells)\nCells can be either rectangle or radialï¼ˆå¾„å‘çš„ï¼‰.\nEach cell accumulating a weighted local 1-D histogram of gradient directions over the pixels of the cell. è®¡ç®—æ¯ä¸ªåƒç´ çš„æ¢¯åº¦ï¼Œå°†æ¢¯åº¦çš„æ–¹å‘é‡åŒ–ä¸ºKä¸ªï¼Œç„¶åå°†æ¯ä¸ªå•å…ƒå†…ç›¸åŒçš„æ¢¯åº¦æ–¹å‘çš„æ¢¯åº¦å¹…å€¼ç›¸åŠ å¾—åˆ°è¯¥æ–¹å‘çš„æ¢¯åº¦å¼ºåº¦ï¼Œä¹Ÿå°±æ˜¯ç›´æ–¹å›¾æ¯ä¸ªbinçš„å€¼ã€‚\n\n\n\n3. Normalization\nFor better invariance to illumination and shadowing. it is useful to contrast-normalize the local responses before using them.\n\nAccumulate local histogram â€œenergyâ€ over a larger regions (â€œblocksâ€) to normalize all of the cells in the block.\n\n\n\n4. Visualizing HoG\n5. Difference between HoG and SIFT\nHoG is usually used to describe entire images. å³ä¸€ä¸‹å­è®¡ç®—äº†æ•´å¼ å›¾çš„æ¢¯åº¦SIFT is used for key point matching\n\nSIFT histograms are oriented æœå‘towards the dominant gradientä¸»æ–¹å‘.ï¼ˆæé«˜äº†å¯¹æ—‹è½¬çš„é²æ£’æ€§ï¼‰HoG is not.\n\nSIFT descriptors use varying scales to compute multiple descriptors. æé«˜å¯¹å°ºåº¦é²æ£’æ€§\n\nHoGgradients are normalized using neighborhood binsï¼ˆblockå†…çš„ç›´æ–¹å›¾ä¹‹å’Œï¼‰.\n\n\n","categories":["CV"]},{"title":"LBP","url":"/2021/08/15/cv/4.3%20LBP/","content":"LBP\n\n1. Texture\nDef:\n\nIncludes: more regular patterns\n\n\n\nIncludes: more random patterns\n\n\n2. Texture-related tasks\nShape from texture\nEstimate surface orientationæ–¹å‘ or shape from image texture\n\n\nSegmentation/classification from texture cues\nAnalyze, represent texture\nGroup image regions with consistent texture\n\n\nSynthesisåˆæˆ\nGenerate new texture patches/images given some examples\n\n\n\n\n3.Why analyze texture?Importance to perception:\n\nOften indicative of a materialâ€™s properties è¡¨ç¤ºä¸€ç§ææ–™çš„ç‰¹æ€§\n\nCan be important appearance cue, especially if shape is similar across objects\n\nAim to distinguish between shape, boundaries, and texture\n\n\nTechnically:\n\nRepresentation-wise, we want a feature one step above â€œbuilding blocksâ€ of filters, edges.\n\n4. Texture representation\nTextures are made up of repeated local patterns, so:\nFind the patterns\nUse filters that look like patterns (spots, bars, â€¦)\nConsider magnitude of response\n\n\nDescribe their statistics within each local window, e.g., ç”¨æ•°å€¼ç‰¹å¾è¡¨ç¤º\nMean, standard deviation\nHistogram\nHistogram of â€œprototypicalâ€ feature occurrences\n\n\n\n\n\n4.1 Texture representation: example\n\nå›¾ä¸­ï¼Œåˆ†åˆ«ä½¿ç”¨xæ¢¯åº¦ç®—å­ä¸yæ¢¯åº¦ç®—å­ï¼Œå¯¹æ¯ä¸ªå›¾åƒä¸­çš„patternè¿›è¡Œå·ç§¯ï¼Œç„¶åå–è¿™ä¸ªpatternçš„å¹³å‡å€¼ä½œä¸ºè¾“å‡º\n\n\n\nå°†å…¶æŠ•å°„åˆ°åæ ‡ç³»ï¼Œå¯ä»¥å¾—åˆ°ï¼Œé è¿‘åŸç‚¹å³ä¸ºå¹³æ»‘åŒºåŸŸï¼Œè¿œç¦»åˆ™ä¸ºè§’ç‚¹\n\n\n\nåæ ‡ç³»ä¸­ä¹Ÿå¯ä»¥çœ‹å‡ºçº¹ç†çš„åŒºåˆ«\n\n\nD(a, b)=\\sqrt{\\left(a_{1}-b_{1}\\right)^{2}+\\left(a_{2}-b_{2}\\right)^{2}}\nDistance reveals how dissimilar texture from window a is from texture in window b.\n\n\n4.2 window scale\nWeâ€™re assuming we know the relevant window size for which we collect these statistics. \n\n\n\nç”¨ä¸åŒçª—å£çš„sizeï¼Œæå–ä¸åŒå°ºåº¦çš„çº¹ç†ï¼Œç±»ä¼¼SIFTï¼Œéå†æ‰€æœ‰size\n\nPossible to perform scale selectionby looking for window scale where texture description not changing.\n\n\n5. Filter banks\nOur previous example used two filters, and resulted in a 2-dimensional feature vector to describe texture in a window.\nx and y derivatives revealed something about local structure.\n\n\nWe can generalize to apply a collection of multiple (d) filters: a â€œfilter bankâ€\nThen our feature vectors will be d-dimensional.\nstill can think of nearness, farness in feature space\n\n\n\n\n5.1 What filters to put in the bank?\nTypically we want a combination of scales and orientations, different types of patterns. ç”±æ£€æµ‹ä¸åŒå°ºåº¦ä¸æ–¹å‘çš„ç‰¹å¾ç»„åˆ\n\n5.1.1 Multivariate Gaussian\nFilter bankï¼š\n\nCan you match the texture to the response?\n\n5.2 Representing texture by mean abs response\n\nWe can form a feature vector from the list of responses at each pixel.\n\n5.3 d-dimensional features\nD(a, b)=\\sqrt{\\sum_{i=1}^{d}\\left(a_{i}-b_{i}\\right)^{2}}\nEuclidean distance ($L_2$â€‹)\n\n\n\nè·Ÿè¿™å…­ç±»æ¯”è¾ƒï¼Œä½¿ç”¨SVMåˆ†ç±»\n\n6. Local Binary Pattern (LBP)\n\nç”¨ä¸­å¿ƒåƒç´ ä¸é¢†åŸŸåƒç´ çš„å¤§å°å…³ç³»æ¥è¡¨ç¤ºå…¶ç‰¹å¾ï¼Œæœ€ç»ˆåŒ–ä¸ºäºŒå€¼å‘é‡\nUse center pixel value to threshold the 3x3 neighborhood ç”¨ä¸­å¿ƒåƒç´ é˜ˆå€¼ï¼Œå› ä¸ºæ¯”å®ƒå°çš„ç›´æ¥å°±å˜æˆé›¶äº†\nResult in binary number è½¬åŒ–ä¸ºäºŒè¿›åˆ¶å‘é‡\nMultiplied by powers of two (Decimal) è½¬åŒ–ä¸ºåè¿›åˆ¶ï¼Œä»¥ç¼©çŸ­é•¿åº¦\nSummed to obtain a label for the center pixel -&gt; 256 different labelsï¼ˆæ¯ä¸ªwindowéƒ½ç”¨1*8çš„äºŒè¿›åˆ¶æ•°è¡¨ç¤ºï¼Œå…¶èŒƒå›´ä¸º0-255ï¼‰\nHistogram of the labels is used as a texture descriptor ç”¨LBPç›´æ–¹å›¾ç»Ÿè®¡labelä¸ªæ•°ï¼Œç„¶åç”¨1*256çš„å‘é‡è¡¨ç¤ºä¸€å¼ å›¾ç‰‡\nä»è€Œä½¿å¾—ä¸€å¼ 20002000çš„å›¾ç‰‡å˜æˆ1\\256\n\n\n\n    \n\n6. 1 What are the problems? How can you be invariant to changes in scale ?\næ²¡æœ‰è€ƒè™‘ä¸åŒçš„å°ºåº¦ç©ºé—´ã€‚\n\nè§£å†³æ–¹æ³•\n6.2 Circle LBP\nLBP is extended to use different sizes of neighborhoods. \nLocal neighborhoods is defined as a set of sampling points.\npoints evenly ï¼ˆå¹³å‡ï¼‰ spaced on a circle centered at the labeled pixel.\n(P,R) , P = number of sampling points , R = radius\n\n\n6.3 Uniform LBP\nStandard LBP has $2^n$â€‹â€‹ patterns for n sampling points å› ä¸ºæœ€ç»ˆä¼šè¡¨ç¤ºæˆäºŒè¿›åˆ¶æ•°çš„ç›´æ–¹å›¾\nHistogram dimension becomes high when n is increased\nSensitive to noise\n\n\nUniform patterns has at most 2 bitwise transitions in binary pattern. å½“0å˜æˆ1å°±è¢«å™ªéŸ³å½±å“äº†\n\nHistogram assigns separate bin for every uniform pattern.\n\nHistogram assigns a single bin for all non-uniform pattern.\nIn FERET dataset, (8,1) neighborhoods : 90.6 percent of patterns are uniform.\n\nç‰¹å¾ç©ºé—´è¿˜æ˜¯è¿‡é•¿äº†\n\nLBPæ˜¯æ¯”è¾ƒä¸­é—´åƒç´ ä¸é¢†åŸŸåƒç´ çš„æ¯”è¾ƒï¼Œä½†å¦‚æœæœ‰å™ªå£°1å°±å˜æˆ0äº†ï¼Œå³å¯¹å™ªå£°è¿‡äºæ•æ„Ÿäº†\nå¦‚æœæœ‰å¤§äºä¸¤æ¬¡è·³å˜ï¼Œå°±æ˜¯ä¸å¹³æ»‘ï¼Œæ‰€ä»¥æˆ‘ä»¬æŠŠæ‰€æœ‰è¶…è¿‡ä¸¤æ¬¡è·³å˜çš„å½’ä¸ºä¸€ç±»ï¼Œåœ¨ç›´æ–¹å›¾ç»Ÿä¸€è®¡ç®—binï¼Œè€Œå°äºç­‰äºä¸¤æ¬¡è·³å˜çš„ï¼Œå³ä¸ºuniform LBPï¼Œè¿™äº›å¯ä»¥åˆ†å¼€è®¡æ•°ï¼Œä»è€Œå‹ç¼©å™ªå£°\n\n\n\næ­¥éª¤ï¼š\nStep 1: facial image is divided into local regions (blocks). {R0, R1, â€¦, Rm-1} (pixel-level locality)\n\nStep 2: Extract LBP histogram for each region. (regional-level locality)\n\nStep 3: Concatenatedï¼ˆè¿æ¥ï¼‰ all histograms into a spatially enhanced histogram with length of m x n (n is length of a single LBP histogram). (global-level locality)\n\nm blocks\n\n\nStep 4: Chi-square distance\n\n\n7. Summary\nTexture is a useful property that is often indicative of materials, appearance cues\nTexture representations attempt to summarize repeating patterns of local structure\nFilter banks useful to measure redundantï¼ˆå†—ä½™çš„ï¼‰ variety of structures in local neighborhood\nFeature spaces can be multi-dimensional\n\n\nLocal binary patterns describe small-scale appearance (textures) of the image\n\n","categories":["CV"]},{"title":"çŸ¥è¯†å·¥ç¨‹ç®€ä»‹","url":"/2021/08/15/knowledge%20engineering/1.%20%E7%9F%A5%E8%AF%86%E5%B7%A5%E7%A8%8B%E7%AE%80%E4%BB%8B/","content":"çŸ¥è¯†å·¥ç¨‹ç®€ä»‹\næœ±å¯é¹ 581193041. What is a knowledge graph? what is its role in machine intelligence?What is a knowledge graph?\n\nçŸ¥è¯†å›¾è°±ä¹Ÿè¢«ç§°ä¸ºè¯­ä¹‰ç½‘ç»œï¼ˆsemantic networkï¼‰ï¼Œå®ƒè¡¨ç¤ºäº†ç°å®ä¸–ç•Œä¸­çš„å®ä½“äº‹ç‰©çš„ä¸€ç§ç½‘ç»œå…³ç³»ï¼Œå¹¶å…·ä½“å±•ç¤ºäº†è¿™äº›äº‹ç‰©ä¹‹é—´çš„å…³ç³»ï¼Œè€Œå…¶ä¸­çš„å®ä½“äº‹ç‰©å¯ä»¥ç†è§£ä¸ºç°å®ä¸­çš„ä¸€äº›å¯¹è±¡ã€äº‹ä»¶ã€æƒ…å†µæˆ–æ¦‚å¿µã€‚è€Œè¿™äº›ä¿¡æ¯é€šå¸¸è¢«å­˜å‚¨åœ¨å›¾æ•°æ®åº“ï¼ˆGraph databaseï¼‰ä¸­ï¼Œå¹¶å¯è§†åŒ–ä¸ºå›¾ç»“æ„ã€‚\n\nå…·ä½“è€Œè¨€ï¼Œä¸€ä¸ªçŸ¥è¯†å›¾è°±ç”±ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«ä¸ºï¼šèŠ‚ç‚¹ã€è¾¹ã€æ ‡ç­¾ã€‚ä»»ä½•ç‰©ä½“ã€åœ°ç‚¹ã€æˆ–è€…èŠ‚ç‚¹ç­‰éƒ½å¯ä»¥æ˜¯ä¸€ä¸ªèŠ‚ç‚¹ã€‚è€Œè¾¹å®šä¹‰äº†èŠ‚ç‚¹çš„å…³ç³»ã€‚\n\nå¯¹äºç½‘ç»œä¸­çš„æ¯ä¸€æ¡çŸ¥è¯†ï¼Œæ„æˆä¸€ä¸ªä¸‰å…ƒç»„ï¼ˆsubject, predicate, objectï¼‰ï¼Œæ‰€ä»¥çŸ¥è¯†å›¾è°±ä¹Ÿå¯ä»¥ç®€å•ç†è§£ä¸ºRDFSè¿™æ ·çš„æ¨¡å‹ï¼Œå¯¹äºä¸‰å…ƒç»„\n\n\n\n  â€‹        A è¡¨ç¤ºä¸»è¯­ï¼ŒBè¡¨ç¤ºè°“è¯­ï¼ŒCè¡¨ç¤ºå®¾è¯­ã€‚\n\nRDFï¼šTriple-based Assertion Modelï¼Œå…·ä½“å¦‚ä¸‹å›¾å±•ç¤º\nRDF Graph: Directed Labeled Graph\n\n\n\n\nRDFSï¼šSimple Vocabulary and Schemaï¼Œå¯ä»¥ç”±ä¸‹å›¾å±•ç¤ºï¼š\n\n\n  è¿™ä¸ªæ¨¡å‹çš„ä¸‹åŠéƒ¨åˆ†ä¸ºä¸€äº›å…·ä½“çš„å®ä¾‹ï¼Œè€Œæ¨¡å‹çš„ä¸ŠåŠéƒ¨åˆ†ä¸ºè¿™äº›å®åŠ›çš„æŠ½è±¡ç±»å‹ï¼Œå…¶ä¸­æˆ‘ä»¬å¯ä»¥çŸ¥é“äººå·¥æ™ºèƒ½è¿™ä¸ªå®ä¾‹æ˜¯å±äºè®¡ç®—æœºç§‘å­¦è¿™ä¸ªç±»åˆ«ï¼Œè€Œè®¡ç®—æœºç§‘å­¦ä¸ºä¿¡æ¯ç§‘å­¦çš„å­ç±»ï¼Œè€Œè¿™ä¸ªå›¾è°±çš„è¡¨ç¤ºäº†å›¾çµçš„ç ”ç©¶é¢†åŸŸä¸ºäººå·¥æ™ºèƒ½è¿™æ ·ä¸€æ¡çŸ¥è¯†ã€‚\nwhat is its role in machine intelligence?\nä¸‹å›¾ä¸ºå¼ºäººå·¥æ™ºèƒ½é‡‘å­—å¡”ç¤ºæ„å›¾ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°çŸ¥è¯†å·¥ç¨‹ä½äºé‡‘å­—å¡”çš„ç¬¬äºŒå±‚\n\n\n\nä¸‹å›¾ä¸ºæ™ºèƒ½AIä¸æœ‰çŸ¥è¯†çš„AIå¯¹æ¯”çš„ç¤ºæ„å›¾\n\n\n\nç”±å¦‚ä¸Šä¸¤å¼ å›¾æˆ‘ä»¬å¯ä»¥å¾—å‡ºï¼Œè¦æƒ³å®ç°çœŸæ­£çš„äººå·¥æ™ºèƒ½ï¼Œå‘å±•çŸ¥è¯†å›¾è°±æ˜¯ååˆ†é‡è¦çš„ä¸€éƒ¨åˆ†ï¼Œå…¶åœ°ä½ä¸æ™ºèƒ½å‹AIå¹³åˆ†ç§‹è‰²ï¼Œæˆ–è€…è¯´æ˜¯æ™ºèƒ½å‹AIçš„ä¸€ä¸ªé‡è¦åŸºç¡€ã€‚\n\næ•°åå¹´æ¥ï¼Œäººå·¥æ™ºèƒ½çŸ¥è¯†è¡¨ç¤ºå’Œæ„ŸçŸ¥æ¨ç†ä¸€ç›´æ˜¯äººå·¥æ™ºèƒ½ (AI) çš„åŸºçŸ³ã€‚è€ŒçŸ¥è¯†å›¾è°± (KG) æ˜¯ä¸€ç§å¼ºå¤§çš„æ•°æ®ç»“æ„ï¼Œå…¶ä¸»è¦ç‰¹ç‚¹ä¸ºä»¥å›¾çš„æ ¼å¼å‚¨å­˜å¹¶è¡¨ç¤ºè¡¨ç¤ºä¿¡æ¯ã€‚DBpedia ï¼ˆä¸€ä¸ªå¼€æºçš„çŸ¥è¯†å›¾è°±ï¼‰å°†çŸ¥è¯†å›¾è°±å®šä¹‰ä¸ºâ€œä¸€ç§ç‰¹æ®Šçš„æ•°æ®åº“ï¼Œå®ƒä»¥æœºå™¨å¯è¯»çš„å½¢å¼å­˜å‚¨çŸ¥è¯†ï¼Œå¹¶æä¾›ä¸€ç§æ”¶é›†ã€ç»„ç»‡ã€å…±äº«ã€æœç´¢å’Œåˆ©ç”¨ä¿¡æ¯çš„æ‰‹æ®µã€‚â€æœ€é‡è¦çš„æ˜¯ï¼ŒçŸ¥è¯†å›¾è°±æœ‰åŠ©äºå…¶ä»»ä½•æ•°æ®ç‚¹ä¹‹é—´çš„å…³ç³»æ¨ç†ã€‚ é€šè¿‡è¿™æ ·çš„å·¥å…·ï¼Œä½¿å¾—äººå·¥æ™ºèƒ½èƒ½å¤Ÿå¯¹æµ·é‡çš„çŸ¥è¯†è¿›è¡Œå­˜å‚¨ä»¥åŠè¡¨ç¤ºï¼Œå¹¶ä¸”å®ç°åƒäººä¸€æ ·çš„æ¨ç†ä»¥åŠå¾—å‡ºç»“è®ºã€‚\n\n\n2.List at least 3 techniques of Knowledge Graph, using examples in real life (do not use examples in this ppt)\nï¼ˆ1ï¼‰Reasoning based on Rules\n\n\n\n(2)  Knowledge-based Question Answeringæ—…æ¸¸å†…å®¹æ¨èæ—…æ¸¸äº§å“éå¸¸å¤šæ ·åŒ–ï¼Œæ‰€ä»¥å¾ˆä¾èµ–æ¨èã€‚æˆ‘ä»¬å¾€å¾€ä¼šæŠ“ä½æ—…æ¸¸äº§å“å’Œç”¨æˆ·çš„æµ…å±‚ç‰¹å¾å»æ¨èï¼Œè€Œå¿½ç•¥äº†ä¸€äº›æ·±å±‚æ¬¡çš„ç‰¹å¾ã€‚å½“ç”¨æˆ·å’ŒæŸä¸ªçŸ¥è¯†å›¾è°±å®ä½“äº§ç”Ÿå…³è”ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨çŸ¥è¯†å›¾è°±å»è¡¥å……ç”¨æˆ·ç‰¹å¾ã€‚\n\n\n\n  å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œå½“æˆ‘ä»¬é€šè¿‡æ•°æ®æŒ–æ˜å‘ç°ç”¨æˆ·Açš„å…´è¶£ç‚¹æ˜¯æµ·å²›å’Œäº”æ˜Ÿçº§é…’åº—åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡çŸ¥è¯†å›¾è°±å…³è”å‡ºç›¸å…³çš„å›¢é˜Ÿæ¸¸äº§å“ã€‚çŸ¥è¯†å›¾è°±æä¾›çš„ä¿¡æ¯å¯ä»¥ä½œä¸ºæ¨èç³»ç»Ÿçš„ä¸€ä¸ªé‡è¦ç»´åº¦ï¼Œå‚ä¸ä¸‹ä¸€æ­¥çš„è®¡ç®—ï¼Œä¸ºç²¾å‡†æ¨èå¢åŠ ä¸€å—ç ç ã€‚\n(3)Knowledge ExtractionåŠç»“æ„åŒ–æ•°æ®æŠ½å–\næ— ç»“æ„åŒ–æ•°æ®æŠ½å–\n","categories":["KnowledgeEngineering"]},{"title":"Graph Database","url":"/2021/08/15/knowledge%20engineering/14.%20Graph%20Database/","content":"Graph Database\n\n1.  Definition\nA database for storing and querying data in a data structure like graphs Composition\n\nNode \n\nSpecific entities, such as the movie â€œHarry Potter 2â€œ,\n\n\nRelation \nThe connection between entities.\n\n\nLabel \nAbstract concepts that group similar nodes together, such as movie characters.\n\n\nProperty \nSpecific information about the node or relationship, such as name, age, etc.\n\n\n\n2. Neo4j2.1 Introduction\nçŸ¥è¯†å›¾è°±å­˜å‚¨å·¥å…·ï¼šRDF4Jã€Jenaã€Neo4j\n\nNeo4j is a robust, scalable, high-performance open source graph database\n\n\n\n2.2 Neo4j-Important element2.2.1 Structural Node\nID: unique identifier\nLabel: a form of pattern syntax to group nodes together\nMap(properties): \nkey: property name \nvalue: property value\n\n\n\n\n\n2.2.2  Properties\nKey: property name\nValue: property value\n\nValue Type\nBoolean\nByte\nShort\nInt\nLong\nFloat\nDouble\nChar\nString\nArray\n\n\n2.2.3 Structural Relation\nID\nType\nMap(properties)\nID of the start node\nID of the end node\n\n\n\n2.2.4 Path\nAn sequence of nodes and relationships\nComposition \nat least one node \nconnected relationships\n\n\nOften as a result of a query or traversal\n\n\n\nA path from nodeA to nodeB\n\n\n3. Cypher3.1 Introduction\nCypher is a declarative graph query language that allows for expressive and efficient querying, updating and administering of the graph.\n\n\n\nNoteï¼š Keywords are not case sensitive\n\n3.2 Cypher-Create3.2.1 Create a node\n\n\n\nCREATE(\tnode:Movie\t&#123;\t\ttitle:&quot;The American President&quot;\t&#125;)\n3.2.2 Create relationshipsCREATE(&lt;node1-name&gt;:&lt;node1-label-name&gt;&#123;&lt;define-properties-list&gt;&#125;)-[&lt;relationship-name&gt;:&lt;relationship-label-name&gt;&#123;&lt;define-properties-list&gt;&#125;]-&gt;(&lt;node2-name&gt;:&lt;node2-label-name&gt;&#123;&lt;define-properties-list&gt;&#125;)\n\n\nExercise\nCreate the relationship using cypher.\n\n\nCREATE\t(n1:Person &#123;name:&#x27;Oliver Stone&#x27;&#125;)\t-[r:DIRECTED]\t-&gt;(N2:Movie&#123;title:&quot;Wall Street&quot;&#125;)\n3.3 Cypher-MATCH\nMatch\n\nMATCH    (&lt;node-name&gt;:&lt;label-name&gt;    &#123;    &lt;Property1-name&gt;:&lt;Property1-Value&gt;    ........    &lt;Propertyn-name&gt;:&lt;Propertyn-Value&gt;    &#125;)    -[&lt;relationship-name&gt;:&lt;relationship-label-name&gt;&#123;&lt;define-properties-list&gt;&#125;]    -&gt;(&lt;node-name&gt;:&lt;label-name&gt;    &#123;    &lt;Property1-name&gt;:&lt;Property1-Value&gt;    ........    &lt;Propertyn-name&gt;:&lt;Propertyn-Value&gt;    &#125;)RETURN ........\n\nReturn\nVariable, like node-name: node\nSpecific value, like node-name.property: node.name\n\n\n\n3.3.1 Match node\næŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹\n\nMATCH (n) RETURN n\n\n\næŸ¥è¯¢æ‰€æœ‰ç”µå½±title\n\nMATCH (movie:Movie)RETURN movie.title\n\n3.3.2 Match related nodes\nåå«Oliver Stoneç›¸å…³è”çš„äº‹ç‰©æ ‡é¢˜\n\nMATCH (director &#123;name: &#x27;Oliver Stone&#x27;&#125;)--(movie) RETURN movie.title\n\n\n\nâ€” : connected relationship of unknown relationship type and direction\n\nä¸äººç‰©Oliver Stoneç›¸å…³è”çš„ç”µå½±æ ‡é¢˜\n\n\nMATCH (:Person &#123;name: &#x27;Oliver Stone&#x27;&#125;)--(movie:Movie) RETURN movie.title\n\n\nä¸äººç‰©Oliver Stoneç›¸å…³è”çš„å…³ç³»ç±»å‹\n\nMATCH (:Person &#123;name: &#x27;Oliver Stone&#x27;&#125;)-[r]-&gt;(movie) RETURN type(r)\n\n\n-&gt; / &lt;- : directed relation, &gt; towards the tail entity\n\nå‡ºæ¼”åä¸ºâ€˜Wall Streetâ€™ç”µå½±çš„æ¼”å‘˜å§“å\n\n\nMATCH (wallstreet:Movie &#123;title: &#x27;Wall Street&#x27;&#125;)&lt;-[:ACTED_IN]-(actor) RETURN actor.name\n\n3.3.4 Match on multiple relationship types\nå‚æ¼”æˆ–å¯¼æ¼”åä¸ºWall Streetçš„ç”µå½±çš„æ‰€æœ‰äººç‰©\n\nMATCH (wallstreet:Movie &#123;title: &#x27;Wall Street&#x27;&#125;)&lt;-[:ACTED_IN|:DIRECTED]-(person:Person) RETURN person.name\n\n3.3.5 Match on relationship type and use a variable\nåä¸ºWall Streetçš„ç”µå½±çš„ä¸­æ‰€æœ‰çš„è§’è‰²\n\nMATCH (wallstreet:Movie &#123;title: &#x27;Wall Street&#x27;&#125;)&lt;-[r:ACTED_IN]-(actor) RETURN r.role\n3.4 Match and Create\nwhen nodes already exist, we can use MATCH first, then CREATE\n\n\nMATCH \t(charlie:Person &#123;name: &#x27;Charlie Sheen&#x27;&#125;),     (rob:Person &#123;name: &#x27;Rob Reiner&#x27;&#125;) CREATE     (rob)-[:TYPE INCLUDING A SPACE]-&gt;(charlie)\nExercise\næŸ¥è¯¢å‚æ¼”åä¸ºâ€˜The American Presidentâ€™çš„æ‰€æœ‰æ¼”å‘˜å§“å\n\n\nMATCH\t(person:Person)-[:ACTED_IN]\t-&gt;(movie:Movie&#123;title:&quot;The American President&quot;&#125;)RETURN person.name\n\næŸ¥è¯¢åŒ…å«è§’è‰²â€™Card Foxâ€™çš„ç”µå½±å\n\n\nMATCH\t(actor)-[:ACTED&#123;role:&quot;Card Fox&quot;&#125;]\t-&gt;(movie:Movie)RETURN movie.title\n3.5 Cypher-DELETE\nDelete single node\nDelete all nodes and relationships\nDelete a node with all its relationships\nDelete relationships only\n\n\n3.5.1 Delete single node\nåˆ é™¤åä¸ºUNKNOWNçš„èŠ‚ç‚¹\n\nMATCH (n:Person &#123;name: &#x27;UNKNOWNâ€™&#125;) DELETE n\n3.5.2 Delete all nodes and relationships\nåˆ é™¤æ•°æ®åº“ä¸­æ‰€æœ‰èŠ‚ç‚¹åŠä¸å…¶ç›¸è¿çš„å…³ç³»\n\nMATCH (n) DETACH DELETE n\n3.5.3 Delete a node with all its relationships\nåˆ é™¤åä¸ºAndyçš„èŠ‚ç‚¹å’Œä¸å…¶ç›¸è¿çš„æ‰€æœ‰å…³ç³»\n\nMATCH (n &#123;name: &#x27;Andyâ€™&#125;) DETACH DELETE n\n3.5.4 Delete relationships only\nåˆ é™¤Andyçš„æ‰€æœ‰KNOWSå…³ç³»\n\nMATCH (n &#123;name: &#x27;Andy&#x27;&#125;)-[r:KNOWS]-&gt;() DELETE r\nExercise\nåˆ é™¤äººç‰©å¹´é¾„ä¸º34å²çš„æ‰€æœ‰å…³ç³»\n\n\nMATCH (person:Person &#123;age:34&#125;)-[r]-&gt;()DELETE r\n3.6 Cypher-UPDATE :3.6.1 SET\nSET can be used with a map â€” provided as a literal, a parameter, or a node or relationship â€” to set properties.\n\nUpdate a property\n\n\nMATCH (n &#123;name: &#x27;Andy&#x27;&#125;) SET n.age = toString(n.age) RETURN n.name, n.age\n\n\n3.6.2 multiple properties using one SET clauseMATCH (n &#123;name: &#x27;Andy&#x27;&#125;) SET n.position = &#x27;Developer&#x27;, n.surname = &#x27;Taylor&#x27;\n3.6.3 Replace all properties using a mapMATCH (p &#123;name: &#x27;Peter&#x27;&#125;) SET p = &#123;name: &#x27;Peter Smithâ€™, \tposition: &#x27;Entrepreneur&#x27;&#125; RETURN p.name, p.age, p.position\n\nExercise\næ›´æ–°Georgeçš„å¹´é¾„ä¸º28\n\n\nMATCH (p &#123;name:&#x27;George&#x27;&#125;)SET p = &#123;name: &#x27;George&#x27;\tage: 28&#125;\nExercise\n\nWrite cypher to get the second graph\n\nMATCH \t(actor1:Actor &#123;name: &#x27;Anthony Hopkins&#x27;&#125;),\t(actor2:Actor &#123;name: &#x27;Hitchcock&#x27;&#125;),\t(movie:Movie &#123;title: &#x27;Hitechcock&#x27;&#125;)CREATE\t(actor1)-[r:ACTS_IN]\t-&gt;(movie)DELETE actor2\n\nQuery all relationship types connected by actor Anthony Hopkins\n\nMATCH\t(actor:Actor &#123;name: &#x27;Anthony Hopkins&#x27;&#125;)-[r]-()RETURN type(r)\n","categories":["KnowledgeEngineering"]},{"title":"1. XML","url":"/2021/08/15/knowledge%20engineering/2.%20XML%20Ref%20and%20Refs/","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\n1.1 Def:\nA markup language for documents containing structured information.\nç”¨äºæ•°æ®äº¤æ¢çš„ä¸€ç§æ ‡è®°è¯­è¨€\n\n\n1.2 Comparisonï¼š1.2.1 XMLï¼š\nExtensible set of tags  æ ‡ç­¾å¯ä»¥è‡ªå®šä¹‰\n\nContent orientated  æ•°æ®ä¸æ ¼å¼åˆ†ç¦»\n\nStandard Data infrastructure  ä¸å…è®¸å‡ºé”™\nAllows multiple output forms  æœ‰å¤šç§è¾“å‡ºæ ¼å¼\n1.2.2 HTMLï¼š\nFixed set of tags  æ ‡ç­¾æ— æ³•è‡ªå®šä¹‰\n\nPresentation oriented  æ•°æ®ä¸æ ¼å¼é•¶åµŒ\nNo data validation capabilities å…è®¸æœ‰erroræ˜¾ç¤º\nSingle presentation  å•ä¸€è¾“å‡ºæ ¼å¼\n\n1.3 XML Syntax\nempty elements can be abbreviated: e.g.  can be written as \nthe outermost element is called root element (there is only one)\n\nExampleï¼š&lt;?xml version=\"1.0\" encoding=\"GB2312\" ?&gt; &lt;!--ç‰ˆæœ¬å·ï¼Œç¼–ç --&gt;&lt;author&gt;&lt;!--å¼€å§‹tag--&gt;&lt;firstName&gt;Guilin&lt;/firstName&gt;\t&lt;lastName&gt;Qi&lt;/lastName&gt;\t&lt;email&gt;gqi@seu.edu.cn&lt;/email&gt; &lt;!--å­å…ƒç´ --&gt;\tThis is some text inside an XML element. &lt;!--text--&gt;&lt;/author&gt; &lt;!--end tag--&gt;\n1.4 XML Attributes:1.4.1 EP1:&lt;City ZIP=â€œ210000â€&gt; Nanjing&lt;/City&gt;\nâ€‹    \n1.4.2 EP2:&lt;author&gt;\t&lt;firstName&gt;Guilin&lt;/firstName&gt;\t&lt;lastName&gt;Qi&lt;/lastName&gt;\t&lt;email&gt;gqi@seu.edu.cn&lt;/email&gt;\tThis is some text inside an XML element.&lt;/author&gt;\nç­‰ä»·äº\n&lt;author email=â€œgqi@seu.edu.cnâ€&gt;\t&lt;firstName&gt;Guilin&lt;/firstName&gt;\t&lt;lastName&gt;Qi&lt;/lastName&gt;\tThis is some text inside an XML element.&lt;/author&gt;\n1.5 è§„èŒƒï¼šAuthoring guidelines:\n\nAll elements must have an end tag. æ ‡ç­¾æœ‰å¤´æœ‰å°¾\nAll elements must be cleanly nested (overlapping elements are not allowed). æ‰€æœ‰å…ƒç´ å¿…é¡»ä¸èƒ½é‡å¤\nAll attribute values must be enclosed in quotation marks. \nEach document must have a unique first element, the root node.\nå¤§å°å†™æ•æ„Ÿ\n\nExerciseï¼š&lt;book&gt;\t&lt;title&gt;Knowledge Graph&lt;/Title&gt; &lt;!--å°¾æ ‡ç­¾æœ‰è¯¯--&gt;\t&lt;author&gt;\t\t&lt;firstName&gt;Guilin&lt;/firstName&gt;\t\t&lt;lastName&gt;Qi&lt;/lastName&gt;\t\t&lt;email&gt;gqi@seu.edu.cn&lt;/email&gt;\t\tThis is some text inside an XML element.\t&lt;/author&gt;\t&lt;author&gt;\t\t&lt;firstName&gt;Tianxing&lt;lastName&gt;\t\t&lt;/firstName&gt;Wu&lt;/lastName&gt; &lt;!--åµŒå¥—å‡ºé”™--&gt;\t&lt;email&gt;tianxingwu@seu.edu.cn&lt;/email&gt;&lt;/author&gt;&lt;!--ç¼ºå°‘&lt;/book&gt;--&gt;\n1.6 XMLæ’å…¥HTML&lt;æ–‡ç« &gt; \t&lt;æ®µè½&gt;&lt;![CDATA[ \t\t&lt;html&gt; &lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt; \t\t\t&lt;body&gt;            \t&lt;h1&gt;ä¸œå—å¤§å­¦&lt;/h1&gt;             &lt;/body&gt;         &lt;/html&gt;]]&gt;      &lt;/æ®µè½&gt;  &lt;/æ–‡ç« &gt;\n1.7 XML Namespacesï¼š\nä¸ºäº†è§£å†³å±æ€§ç›¸åŒäº§ç”Ÿæ­§ä¹‰è€Œæå‡º\n\n&lt;h:table xmlns:h=\"http://www.w3.org/TR/html4/\"&gt;\t&lt;h:tr&gt;\t\t&lt;h:td&gt;Apples&lt; / h:td&gt;\t\t&lt;h:td&gt;eananas&lt; / h:td&gt;\t&lt; / h:tr&gt;&lt;/ h:table&gt;\n\nDefining the default namespaces:\n\n&lt;table xm1ns=\"http:// www.w3.org/TR/htm14/ \"&gt;\t&lt;tr&gt;\t\t&lt;td&gt;Apples&lt;/td&gt;\t\t&lt;td&gt;Bananas&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;\n\n1.8 URI format:\n1.9 XML Schema:\n\nç”±äºXMLè¿‡äºçµæ´»ï¼Œæ‰€ä»¥éœ€è¦å®šä¹‰ä¸€ç§è§„èŒƒï¼Œä»¥ä¾¿äºæ•°æ®äº¤æ¢\n\nä¸‹é¢ä¸ºç¤ºä¾‹ä»£ç ï¼š\n\n\n&lt;?xml version=â€œ1.1â€ encoding=â€œutf-16â€?&gt;&lt;xsd:schema xmlns:xsd=â€œhttp://www.w3.org/2001/XMLSchemaâ€&gt; &lt;!--å¯ä»¥ç†è§£ä¸ºå®šä¹‰äº†ä¸€ä¸ªæ ¼å¼--&gt;\t&lt;xsd:element name=â€œauthorâ€ type=â€œxsd:stringâ€ \t\t\t\tminOccurs=â€œ1â€ maxOccurs=â€œunboundedâ€&gt;  &lt;!--å®šä¹‰äº†å…ƒç´ --&gt;\t\t&lt;xsd:attribute name=â€œemailâ€ type=â€œxsd:stringâ€use=â€œrequiredâ€&gt; &lt;!--å…·ä½“ä¸€äº›å±æ€§--&gt;\t\t&lt;xsd:attribute name=â€œhomepageâ€ type=â€œxsd:anyURIâ€ use=â€œoptionalâ€&gt;\t&lt;/xsd:element&gt;&lt;/xsd:schema&gt;\n2 RDF2.1 Def:\nå¯¹ç½‘ç«™æºæ•°æ®è¿›è¡Œæ ‡æ³¨ï¼Œç”¨äºæœºå™¨å¯è¯»çš„æ•°æ®äº¤æ¢ã€‚\n\nThe data model of Semantic Technologies and of the Semantic Web\n\n\n\n2.2 URI\nä¸ºäº†è§£å†³å‘½åæ¨¡ç³Šé—®é¢˜ï¼ŒRDFä¹Ÿé‡‡ç”¨URIå®šä¹‰sourceçš„å½¢å¼\n\n\n2.3 QName2.3.1 Def:used in RDF as shorthand for long URIs (IRIs)\nExample:\n\n\n\næ—¢å¯ä»¥ç”¨QNameså½¢å¼ï¼Œä¹Ÿå¯ä»¥ç”¨URIå½¢å¼\n\n\n2.4 RDF Triple (Statement):\n\nå¯ä»¥å‘ç°S P Oéƒ½å¯èƒ½æ˜¯Resource\n\n2.4.1 ResourcesDef: IRIs  ç±»ä¼¼å‘½åç©ºé—´2.4.2 LiteralsDef:  ç±»ä¼¼ä¸€ä¸ªå€¼ï¼Œæ”¾åœ¨å°–å«æ‹¬å·å¤–\ndata values; \nencoded as strings; \ninterpreted by datatypes; \ntreated the same as strings without datatypes, called plain literal; \nA plain literal may have a language tag; \nDatatypes are not defined by RDF, but usually from XML Schema.\n\n\nå¤§è‡´æ„æ€æ˜¯ï¼šliteralsåˆ†ä¸ºæœ‰ç±»å‹çš„å’Œæ— ç±»å‹çš„ï¼Œå…¶æœ‰ç±»å‹çš„ç±»å‹ä¸€èˆ¬æ¥è‡ªäºå‘½åç©ºé—´ï¼Œå¯¹äºæ— ç±»å‹çš„ï¼Œè¢«ç§°ä¸ºplain literalsï¼›å…¶ä¸­plain literalsåˆå¯ä»¥è¢«è¯­è¨€æ ‡ç­¾æ ‡æ³¨ï¼Œç”¨äºè§£é‡Šliteralsçš„è¯­è¨€ç±»å‹ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥ä¸è¿›è¡Œä¸æ ‡æ³¨ï¼Œä½†æ³¨æ„è¿™ä¸¤ç§literalsæ˜¯ä¸åŒçš„ã€‚\n\n&lt;!--Typed Literals:--&gt;â€œBeantownâ€^^xsd:stringâ€œThe Bay Stateâ€ ^^xsd:string&lt;!--Plain literal and literals with language tags:--&gt;â€œFranceâ€ â€œFranceâ€@en â€œFranceâ€@frâ€œæ³•å›½â€@zh â€œFrankreichâ€@de&lt;!--Equalities for Literals:--&gt; â€œ001â€^^xsd:integer = â€œ1â€^^xsd:integer â€œ123.0â€^^xsd:decimal = â€œ00123â€^^xsd:integer (based on datatype hierarchy)&lt;!--ä¸Šé¢è¿™ä¸¤ç§å½¢å¼ç­‰ä»·ï¼Œå› ä¸ºintegeræ˜¯decimalçš„çˆ¶èŠ‚ç‚¹--&gt;\n\n\nDoes the datatype â€œå¾·å›½â€ equals to â€œå¾·å›½â€ @ zh ?\nAnswerï¼šä¸ç›¸åŒï¼Œå› ä¸ºä»–ä»¬ä½äºçš„å±‚æ¬¡ç»“æ„ä¸åŒ\n\n\n\nBlank nodeDef: unnamed resource or complex node (later)æ— åçš„èµ„æºæˆ–è€…å¤æ‚çš„èŠ‚ç‚¹ï¼Œç®€å•æ¥è¯´å°±æ˜¯å›¾ä¸Šç©ºçš„èŠ‚ç‚¹ï¼Œè¯­ä¹‰è¾ƒæ¨¡ç³Šçš„ä½ç½®\nRepresentation of blank nodes is syntax-dependent:underline+colon+ID (Turtle syntax): _:xyz, _:bn; ä¸‹åˆ’çº¿åŠ å†’å·åŠ ID\n\n\n2.5 RDF Syntax2.5.1 Turtle\nlist as S P O triples (easy to read)å°†ä¸»è°“å®¾ä¾æ¬¡åˆ—å‡º\nIRIs are in  IRIsåœ¨&lt;&gt;ä¸­ï¼Œä¹Ÿå°±æ˜¯sources\ntriples end with a full-stop .ä»¥ . ç»“æŸ\nwhitespaces are ignoredç©ºç™½å¯ä»¥çœç•¥\n\n\n\nIRISç›´æ¥è¡¨ç¤º\n\n&lt;http://dbpedia.org/resource/Massachusets&gt; &lt;http://example.org/terms/captial&gt; &lt;http://dbpedia.org/resource/Boston&gt; . &lt;http://dbpedia.org/resource/Massachusets&gt; &lt;http://example.org/terms/nickname&gt; â€œThe Bay Stateâ€. &lt;http://dbpedia.org/resource/Boston&gt; &lt;http://example.org/terms/inState&gt; &lt;http://dbpedia.org/resource/Massachusets&gt;. &lt;http://dbpedia.org/resource/Boston&gt; &lt;http://example.org/terms/nickname&gt; â€œBeantownâ€. &lt;http://dbpedia.org/resource/Boston&gt; &lt;http://example.org/terms/population&gt; â€œ642109â€^^xsd:integer.\n\nQNameè¡¨ç¤ºï¼š\n\n@prefix db: &lt;http://dbpedia.org/resource/&gt; @prefix dbo: http://example.org/terms/ #é¢„å®šä¹‰QNamesdb:Massachusets dbo:capital db:Boston . db:Massachusets dbo:nickname â€œThe Bay Stateâ€ . db:Boston dbo:inState db:Massachusets . db:Boston dbo:nickname â€œBeantownâ€ . db:Boston dbo:population â€œ642109â€^^xsd:integer .\n\nQNameç®€åŒ–ä¹¦å†™æ¡ä¾‹ï¼š\n\nGrouping of triples with the same subject using semi-colon â€˜;â€™; ä¸»è¯­ç›¸åŒå¯ç”¨;é—´éš”\n\nGrouping of triples with the same subject and predicate using comma â€˜,â€™.ä¸»è¯­è°“è¯­ç›¸åŒå¯ç”¨,é—´éš”\n\n\n\n\n@prefix db: &lt;http://dbpedia.org/resource/&gt; @prefix dbo: http://example.org/terms/ db:Massachusets dbo:captial db:Boston ; \t\t\t\tdbo:nickname â€œThe Bay Stateâ€ . db:Boston dbo:inState db:Massachusets ; \t\t  dbo:nickname â€œBeantownâ€ ; \t\t  dbo:population â€œ642109â€^^xsd:integer .\n2.5.2 RDF/XML:Def: RDF is originally designed on basis of XML (data exchange format on the Web)\na lot of tools and libraries support XML\n\nNamespaces are used for disambiguating tags; \n\nTags belonging to the RDF language come with a fixed namespace, usually abbreviated â€œrdfâ€. rdfæœ‰å›ºå®šçš„å‘½åç©ºé—´\n\n\n\n\nå¯ä»¥è¿™ä¹ˆç†è§£ï¼Œé¦–å…ˆè¦è¯´æ˜è¿™ä¸ªéƒ¨åˆ†ä¸ºRDFè¯­å¥ï¼Œä»¥åŠå£°æ˜è¿™éƒ¨åˆ†æ‰€éœ€è¦ä½¿ç”¨çš„å‘½åç©ºé—´ï¼›\n\nç„¶åï¼Œå®šä¹‰ä¸»ä½“æè¿°å†…å®¹ï¼šä¸»è¯­ è°“è¯­ å®¾è¯­\n\nå¯¹äºrdf:Descriptionçš„elementåŒ…å«å¯¹resourceçš„æè¿°ï¼Œå¹¶è¢«rdf:aboutè¯†åˆ«\nex:publishedByä¹Ÿè•´å«äº†resourceå¸¸å¸¸ç”¨ä½œè°“è¯­\n\n&lt;rdf:Description rdf:about=\"http: //semantic-web-book.org/uri\"&gt; &lt;!--ä¸»è¯­--&gt;&lt;ex:title&gt;Foundations of Semantic web Technologies&lt;/ex:title&gt; &lt;!--è°“è¯­ å®¾è¯­ï¼ˆliteralsï¼‰--&gt;&lt;ex :publishedBy&gt; &lt;!--å¹¶åˆ—è°“è¯­--&gt;\t&lt;rdf : Description rdf:about=\"http://crcpress.com/uri\"&gt;      &lt;!--ä¸Šä¸€çº§çš„å®¾è¯­ ä¹Ÿæ˜¯ä¸‹ä¸€çº§çš„ä¸»è¯­ æ­¤å¤„ä¸ºåµŒå¥—ç»“æ„--&gt;\t\t&lt;ex : name&gt;CRC Press&lt;/ex :name&gt;         &lt;!--å®¾è¯­ï¼ˆliteralsï¼‰--&gt;\t&lt;/rdf : Description&gt;&lt;/ex :publishedBy&gt;&lt;l rdf :Description&gt;\n\n\n2.6 RDFè¡¨ç¤ºNå…ƒå…³ç³»\n\nç”¨ä¸€ä¸ªèŠ‚ç‚¹ä¸­ä»‹\n\n\n\n\nåˆ©ç”¨ä¸€ä¸ªç©ºèŠ‚ç‚¹\n\n\n&lt;rdf :Description rdf :about=\"http: //example.org/Chutney\"&gt;\t&lt;ex :hasIngredient rdf:nodeID=\"id1\"/&gt; &lt;!--ä¸å…·ä½“æŒ‡æ˜å®¾è¯­ï¼Œè€Œæ˜¯ç”¨å±æ€§nodeIDå®šä¹‰ä¸€ä¸ªå­—ç¬¦ä¸²--&gt;&lt;/rdf : Description&gt;&lt;rdf : Description rdf :nodeID=\"id1\"&gt;    &lt;!--ç´§æ¥ä¸Šæ–‡çš„nodeIDï¼Œç§°ä¸ºä¸»è¯­resource--&gt;\t&lt;ex : ingredient rdf :resource=\"http : / /example.org/greenMango\" /&gt;    &lt;ex : amount&gt;1lb&lt;/ex : amount&gt;&lt;/rdf : Description&gt;\n2.7 RDF vs XML\nIRIs solve the problem of term meaning.   IRIsè§£å†³å‘½åé‡å¤é—®é¢˜\nTriple-based data model describe relations or properties among terms. RDFè§£å†³æ•°æ®é—´çš„å…³ç³»\n\nTriple is good and easy to use, but cannot cover all kinds of knowledge! Semantic Web Knowledge Graph\n2.8 Exercise\n@prefix sw: &lt;http://www.semanticweb.org/ontology-9/&gt;sw:John sw:is_a sw:professors;\t\tsw:has_id sw:987654321;\t\tsw:has_name sw:John Doe.\n3. RDFs3.1 Def\nä¸ºRDF dataæä¾›è¯æ±‡é›†ï¼Œå¸®åŠ©å®šä¹‰RDF schema\nallows for specifying schema knowledge; âˆ™\nMothers are female \nOnly persons write books \nis a part of the W3C Recommendation.\n\n\n\n\nRDFsä¸ºRDFå®šä¹‰ä¸€äº›æŠ½è±¡ç±»åˆ«è¯æ±‡ï¼Œä»¥ä¾¿äºè§„èŒƒRDFçš„ä½¿ç”¨\nä¸ºä½•ä¸ç”¨XML Schema?\nå› ä¸ºXML Schemaæ²¡æœ‰è¯­ä¹‰semantics\nå› ä¸ºå…¶å¼•ç”¨çš„thingsä¸èƒ½è¶…è¿‡document\n\n\n\n3.2 RDFS: Class and Instance\nGiven a triple: \n\nex:Semantic     Web rdf:type     ex:Textbook .\n\nInstance and class names cannot be distinguished syntactically with IRIs   \nä½†æ˜¯rdfä¸èƒ½æ˜¾ç¤ºè¡¨ç¤ºè¿™æ˜¯ä¸€ç§æŠ½è±¡çš„å…³ç³»\n\n\n\nRDFS helps explicitly state that a resource denotes a class:\n\nrdfs:Class is theâ€œclass of all classesâ€.\n\n\n\n\n3.3 RDFS: Class Hierarchy (Taxonomy)3.3.1 rdfs: subClassOf is also reflexive: è‡ªåæ€§\nex:Textbook rdfs: subClassOf ex:TextBook . \nex:Book rdfs:subClassOf ex:Book .\n\n3.3.2 rdfs: subClassOf can derive class equivalence:ç­‰ä»·æ€§\n\n3.4 RDFså¯ä»¥ç¼©å†™\n\nå¤§è‡´æ„æ€æ˜¯å¯ä»¥ç”¨rdfs:ClassåŒæ—¶ä»£æ›¿rdf:Descriptionä¸rdf:typeï¼Œå¤§è‡´æ˜¯å› ä¸ºrdfsç›´æ¥åŒ…å«äº†classï¼Œç›´æ¥è¡¨é¢äº†è¯¥å®šä¹‰ä¸‹ä¸ºä¸€ä¸ªç±»\n\n\n3.5 RDFS: Property and Property Hierarchy\nå¯ä»¥è¿›è¡Œç®€ç­”æ¨ç†\n\n\n3.6 RDFS: Property Restrictions\nè°“è¯­æœ‰å€¼åŸŸä¸å®šä¹‰åŸŸï¼šå³ä¸»è¯­çš„å–å€¼èŒƒå›´ä»¥åŠå®¾è¯­çš„å–å€¼èŒƒå›´\n\n\n\nè°“è¯çš„å€¼åŸŸå¯ä»¥è¿›è¡Œäº¤é›†ä¸å¹¶é›†\n\n\n3.7 RDFS: Reification\nç”¨ç©ºèŠ‚ç‚¹è¡¨ç¤ºä¸€ç§å¤æ‚çš„å…³ç³»\n\n\n\nRepresent the following sentence graphically by means of the blank node:Wikipedia said that Tolkien wrote Lord of the Rings.\n\n\n3.8 Example: Reasoning with RDFS\nGivenï¼š\n\nex:happilyMarriedWith rdfs:subPropertyOf ex:isMarriedTo . ex:isMarriedTo rdfs:domain ex:Person . ex:isMarriedTo rdfs:range ex:Person . ex:pascal ex:happilyMarriedWith ex:lisa .\n\nå¯æ¨å‡ºï¼š\n\nex:pascal ex:isMarriedTo ex:lisa . ex:pascal rdf:type ex:Person . ex:lisa rdf:type ex:Person .\nExerciseï¼šWhat can be inferred from the following triples using RDFS semantics?\nex:Postgraduate_student rdfs:subClassOf ex:Student ex:Professor rdfs:subClassOf ex:Academic_staff ex:Supervise rdfs:domain ex:Professor ex:Supervise rdfs:range ex:Postgraduate_student ex:John ex:Supervise ex:Mary\nex:John rdf:type ex:Professor ex:Mary rdf:type ex:Postgraduate_student ex:John rdf:type ex:Academic_staffex:Mary rdf:type ex:Studentt\n","categories":["KnowledgeEngineering"]},{"title":"OWL","url":"/2021/08/15/knowledge%20engineering/3.%20OWL/","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\n1. Introduction to Knowledge Graph Representation (II)1.1 Write RDF in Turtle for the part circled by the red line. All resources are defined in the namespace, and the prefix of its QName is â€œswâ€.\nsw:John sw:is_a sw:professors . sw:John sw:has_name â€œJohn Doeâ€ . sw:John sw:has_id â€œ987654321â€ .\nsw:John sw:is_a sw:professors ; \t\tsw:has_name â€œJohn Doeâ€ ; \t\tsw:has_id â€œ987654321â€ .\n1.2 Represent the following sentence graphically by means of the blank node: Wikipedia said that Tolkien wrote Lord of the Rings.\n1.3 What can be inferred from the following triples using RDFS semantics?1) ex:Postgraduate_student rdfs:subClassOf ex:Student 2) ex:Professor rdfs:subClassOf ex:Academic_staff 3) ex:Supervise rdfs:domain ex:Professor 4) ex:Supervise rdfs:range ex:Postgraduate_student 5) ex:John ex:Supervise ex:Mary\n3)5) â†’ ex:John rdf:type ex:Professor (6) 4)5) â†’ ex:Mary rdf:type ex:Postgraduate_student (7) 2)6) â†’ ex:John rdf:type ex:Academic_staff 1)7) â†’ ex:Mary rdf:type ex:Student\n1.4 New Exercises:1.4.1 Use a RDF graph to represent the sentence â€œJohn is working in a company located in Sydneyâ€ (bland node can be considered).\nè¿™é‡Œçš„ç©ºç™½èŠ‚ç‚¹æ˜¯ä¸€ä¸ªå®ä¾‹ï¼ˆåŒºåˆ«äºä¸Šä¸€é¢˜æ˜¯ä¸€ä¸ªä¸‰å…ƒç»„ï¼‰\n\n\n\nä¸èƒ½ç”¨located inä¿®é¥°companyï¼Œå› ä¸ºè¿™é‡Œçš„companyåªæ˜¯ä¸€ä¸ªæ¦‚å¿µï¼Œä¸æ˜¯æ‰€æœ‰companyéƒ½åœ¨Sydney\n\n1.4.2 2. Does the datatype â€œ3.14â€^^xsd:string equal to â€œ+03.14â€^^xsd:string? If not, why?Answer:ä¸æ˜¯ï¼›è¿™æ˜¯å­—ç¬¦ä¸²å½¢å¼ï¼Œå­—ç¬¦ä¸²è¦è€ƒè™‘æ¯ä¸ªcharacterï¼Œæ˜æ˜¾ä¸¤ä¸ªå­—ç¬¦ä¸²ä¸ä¸€æ ·ã€‚\n2. owl2.1 Def\nA more expressive vocabulary definition language.è¯æ±‡å®šä¹‰è¯­è¨€ã€‚\n\n2.2 Why do we need OWL?\nRDFS does not have constraints on property domain and range: å¯¹è°“è¯æ²¡æœ‰çº¦æŸ\nFor â€œHumanâ€, the range of â€œhasChildâ€ should be â€œHumanâ€; \nFor â€œElephantâ€, the range of â€œhasChildâ€ should be â€œElephantâ€.\n\n\nRDFS does not have cardinality constraints: æ²¡æœ‰ä¸€ä¸ªåŸºæ•°çº¦æŸ\nThe number of â€œFatherâ€ for one person should be one; One person has at most two parent. (property: â€œhasParentâ€)\n\n\nRDFS does not have descriptions on property characteristics:\ntransitivity ä¼ é€’æ€§, symmetryå¯¹ç§°æ€§, functionalityå‡½æ•°æ€§, relations to other properties (inverse, equivalence)â€¦\n\n\nRDFS lacks definitions on equivalence: ç¼ºå°‘å¯¹ç­‰ä»·çš„å®šä¹‰\nequivalence on individuals, classes, and properties\n\n\n\n2.3 What is Ontology?\n\nå¯ä»¥ç†è§£ä¸ºå°±æ˜¯Schemaã€‚\n\nDef:\n\nformal : machine-readable æœºå™¨å¯ç†è§£\nexplicit : unambiguous vocabulary definitions æ²¡æœ‰æ­§ä¹‰\nshared : widely accepted and reused å…¬è®¤çš„\nconceptualization ï¼šç‰¹å®šé¢†åŸŸå»ºæ¨¡\n\næ•´ä½“ç†è§£å°±æ˜¯ä¸€ç§æœºå™¨å¯ç†è§£ã€æ¸…æ™°æ— æ­§ä¹‰ã€å…¬è®¤çš„ã€ç‰¹å®šé¢†åŸŸå»ºæ¨¡çš„è¯­è¨€\n2.4 Details2.4.1 Equivalence between classes, individuals, and properties: ä¸€äº›ç­‰ä»·å…³ç³»exp:Athlete owl:equivalentClass exp:SportsPlayer . exp:obtain owl:equivalentProperty exp:acquire . exp:SportsPlayerA owl:sameAs exp:Thomas .\n2.4.2 Disjointness between classes: ç±»åˆ«ä¸ç›¸äº¤å…³ç³»exp:Man owl:disjointWith exp:Woman .\n2.4.3 Intersection of classes: äº¤é›†exp:Mother rdf:type owl:class ; \t\t   owl:intersectionOf (exp:Woman exp:Parent) .\n\nè¿™é‡Œæ‹¬å·é‡Œé¢å¯ä»¥æœ‰æ›´å¤šç±»åˆ«\n\n2.4.4 Negation of a class: ç±»åˆ«å–åexp:ABC rdf:type owl:class ; \t\towl:complementOf exp:Meat .\n2.4.5 Property definitions: object property and data property.å¯¹å±æ€§çš„å®šä¹‰ï¼ˆè°“è¯ï¼‰ex:friendOf rdf:type owl:ObjectProperty . ex:age rdf:type owl:DataProperty .\n2.4.6 Transitive property: ä¼ é€’æ€§exp:ancestor rdf:type owl:TransitiveProperty .\n\nGiven triples\n\nexp:Thmoas exp:ancestor exp:Jimmy . exp:Jimmy exp:ancestor exp:Michael .\n\nThen what can we infer from them?\n\nexp:Thmoas exp:ancestor exp:Michael .\n2.4.7 Functional property:exp:hasMother rdf:type owl:FunctionalProperty .\n\nPlease explain using natural language:Everyone has only one mother.\n\nè°“è¯çš„å‡½æ•°ç‰¹æ€§è¡¨ç¤ºä»–çš„rangeå–å€¼åªèƒ½æœ‰ä¸€ä¸ª\n\n\n2.4.8 inverse functional property å…·æœ‰åå‡½æ•°ç‰¹æ€§exp:postgraduateSupervisor rdf:type owl:InverseFunctionalProperty .\n\nPlease explain using natural language:\n\nEach post-graduate student has only one supervisor.\n\nè¿™è¡¨ç¤ºè°“è¯­çš„å®šä¹‰åŸŸåªèƒ½æœ‰ä¸€ä¸ª\n\n2.4.9 Symmetric property å¯¹ç§°ç‰¹æ€§exp:friendOf rdf:type owl:SymmetricProperty .\n\nGiven a triple\n\nexp:Thmoas exp:friendOf exp:Lisa .\n\nThen what can we infer from it?\n\nexp:Lisa exp:friendOf exp:Thmoas .\n2.4.10 Inverse relations between propertiesexp:ancestor owl:inverseOf exp:descendant .\n\nGiven a triple\n\nexp:Thmoas exp:ancestor exp:Jimmy .\n\nThen what can we infer from it?\n\nexp:Jimmy exp:descendant exp:Thmoas .\n2.4.11 Constraints on properties: universal quantifier âˆ€ä»»æ„ï¼ˆè°“è¯é™å®šè¯ï¼‰exp:Person rdf:type owl:Restriction ; \t\t   owl:onProperty exp:hasMother ; #è¡¨ç¤ºPersonå¯ä»¥å……å½“hasMotherçš„ä¸»è¯­           owl:allValuesFrom exp:Women . #è¡¨ç¤ºå‰ä¸€å¥è°“è¯­çš„rangeçš„å–å€¼èŒƒå›´\n\nWhat do we know from the above triples?\nIf the subject of exp:hasMother comes from the class exp:Person, then the object can be only from the class exp:Women\n\n2.4.12 Constraints on properties: existential quantifier âˆƒ å­˜åœ¨exp:SemanticWebPapers rdf:type owl:Restriction ; \t\t\t\t\t  owl:onProperty exp:publishedIn ; \t\t\t\t\t  owl:someValuesFrom exp:AAAIPapers . #å­˜åœ¨ä¸€éƒ¨åˆ†çš„å‘è¡¨åœ¨AAAIPapers\n\nWhat do we know from the above triples?\nIf the subject of exp:publishedIn comes from the class exp:SemanticWebPapers, then the object may be (at least one) from the class exp:AAAIPapers.\n\nA part of the Semantic Web papers were published in AAAI.\n\n\n2.4.13 Constraints on properties: cardinalities åŸºæ•°çº¦æŸexp:Person rdf:type owl:Restriction ; \t\t   owl:onProperty exp:hasParent ; \t\t   owl:cardinality â€œ2â€^^xsd:integer . #é™å®šhasParentçš„rangeåªèƒ½æœ‰ä¸¤ä¸ª\n\nPlease explain using natural language:\nEach person should have two parents.\n\ncardinalityä¹Ÿå¯ä»¥æ¢æˆowl:maxCardinality/ owl:minCardinalityï¼Œè¡¨ç¤ºæœ€å¤šæˆ–è€…æœ€å°‘\n\n\n2.5 Exercise2.5.1\nPlease explain the following triples using natural language:\n\n@prefix sw: &lt;http://semanticweb.org/&gt; @prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; . @prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; . @prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; . sw:Giraffe rdfs:subClassOf _:x ._:x rdfs:subClassOf sw:Animal ; \trdf:type owl:Restriction ; \towl:onProperty sw:eat ; \towl:allValuesFrom sw:Leaf .\n\nGiraffe is a kind of animal which eats leaves.\n\n2.5.2\nPlease write the corresponding RDF triples (in Turtle) of the following sentence: â€œChildlessPersons are the persons who are not parentsâ€. Note that classes â€œChildlessPersonâ€, â€œPersonâ€, â€œParentâ€ are defined in the namespace http://semanticweb.org/ with the prefix â€œSWâ€.\n\n_:x0 rdf:type owl:class;\t owl:complement owl:Parent._:x1 rdf:type owl:class;\t owl:intersectionOf (sw:Person _:x0);\t owl:equivalentClass sw:ChildlessPerson.\n2.6 OWL Sub-Languages\nOWL Lite \nOWL DL \nOWL Full\n\n\nOWL2\n","categories":["KnowledgeEngineering"]},{"title":"Description Logic","url":"/2021/08/15/knowledge%20engineering/4.%20Description%20Logic/","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\n1. Why adding such definitions in OWL? How to know them?\nWe expect the vocabulary definition language should have following features: \nEasy to use and understand \nFormal representation \nSufficient expressive ability \nSupport automated reasoning (decidable with suitable complexity)\n\n\n\n2. Propositional Logic2.1 Proposition2.1.1 Def\nA Proposition is a statement which has truth value: it is either true (T) or false (F).\n\nå¯ä»¥åˆ¤æ–­å¯¹é”™çš„é™ˆè¿°å¥\n\n\n2.1.2 Example\nWhich of the following are propositions?\n17 + 25 = 42 (âˆš) \nJuly 4 occurs in the winter in the Northern Hemisphere. (âˆš) \nThe population of the United States is less than 250 million. (âˆš) \nIs the moon round  (âˆš)\n\n\n\n2.2 Propositional Logic2.2.1 Def:\ndeals with propositions (which can be true or false) and relations between propositions, including the construction of arguments based on them.\nå³å¤„ç†å‘½é¢˜ä»¥åŠå‘½é¢˜ä¹‹é—´çš„å…³ç³»ã€‚\n\n2.2.2 multiple statements with logical connectives\nNegation (not): Â¬\nConjunction (and): âˆ§ ,\nDisjunction (or): âˆ¨,\nMaterial implication (ifâ€¦then): â†’ ,\nBiconditional (if and only if): â†” .\n\n2.2.3 Example\nIf it is sunny outside then I walk to work; otherwise I drive, and if it is raining then I carry my umbrella.\n\np = â€œIf it is sunny outsideâ€ \nq = â€œI work to workâ€ \nr =â€œI driveâ€ \ns =  â€œIt is rainingâ€ \nt = â€œI carry my umbrellaâ€\n\n\nIf p then q; otherwise r and if s then t. \n\nIf p then q and (if not p then (r and (if s then t))). \n(p â†’ q) âˆ§ (Â¬ Â¬ p â†’(r âˆ§ (s â†’ t)))\n\n2.2.4 Rule Reasoning: Modus Ponens æ¨ç†ä¸‰æ®µå¼\n","categories":["KnowledgeEngineering"]},{"title":"Knowledge Graph Reasoning","url":"/2021/08/15/knowledge%20engineering/5.Knowledge%20Graph%20Reasoning/","content":"Knowledge Graph Reasoning\n1. ç®€ä»‹1.1 Def\nKG Reasoning is to infer new knowledge from the given KG.\n\nClassification:\n\nLogical reasoning ä¸»è¦ä»‹ç» \nStatistical reasoning\n\n\n\n1.2 Logical Reasoning include:\nDeductive Reasoning determines whether the truth of a conclusion can be determined for that rule, based solely on the truth of the premises. æ¨å¯¼ç»“è®º\n\nInductive Reasoning attempts to support a determination of the rule. å­¦ä¹ è§„åˆ™\n\nAbductive reasoning selects a cogent set of preconditions.å¯»æ‰¾å‰æ\n\nExample:\n\npre-condition: it rains \nrule: if it rains, then the grass gets wet \nconclusion: the grass gets wet\n\nDeductive Reasoning: If it rains, then the grass gets wet. Since today is raining, the grass is wet. è‹¥ä¸‹é›¨ï¼Œåˆ™è‰åœ°ä¼šå˜æ¹¿ã€‚å› ä¸ºä»Šå¤©ä¸‹é›¨äº†ï¼Œæ‰€ä»¥ä»Šå¤©è‰åœ°æ˜¯æ¹¿çš„ã€‚ \n\nInductive Reasoning: The grass is wet each time when it rains. Thus, if it rains, then the grass gets wet. æ¯æ¬¡ä¸‹é›¨ï¼Œè‰åœ°éƒ½æ˜¯æ¹¿çš„ã€‚æ‰€ä»¥ä¸‹é›¨ä¼šä½¿è‰åœ°å˜æ¹¿ã€‚\n\nAbductive Reasoning: If it rains, then the grass gets wet. The grass is wet because it is raining. è‹¥ä¸‹é›¨ï¼Œè‰åœ°ä¼šå˜æ¹¿ã€‚ä¹‹æ‰€ä»¥è‰åœ°æ˜¯æ¹¿çš„ï¼Œå› ä¸ºæ­£åœ¨ä¸‹é›¨ã€‚\n\n\n1.3 Classification:\nForward reasoning \nBackward reasoning\n\n2. Forward reasoning2.1 Def\nstarts with the available data and uses inference rules to extract more data until a goal is reached.åˆ©ç”¨å·²æœ‰çš„è§„åˆ™ä¸æ–­è·å–æ–°çš„çŸ¥è¯†ï¼Œç›´åˆ°çŸ¥è¯†äº§ç”Ÿï¼Œæ³¨ï¼šç›®æ ‡å¹¶ä¸æ˜¯æ˜ç¡®çš„\n\nAn inference engine using forward chaining searches the inference rules until it finds one where the antecedent  å…ˆå‰çš„ (If clause) is known to be true.\nWhen such a rule is found, the engine can conclude, or infer, the consequent (Then clause), resulting in the addition of new information to its data. å½’çº³æ–°çŸ¥è¯†\n\nThe forward chaining approach is often employed by expert systems.\n\n\n\n\n2.2 Materialization å®ä½“åŒ–\nMaterialization is to compute all implicitï¼ˆéšå¼ï¼‰ statements by applying rules on assertions.\n\nExample1:\n\nExample2:\n\n\n\nSo what type of Endocarditis is?\n\n\n2.3 ClassificationExample1:\n\n\nClassification is to compute all implicit subclass relations by applying rules on a TBox.\nåˆ©ç”¨TBoxçš„è§„åˆ™è®¡ç®—æ‰€æœ‰å­ç±»çš„ä¾èµ–å…³ç³»\n\n\nExample2:\n\nHighvalue_Company âŠ‘ âˆƒbeInvestedBy. Investment_Company\né«˜ä»·å€¼å…¬å¸ç”±æŠ•èµ„å…¬å¸æŠ•èµ„ã€‚\nInvestment_Company âŠ‘ Financial_Institute\næŠ•èµ„å…¬å¸å±äºé‡‘èæœºæ„\nâˆƒbeInvestedBy. Financial_Institute âŠ‘ Solvent_Company\nå€ŸåŠ©é‡‘èæœºæ„æŠ•èµ„çš„å…¬å¸éƒ½æ˜¯å…·å¤‡å¿è¿˜èƒ½åŠ›çš„ ä¼ä¸šã€‚\n\nAnswer:\n\nHighvalue_Company âŠ‘ âˆƒbeInvestedBy. Financial_Institute\nHighvalue_Company âŠ‘ Solvent_Company\n\n3. Backward Reasoning\nBackward reasoning (Backward chaining) is an inference method described colloquially as working backward from the goal.\n\nIt is often used in entailmentï¼ˆè•´å«ï¼‰ checking or query answering in KG.\nIt uses the rules to rewrite the query in several ways and the initial query is entailed if a rewritten query maps to the initial facts.\n\n\næœ‰ç›®æ ‡ï¼ŒQAâ€”â€”çœŸæˆ–å‡\n\n\nExample1:\n\nRule: If you are human, then you are mortal.\nHuman(x)â†’Mortal(x)\nQuestion: Is Socrates a mortal?\nSolution: Check whether Mortal(Scorates) or Human(Scorates) is true.\n\nExample2:\n\n\nQuery: Find all patients with heart diseases, i.e., Heart_Disease(x)\n\nRewriting: Endocarditis(x) â‹ Miocardial_Infarction(x) â‹ Coronary_disease(x)\n\nå¯ä»¥ç†è§£æˆé‡å†™é—®é¢˜\n\n\nExercizeï¼š\nFind all sports players with the following KG, i.e., rewrite the query Sports_Player(x).\n\n\nQuery: Find all sports players \nRewriting: SportsPlayer(x) â‹ BasketballPlayer(x) â‹ FootballPlayer(x) â‹ TennisPlayer(x) \n\nOther Tasks in Logical Reasoning: Inconsistency CheckingIncoherentä¸ä¸€è‡´ ontology: ontology with at least one unsatisfiable concept è‡³å°‘æœ‰ä¸€ä¸ªä¸å¯æ»¡è¶³æ¦‚å¿µçš„æœ¬ä½“ï¼ˆç©ºé›†ï¼‰\nExample: \n\nPhDStudent âŠ‘ Student, \n\nPhDStudent âŠ‘ Employee, \n\nStudent âŠ‘ Â¬ Employee\n\nä»¥ä¸Šæœ€ç»ˆå¯ä»¥é€€å‡ºStudentå’ŒEmployeeéƒ½æ˜¯ç©ºé›†ï¼Œæ‰€ä»¥æ‰¾ä¸åˆ°ä¸€ä¸ªmodel\nInconsistent ontology: ontology without a model. \n\n\n\nExample: \n\nPhDStudent âŠ‘ Student, \n\nPhDStudent âŠ‘ Employee,\n\nStudent âŠ‘ Â¬ Employee, \n\nPhDStudent(John)\n\nè¿™é‡Œåˆ™äº§ç”Ÿäº†çŸ›ç›¾\n\n\n\nExample: DICE ontology:\n\nBrain $\\subseteq$â€‹ CentralNervousSystem Ğ¿ $\\exists$â€‹systempart.NervousSystem ×— BodyPart Ğ¿ $\\exists$â€‹ region.HeadAndNeck Ğ¿ $\\forall$â€‹â€‹â€‹ region.HeadAndNeck\nCentralNervousSystem $\\subseteq$â€‹â€‹ NervousSystem\nBodyPart $\\subseteq \\neg$â€‹ NervousSystem    or   DisjointWith(BodyPart,NervousSystem)\nReasoning: \nBrain $\\subseteq$â€‹ Bodypart $\\subseteq$â€‹ $\\neg$ NervousSystem\nBrain $\\subseteq$ CentralNervousSystem $\\subseteq$ NervousSystem\nBrain = $\\emptyset$\n\n\nBrainæ˜¯ç©ºé›†\n\n\n\nExample from Foaf:\n\nPerson(timbl)\nHomepage(timbl, http://w3.org/)\nHomepage(w3c, http://w3c.org/)\nOrganization(w3c)\nInverseFunctionalProperty(Homepage) (Homepageçš„domainåªæœ‰ä¸€ä¸ªå€¼ï¼Œæ‰€ä»¥çŸ›ç›¾)\nDisjointWith(Organization, Person)\n\nExample from OpenCyc:\n\nArtifactualFeatureType(PopulatedPlace)\nExistingStuffType(PopulatedPlace)\nDisjointWith(ExistingobjectType,ExistingStuffType)\nArtifactualFeatureType $\\subseteq$ ExistingObjectType\n\nExistingObjectTypeä¸ExistingStuddTypeä¸ç›¸äº¤ï¼Œä½†æ˜¯å´æ‹¥æœ‰ç›¸åŒçš„å®ä¾‹ï¼Œæ‰€ä»¥çŸ›ç›¾\n\n\nExerciseï¼šThe following ontology is inconsistent, and remove one axiom or assertion in it to make it consistent.\n\n\\begin{aligned}\n&\\operatorname{Ph} D_{\\text {student }} \\sqcup \\text { Undergraduatge }_{\\text {student }} \\sqsubseteq \\text { Student, } \\\\\n&\\text { Student } \\sqsubseteq \\neg \\text { Employee } \\\\\n&\\text { PhD }_{\\text {student }} \\text { (John), } \\\\\n&\\text { Employee(John), } \\\\\n&\\text { Marriedto(John, Lisa), } \\\\\n&\\text { Undergraduate(Jack) }\n\\end{aligned}\n$\\text { Student } \\sqsubseteq \\neg \\text { Employee }$ or $\\text { Employee(John)}$ or $\\text { PhD }_{\\text {student }} \\text { (John) }$\n\n4. Summary\nIn logical reasoning, we mainly focus on deductive reasoning, i.e., leveraging rules and preconditions to infer new knowledge.\nDeductive reasoning including forward reasoning and backward reasoning.\nForward reasoning actually gets as much knowledge as possible before application. ç›¸å½“äºè¡¥å…¨çŸ¥è¯†\nBackward reasoning starts from the target/ application and can quickly get the result. ä¸è€ƒè™‘è¡¥å…¨ï¼Œä¸“æ³¨äºæ‰¾åˆ°ç»“æœï¼Œå®ç”¨æ€§\n\n5. Logical Reasoning in Practice\nDatalog is a declarativeå£°æ˜å¼ logic programming language, which is designed for knowledge base and database.\nDatalog has similar expressive ability with OWL.\nDatalog supports recursion, and rule editing (more freely) for reasoning. å¯ä»¥è‡ªå®šä¹‰è§„åˆ™ï¼Œæ¥åšæ¨ç†\n\n\n\nOWLä¸Datalogç›¸äº¤çš„è¯­è¨€\n\nDatalog syntax: \n\nAtom: $ğ‘(ğ‘¡_1,ğ‘¡_2,â€¦,ğ‘¡_ğ‘›)$ , predicate(è°“è¯­): p, variable or constant: t \nExample: $\\text{has_child}(ğ‘‹,ğ‘Œ) $â€‹â€‹\n\nRule: $ğ»:âˆ’ğµ_1,ğµ_2,â€¦,ğµ_ğ‘š,$ \n\nhead (an atom): H, \nbody (one atom or the AND of more atoms): ğµ1,ğµ2,â€¦,ğµğ‘š  (body å¯ä»¥ç†è§£ä¸ºè§£é‡Šï¼Œå³å¯ä»¥ç”±bodyæ¨å‡ºhead)\n\nExample: $\\text{has_child}(ğ‘‹,ğ‘Œ):âˆ’\\text{has_son}(ğ‘‹,ğ‘Œ)$ \n\nFact: $ğ¹(ğ‘_1,ğ‘_2,â€¦,ğ‘_ğ‘›):âˆ’$â€‹ , constant: $c$ , without body or variable \nExample: $\\text{has_child}(Alice,Bob):âˆ’$\n\n\n6. Datalog program:%%Factsfriend(joe,sue) .friend(ann,sue) .friend(sue,max) .friend(max,ann) .%% Rulesfof(X,Y) :- friend(X,Y)fof(X,Z) :- friend(X,Y), fof(Y,Z)%%Quiery 1query(X) :- fof(X,ann)%%Answer:fof(sue,ann) .fof(max,ann) .fof(joe,ann) .fof(ann,ann) .\n\nDatalog Rule Operators: \n\nIntersection: $Q(x_1, x_2, â‹¯ , x_n) :- R(x_1, x_2, â‹¯ , x_n) , S(x_1, x_2, â‹¯ ,x_n) $\nExample:\n\n$\\text{smart_phone(x)} :- \\text{cell_phone(x)}, \\text{intelligent_device(x)}$â€‹ \n\n\nUnion: $Q(x_1, x_2, â‹¯, x_n) :- R(x_1, x_2, â‹¯ ,x_n) ,  Q(x_1, x_2, â‹¯, x_n) :- S(x_1, x_2 , â‹¯ , x_n) $\nExample: \n\n$human(x) :- woman(x) $\n$human(x) :- man(x) $\n\n\nDifference: $Q(x_1, x_2, â‹¯ ,x_n) :- R(x_1, x_2, â‹¯, x_n) , \\text{not} S(x_1, x_2, â‹¯ , x_n)$â€‹â€‹â€‹ \nExample:\n\n$younger_brother(x, y) :- brother(x, y), not elder_brother(x, y)$â€‹\n\n\n\n\nExercise\n\nRuleï¼šfatherinlawOf(X,Z) :- wifeOf(X,Y), fatherOf(Y,Z)\nFactï¼š wifeOf (YaoMingï¼ŒYeLi)\nFactï¼š fatherOf (YeLiï¼ŒYeFa)\nWho is the father-in-law of Yao Mingï¼Ÿ\n\nfatherinlawOf(YaoMing, YeFa)\n\n","categories":["KnowledgeEngineering"]},{"title":"Statistical Resoning","url":"/2021/08/15/knowledge%20engineering/6%20Statistical%20Resoning/","content":"Statistical Resoning\nStatistical Resoning1.Def\nStatistical Reasoning tries to find suitable statistical models to fit the samples and predicts the expected probabilities of the inferred knowledge. é¢„æµ‹æœªæ¥çŸ¥è¯†å‡ºç°çš„æ¦‚ç‡\n\nknowledge graph embedding based reasoning \n\ninductive rule learning based reasoning \nmulti-hop reasoning\n\n\nTasks:\nPredicting the missing link.  \nGiven e1 and e2, predict the relation r. \nPredicting the missing entity.  \nGiven e1 ï¼ˆe2ï¼‰and relation r, predict the missing entity e2 ï¼ˆe1ï¼‰. \nFact Prediction.  \nGiven a triple, predict whether it is true or false.\n\n2. Embedding: Meaning of a Word\nWhat is the meaning of a word?\nBy ontologies? By Knowledge Graph?\nBut ontologies and KGs are hard to construct and often incomplete æ— æ³•ç©·ä¸¾\nHow to encode the meaning of a word?\n\n3. One-hot Representation\nVocabulary: (cat, mat, on, sat, the) \ncat: 10000 mat: 01000 on: 00100 sat: 00010 the: 00001\n\n\nâ€œThe cat sat on the matâ€\n\n\n\nDisadvantage: too sparsity\n\n\n\nOne-hot representation: \nFoundation of Bag-of-words Model\n\n\næ— æ³•è¡¡é‡è¯­ä¹‰ç›¸å…³åº¦\n\n\n4. Distributional Representation\nWhen a word w appears in text, its context is the set of words that appear nearby (within a fixed-size window)ï¼š ç”¨ä¸­å¿ƒè¯å‘¨å›´çš„è¯è¡¨ç¤ºè¯¥è¯\n\nUse many contexts of w to build up a representation of w\n\n\n\n\nå»ºç«‹ä¸€ä¸ªç¨ å¯†å‘é‡\n\n5. Word Vectors\nWe will build a dense vector for each word, chosen so that it is similar to vectors of words that appear in similar contexts.\n\n\n\nNote: word vectors are sometimes called word embeddings. They are a distributed representation.\n\nSimilarity:\n\\begin{gathered}\n\\operatorname{euclidean}(u, v)=\\sqrt{\\sum_{i=1}^{n}\\left|u_{i}-v_{i}\\right|^{2}} \\\\\n\\operatorname{cosine}(u, v)=1-\\frac{\\sum_{i=1}^{n} u_{i} \\times v_{i}}{\\|u\\|_{2} \\times\\|v\\|_{2}}\n\\end{gathered}6. Advantage of Distributed Representation\nDeal with data sparsity problem in NLP\nRealize knowledge transfer across domains and across objects\nProvide a unified representation for multi-task learning\n\n\n6.1 Representation Learning\nWhat is the representation learning?\nObjects are represented as dense, real-value and low-dimensional vector\n\n\n\n\n6.2 Different ways of KG Representation\n\nTensor: è‡ªç”±åº¦æ›´é«˜ï¼Œéšå¼çŸ¥è¯†ï¼Œä½†ä¸å®¹æ˜“æ‰©å±•ï¼Œä¸å®¹æ˜“è§£é‡Š\n\n6.3 Knowledge Graph Embedding: Application\nEntity Prediction\nå§è™è—é¾™ Has-director ?\nå§è™è—é¾™ Has-directorï¼šAng Lee\n\n\n\n\n\nRelation Prediction\n\n\n\nRecommendation System\n\n\n7. TransE: Take Relation as Translation\nFor a fact (head, relation, tail), take the relation as a translation operator from the head to the tail .\n\n\n\nå®ä½“ç»è¿‡å…³ç³»çš„ç¿»è¯‘åˆ°å¦ä¸€ä¸ªå®ä½“\n\nTransE\nFor each triple , h is translated to t by r.\n\n\n\n\n\n\n\n\nt=h+r\nTrain TransE Energy Function:\n\n\nf(h, r, t)=|h+r-t|_{L_{1} / L_{2}}\nIf the triple is true, the translated distance between (h + r) and t is shorter.\n\nL1 (Manhattan) distance:\n\n\n\n\\mathbf{d}_{1}(a, b)=\\|a-b\\|_{1}=\\sum_{i=1}\\left|a_{i}-b_{i}\\right|\nL2 (Euclidean) distance:\n\n\n\\begin{aligned}\n \\mathbf{d}_{2}(a, b)=\\|a-b\\|=\\|a-b\\|_{2}=\\sqrt{\\sum_{i=1}^{d}\\left(a_{i}-b_{i}\\right)^{2}}\n\\end{aligned}TransE \n\nTriple1:  \nTriple2:   \nTriple3:  \nâ€¦ \nfalse triple examplesï¼š\n\n\n\nâ€¦\n\nHow to distinguishï¼Ÿ(true and false)\n\nMinimize the distance between (h+l) and t.\nMaximize the distance between (hâ€™+l) to a randomly sampled tail tâ€™ (negative example).\næœ€å°åŒ–æ­£ç±»è¡¨ç¤ºçš„å·®è·ï¼Œæœ€å¤§åŒ–è´Ÿç±»è¡¨ç¤ºçš„å·®è·\n\n\n\n\n\nTbatchå°±æ˜¯ä¸€ä¸ªæ­£ä¾‹å’Œè´Ÿä¾‹å…ƒç»„çš„é›†åˆ\n\n\ninput Training set $S=\\{(h, \\ell, t)\\}$, entities and relations. sets $E$ and $L$, margin $\\lambda$, embeddings dim. $k$.\nInitialize entity and relationship embedding;\nEntity and relationship embedding normalization;For each entity eï¼ˆSuppose there are M elements in the entity set Eï¼‰\n\n\ne=\\frac{e_{i}}{\\sqrt{e_{1}^{2}+e_{2}^{2}+\\cdots+e_{M}^{2}}}4ã€Negative Sampling \n\n\nEvaluation protocol:\n\nMetrics: éå†æ‰€æœ‰å®ä¾‹ï¼Œè¿›è¡Œè·ç¦»è®¡ç®—ï¼Œå¹¶æ’åº\n\nLink Prediction( WALL-E , _has_genre , ? )\n\nMean Ranks: the mean of those predicted ranks.\n\nHits@10: the proportion of correct entities ranked in the top 10.e.g. Entity 1: rank -&gt; 50; Entity 2: rank -&gt; 100; MR = (50+100)/2 = 75\n\n8.QuestionWe have two types of relations in KG, for example:\n\nSymmetric Relation: \n\ne.g., (stu1, classmate, stu2), (stu2, classmate, stu1)\n\n\nCompositionï¼ˆç»„åˆï¼‰ Relation: \n\ne.g., (B, husband_of, A)ï¼Œ(A, mother_of, C)ï¼Œ(B, father_of, C)\n\n\n\nWhich Relation can be modeled by TransE? Why?\nTransE cannot model symmetric relations\n\n\n\nTransE can model composition relationsï¼Œwhen $r_3=r_1+r_2$\n\n\n\nCan TransE model 1-to-N relations? \ne.g., (qiguilin, teacher_of, stu1), (qiguilin, teacher_of, stu2)ï¼Œ(qiguilin, teacher_of, stu3), (qiguilin, teacher_of, stu4)â€¦\nä¸èƒ½ï¼Œå¦åˆ™stuiå‡ç›¸ç­‰\n\n\n\nIssue of TransE\nTransE is too simple to handle complex relations\n1-to-N, N-to-1, N-to-N relations ä¸å¯èƒ½å‘ç”Ÿ\n\n\n\n\n\\begin{array}\\\\\na+r_1=b_1\\\\\na+r_2=b_2\n\\end{array}\n9. Variantsï¼ˆå˜ç§ï¼‰ of TransE: TransHFor each relation, define a hyperplane $W_r$â€‹ and a relation vector dr. Then project the head entity vector $h$ and the tail entity vector $t$ onto the hyperplane $W_r$. å°†å‘é‡æ˜ å°„åˆ°è¶…å¹³é¢åšç¿»è¯‘\n\n\nFor example:\n in TransE, h and hâ€™â€™ will overlap. While in TransH, entity h and entity hâ€™â€™ will overlap only with the projection hâŠ¥.\n\n10. Variants of TransE: TransR\nBoth TransE and TransH models assume that entities and relationships are vectors in the same semantic space.\n\n\n\nå‡è®¾æ¯ä¸€ä¸ªå…³ç³»ï¼Œæœ‰è‡ªå·±çš„å‘é‡ç©ºé—´\nå› ä¸ºæ¯›ä¸»å¸­å’Œå¥¥å·´é©¬è™½ç„¶åœ¨æ€»ç»Ÿç©ºé—´æ¥è¿‘ï¼Œä½†æ˜¯è¯—äººç©ºé—´å´æ˜¯ä¸æ¥è¿‘\n\nTransR proposes:\n\nBuild entity and relation embeddings in the separate entity space and relation spaces;\n\nThen projecting entities from entity space to the corresponding relation space and building translations between projected entities.\n\n\nTransR: \n\nMapping entity embeddings into different semantic spaces\n\n\n\\mathbf{h}_{r}=\\mathrm{h} \\mathbf{M}_{r}, \\quad \\mathbf{t}_{r}=\\mathrm{tM}_{r}\n\nThe score(energy) function is correspondingly defined as (same as TransE):\n\n\nf_{r}(h, t)=\\left\\|\\mathbf{h}_{r}+\\mathbf{r}-\\mathbf{t}_{r}\\right\\|_{2}^{2}11. Summary\nStatistical reasoning uses statistical models to fit the samples and predicts the expected probabilities of the inferred knowledge .\n\nKnowledge graph embedding based reasoning actually performs entity prediction and relation prediction with vector calculations.\n\nTranslation-based models are now widely used KG embedding models for KG completion and other applications due to its good performance and succinctness.\n\n\n","categories":["KnowledgeEngineering"]},{"title":"Parsing","url":"/2021/08/15/nlp%20learning/Chapter10_Parsing/","content":"Parsing\n\nParsing1.ä¸Šä¸‹æ— å…³æ–‡æ³•ä¸ä¸Šä¸‹æœ‰å…³æ–‡æ³•\nStarting unit:\n\n\n\\underset{\\text{éç»ˆç»“ç¬¦}}{S}V\\ O\ntransition rule:\n\n\n\\begin{array}{l}\nS\\rightarrow \\text{äºº|å¤©}\\\\\nV\\rightarrow \\text{åƒ|ä¸‹}\\\\\nO\\rightarrow \\text{é›¨|é¥­|è‚‰}\\\\\n\\end{array}\nä¸Šä¸‹æ–‡æ–‡æ— å…³è¯­æ³•\nä¸è€ƒè™‘å‰åä¾èµ–å…³ç³»\n\n\n\n\nsent\\rightarrow SVO\\rightarrow\\text{å¤©}VO\\rightarrow\\text{å¤©åƒ}O\\rightarrow\\text{å¤©åƒè‚‰}\nä¸Šä¸‹æ–‡æœ‰å…³è¯­æ³•\nè€ƒè™‘å‰åä¾èµ–å…³ç³»\n\n\n\n\n\\begin{array}{l}\nS\\rightarrow \\text{äºº|å¤©}\\\\\n\\text{äººV}\\rightarrow \\text{äººåƒ}\\\\\n\\text{å¤©V}\\rightarrow \\text{å¤©ä¸‹}\\\\\n\\text{ä¸‹O}\\rightarrow \\text{ä¸‹é›¨}\\\\\n\\text{åƒO}\\rightarrow \\text{åƒé¥­|åƒè‚‰}\\\\\n\\end{array}\nä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ä»¥åŠä¸Šä¸‹æ–‡æœ‰å…³æ–‡æ³•éƒ½å…·æœ‰æ­§ä¹‰ï¼Œå³ä¸åŒè¯­æ–™è¡¨è¾¾çš„æ„æ€ä¸ä¸€å®šç›¸åŒ\n\n2. Parsing2.1 Def\nSuntactic Structure: Constitunency = phrase structure grammar = context - free grammars\nä¼ ç»Ÿè®¤ä¸ºï¼Œå¥å­æ„æˆåº”è¯¥æ˜¯ï¼šä»æœ€ç®€å•çš„å•è¯å‡ºå‘ï¼Œç„¶åä¸åŒçš„è¯ç»„æˆçŸ­è¯­ï¼Œå†å°†çŸ­è¯­ç»„æˆå¤§çš„çŸ­è¯­ã€‚\n(the, cuddly, cat, by, the, door)(the cuddly cat|by the door)(the cuddly cat by the door)\n\n\n\n\n\\begin{array}{l}\n\\text{Lexicon:}\\\\\nN\\rightarrow \\text{dog}\\\\\nN\\rightarrow \\text{cat}\\\\\nDet\\rightarrow \\text{a}\\\\\nDet\\rightarrow \\text{the}\\\\\nP\\rightarrow \\text{in|on|by}\\\\\nV\\rightarrow \\text{talk|walk|...}\\\\\n\\end{array}\nGramma:\n\n\n\\begin{array}{l}\n\\text{NP}\\rightarrow\\text{Det N}\\\\\n\\text{NP}\\rightarrow\\text{Det $(Adj)^*$ N (PP)}\\\\\nPP\\rightarrow\\text{P NP}\\\\\nVP\\rightarrow\\text{V PP}\\\\\nsent\\rightarrow\\text{NP VP}\\\\\n\\end{array}2.2 PP Attachment Ambiguities Multiply\nLook in the large crate  in the kitchen by the door\nPPå­˜åœ¨ä¿®é¥°æ­§ä¹‰\n\n\n\n\n\\text{Look in } \\underset{NP}{\\underbrace{\\text{the large crate}}} \\underset{PP}{\\underbrace{\\text{ in the kitchen}}} \\underset{PP}{\\underbrace{\\text{ by the door}}}\né€šå¸¸æˆ‘ä»¬æŠŠä¸€ä¸ªå¥å­çš„æ ¸å¿ƒè¯ç§°ä¸ºheadï¼Œä¿®é¥°éƒ¨åˆ†ä¸ºmodification\n\n\n\nPrepositional Phrase Attachment Ambiguity\nSan Jose cops kill man with knife\n\n\n\n\n\nä¸åŒçš„æ˜¯ï¼Œä¸­æ–‡ç”±äºè¯­æ³•ä¹ æƒ¯ä¸ä¸€æ ·ä¸å­˜åœ¨ç›¸åŒçš„æ­§ä¹‰ã€‚\n\n\n\n\nA key parsing decision is how we â€˜attachâ€™ various constituents\nPPs , adverbial or participial phrases, infinitives, coordinations\n\n2.3 Coordination Scope Ambiguity\nå®šè¯­ä¿®é¥°èŒƒå›´å‡ºç°é”™è¯¯\n\nShuttle veteran and longtime NASA executive Fred Gregory appointed to board\n\n[Shuttle veteran] and [longtime NASA executive Fred Gregory ]appointed to board\n[Shuttle veteran and longtime NASA executive] Fred Gregory appointed to board\n\n\nDoctor:No heart, cognitive issues\nDoctor:No [heart, cognitive issues]\nDoctor:[No heart], [cognitive issues]\n\n\n\n2.4 Adjectival/Adverbial Modifier Ambiguity\nStudents get first hand job experience\nStudents get [first hand] [job experience]\nStudents get [first [hand job] experience]\n\n\n\n2.5 Verb Phrase (VP) attachment ambiguity\nMultilated body washes up on Rio beach to be used for Olympics beach volleyball\nMultilated body washes up on Rio beach to be used for Olympics beach volleyball\nMultilated body washes up on Rio beach to be used for Olympics beach volleyball\n\n\n\n3. Dependency Grammar and Dependency Structure3.1 Def\n\nDependency syntax postulates that syntactic structure consists of relations between lexical items, normally binary asymmetric relations (â€œarrowsâ€) called dependencies\nç ”ç©¶ç´§æŒ¨ç€çš„ä¸¤ä¸ªè¯çš„å…³ç³»ï¼Œå¹¶ä¸”ä¼šç»™è¾¹æ‰“ä¸Šç›¸å…³çš„æ ‡ç­¾\n\n\nThe arrows arecommonly typed with the name of grammatical relations (subject,prepositional object,apposition, etc.)\nAn arrow connects a head(governor, superior,regent) with a dependent(modifier, inferior,subordinate)\nUsually, dependencies form a tree (a connected,acyclic, single-root graph)\n\n\nå¤„äºæ”¯é…åœ°ä½çš„æˆåˆ†ç§°ä¸ºæ”¯é…è€…head,governor,regentï¼Œè€Œå¤„äºè¢«æ”¯é…åœ°ä½çš„æˆåˆ†ç§°ä¸ºä»å±è€… modifier,subordinate,dependency\n\nå€¼å¾—ä¸€æçš„æ˜¯ï¼Œæˆ‘ä»¬éƒ½ä¼šåœ¨å¥å­è§£æç»“æ„åŠ ä¸Šæ ¹èŠ‚ç‚¹ä»¥ä¿è¯æ ‘çŠ¶ç»“æ„\n\n\n3.2 Dependency Relations\n3.3 Dependency Grammar and Dependency StructureROOT\nWhat are the sources of information for dependency parsing?\n\nBilexical affinities åŒè¯æ€§ä¹‹é—´çš„ä¾èµ–å…³ç³»â€‹ \n\nThe dependency [discussion  issues] is plausible\n\n\nDependency distance ä¾èµ–è·ç¦»\n\nMost dependencies are between nearby words\n\n\nIntervening material   \n\nDependencies rarely span intervening verbs or punctuation\nä¾èµ–å…³ç³»å¾ˆå°‘è·¨è¶Šä¸­é—´çš„åŠ¨è¯æˆ–æ ‡ç‚¹ç¬¦å·\n\n\nValency of heads \n\nHow many dependents on which side are usual for a head?\n\n\n\n\n\nA sentence is parsed by choosing for each word what other word (including ROOT) it is a dependent of\nUsually some constraints:\nOnly one word is a dependent of ROOT (single headed)\nDonâ€™t want cycles  (acyclic)\n\n\nThis makes the dependencies a tree\nFinal issue is whether arrows can cross (be non-projective) or not\næ˜¯å¦å…è®¸äº¤å‰å°†ä½¿å¾—å»ºæ ‘çš„æ–¹æ³•å’Œç»“æœæœ‰æ‰€ä¸åŒ\n\n\n\n\n3.4 Methods of Dependency Parsing\n3.4.1 Greedy transition based parsing\nA simple form of greedy discriminative dependency parser\nThe parser does a sequence of bottom up actions\n\nRoughly like â€œshiftâ€ or â€œreduceâ€ in a shift-reduce parser, but the â€œreduceâ€ actions are specialized to create dependencies with head on left or right\n\n\nThe parser has:\n\na stack , written with top to the right\nwhich starts with the ROOT symbol\nç”¨ä¸€ä¸ªæ ˆå­˜æ”¾ä»£æ“ä½œçš„å­—ç¬¦ï¼Œåè¿›å…ˆå‡º\n\n\na buffer , written with top to the left\nwhich starts with the input sentence\nç”¨ä¸€ä¸ªé˜Ÿåˆ—å­˜æ”¾å‰©ä½™éœ€è¦æ“ä½œçš„å¥å­ï¼Œå…ˆè¿›å…ˆå‡º\n\n\na set of dependency \nwhich starts off empty\næœ‰ä¸€ä¸ªé›†åˆå­˜æ”¾æ‰€æœ‰å¼§çš„å…³ç³»\n\n\na set of actions\nç”¨ä¸€ä¸ªé›†åˆå­˜æ”¾æ‰€æœ‰æ“ä½œ\n\n\n\n\n\nBasic Transition based Dependency Parser\nArc standard Transition based Parser\n(there are other transition schemes â€¦) Analysis of  â€œI ate fishâ€œ\n\n\n\nExample\nLeft-Arc Precondition: â€‹ ROOT\n\næ„æ€æ˜¯å½“æ‰€åœ¨çš„stackä¸­ç›¸é‚»çš„ä¸¤ä¸ªsymbolçš„å·¦ä¾èµ–å…³ç³»æ²¡æœ‰åœ¨é›†åˆé‡Œæ—¶ï¼Œå¯ä»¥è¿›è¡Œæ“ä½œ\næ“ä½œæ—¶ï¼Œæˆ‘ä»¬æ¯”è¾ƒæ ˆé¡¶å’Œé˜Ÿé¦–çš„ä¸¤ä¸ªè¯ï¼Œå¦‚æœå­˜åœ¨Left Arcï¼Œé‚£ä¹ˆæˆ‘ä»¬åªpopæ‰æ ˆé¡¶çš„è¯\n\n\nRight-Arc â€‹\n\næ“ä½œæ—¶ï¼Œæˆ‘ä»¬æ¯”è¾ƒæ ˆé¡¶å’Œé˜Ÿé¦–çš„ä¸¤ä¸ªè¯ï¼Œå¦‚æœå­˜åœ¨right Arcï¼Œæˆ‘ä»¬å°±popæ‰é˜Ÿé¦–å¹¶ä¸”pushè¿›æ ˆé¡¶\nè¿™é‡Œæˆ‘ç†è§£æ˜¯ï¼ŒRight arcçš„ä¸¤ä¸ªè¯éƒ½æœ‰å¯èƒ½äº§ç”Ÿæ–°çš„ä¾èµ–å…³ç³»ï¼Œæœ€å…·æ ‡å¿—æ€§çš„å°±æ˜¯ROOTè¿æ¥å¥å­çš„ç¬¬ä¸€ä¸ªä¿®é¥°çš„è¯\n\n\nReduce Precondition: â€‹\n\næ„æ€æ˜¯å½“é˜Ÿåˆ—ä¸ºç©ºï¼Œä¸”æ‰€åœ¨çš„stackä¸­ç›¸é‚»çš„ä¸¤ä¸ªsymbolçš„å·¦ä¾èµ–å…³ç³»æœ‰åœ¨é›†åˆé‡Œæ—¶ï¼Œé‚£ä¹ˆç›´æ¥popæ ˆé¡¶\n\n\nShift â€‹\n\nå½“æ ˆé¡¶å’Œé˜Ÿé¦–ä¸å­˜åœ¨ä»»ä½•ä¾èµ–å…³ç³»æ—¶ï¼Œä¸”é˜Ÿåˆ—ä¸ä¸ºç©ºæ—¶ï¼Œç›´æ¥å°†é˜Ÿé¦–çš„è¯åŠ å…¥æ ˆé¡¶\n\n\n\n\nMaltParser\n\nå¯ä»¥ç”¨SVMæ¥åˆ¤æ–­åº”è¯¥åšä»€ä¹ˆaction\n\nå¯ä»¥ä½¿ç”¨beam searchçš„æ–¹æ³•æ¥ä¼˜åŒ–æœç´¢\n\n\n3.4.2 Conventional Feature Representation\n3.5 Evaluation of Dependency Parsing: (labeled)dependency accuracy\n\n\næ²¡æœ‰æ ‡ç­¾ï¼šUAS\næœ‰æ ‡ç­¾ï¼šLAS\n\n3.6 Indicator Features Revisited\nProblem #1: \nsparse\n\n\nProblem#2: \nincomplete\n\n\nProblem#3: \nexpensive computation\n\n\nMore than 95% of parsing time is consumed by feature computation\n\n\n3.7 Why do we gain from a neural dependency parser?\ndense vector\ncomplete\ntrainable, low computation\n\n\n4. Further developments in transition based neural dependency parsing\nGraph based Dependency Parsers\nCompute a score for every possible dependency for each word\n\n\n\næƒé‡æœ€å¤§çš„ç»„æˆä¾èµ–å…³ç³»\n\n","categories":["nlp"]},{"title":"Bert","url":"/2021/08/15/nlp%20learning/Chapter13_Bert/","content":"Bert\n\n1. Seq2Seq\næœºå™¨ç¿»è¯‘ã€è¯­éŸ³ç¿»è¯‘ã€å¯¹è¯ç¿»è¯‘ã€å¯¹è¯ã€QAã€å¥æ³•æ ‘ï¼ˆæ‹¬å·å¯¹é½ï¼‰ã€å¤šåˆ†ç±»é—®é¢˜ã€å›¾åƒè¯†åˆ«ã€è¯å‘é‡\nä½ç½®ç¼–ç ï¼šæœ‰äº›è¯å‡ºç°çš„ä½ç½®æ˜¯æœ‰è§„å¾‹äº†ï¼Œæ‰€ä»¥ä½ç½®æ˜¯éå¸¸é‡è¦çš„\n\n\nBertä¸CBOWçš„å·®å¼‚\nBERTç›¸æ¯”CBOWæ›´å¤æ‚\n\n\nè¯­ä¹‰å¯¹é½\n\n2. Multimodal\nè§†è§‰ä¿¡æ¯å’Œæ–‡å­—ä¿¡æ¯ç†è§£ä¸åŒ\nå¯¹äºåŒä¸€ä¸ªäº‹ç‰©ï¼Œæˆ‘ä»¬æœ‰å¤šç§æ¨¡æ€æ¥è¡¨ç¤º\n\n","categories":["nlp"]},{"title":"Language Modeling","url":"/2021/08/15/nlp%20learning/Chapter3_n-gram_model/","content":"Language Modeling\n\nThe Language Modeling Problem\nSetup: assume a (finite) vocabulary of words:\n\n\\mathcal{V}=\\{ \\text{the, a, man, telescope, Beckham, two, Madrid, ...}\\}\nWe can construct an (infinite) set of strings:\n\n\\mathcal{V}^{\\dagger}=\\{ \\text{the, a, the a, the fan, the man, the man with the telescope, ...} \\}\nData: given a training set of example sentences \n\nProblem: estimate a probability distribution\n\n\n\nProbabilistic Language Modeling\nGoal\n\nassign a probability  to a sentence \n\n\nP(W) = P(w_1,w_2,w_3,...,w_n)\nRelated task\n\nprobability of an upcoming word\n\n\nP(w_5 \\mid w_1,w_2,w_3,w_4)\nA model that computes either of these is called a language model or LM\n\n\nHow to compute \nP(w_1,w_2,...,w_n) = \\prod_{i}^n P(w_i \\mid w_1,w_2,...,w_{i-1})e.g.\n\n\\begin{align}\nP(\\text{its water is so trasparent}) \n&=P(\\text{its}) \\\\\n&\\times P(\\text{water} \\mid \\text{its})\\\\\n&\\times P(\\text{is} \\mid \\text{its water}) \\\\\n&\\times P(\\text{so} \\mid \\text{its water is}) \\\\\n&\\times P(\\text{transparent} \\mid \\text{its water is so}) \\\\\n\\end{align}Markov Assumption\nFirst-order markov processes\n\n\n  P(\\text{the} \\mid \\text{its water is so transparent that}) = P(\\text{the} \\mid \\text{that})\nSecond-order markov processes\n\n\nP(\\text{the} \\mid \\text{its water is so transparent that}) = P(\\text{the} \\mid \\text{transparent that})\nwe approximate each component in the product\n\n\nP(w_1,w_2,...,w_n) = \\prod_{i}^n P(w_i \\mid w_{i-k},...,w_{i-1}) \\\\\nP(w_i \\mid w_1,...,w_{i-1}) =  P(w_i \\mid w_{i-k},...,w_{i-1})Unigram model\nP(w_1,w_2,...,w_n) = \\prod_{i}^n P(w_i)Problem\nP(\\text{the the the the}) \\gg P(\\text{I like ice cream})Bigram model\nP(w_i \\mid w_1,...,w_{i-1}) = P(w_i \\mid w_{i-1}) \\\\\nP(w_1,w_2,...,w_n) = \\prod_{i}^n P(w_i \\mid w_{i-1})Estimating\nP(w_i \\mid w_{i-1}) = \\frac{count(w_i,w_{i-1})}{count(w_{i-1})}= \\frac{c(w_i,w_{i-1})}{c(w_{i-1})}e.g.\n\n&lt;s&gt; I am Sam &lt;/s&gt;,&lt;s&gt; Sam am I &lt;/s&gt;,&lt;s&gt; I do not like green eggs an ham &lt;/s&gt;\n\n\n\\begin{array}{lll}\nP(\\text{I} \\mid \\text{}) = 0.67 & P(\\text{Sam} \\mid \\text{})=0.33 & P(\\text{am} \\mid \\text{I})=0.67 \\\\\nP(\\text{} \\mid \\text{Sam})=0.5 & P(\\text{Sam} \\mid \\text{am})=0.5 & P(\\text{do} \\mid \\text{I})=0.33\n\\end{array}\n\nRaw bigram counts\nRaw unigram counts\nRaw bigram probabilities\nExample: $P(\\text{ I want english food})$\nGiven\n\n\n\\begin{array}{ll}\nP(\\text{i} \\mid \\text{})=0.25 & P(\\text{english} \\mid \\text{want})=0.0011 \\\\\nP(\\text{food} \\mid \\text{english})=0.5 & P(\\text{}\\mid \\text{food})=0.68\n\\end{array}\nGet\n\n\nP(\\text{ I want english food})=\\begin{aligned}\nP(I \\mid)&\\times P(\\text {want} \\mid I) \n\\times P(\\text{english} \\mid \\text{want}) \n\\times P(\\text{food} \\mid \\text{english}) \n\\times P(\\text{}\\mid \\text {food)} \n=0.000031\n\\end{aligned}Practical Issue\nWe do everything in log space\nAvoid underflow\nadding is faster than multiplying\n\n\n\n\n\\log(p_1 \\cdot p_2 \\cdot p_3 \\cdot p_4) = \\log p_1 + \\log p_2 + \\log p_3 + \\log p_4N-gram model\nWe can extend to trigrams, 4 grams, 5 grams\nIn general this is an insufficient model of language\nbecause language has long distance dependencies\ne.g. The computer which I had just put into the machine room on the fifth floor crashed\n\n\n\n\nBut we can often get away with N-gram models\n\nHow to evaluate language models: Perplexity å›°æƒ‘åº¦\nPerplexity is the inverse probability of the test set, normalized by the number of words\nLower perplexity  Better model\n\n\nPP(W) = P(w_1w_2...w_n)^{-\\frac{1}{N}}\nChain rule\n\n\nPP(W) = (\\prod_{i=1}^{N}\\frac{1}{P(w_i \\mid w_1,...,w_{i-1})})^{\\frac{1}{N}}\nBigrams\n\n\nPP(W) = (\\prod_{i=1}^{N}\\frac{1}{P(w_i \\mid w_{i-1})})^{\\frac{1}{N}}SmoothingAdd-one estimation / Laplace smoothed\nPretend we saw each word one more time than we did\n\n\nP_{Add-1}(w_i \\mid w_{i-1}) = \\frac{c(w_{i-1},w_i)+1}{c(w_{i-1})+V}\\\\\nP_{Add-k}(w_i \\mid w_{i-1}) = \\frac{c(w_{i-1},w_i)+k}{c(w_{i-1})+kV}\n\nAdvanced smoothing algorithms\nGood-Turing\n\nReplace the empty frequency with those things weâ€™ve seen only  times\n\n\n\nKneser-Ney\n\n\nInterpolation\nSimple interpolation\n\n\n\\begin{aligned}\n\\hat{P}\\left(w_{n} \\mid w_{n-1} w_{n-2}\\right)&= \\lambda_{1} P\\left(w_{n} \\mid w_{n-1} w_{n-2}\\right) \\\\\n&+\\lambda_{2} P\\left(w_{n} \\mid w_{n-1}\\right) \\\\\n&+\\lambda_{3} P\\left(w_{n}\\right)\n\\end{aligned}\n\\quad \\sum_i \\lambda_i = 1\nChoose  to maximize the probability of validation data\nFix the N-gram probabilities without smoothing (on the training data)\nThen search for Î»s that give largest probability to validation set\nCan use any optimization technique (line search or EM usually easiest)\n\n\n\nUnknown words\nIf we know all the words in advanced\nVocabulary V is fixed\nClosed vocabulary task\n\n\nOften we donâ€™t know this\nOut Of Vocabulary = OOV words\nOpen vocabulary task\n\n\nInstead: create an unknown word token \nTraining of \\ probabilities\nCreate a fixed lexicon L of size V\nAt text normalization phase, any training word not in L changed to \\\nNow we train its probabilities like a normal word\n\n\nAt decoding time\nIf text input: Use UNK probabilities for any word not in training\n\n\n\n\n\n","categories":["nlp"]},{"title":"BOW","url":"/2021/08/15/nlp%20learning/Chapter4_BOW/","content":"BOW\n\n1. Language model has a history of over one hundred yearsPast:\nğ‘›-gram Language Model\n\nPresent:\nNeural Language Model\n\nPretrained Language Model\n\n\nFuture:\nBrain-Inspired Language Model\n\n2. Brain-Inspired Language Model\n\nHumansâ€™ language system in their brains can be divided into three regions including storing languages, sentiment, and representation,\nWhen people see the sentence, they will think of it as a picture in their brain. So though the two sentences above are very similar, the images may be different.\n\n3. Text Classification\nAssigning subject categories, topics, or genres\nSpam detection\nAuthorship identification\nAge/gender identification\nLanguage Identification\nSentiment analysis\n\n3.1 input\na document \na fixed set of classes  \n\n3.2 Output\na predicted class \n\n3.3 methodsRules-based on combinations of words or other features\n\nspam: black-list-address OR (â€œæŠ˜æ‰£â€ AND â€œé™ä»·â€)\n\nAccuracy can be high\n\nIf rules are carefully refined by expert\n\nBut building and maintaining these rules is expensive\n\n\n\n\n3.4 The Bag of Words Representation\n\nCount the words of the document, and get a dictionary about the document. Then we can get the frequency of each word from the document.\nSometimes, itâ€™s useless for us to count all words of the document. So we usually calculate the useful words of the document.\n\n\n\n4. How to learn the classifier 4.1 Letâ€™s start with Naive Bayes(Simple â€œnaÃ¯veâ€ classification method based on Bayes rule)\n4.1.1 Imagine two people Alice and Bob whose word usage pattern you knowï¼šAlice often uses words:  love, great, wonderful\nBob  often uses words:  dog, ball, wonderful\nAlice words probabilities: love(0.1), great(0.8), wonderful(0.1)\nBob words probabilities: love(0.3), ball(0.2), wonderful(0.5)\nCan you guess who sends: â€œwonderful loveâ€?\n\\begin{array} \\\\\nP(Alice|\\text{\"wonderful love\"})=0.1\\times 0.1=0.01 \\\\\nP(Bob|\\text{\"wonderful love\"})=0.5\\times 0.3=0.15 \\end{array}\nSo Bob do it\n\n4.1.2 Suppose there are two bowls of cookiesï¼š\nBowl 1 contains 30 vanilla cookies and 10 chocolate cookies. \n\nBowl 2 contains 20 of each.\n\n\n\nNow suppose you choose one of the bowls at random and, without looking, select a cookie at random. The cookie is vanilla. \nWhat is the probability that it came from Bowl 1? \n\n\\begin{array}\\\\\nP(Bowl_1|vanilla)\n=\\frac{P(Bowl_1, vanilla)}{P(vanilla)}=\\frac{P(vanilla|Bowl_1)\\times P(Bowl_1)}{\\sum_{i=1}^2 P(vanilla|Bow_i)\\times P(Bow_i)}\\\\\n=\\frac{\\frac{1}{2}\\times\\frac{3}{4}}{\\frac{1}{2}\\times\\frac{3}{4}+\\frac{1}{2}\\times\\frac{1}{2}}=\\frac{3}{5}\n\\end{array}\nP(c \\mid x)=\\frac{P(x \\mid c) P(c)}{P(x)}\nP(c|x) is the posterior probability of class c given features.\nP(c) is the probability of class.\nP(x|c) is the likelihood which is the probability of features given class.\nP(x) is the prior probability of features.\n\n4.1.3\nBased on our training set we can also say the following:\n\nFrom 500 bananas 400 (0.8) are Long, 350 (0.7) are Sweet and 450 (0.9) are Yellow\n\nOut of 300 oranges, 0 are Long, 150 (0.5) are Sweet and 300 (1) are Yellow\n\nFrom the remaining 200 fruits, 100 (0.5) are Long, 150 (0.75) are Sweet and 50 (0.25) are Yellow\n\n\n\nP\\left(x_{1}, x_{2}, \\ldots, X_{n} \\mid c\\right)=\\prod_{x \\in X} P(x \\mid c)\n\\begin{gathered}\nP\\left(\\frac{\\text { Banana }}{\\text { Long, } \\text { Sweet }, \\text { Yellow }}\\right)=\\frac{P\\left(\\frac{\\text { Long }}{\\text { Banana }}\\right) \\times P\\left(\\frac{\\text { Sweet }}{\\text { Banana }}\\right) \\times P\\left(\\frac{\\text { Yellow }}{\\text { Banana }}\\right) \\times P(\\text { Banana })}{P(\\text { Long }) P(\\text { Sweet }) P(\\text { Yellow })} \\\\\nP\\left(\\frac{\\text { Banana }}{\\text { Long }, \\text { Sweet }, \\text { Yellow }}\\right)=(0.8) \\times(0.7) \\times(0.9) \\times(0.5)\\times\\alpha=0.252\\alpha\n\\end{gathered}\n\\begin{gathered}\nP\\left(\\frac{\\text { Orange }}{\\text { Long, } \\text { Sweet }, \\text { Yellow }}\\right)=0\\end{gathered}\n\\begin{gathered}\nP\\left(\\frac{\\text { Other }}{\\text { Long, Sweet, Yellow }}\\right)=\\frac{P\\left(\\frac{\\text { Long }}{\\text { Other }}\\right) \\times P\\left(\\frac{\\text { Sweet }}{\\text { Other }}\\right) \\times P\\left(\\frac{\\text { Yellow }}{\\text { Other }}\\right) \\times P \\text { (Other) }}{P(\\text { Long }) P(\\text { Sweet }) P(\\text { Yellow })}\\\\\n={P\\left(\\frac{(0.5) \\times(0.75) \\times(0.25) \\times(0.2)}{\\text { Long, Sweet, Yellow }}\\right)=(0.5) \\times(0.75) \\times(0.25) \\times(0.2)\\times\\alpha=0.01875\\alpha}\n\\end{gathered}\nSo itâ€™s banana\n\n4.2 Naive Bayes Classifier\n\\begin{aligned}\n&c_{M A P}=\\underset{c \\in C}{\\operatorname{argmax}} P(c \\mid d)\\\\\n&=\\underset{c \\in C}{\\operatorname{argmax}} \\frac{P(d \\mid c) P(c)}{P(d)}\\\\\n&=\\underset{c \\in C}{\\operatorname{argmax}} P(d \\mid c) P(c)\n\\end{aligned}\n\\left.c_{M A P}=\\underset{c \\in C}{\\arg \\max } P(d / c)\\right\\}(c)ä¾‹ï¼šç»™å®šå¥½è¯„ï¼Œå¯¹åº”è¯„è®ºçš„æ¦‚ç‡? æ˜¯å¦æ„Ÿåˆ°å¾ˆå¥‡æ€ª?\n\nc_{M A P}=\\arg \\max _{c \\in C}[P(d / c) p(c)\n=\\underset{c \\in C}{\\operatorname{argmax}} P\\left(x_{1}, x_{2}, \\ldots, x_{n} \\mid c\\right) P(c)\n parameters\n\n\nP\\left(x_{1}, x_{2}, \\ldots, x_{n} \\mid c\\right)=\\prod_{x \\in X} P(x \\mid c)\nAssume that conditionally independent\n\n\nc_{N B}=\\underset{c \\in C}{\\operatorname{argmax}} P\\left(c_{j}\\right) \\prod_{x \\in X} P(x \\mid c)5. Learning the Naive Bayes Model\n\nSimply use the frequencies in the data (maximum likelihood estimates)\n\n\n\\begin{gathered}\n\\hat{P}\\left(c_{j}\\right)=\\frac{\\operatorname{doccount}\\left(C=c_{j}\\right)}{N_{d o c}} \\\\\n\\hat{P}\\left(w_{i} \\mid c_{j}\\right)=\\frac{\\operatorname{count}\\left(w_{i}, c_{j}\\right)}{\\sum_{w \\in V} \\operatorname{count}\\left(w, c_{j}\\right)}\n\\end{gathered}\n is equal to the likelihood of documents from class \n is equal to the likelihood of the word  in class \n\nCreate mega-document for topic j by concatenating all docs in this topic\n\nUse frequency of w in mega-document\n\n\n\n5.1 Laplace (add-1) smoothing\n\\begin{aligned}\n\\hat{P}\\left(w_{i} \\mid c\\right) &=\\frac{\\operatorname{count}\\left(w_{i}, c\\right)+1}{\\left.\\sum_{w \\in V}(\\operatorname{count}(w, c))+1\\right)} \\\\\n&=\\frac{\\operatorname{count}\\left(w_{i}, c\\right)+1}{\\left.\\sum_{w \\in V} \\operatorname{count}(w, c)\\right)+|V|}\n\\end{aligned}\n5.2 unknown wordAdd one extra word to the vocabulary, the â€œunknown wordâ€ \n\n\\begin{aligned}\n\\hat{P}\\left(w_{u} \\mid c\\right) &=\\frac{\\operatorname{count}\\left(w_{u}, c\\right)+1}{\\left(\\sum_{w \\in V} \\operatorname{count}(w, c)\\right)+|V+1|} \\\\\n&=\\frac{1}{\\left(\\sum_{w \\in V} \\operatorname{count}(w, c)\\right)+|V+1|}\n\\end{aligned}6. Try again with Textual examples\n\n\\begin{array}{r}\n\\hat{P}(c)=\\frac{N_{c}}{N} \\\\\n\\hat{P}(w \\mid c)=\\frac{\\operatorname{count}(w, c)+1}{\\operatorname{count}(c)+|V|}\n\\end{array}Priors\n\n\\begin{array}\\\\\nP(c)=\\frac{3}{4}\\\\\nP(j)=\\frac{1}{4}\n\\end{array}Conditional Probabilities:\n\n\\begin{array}\\\\\nP(\\text{Chinese|c}) = \\frac{5+1}{8+6}=\\frac{3}{7}\\\\\nP(\\text{Tokyo|c}) = \\frac{0+1}{8+6}=\\frac{1}{14}\\\\\nP(\\text{Japan|c}) = \\frac{0+1}{8+6}=\\frac{1}{14}\\\\\nP(\\text{Chinese|j}) = \\frac{1+1}{3+6}=\\frac{2}{9}\\\\\nP(\\text{Tokyo|j}) = \\frac{1+1}{3+6}=\\frac{2}{9}\\\\\nP(\\text{Japan|j}) = \\frac{1+1}{3+6}=\\frac{2}{9}\\\\\n\\end{array}Choosing a class:\n\n\\begin{aligned}\n\\mathrm{P}(\\mathrm{c} \\mid \\mathrm{d} 5) \\propto 3 / 4\\times (3 / 7)^{3} \\times 1 / 14 \\times 1 / 14 \n& \\approx 0.0003 \\\\\n\\mathrm{P}(\\mathrm{j} \\mid \\mathrm{d} 5) \\propto 1 / 4\\times(2 / 9)^{3} \\times 2 / 9 \\times 2 / 9 \n& \\approx 0.0001\n\\end{aligned}7. Sentiment Classification: Dealing with Negation å¦å®šè¯\nI really like this movie\n\nI really donâ€™t like this movie\n\n\nNegation changes the meaning of â€œlikeâ€ to negative.\nNegation can also change negative to positive-ish \n\nDonâ€™t dismiss this film\nDoesnâ€™t let us get bored\n\n7.1 Sentiment Classification: Dealing with NegationDas, Sanjiv and Mike Chen. 2001. Yahoo! for Amazon: Extracting market sentiment from stock message boards. In Proceedings of the Asia Pacific Finance Association Annual Conference (APFA).\nBo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning Techniques. EMNLP-2002, 79â€”86.\n\n8. NaÃ¯ve Bayes and Language ModelingNaÃ¯ve bayes classifiers can use any sort of feature\n\nURL, email address, dictionaries, network features\n\nBut if, as in the previous slides\n\nWe use only word features \nwe use all of the words in the text (not a subset)\n\nThen\n\nNaive bayes has an important similarity to language modeling.\n\nEach class = a unigram language model\nAssigning each word: P(word | c)\nAssigning each sentence: P(s|c)=Î  P(word|c)\n\n\n9. Evaluation\nprecision just represent the rate of positive example predicted by the LM, so it canâ€™t be an evidence that the model is a good model\n\n\n\\begin{gathered}\nF_{\\beta}=\\frac{\\left(\\beta^{2}+1\\right) P R}{\\beta^{2} P+R} \\\\\n\\mathrm{~F}_{1}=\\frac{2 P R}{P+R}\n\\end{gathered}10.New Generation\n\n","categories":["nlp"]},{"title":"hmm","url":"/2021/08/15/nlp%20learning/Chapter7_hmm/","content":"hmm\n\n1. Generation and Discreminent Model\n for    input  to labels \n\nå¯¹äºåˆ¤åˆ«æ¨¡å‹ï¼šæ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ\n\nå¯¹äºç”Ÿæˆæ¨¡å‹ï¼šè”åˆæ¦‚ç‡åˆ†å¸ƒ\n\nå…¶ä¸­è¡¨ç¤ºå…ˆéªŒï¼Œè¡¨ç¤ºä¼¼ç„¶\nwhere \n\n\né¢„æµ‹ï¼šå¯¹äºåˆ¤åˆ«å¼æ¨¡å‹\nâ€‹            å¯¹äºç”Ÿæˆå¼æ¨¡å‹\n\n\n2. Definition HMM\nHMMæœ‰ä¸¤ä¸ªç‹¬ç«‹æ€§å‡è®¾ï¼š\n\nè§‚æµ‹åºåˆ—ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ (A B ç‹¬ç«‹ æœ‰P(A, B) = P(A)P(B)ï¼Œæ‰€ä»¥è®¡ç®—è”åˆæ¦‚ç‡çš„æ—¶å€™æ‰èƒ½ç”¨å ä¹˜ )\nå½“å‰çŠ¶æ€ä»…ä¾èµ–äºå…ˆå‰çš„çŠ¶æ€\n\n\nNumber of states = K, Number of observations = M\n\nï¼šInitial probabilities over states (K*K matrix)\n\nï¼šTransition probabilities (K*M matrix)\n\n\n\nInput , Output â€‹ that corresponds to \n\n\nargmax_\\bold{y}P(\\bold{y}|\\bold{x},\\pi,A,B)=argmax_\\bold{y}P(\\bold{y},\\bold{x},\\pi,A,B)\nMaximun a posterior inference(MAP inference)\n\n\n\n\\begin{array}{ll}\nP(\\bold{y},\\bold{x})\n&=P(y_1,\\ldots,y_n,x_1,\\ldots,x_n)\\\\\n&=P(\\bold{x}|\\bold{y})P(\\bold{y})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))\\\\\n&\\text{æ³¨é‡Šï¼šè¿™é‡Œç”¨äº†æ¡ä»¶ç‹¬ç«‹å‡è®¾ï¼Œä»¥åŠå¯è§ç¬¦å·çš„æ¦‚ç‡åªä¸å½“å‰çŠ¶æ€æœ‰å…³}\\\\ \n&\\times P(y_1)P(y_2|y_1)P(y_3|y_1,y_2)\\ldots P(y_n|y_1,\\ldots,y_{n-1})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))P(y_1)\\prod^n_{i=2}P(y_i|y_1,\\ldots,y_{i-1})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))P(y_1)\\prod^n_{i=2}P(y_i|y_{i-1})\\\\\n&\\text{æ³¨é‡Šï¼šè¿™é‡Œç”¨äº†éšé©¬å°”å¯å¤«ä¸€é˜¶å‡è®¾ï¼Œå³å½“å‰çŠ¶æ€çš„æ¦‚ç‡åªä¸ä¸Šä¸€ä¸ªçŠ¶æ€æœ‰å…³}\\\\\n&=P(y_1)\\prod^n_{i=2}P(y_i|y_{i-1})\\prod^n_{i=1}P(x_i|y_i)\n\\end{array}\nDPæ¨å¯¼ï¼š\n\n\n\\begin{array}{ll}\n\\max_{y_1,\\ldots,y_n} P(\\bold{y},\\bold{x})\n&=\\max_{y_1,\\ldots,y_n}P(y_1,\\ldots,y_n,x_1,\\ldots,x_n)\\\\\n&=\\max_{y_1,\\ldots,y_n}P(y_1)\\prod^n_{i=2}P(y_i|y_{i-1})\\prod^n_{i=1}P(x_i|y_i)\\\\\n&=\\max_{y_1,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_2,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots\\\\& P(y_3|y_2)P(x_3|y_3)\\max_{y_1}P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_2,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots\\\\& P(y_3|y_2)P(x_3|y_3)\\max_{y_1}P(y_2|y_1)P(x_2|y_2)Score(y_1)\\\\\n&\\text{Initialize: } score_1(y_1)=P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_3,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots\\\\& P(y_4|y_3)P(x_4|y_4) \\max_{y_2}(P(y_3|y_2)P(x_3|y_3)\\max_{y_1}P(y_2|y_1)P(x_2|y_2)Score(y_1))\\\\\n&=\\max_{y_3,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots\\\\& P(y_4|y_3)P(x_4|y_4)\\max_{y_2}(P(y_3|y_2)P(x_3|y_3)Score(y_2))\\\\\n&\\text{Update: }score_2(y_2)=\\max_{y_1}P(y_2|y_1)P(x_2|y_2)Score(y_1)\\\\\n&=max_{y_n}score(y_n)\\\\\n\\end{array}\nscore(y_i)=\n\\left\\{\n\\begin{array}{cc}\nP(y_i)P(x_i|y_i),&\\text{i=1}\\\\\n\\max_{y_{i-1}}P(y_i|y_{i-1})P(x_i|y_i)Score(y_{i-1}),&\\text{i=2,$\\ldots$,n}\n\\end{array}\n\\right.\n\n\nä¸ç”¨åŠ¨æ€è§„åˆ’å‰ï¼Œç®—æ³•å¤æ‚åº¦ä¸ºâ€‹ï¼Œå³è¦éå†â€‹çš„è·¯å¾„æ•°é‡ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’åå˜ä¸ºâ€‹ï¼Œå³å¯¹äºæ¯æ¬¡è¿­ä»£åªéœ€è¦è®¡ç®—kä¸ªè”åˆæ¦‚ç‡ï¼Œæ¯ä¸ªè”åˆæ¦‚ç‡éœ€è¦è®¡ç®—kæ¬¡ä¹˜æ³•ï¼Œè€Œè¿­ä»£æ•°ä¸ºnæ¬¡ï¼Œæ‰€ä»¥æ—¶é—´å¤æ‚åº¦å¦‚ä¸Š\n\n3. Vitebri Algorithm\nâ€‹\n\nInitialization\n\nfor each hidden  â€‹â€‹â€‹\n\n\nRecursion\n\nfor t = 2 to n, for each :\n\nå³tæ—¶åˆ»éšè—çŠ¶æ€jçš„è”åˆæ¦‚ç‡ä¸ºä¸Šä¸€ä¸ªçŠ¶æ€è½¬ç§»çš„æœ€å¤§å€¼æ‰€æ¿€å‘å¯è§ç¬¦å·çš„æ¦‚ç‡\n\n\nâ€‹\næ‰¾åˆ°è·¯å¾„\n\n\n\n\nEnd\n\n\nâ€‹â€‹\nfor t=n-1 to 1(path back tracking)\n$w^(t)=\\psi_{w^(t+1)}(t+1)$\n\n\nend\n\n4. Supervised learning details\n can be estimated separately just by counting\n\ns denotes label, x denotes word, n denotes the number of total words\n\nInitial prob\n\n\n\\pi_s=\\frac{count(start\\rightarrow s)}{n}\nTransition prob\n\n\nA_{s',s}=\\frac{count(s\\rightarrow s')}{count(s)}\nEmission prob\n\n\nB_{s,x}=\\frac{count\\left(\n\\begin{array}{c}\ns\\\\\n\\downarrow\\\\\nx\n\\end{array}\n\\right)}{count(s)}5. tri-gram markov\n\\begin{array}{ll}\nP(\\bold{y},\\bold{x})\n&=P(y_1,\\ldots,y_n,x_1,\\ldots,x_n)\\\\\n&=P(\\bold{x}|\\bold{y})P(\\bold{y})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))\\\\\n&\\text{æ³¨é‡Šï¼šè¿™é‡Œç”¨äº†æ¡ä»¶ç‹¬ç«‹å‡è®¾ï¼Œä»¥åŠå¯è§ç¬¦å·çš„æ¦‚ç‡åªä¸å½“å‰çŠ¶æ€æœ‰å…³}\\\\ \n&\\times P(y_1)P(y_2|y_1)P(y_3|y_1,y_2)\\ldots P(y_n|y_1,\\ldots,y_{n-1})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))P(y_1)P(y_2|y_1)\\prod^n_{i=3}P(y_i|y_1,\\ldots,y_{i-1})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))P(y_1)P(y_2|y_1)\\prod^n_{i=3}P(y_i|y_{i-2},y_{i-1})\\\\\n&\\text{æ³¨é‡Šï¼šè¿™é‡Œç”¨äº†éšé©¬å°”å¯å¤«äºŒé˜¶å‡è®¾ï¼Œå³å½“å‰çŠ¶æ€çš„æ¦‚ç‡åªä¸ä¸Šä¸€ä¸ªçŠ¶æ€æœ‰å…³}\\\\\n&=P(y_1)P(y_2|y_1)\\prod^n_{i=3}P(y_i|y_{i-2},y_{i-1})\\prod^n_{i=1}P(x_i|y_i)\n\\end{array}\n\\begin{array}{ll}\n\\max_{y_1,\\ldots,y_n} P(\\bold{y},\\bold{x})\n&=\\max_{y_1,\\ldots,y_n}P(y_1,\\ldots,y_n,x_1,\\ldots,x_n)\\\\\n&=\\max_{y_1,\\ldots,y_n}P(y_1)P(y_2|y_1)\\prod^n_{i=3}P(y_i|y_{i-2},y_{i-1})\\prod^n_{i=1}P(x_i|y_i)\\\\\n&=\\max_{y_1,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots \\\\&P(y_3|y_1,y_2)P(x_3|y_3)P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_2,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_4|y_2,y_3)P(x_4|y_4)\\\\&\\max_{y_1}P(y_3|y_1,y_2)P(x_3|y_3)P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_2,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_4|y_2,y_3)P(x_4|y_4)\\\\&\\max_{y_1}P(y_3|y_1,y_2)P(x_3|y_3)Score(y_1,y_2)\\\\\n&\\text{Initialize: } score_1(y_1,y_2)=P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_3,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_5|y_3, y_4)P(x_5|y_5) \\\\&\\max_{y_2}P(y_4|y_2,y_3)P(x_4|y_4)\\max_{y_1}P(y_3|y_1,y_2)P(x_3|y_3)Score(y_1,y_2)\\\\\n&=\\max_{y_3,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_5|y_3,y_4)P(x_5|y_5)\\\\&\\max_{y_2}P(y_4|y_2,y_3)P(x_4|y_4)Score(y_2,y_3))\\\\\n&\\text{Update: }score(y_2,y_3)=\\max_{y_1}P(y_3|y_1,y_2)P(x_3|y_3)Score(y_1,y_2)\\\\\n&\\vdots\\\\\n    &=\\max_{y_{n-2},y_{n-1},y_n}P(y_n|y_{n-2},y_{n-1})P(x_n|y_n)\\\\&\\max_{y_{n-3}}P(y_{n-1}|y_{n-3},y_{n-2})P(x_{n-1}|y_{n-1})Score(y_{y_{n-3}},y_{n-2})\\\\\n&\\text{Update: }score(y_{n-2},y_{n-1})=\\max_{y_{n-3}}P(y_{n-1}|y_{n-3},y_{n-2})P(x_{n-1}|y_{n-1})Score(y_{y_{n-3}},y_{n-2})\\\\\n&=\\max_{y_{n-2},y_{n-1},y_n}P(y_n|y_{n-2},y_{n-1})P(x_n|y_n)score(y_{n-2},y_{n-1})\\\\\n&=\\max_{y_{n-1},y_n}\\max_{y_{n-2}}P(y_n|y_{n-2},y_{n-1})P(x_n|y_n)score(y_{n-2},y_{n-1})\\\\\n&=\\max_{y_{n-1},y_{n}}score(y_{n-1},y_{n})\n\\end{array}\nscore(y_{i},y_{i+1})=\n\\left\\{\n\\begin{array}{cc}\nP(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1),&\\text{i=1}\\\\\n\\max_{y_{i-1}}P(y_{i+1}|y_{i-1},y_{i})P(x_{i+1}|y_{i+1})score(y_{i-1},y_{i}),&\\text{i=2,$\\ldots$,n-1}\n\\end{array}\n\\right.5.1 Vitebri Algorithm\n\næ¯æ¬¡éœ€è¦è®¡ç®—k*kç§ç»„åˆçš„éšè—çŠ¶æ€æ¦‚ç‡ï¼Œæ¯æ¬¡è®¡ç®—éœ€è¦kæ¬¡ä¹˜æ³•ï¼Œæœ€ç»ˆå¤æ‚åº¦ä¸º\n\n","categories":["nlp"]},{"url":"/2022/02/02/github_skills/github_push/","content":"\ntitle:github_pushdate:2022-02-08description:github push\ncategories:github_skillsgithub push\n\n\nä½¿ç”¨VS Codeæ¨é€ä»£ç åˆ°GitHub - cheney-yang - åšå®¢å›­ (cnblogs.com)\n\nå…³äºpullå†²çªé—®é¢˜\n\ngithubè¿œç¨‹ä»“åº“å’Œæœ¬åœ°ä»“åº“ä¿®æ”¹åçš„pushé—®é¢˜_Wind_wavingçš„åšå®¢-CSDNåšå®¢\n\n\n"},{"url":"/2022/02/08/github_skills/teamwork_tips/","content":"\ntitle:pull-requestdate:2022-02-08description:pull requestcategories:github_skills\n\nå›¢é˜Ÿåä½œ\n\n\nã€åŸåˆ›ã€‘Githubå›¢é˜Ÿåä½œä¹‹Pullè¯·æ±‚_weixin_34410662çš„åšå®¢-CSDNåšå®¢\ngit å›¢é˜Ÿåä½œ ä½¿ç”¨GitHub push pull clone - SKPrimin - åšå®¢å›­ (cnblogs.com)\n\n"},{"title":"Gray-Level Grouping","url":"/2021/08/15/Image%20processing/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1/GLG%E7%AE%97%E6%B3%95/","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.https://blog.csdn.net/linyacool/article/details/74982487\næ€æƒ³æ¦‚è¿°æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåº”ç”¨åœ¨ç°åº¦å›¾ä¸Šçš„å›¾åƒå¯¹æ¯”åº¦å¢å¼ºç®—æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦äººå·¥æ”¹å˜ç®—æ³•å‚æ•°çš„æƒ…å†µä¸‹è‡ªåŠ¨å¢å¼ºå›¾åƒçš„å¯¹æ¯”åº¦ï¼Œæé«˜æ˜¾ç¤ºæ•ˆæœã€‚ç®—æ³•æ“ä½œçš„å¯¹è±¡é›†ä¸­åœ¨ç°åº¦ç›´æ–¹å›¾ä¸Šï¼Œå¯¹æ¯”åº¦è¾ƒä½çš„å›¾åƒçš„ç›´æ–¹å›¾ç°åº¦å¤§å¤šé›†ä¸­åœ¨æŸä¸€åŒºåŸŸï¼Œç®—æ³•çš„ç›®æ ‡å°±æ˜¯è®©ç°åº¦çº§æ›´åˆç†çš„åˆ†å¸ƒåœ¨ç›´æ–¹å›¾ä¸Šã€‚æŒ¯å¹…å°çš„ç°åº¦çº§åº”å½“è·ç¦»ç›¸å¯¹è¾ƒè¿‘ï¼ŒæŒ¯å¹…å¤§çš„ç°åº¦çº§åˆ™åº”å½“ç›¸è·è¾ƒè¿œã€‚\nç®—æ³•æ¦‚è¿°\nå¯¹äºä¸€å¹…ç°åº¦å›¾åƒï¼Œé¦–å…ˆå¾—åˆ°å®ƒçš„ç»Ÿè®¡ç›´æ–¹å›¾ â€‹, æŠŠå¼ºåº¦å€¼é0çš„ç°åº¦çº§ä½œä¸ºåˆå§‹çš„ç»„, åˆå§‹åŒ– â€‹â€‹ å’Œ, åˆ†åˆ«ä½œä¸ºæ¯ä¸ªç»„ç°åº¦çº§å¤§å°çš„å·¦è¾¹ç•Œå’Œå³è¾¹ç•Œã€‚\nå¯¹äºæ¯ä¸€æ¬¡å¾ªç¯ï¼š\n(1)æ‰¾åˆ°æ‰€æœ‰ç»„ä¸­æœ€å°çš„å¼ºåº¦å€¼, è®°å½•å…¶ä¸‹æ ‡ï¼Œåœ¨è¯¥ç»„å·¦å³ä¸¤è¾¹å¯»æ‰¾è¾ƒå°çš„ç»„ä¸å…¶ç»„æˆä¸€ä¸ªæ–°çš„ç»„, æ›´æ–° ã€ã€ ã€‚\n(2)è®¡ç®—ç°åº¦çº§è½¬æ¢è¡¨ã€‚è®¡ç®—ç»„é—´é—´è·N, é¦–å…ˆå°†ä¸¤ç«¯çš„ç°åº¦çº§æ‹‰ä¼¸åˆ°è¯¥ç°åº¦çº§çš„ç«¯ç‚¹ï¼Œç„¶åæŒ‰ç…§ç»„é—´é—´è· , ç»„å†…é—´è·åœ¨  å†…å‡åŒ€åˆ†å¸ƒçš„åŸåˆ™, è®¡ç®—æ‰€æœ‰ç°åº¦çº§çš„è½¬æ¢è¡¨  ã€‚\n(3)å°†è½¬æ¢å‡½æ•°åº”ç”¨åˆ°åŸå§‹å›¾åƒä¸Šï¼Œå¾—åˆ°æ–°çš„ç›´æ–¹å›¾ï¼Œè®¡ç®—åƒç´ é—´çš„å¹³å‡è·ç¦»Dã€‚å¾ªç¯ç›´åˆ°ç»„æ•°ä¸º2ã€‚å¯»æ‰¾æœ€å¤§çš„åƒç´ å¹³å‡è·ç¦»Dæ‰€å¯¹åº”çš„è½¬æ¢å‡½æ•° , å¹¶å°†åŸå§‹å›¾åƒè½¬æ¢ä¸ºæœ€ç»ˆçš„å¯¹æ¯”åº¦å¢å¼ºäº†çš„å›¾åƒã€‚\n\n\n\n\n\n\n\nâ€‹ ä¸ºå½“å‰ç»„æ•°ï¼Œkä¸ºç°åº¦é˜¶æ•°\n\nåˆå§‹å€¼ â€‹\n\næ›´æ–°\n\n\nG_{n-1}(i)= \\begin{cases}G_{n}(i), & \\text { for } i=1,2, \\ldots, i^{\\prime}-1 \\\\ a+b, & \\text { for } i=i^{\\prime} \\\\ G_{n}(i+1), & \\text { for } i=i^{\\prime}+1, i^{\\prime}+2, \\ldots, n-1\\end{cases}\n\nb=\\min \\left\\{G_{n}\\left(i_{a}-1\\right), G_{n}\\left(i_{a}+1\\right)\\right\\}\n\ni^{\\prime}= \\begin{cases}i_{a}-1, & \\text { for } G_{n}\\left(i_{a}-1\\right) \\leq G_{n}\\left(i_{a}+1\\right) \\\\ i_{a}, & \\text { otherwise. }\\end{cases}\n\n\n\n\nâ€‹â€‹\n\nå·¦/å³è¾¹ç•Œ ä¿å­˜ç»„å†…åºå·\n\nåˆå§‹å€¼\n\n\nL_{n}(i)=R_{n}(i) =k, \\text { for } H_{n}(k) \\neq 0 \\\\\nk=0,1,2, \\ldots, M-1, \\quad i=1,2,3, \\ldots, n\n\n\n\n\n\n\nç°åº¦é˜¶æ•°æœ€å°çš„ç»„çš„\n\n\n\n\ntransformation fuction\n\n\n\n\n\nN_{n-1}=\\frac{M-1}{n-1-\\alpha}\né˜²æ­¢å½“æœ€å·¦ä¾§ç»„åªæœ‰ä¸€ä¸ªç°åº¦é˜¶æ•°çš„æ—¶å€™ è¿™ä¸€ä¸ªç°åº¦é˜¶æ•°å å¤ªå¤šç©ºé—´ ä»è€Œä¸å¹³å‡\n\n\n\n\n\nåƒç´ çš„å¹³å‡è·ç¦»\n\n\nD_{n-1}=\\frac{1}{N_{p i x}\\left(N_{p i x}-1\\right)} \\sum_{i=0}^{M-2} \\sum_{j=i+1}^{M-1} H_{n-1}(i) H_{n-1}(j)(j-i)\n\n\nå›¾ç‰‡ä¸­çš„æ€»åƒç´ æ•°\n\n\næ‰¾åˆ°æœ€å¥½çš„â€‹ä½¿å¾—æœ€å¤§\n\n\n\n\nä»£ç å®ç°pythonç‰ˆæœ¬2.7\n# coding=utf-8import numpy as npimport cv2import scipy.miscimport os#import matplotlib.pyplot as pltimport warningsfrom argparse import ArgumentParserwarnings.filterwarnings(\"ignore\")ALPHA = 0.8M = 256Threshold = 10def build_parser():    parser = ArgumentParser()    parser.add_argument('--image',                        dest = 'img', help = 'input image',                        metavar = 'INPUT_IMAGE.jpg', required = True)    parser.add_argument('--result',                        dest='res', help='output image',                        metavar='OUTPUT_IMAGE.jpg', required=True)    return parserdef Trans_and_CalcD(H = [],T = []):    M = len(H)    Tar = np.zeros(M+1)    for i in range(M):        if H[i] != 0:            Tar[T[i]] = H[i]    D = 0    for i in range(0,M-1):        for j in range(i+1,M):            D = D + Tar[i] * Tar[j] * (j - i)    return Ddef ten(img):    height, width = np.shape(img)    '''    ix = [-1,0,1   iy = [1,2,1          -2,0,2         0,0,0          -1,0,1]        -1,-2,-1]    '''    ans = 0    for i in range(1,height-1):        for j in range(1,width-1):            Sx = img[i-1][j+1] + 2 * img[i][j+1] + img[i+1][j+1] - (img[i-1][j-1] + 2 * img[i][j-1] + img[i+1][j-1])            Sy = img[i-1][j-1] + 2 * img[i-1][j] + img[i-1][j+1] - (img[i+1][j-1] + 2 * img[i+1][j] + img[i+1][j+1])            temp = Sx * Sx + Sy * Sy            if temp &gt; Threshold:                ans = ans + temp    return ansdef glg(img):    height,width = np.shape(img)    Npix = height * width    scipy.misc.imsave('original_img.jpg', img)    hist = cv2.calcHist([img], [0], None, [M], [0.0, 255.0])    #show histogram of the original image    '''    bins = np.arange(257)    item = img[:, :]    hist, bins = np.histogram(item, bins)    width = 0.7 * (bins[1] - bins[0])    center = (bins[:-1] + bins[1:]) / 2    plt.bar(center, hist, align='center', width=width)    plt.show()    '''    temp = [0]    temp_gray_level = np.zeros(M)    cnt = 1    for i in range(M):        if hist[i] != 0:            temp.append(hist[i])            temp_gray_level[cnt] = i            cnt = cnt + 1    n = len(temp) - 1    G = [[0] for i in range(n+2)]    gray_level = [[0 for _ in range(n+1)] for __ in range(n+1)]    G[n] = temp    gray_level[n] = temp_gray_level    L = [[0] for i in range(n+2)]    R = [[0] for i in range(n+2)]    for k in range(M):        if hist[k] != 0:            L[n].append(k)            R[n].append(k)    N = np.zeros(n+2).astype(float)    T = [[0 for k in range(M+1)] for i in range(n+2)]    D = np.zeros(n+2)    maxD = 0    Iopt = n - 1    while n &gt;= 3:        #compute Gn-1,Ln-1,Rn-1,i'        a = min(G[n][1:n+1])        ia = G[n].index(a)        left = True        if ia == 1:            b = G[n][ia+1]            left = False        elif ia == n:            b = G[n][ia-1]        else:            if G[n][ia-1] &lt;= G[n][ia+1]:                b = G[n][ia-1]                left = True            else:                b = G[n][ia+1]                left = False        if left:            ii = ia - 1        else:            ii = ia        for i in range(1,ii):            G[n-1].append(G[n][i])            gray_level[n-1][i] = gray_level[n][i]        G[n-1].append(a+b)        gray_level[n-1][ii] = gray_level[n][ii]        for i in range(ii+1,n):            G[n-1].append(G[n][i+1])            gray_level[n-1][i] = gray_level[n][i+1]        for i in range(1,ii+1):            L[n-1].append(L[n][i])        for i in range(ii+1,n):            L[n-1].append(L[n][i+1])        for i in range(1,ii):            R[n-1].append(R[n][i])        for i in range(ii,n):            R[n-1].append(R[n][i+1])        if L[n-1][1] != R[n-1][1]:            N[n-1] = (M - 1)/float(n - 1)        else:            N[n-1] = (M - 1)/float(n - 1 - ALPHA)        for k in range(0,M):            if k &lt;= L[n-1][1]:                T[n - 1][k] = 0                continue            if k &gt;= R[n-1][n-1]:                T[n-1][k] = M - 1                continue            i = 0            for x in range(1,n):                if k &gt;= L[n-1][x] and k &lt; R[n-1][x]:                    i = x                    if i &gt; 0 and L[n-1][i] != R[n-1][i]:                        if L[n-1][1] == R[n-1][1]:                            ans = int((i - ALPHA - (R[n - 1][i] - k) / float(R[n - 1][i] - L[n - 1][i])) * float(N[n - 1]) + 1 + 0.5)                            T[n - 1][k] = ans                        else:                            ans = int((i - (R[n - 1][i] - k) / float(R[n - 1][i] - L[n - 1][i])) * float(N[n - 1]) + 1 + 0.5)                            T[n - 1][k] = ans                    elif i &gt; 0 and L[n-1][i] == R[n-1][i]:                        if L[n-1][1] == R[n-1][1]:                            T[n - 1][k] =int(((i - ALPHA) * float(N[n - 1])) + 0.5)                        else:                            T[n - 1][k] =int((i * float(N[n - 1])) + 0.5)                elif k == R[n-1][x]:                    i = x                    if L[n-1][1] == R[n-1][1]:                        T[n - 1][k] = int(((float (i) - ALPHA) * float(N[n - 1])) + 0.5)                    else:                        T[n - 1][k] = int((i * float(N[n - 1])) + 0.5)             #can be deleted                if i == 0:                    T[n-1][k] = T[n-1][k-1]        D[n-1] = Trans_and_CalcD(hist,T[n-1])        if D[n - 1] &gt; maxD:            maxD = D[n - 1]            Iopt = n - 1        #print n - 1, D[n - 1]        n = n - 1    return T[Iopt],D[Iopt]/(float (Npix) * (Npix - 1))def main():    parser = build_parser()    options = parser.parse_args()    if not os.path.isfile(options.img):        parser.error(\"Image %s does not exist.)\" % options.network)    res = options.res    img = cv2.imread(options.img, cv2.IMREAD_GRAYSCALE)    Trans,PixDist = glg(img)    height, width = np.shape(img)    #reconstruct the enhangced image    image = np.copy(img)    for i in range(0,height):        for j in range(0,width):            image[i][j] = Trans[img[i][j]]    scipy.misc.imsave(res,image)    print \"The PixDist is %.1lf\" %PixDistif __name__ == '__main__':    main()\n","categories":["ImageProcessing"]},{"title":"Structure from motion (SFM)","url":"/2021/08/15/cv/10.%20Structure%20from%20motion%20(SFM)/","content":"Structure from motion (SFM)\n\nStructure from motion (SFM)1. Affine structure from motion\nGiven a set of corresponding points in two or more images, compute the camera parameters and the 3D point coordinates\n\nä»å›¾åƒä¸­æ‰¾ä¸€äº›ç‚¹ï¼Œå†æ¢å¤åˆ°3Dç©ºé—´\n\n\n\n1.1 Recall: Corresponding point detection\nDetect SIFT features\n\n\n\nMatch features between each pair of images\n\n\n\nä½•ç§æ–¹æ³•å¯èƒ½ä¼šå‡ºç°é”™è¯¯\nUse RANSAC to estimate fundamental matrix between each pair\nä¸æ–­æ‰¾8ä¸ªç‚¹å»ä¼°è®¡FçŸ©é˜µï¼Œå¯¹äºæ­£ç¡®çš„Fï¼Œä¸€å®šå¯ä»¥ä½¿å¾—è¿™äº›ç‚¹æ»¡è¶³çŸ©é˜µå˜æ¢å…³ç³»ï¼Œé‚£ä¹ˆå½“Fä¿ç•™å†…ç‚¹æœ€å¤šæ—¶ï¼Œåˆ™Fæ­£ç¡®\nè¿™æ ·ä¼°è®¡å‡ºæ¥çš„Få¯ä»¥ç”¨äºå»é™¤ä¸€äº›é”™è¯¯çš„åŒ¹é…\n\n\nKeep only the matches at are â€œinliersâ€ with respect to the best fundamental matrix\nåªä¿ç•™ä¸æœ€ä½³åŸºæœ¬çŸ©é˜µç›¸å…³çš„â€œå†…è”â€åŒ¹é…\n\n\n\n1.2 Structure from motion\nGiven: $m$ images of $n$ fixed 3D points\n\n\\mathbf{x}_{i j}=\\mathbf{P}_{i} \\mathbf{X}_{j}, i=1, \\ldots, m, \\quad j=1, \\ldots, n\nestimate $m$ projection matrices $\\mathbf{P}_{i}$ motion\n\nestimate $n$â€‹ 3D points $\\mathbf{X}_{j}$â€‹ from the $m n$â€‹ correspondences $\\mathbf{x}_{i j}$â€‹ structure\n\n\n\n1.3 Orthographic Projection\n\n\\left[\\begin{array}{llll}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny \\\\\nz \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{l}\nx \\\\\ny \\\\\n1\n\\end{array}\\right] \\Rightarrow(x, y)1.4 Affine cameras\nA general affine camera combines the effects of an affine transformation of the $3 D$ space, orthographic projection, and an affine transformation of the image:\n\n\n\\begin{array}{l}\n\\mathbf{P}=[3 \\times 3 \\text { affine }]\\left[\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{array}\\right][4 \\times 4 \\text { affine }]\\\\\n=\\left[\\begin{array}{cccc}\na_{11} & a_{12} & a_{13} & b_{1} \\\\\na_{21} & a_{22} & a_{23} & b_{2} \\\\\n0 & 0 & 0 & 1\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n\\mathbf{A} & \\mathbf{b} \\\\\n\\mathbf{0} & 1\n\\end{array}\\right]\n\\end{array}\nAffine projection is a linear mapping + translation in non-homogeneous coordinates (in Euclidean space))\nè½¬æ¢ä¸ºéé½æ¬¡åæ ‡ç³»\n\n\n\n\n\n\nGiven: $m$ images of $n$ fixed 3D points:\n\\mathbf{x}_{i j}=\\mathbf{A}_{i} \\mathbf{X}_{j}+\\mathbf{b}_{i}, \\quad i=1, \\ldots, m, j=1, \\ldots, n\nProblem: use the $m n$ correspondences $x_{i j}$ to estimate $m$ projection matrices $A_{i}$ and translation vectors $b_{i}$, and $n$ points $X_{j}$\n\nCentering: subtract the centroid of the image points in each view\n\nå¯¹äºæ¯å¼ å›¾ç‰‡åšä¸€ä¸ªä¸­å¿ƒåŒ–å¤„ç†\nè¿™ç§å˜æ¢ç­‰ä»·äºåœ¨ç©ºé—´ä¸Šå…ˆåšä¸­å¿ƒåŒ–ï¼Œåœ¨è¿›è¡ŒæŠ•å½±\n\n\n\n\n\\begin{aligned}\n\\hat{\\mathbf{x}}_{i j} &=\\mathbf{x}_{i j}-\\frac{1}{n} \\sum_{k=1}^{n} \\mathbf{x}_{i k}=\\mathbf{A}_{i} \\mathbf{X}_{j}+\\mathbf{b}_{i}-\\frac{1}{n} \\sum_{k=1}^{n}\\left(\\mathbf{A}_{i} \\mathbf{X}_{k}+\\mathbf{b}_{i}\\right) \\\\\n&=\\mathbf{A}_{i}\\left(\\mathbf{X}_{j}-\\frac{1}{n} \\sum_{k=1}^{n} \\mathbf{X}_{k}\\right)=\\mathbf{A}_{i} \\hat{\\mathbf{X}}_{j}\n\\end{aligned}\n\\hat{\\mathbf{x}}_{i j}=\\mathbf{A}_{i}\\left(\\mathbf{X}_{j}-\\frac{1}{n} \\sum_{k=1}^{n} \\mathbf{X}_{k}\\right)=\\mathbf{A}_{i} \\hat{\\mathbf{X}}_{j}\nFor simplicity, set the origin of the world coordinate system to the centroid of the 3D points\nä»¥ä¸–ç•Œåæ ‡ç³»çš„åŸç‚¹ä¸ºä¸­å¿ƒç‚¹ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ç®€åŒ–è¡¨è¾¾å¼\n\n\nAfter centering, each normalized $2 D$ point is related to the $3 D$ point $X_{j}$â€‹ by\n\n\n\\hat{\\mathbf{x}}_{i j}=\\mathbf{A}_{i} \\mathbf{X}_{j}\nLetâ€™s create a $2 m \\times n$ data (measurement) matrix:\n\n\n\\mathbf{D}=\\left[\\begin{array}{cccc}\n\\hat{\\mathbf{x}}_{11} & \\hat{\\mathbf{x}}_{12} & \\cdots & \\hat{\\mathbf{x}}_{1 n} \\\\\n\\hat{\\mathbf{x}}_{21} & \\hat{\\mathbf{x}}_{22} & \\cdots & \\hat{\\mathbf{x}}_{2 n} \\\\\n& & \\ddots & \\\\\n\\hat{\\mathbf{x}}_{m 1} & \\hat{\\mathbf{x}}_{m 2} & \\cdots & \\hat{\\mathbf{x}}_{m n}\n\\end{array}\\right]=\\underset{cameras(2m Ã—3)}{\\left[\\begin{array}{c}\n\\mathbf{A}_{1} \\\\\n\\mathbf{A}_{2} \\\\\n\\vdots \\\\\n\\mathbf{A}_{m}\n\\end{array}\\right]}\\underset{points (3Ã—n)}{\\left[\\begin{array}{cccc}\n\\mathbf{X}_{1} & \\mathbf{X}_{2} & \\cdots & \\mathbf{X}_{n}\n\\end{array}\\right]}\n$x_{ij}$â€‹æ˜¯21ï¼Œ$A_i$â€‹æ˜¯2\\3,$X_i$â€‹æ˜¯3*1\n\nThe measurement matrix $\\mathbf{D}=\\mathbf{M S} $â€‹ must have rank 3 !\n\n\n1.5 Factorizing the measurement matrix\nSingular value decomposition of D:\n\n\n\nObtaining a factorization from SVD:\nå¥‡å¼‚å€¼åˆ†è§£åï¼Œæˆ‘ä»¬é€‰å–ç‰¹å¾å€¼æœ€å¤§çš„ä¸‰ä¸ªå€¼æ‰€å¯¹åº”çš„$U$å’Œ$V$\n\n\n\n\n\nå› ä¸ºæ¢å¤å­˜åœ¨æ­§ä¹‰æ€§æ‰€ä»¥æ¢å¤å‡ºæ¥çš„ä¸‰ç»´ç»“æ„å¯èƒ½ä¼šå¤±å»æ·±åº¦ä¿¡æ¯ï¼Œå³ä¼šå‘ç”Ÿå˜å½¢\n$HS$ä¸ºä»¿å°„å˜æ¢ï¼Œæ‰€ä»¥ä¼šå‘ç”Ÿå˜å½¢\n\n\n\n\nD=MS=MH^{-1}HS\nThe decomposition is not unique. We get the same D by using any $3 \\times 3$â€‹ matrix $\\mathrm{C}$â€‹ and applying the transformations $\\mathrm{M} \\rightarrow \\mathrm{MC}, \\mathrm{S} \\rightarrow \\mathrm{C}^{-1} \\mathrm{~S}$â€‹\nThat is because we have only an affine transformation and we have not enforced any Euclidean constraints (like forcing the image axes to be perpendicular, for example)\n\n\n\nä¸€ç§è§£å†³æ–¹æ³•ï¼šåŠ å…¥å…ˆéªŒ\nç¬¬äºŒç§é€šè¿‡ç¯ç®±å®éªŒï¼ŒåŠ å…¥é€‚å½“çº¦æŸ\n\n2. Projective structure from motion\nGiven: $m$ images of $n$ fixed 3 D points\n\n\nx_{i j}=P_{i} X_{j}, i=1, \\ldots, m, \\quad j=1, \\ldots, n\nProblem: estimate $m$â€‹ projection matrices $\\boldsymbol{P}_{i}$â€‹ and $n$â€‹ 3D points $\\boldsymbol{X}_{j}$â€‹ from the $m n$â€‹ correspondences $x_{i j} $â€‹\n\n\n\nWith no calibration info, cameras and points can only be recovered up to a $4 \\times 4$â€‹ projective transformation $\\boldsymbol{H}$â€‹â€‹ :\nåŠ å…¥æ ‡å®šä¿¡æ¯çš„å˜æ¢\n\n\n\n\n\\begin{array}{cc}\nx=P X & P=K[R T] \\\\\n\\downarrow & \\downarrow \\\\\nH X & P H^{-1} \\\\\nx=P X=P H^{-1} H X &\n\\end{array}2.1 Problem\nFactorization method (by SVD) Assume all points are visible. \nThis not true if: occlusions occur \nå¦‚æœå‡ºç°é®æŒ¡ï¼Œä¼šå‡ºç°ç¼ºå¤±ç‚¹ï¼Œå¯¼è‡´ä¸€äº›ç‚¹ç”¨ä¸äº†\n\n\nfailure in establishing correspondences\nå…¶æ¬¡å¦‚æœç‚¹çš„å¯¹åº”å…³ç³»æ— æ³•æ‰¾åˆ°ä¹Ÿç”¨ä¸äº†\n\n\n\n\n\n2.2 Algebraic approach : Two-camera case\nCompute fundamental matrix $\\mathbf{F}$ between the two views From at least 8 point correspondences, compute $F$ associated to camera 1 and 2\nUse $\\mathrm{F}$â€‹ to estimate projective cameras\n\n\n\\mathrm{F}->P_{1}, P_{2}\nUse these cameras to triangulate and estimate points in 3D\n\n\nX_{j}^{*}=\\arg \\min \\left(d^{2}\\left(\\mathbf{x}_{1 j}, \\mathbf{P}_{1} \\mathbf{X}_{j}\\right)+d^{2}\\left(\\mathbf{x}_{2 j}, \\mathbf{P}_{2} \\mathbf{X}_{j}\\right)\\right)\n3. Bundle adjustment\nNon-linear method for refining structure and motion \nMinimize reprojection error\n\n\n\\sum_{i=1}^{m} \\sum_{j=1}^{n} D\\left(\\mathbf{x}_{i j}-\\mathbf{P}_{i} \\mathbf{X}_{j}\\right)^{2}\nD is the nonlinear mapping\nNonlinear minimization: Newton Method\n\n\n4. What is deep learning? How does it work?\nFully connect feedforward neural network\nLoss function\nOptimization of deep neural network\n\n4.1 Perceptron\nMathematical model\n\n\n\nDistance from a incorrect classified point to the line\n\n\n\n\nGoal: make L(w, b) as small as possible\nL(w, b)=-\\sum_{x \\in M} y_{i}\\left(w \\cdot x_{i}+b\\right)\nMethod: optimize $w$ and $b$ through gradÄ±ent descent\n\n\n\nLetâ€™s optimize w as an example\n\n\nQuestion\nCan we solve the problem below with perceptron?\n\n\n\nGoal: classifying samples to class A and class B\n\n4.2 Idea: the Two-Layer Perceptron\nTwo-Layer Perceptron\n\nFor the XOR problem, draw two, instead, of one lines\n\n\nWhat did it do?\n\n\n\nL4.3 etâ€™s consider more general cases\nRecall: Machine Learning â‰ˆ Looking for a function f\n\nSpeech Recognition\n\n\n\n\nImage Recognition\n\n\n\nPlaying Go\n\n\n\nDialogue System\n\n\n4.4 Framework\n\n\n\n4.5 Neuron\n\nz=a_{1} w_{1}+\\cdots+a_{k} w_{k}+\\cdots+a_{K} w_{K}+b4.6 Other activation functions\nRectified Linear Unit (ReLU)\ny=\\max (\\mathbf{0}, z)\nLeaky ReLU\n\n\ny= \\begin{cases}z & z>0 \\\\ \\alpha z & \\text { otherwise }\\end{cases}\nSoftplus\n\n\ny=\\ln \\left(1+e^{z}\\right)4.7 Neural Network\n\nNetwork parameter ğœƒğœƒ:all the weights and biases in the â€œneuronsâ€\n\n4.8 Fully Connect Feedforward Network\n\n4.9 Matrix Operation\n\n4.10 Output Layer as Multi-Class Classifier\n\nSoftmaxlayer as the output layer\nä¸ºäº†æ›´å¥½çš„å¯è§£é‡Šæ€§\n\n\n\n\n\n4.11 Example Application\n4.12 Loss for an Example\n4.13 Total Loss\n4.14 Gradient Descent\n\n\n4.15 Local Minima\n\nDo we really minimize the total loss in engineering?\n\n4.16 Shuffle the samples for each epoch\n4.17 Mini-batch Epoch\n\nStep #1: Randomly initialize network parameters\n\n\n\nMini-batch is Faster\n\n\n4.18 Vanishing gradient and ReLU\n\næ¢¯åº¦å‹ç¼©ï¼Œå¯¼è‡´æ¢¯åº¦åå‘ä¼ æ’­æ—¶åªèƒ½å½±å“é è¿‘è¾“å‡ºçš„layerçš„å‚æ•°\n\n4.19 Rectified Linear Unit (ReLU)\n\n\n4.20 ReLU -variant\n4.21 Learnable activation function -Maxout\nLearnable activation function [Ian J. Goodfellow, ICMLâ€™13]\n\n\n\nYou can have more than 2 elements in a group\n\nReLuæ˜¯Maxoutçš„ç‰¹ä¿—æƒ…å†µ\n\n\n\n\nå› ä¸ºmaxoutä¼šéšç€wå˜åŒ–ï¼Œæ‰€ä»¥æ˜¯å¯å­¦ä¹ çš„æ¿€æ´»å‡½æ•°\n\nHow many pieces depending on how many elements in a group\n\n\n\n\nä¸åŒçš„æ ·æœ¬ä¼šäº§ç”Ÿä¸åŒçš„ç½‘ç»œæ¶æ„ï¼Œä»è€Œæ”¹å˜æ¨¡å¼å’Œå‚æ•°éƒ½è¾¾åˆ°è°ƒæ•´\n\nGiven a training data x, we know which z would be the max\n\n\n\n\nGiven a training data x, we know which z would be the max\n\n\n\nTrain this thin and linear network1x2x\n\nDifferent thin and linear network for different examples\n\n\n4.22 Hard to find optimal parameters\n4.23 In physical worldâ€¦â€¦\n4.24 Review: Vanilla Gradient Descent\nStart at position $\\theta^{0}$\nCompute gradient at $\\theta^{0}$\nMove to $\\theta^{1}=\\theta^{0}-\\eta \\nabla L\\left(\\theta^{0}\\right)$\nCompute gradient at $\\theta^{1}$\nMove to $\\theta^{2}=\\theta^{1}-\\eta \\nabla L\\left(\\theta^{1}\\right)$\nStop until $\\nabla L\\left(\\theta^{t}\\right) \\approx 0$\n\n\n4.25 Momentum\nStart at point $\\theta^{0}$â€‹\nMovement $\\mathrm{v}^{0}=0$â€‹\nCompute gradient at $\\theta^{0}$â€‹\nMovement $\\mathrm{v}^{1}=\\lambda \\mathrm{v}^{0}-\\eta \\nabla L\\left(\\theta^{0}\\right)$â€‹\nMove to $\\theta^{1}=\\theta^{0}+\\mathrm{v}^{1}$â€‹\nCompute gradient at $\\theta^{1}$â€‹\nMovement $\\mathrm{v}^{2}=\\lambda \\mathrm{v}^{1}-\\eta \\nabla L\\left(\\theta^{1}\\right)$â€‹\nMove to $\\theta^{2}=\\theta^{1}+\\mathrm{v}^{2}$â€‹\n\nMovement not just based on gradient, but previous movement\n\n\n\n\n4.26 Dropout\nå›å¿†ä¸€ä¸‹ï¼Œ3.8èŠ‚ (å¤šå±‚æ„ŸçŸ¥æœº) çš„å›¾3.3æè¿°äº†ä¸€ä¸ªå•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºã€‚å…¶ä¸­è¾“å…¥ä¸ªæ•°ä¸º 4 ï¼Œéšè—å•å…ƒä¸ªæ•°ä¸º 5 ï¼Œä¸”éšè—å•å…ƒ $h_{i}(i=1, \\ldots, 5)$ çš„è®¡ç®—è¡¨è¾¾å¼ä¸º\n\n\nh_{i}=\\phi\\left(x_{1} w_{1 i}+x_{2} w_{2 i}+x_{3} w_{3 i}+x_{4} w_{4 i}+b_{i}\\right)\nè¿™é‡Œ $\\phi$ æ˜¯æ¿€æ´»å‡½æ•°ï¼Œ $x_{1}, \\ldots, x_{4}$ æ˜¯è¾“å…¥ï¼Œéšè—å•å…ƒ $i$ çš„æƒé‡å‚æ•°ä¸º $w_{1 i}, \\ldots, w_{4 i}$ ï¼Œåå·®å‚æ•°ä¸º $b_{i}$ ã€‚å½“å¯¹è¯¥éšè—å±‚ä½¿ç”¨ä¸Ÿå¼ƒæ³•æ—¶ï¼Œè¯¥å±‚çš„éšè—å•å…ƒå°†æœ‰ä¸€å®šæ¦‚ç‡è¢«è‡³å¼ƒæ‰ã€‚è®¾ä¸Ÿå¼ƒæ¦‚ç‡ä¸º $p$ ï¼Œé‚£ä¹ˆæœ‰ $p$ çš„æ¦‚ç‡ $h_{i}$ ä¼šè¢« æ¸…é›¶ï¼Œæœ‰ $1-p$ çš„æ¦‚ç‡ $h_{i}$ ä¼šé™¤ä»¥ $1-p$ åšæ‹‰ä¼¸ã€‚ä¸Ÿå¼ƒæ¦‚ç‡æ˜¯ä¸Ÿå¼ƒæ³•çš„è¶…å‚æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œè®¾éšæœºå˜é‡ $\\xi_{i}$ ä¸º 0 å’Œ 1 çš„æ¦‚ç‡åˆ†åˆ«ä¸º $p$ å’Œ $1-p_{\\text {ã€‚ }}$ ä½¿ç”¨ä¸Ÿå¼ƒæ³•æ—¶æˆ‘ä»¬è®¡ç®—æ–°çš„éšè—å•å…ƒ $h_{i}^{\\prime}$\n\n\nh_{i}^{\\prime}=\\frac{\\xi_{i}}{1-p} h_{i}\nç”±äº $E\\left(\\xi_{i}\\right)=1-p$ ï¼Œå› æ­¤\n\n\nE\\left(h_{i}^{\\prime}\\right)=\\frac{E\\left(\\xi_{i}\\right)}{1-p} h_{i}=h_{i}\nå³ä¸Ÿå¼ƒæ³•ä¸æ”¹å˜å…¶è¾“å…¥çš„æœŸæœ›å€¼ã€‚è®©æˆ‘ä»¬å¯¹å›¾3.3ä¸­çš„éšè—å±‚ä½¿ç”¨ä¸Ÿå¼ƒæ³•ï¼Œä¸€ç§å¯èƒ½çš„ç»“æœå¦‚å›¾3.5æ‰€ç¤ºï¼Œå…¶ä¸­ $h_{2}$ å’Œ $h_{5}$ è¢«æ¸…é›¶ã€‚è¿™æ—¶è¾“å‡ºå€¼çš„è®¡ç®—ä¸å†ä¾èµ– $h_{2}$ å’Œ $h_{5}$ ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œä¸è¿™ä¸¤ä¸ªéšè—å•å…ƒç›¸å…³çš„æƒé‡ çš„æ¢¯åº¦å‡ä¸º 0 ã€‚ç”±äºåœ¨è®­ç»ƒä¸­éšè—å±‚ç¥ç»å…ƒçš„ä¸¢å¼ƒæ˜¯éšæœºçš„ï¼Œå³ $h_{1}, \\ldots, h_{5}$ éƒ½æœ‰å¯èƒ½è¢«æ¸…é›¶ï¼Œè¾“å‡ºå±‚çš„è®¡ç®—æ— æ³•è¿‡åº¦ä¾èµ– $h_{1}, \\ldots, h_{5}$ ä¸­çš„ä»»ä¸€ä¸ªï¼Œä»è€Œåœ¨è®­ç»ƒæ¨¡å‹æ—¶èµ·åˆ°æ­£åˆ™åŒ–çš„ä½œç”¨ï¼Œå¹¶å¯ä»¥ç”¨æ¥åº”å¯¹è¿‡æ‹Ÿ åˆã€‚åœ¨æµ‹è¯•æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ä¸ºäº†æ‹¿åˆ°æ›´åŠ ç¡®å®šæ€§çš„ç»“æœï¼Œä¸€èˆ¬ä¸ä½¿ç”¨ä¸Ÿå¼ƒæ³•ã€‚\n\ndef dropout(X, drop_prob):    X = X.float()    assert 0 &lt;= drop_prob &lt;= 1    keep_prob = 1 - drop_prob    # è¿™ç§æƒ…å†µä¸‹æŠŠå…¨éƒ¨å…ƒç´ éƒ½ä¸¢å¼ƒ    if keep_prob == 0:        return torch.zeros_like(X)    mask = (torch.rand(X.shape) &lt; keep_prob).float()    return mask * X / keep_prob\n\n\nEach time before updating the parameters\nEach neuron has p% to dropout\nThe structure of the network is changed.Thinner!\n\n\nUsing the new network for training\nFor each mini-batch, we resample the dropout neurons\n\n\n\n\nWhy the weights should multiply (1-p)% (dropout rate) when testing?\n\n\n\nDropout is a kind of ensemble\n\n\n\nTrain a bunch of networks with different structures\n\n\n\n\n","categories":["CV"]},{"title":"semi-supervised learning","url":"/2021/08/15/cv/12.%20semi-supervised%20learning/","content":"semi-supervised learning\n\n1. What is semi-supervised learning?\n\nHumans learn in semi-supervised way\n\n1.1 Why semi-supervised learning helps?\n\nThe distribution of the unlabeled data tell us something.\n\n\n1.2 Low-density Separation Assumption\n\nå¸Œæœ›åˆ†å¼€çš„ç±»å†…å·®è·å°½é‡å¤§\n\nGiven: labelled data set $=\\left\\{\\left(x^{r}, \\hat{y}^{r}\\right)\\right\\}_{r=1}^{R}$, unlabeled data set $=\\left\\{x^{u}\\right\\}_{u=1}^{U}$\n\nRepeat:\n\n\n\nHard label vs Soft label\nConsidering using neural network $ğœƒ^âˆ—$(network parameter) from labelled data\n\n\n\n\n\nè½¯æ ‡è®°å¯¹è®­ç»ƒæ²¡æœ‰å½±å“ï¼Œæ‰€ä»¥åº”è¯¥ä½¿ç”¨ç¡¬æ ‡è®°\n\n1.3 Entropy-based Regularization\n\næˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„åˆ†ç±»æ˜¯éé»‘å³ç™½çš„\nå¯ä»¥é€šè¿‡ä¿¡æ¯ç†µæ¥åˆ¤æ–­æ˜¯å¦åˆ†ç±»æˆåŠŸï¼Œå¯¹äºæ— æ ‡è®°æ•°æ®æˆ‘ä»¬å¸Œæœ›å…¶åˆ†ç±»è¶Šé›†ä¸­è¶Šå¥½\n\n1.4 Smoothness Assumption\nAssumption: â€œsimilarâ€ $x$â€‹ has the same $\\hat{y}$â€‹\næ•°æ®ç›¸ä¼¼å¸¦æ¥æ ‡ç­¾ç›¸ä¼¼\n\n\nMore precisely:\n$\\mathrm{x}$ is not uniform.\nIf $x^{1}$ and $x^{2}$ are close in a high density region, $\\hat{y}^{1}$ and $\\hat{y}^{2}$ are the same.\n\n\n\n\n\nConnected by a high density path\n\n\n\næˆ‘ä»¬å¯ä»¥åœ¨è®­ç»ƒæ•°æ®åº“ä¸­æ’å…¥å¤šä¸ª2ï¼Œä½¿å¾—å¯ä»¥å·¦è¾¹çš„2å¯ä»¥é€šå‘å³è¾¹çš„2\n\nClassify astronomyvs. travelarticles\n\n\n\n\nå¯ä»¥æ‰¾åˆ°ä¸€æ¡è¿é€šåŒºåŸŸï¼Œä»è€Œè¿›è¡Œåˆ†ç±»\n\n1.5 Graph-based Approach\n$\\text { How to know } x^{1} \\text { and } x^{2} \\text { are connected by a high density path? }$\n\n\n\nDefine the similarity $s\\left(x^{i}, x^{j}\\right)$ between $x^{i}$ and $x^{j}$\n\nAdd edge:\n\nK Nearest Neighbor\ne-Neighborhood\n\n\n\n\n\n\nEdge weight is proportional to $s\\left(x^{i}, x^{j}\\right)$ Gaussian Radial Basis Function:\n\n\ns\\left(x^{i}, x^{j}\\right)=\\exp \\left(-\\gamma\\left\\|x^{i}-x^{j}\\right\\|^{2}\\right)\n\nThe labelled data influence their neighbors. Propagate through the graph\nå›¾ä¸Šçš„æ ‡è®°ä¼šéšç€è·¯å¾„ä¼ æ’­\n\n\n\n\n\n\nä¸ä¸€å®šæœ‰æ•ˆ\n\n\n\nDefine the smoothness of the labelson the graph\nwæ˜¯ç‰¹å¾ç©ºé—´çš„ç›¸ä¼¼åº¦ï¼ŒSè¶Šå°è¶Šå¹³æ»‘\n\n\n\n\n\n\nDefine the smoothness of the labels on the graph\n\n\nS=\\frac{1}{2} \\sum_{i, j} w_{i, j}\\left(y^{i}-y^{j}\\right)^{2}=y^{T} L y\n$y:(R+U)-\\operatorname{dim}$â€‹ vector\nåœ¨æ ‡è®°ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œä¼šå…ˆåˆå§‹åŒ–æ ‡ç­¾ï¼ŒRè¡¨ç¤ºæœ‰æ ‡ç­¾ï¼ŒUè¡¨ç¤ºåŸæ¥æ— æ ‡ç­¾\n\n\n\n\ny=\\left[\\cdots y^{i} \\cdots y^{j} \\cdots\\right]^{T}\n$L:(R+U) \\times(R+U)$â€‹â€‹ matrix\nDæ˜¯è¡Œå’Œæ”¾äºå¯¹è§’çº¿\n\n\n\n\nä¸åŒå±‚éƒ½å¯ä»¥åŠ å¦‚smoothï¼Œå³ä¼ æ’­åä¼šè¿”å›æ¯ä¸€å±‚çš„è¾“å‡ºä»¥ä¾¿äºè®¡ç®—loss\n\n\n2. Unsupervised Neural Network2.1  Recall: Unsupervised learningData: xJust data, no labels!Goal: Learn some underlyinghidden structure of the dataExamples: Clustering, dimensionality reduction, density estimation, etc.\n\nK-means clustering\n\n\n2.2 Auto-encoder\nå¸Œæœ›ç¼–ç å™¨å¯ä»¥è‡ªåŠ¨å‡ç»ƒç‰¹å¾ï¼Œç¼–ç ååˆå¯ä»¥æ¢å¤\n\n\n\nOutput of the hidden layer is the code\n\n\n2.3 Deep Auto-encoder\n\n\næ·±åº¦ç½‘ç»œæ›´å…·è¡¨å¾æ›´å…·åˆ¤åˆ«æ€§\n\n\n\nDe-noising auto-encoder\nå¸Œæœ›æœ‰å™ªéŸ³çš„å›¾åƒèƒ½å¤Ÿæ¢å¤ä¸ºæ— å™ªå›¾åƒï¼Œå³å¸Œæœ›è‡ªç¼–ç å™¨èƒ½å¤Ÿè‡ªä¸»å»å™ª\n\n\n\n\n\n2.4 Auto-encoder â€“Text Retrieval\n\nThe documents talking about the same thing will have close code.\n\n\n2.5 Auto-encoder â€“Similar Image Search\n2.6 Auto-encoder for CNN\n2.7 CNN -Unpooling\n2.8 CNN -Deconvolution\n\nGreedy Layer-wise Pre-training\né€å±‚è¿›è¡Œè®­ç»ƒï¼Œè®­ç»ƒå®Œåçš„å‚æ•°freeze\n\n\n\n\n\n\n\næœ€åè¿›è¡Œå¾®è°ƒ\n\n\n2.9 Why VAE (Variational Auto-Encoders)?\nå¯¹ç¼–ç è¿›è¡Œæ’å€¼èƒ½å¦é‡‡æ ·ï¼Ÿ\nä¸ä¼š\n\n\n\n\n\nä½†æˆ‘ä»¬å¸Œæœ›ç¼–ç èƒ½å¤Ÿä¸€å®šçº¿æ€§æ’å€¼å¾—åˆ°æ–°çš„å›¾ç‰‡\nå°†ç¡®å®šæ€§çš„å‘é‡å˜ä¸ºä¸€ä¸ªåˆ†å¸ƒï¼Œå³å¯¹ç¼–ç è¿›è¡ŒåŠ å™ª\n\n\n\n\n\neä¸ºæ¥è‡ªé«˜æ–¯åˆ†å¸ƒçš„é‡‡æ ·æƒå€¼ï¼Œ$\\sigma$ä¸ºæ ‡å‡†å·®\n\n\n2.10 PokÃ©mon Creation\n\nå‚ç›´æ–¹å‘æ§åˆ¶å¤§å°ï¼Œæ°´å¹³æ–¹å‘æ§åˆ¶æ–¹å‘\n\n\n2.11 Problems of VAE\nIt does not really try to simulate real images\n\n\n\næœ‰å…¶é‡æ„å‡½æ•°æ˜¯åƒç´ çº§åˆ«çš„ï¼Œæ‰€ä»¥ä¸ä¸€å®šå®Œå…¨ç›¸è¿‘\n\n3. Generative Adversarial Network (GAN)3.1 Basic Idea of GAN\n$\\text { The data we want to generate has a distribution } P_{\\text {data }}(x)$\n\n\n\nA generator G is a network. The network defines a probability distribution.\nä¸è€ƒè™‘åŸå§‹æ•°æ®çš„åˆ†å¸ƒ\n\n\n\n\n3.2 Generative adversarial networks\nTrain two networks with opposing objectives:\nGenerator:learns to generate samples\nDiscriminator:learns to distinguish between generated and real samples\n\n\nä¸¤è€…äº’ç›¸åšå¼ˆï¼Œæœ€åè¶Šæ¥è¶Šå¥½\n\n\n3.3 Evolution\n\nGenerator\næ¯ä¸€ç»´åº¦éƒ½è§‰äº†å›¾åƒæŸä¸€ç‰¹å¾\n\n\n\n\n\n\nDiscriminator\n\n\n3.4 The evolution of generation\nå›ºå®šä¸€ä¸ªæ›´æ–°å¦ä¸€ä¸ªï¼Œä»è€Œè¿­ä»£æ›´æ–°\n\n\n\nThe discriminator $D(x)$ should output the probability that the sample $x$ is real\nThat is, we want $D(x)$ to be close to 1 for real data and close to 0 for fake\nExpected conditional log likelihood for real and generated data:\nå¯¹äºåˆ¤åˆ«å™¨ï¼Œæˆ‘ä»¬å¸Œæœ›åŒºåˆ†å‡ºçœŸå‡\nè€Œç”Ÿæˆå™¨åˆ™ç›¸åï¼Œå¸Œæœ›ä»–è¶Šå°è¶Šå¥½\nV(G, D)=\\mathbb{E}_{x \\sim p_{\\text {data }}} \\log D(x)+\\mathbb{E}_{z \\sim p} \\log (1-D(G(z)))\n\n\nWe seed the generator with noise $z$ drawn from a simple distribution $p$(Gaussian or uniform)\n\n3.5 GAN objective\nV(G, D)=\\mathbb{E}_{x \\sim p_{\\text {data }}} \\log D(x)+\\mathbb{E}_{z \\sim p} \\log (1-D(G(z)))\nThe discriminator wants to correctly distinguish real and fake samples:\nD^{*}=\\arg \\max _{D} V(G, D)\nThe generator wants to fool the discriminator:\nG^{*}=\\arg \\min _{G} V(G, D)\nTrain the generator and discriminator jointly in a minimax game\n\nUpdate discriminator:\n\nRepeat for $k$ steps:\nSample mini-batch of noise samples $z_{1}, \\ldots, z_{m}$ and mini-batch of real samples $x_{1}, \\ldots, x_{m}$\n\n3.6 Training algorithm in practice\nUpdate parameters of $D$â€‹ by stochastic gradient ascent on\nRepeat for $k$ steps:\nSample mini-batch of noise samples $z_{1}, \\ldots, z_{m}$ and mini-batch of real samples $x_{1}, \\ldots, x_{m}$\nUpdate parameters of $D$ by stochastic gradient ascent on\n\\frac{1}{m} \\sum_{m}\\left[\\log D\\left(x_{m}\\right)+\\log \\left(1-D\\left(G\\left(z_{m}\\right)\\right)\\right)\\right]\n\n\n\n\nUpdate generator:\nSample mini-batch of noise samples $z_{1}, \\ldots, z_{m}$\nUpdate parameters of $G$ by stochastic gradient ascent on\n\\frac{1}{m} \\sum_{m} \\log D\\left(G\\left(z_{m}\\right)\\right)\n\n\nRepeat until happy with results\n\nUpdate discriminator: push $D\\left(x_{\\text {data }}\\right)$ close to 1 and $D(G(z))$ close to 0\n\nThe generator is a â€œblack boxâ€ to the discriminator\nThe generator is exposed to real data only via the output of the discriminator (and its gradients)\n\n\n\n\n\nTest time â€“the discriminator is discarded\n\n\n3.7 Original GAN results\nåŸå§‹GANæ¯”è¾ƒæ¨¡ç³Šï¼Œå› ä¸ºè¿™æ ·èƒ½å¤Ÿéš¾ä»¥åˆ†ç±»\n\n\n3.8 Problems with GAN training\nStability\n\nParameters can oscillate or diverge, generator loss does not correlate with sample quality\nBehavior very sensitive to hyperparameter selection\n\n\nåªèƒ½æ¨¡ä»¿å‡ ä¸ªæ¨¡å¼è€Œæ— æ³•ç”Ÿæˆå®é™…çš„å¤šæ¨¡æ€\n\nMode collapse\n\nGenerator ends up modeling only a small subset of the training data\n\n\n\n\n3.9 DCGAN\nEarly, influential convolutional architecture for generator\nä½¿ç”¨å·ç§¯ï¼Œä¸”ä¸ç”¨æ± åŒ–ï¼Œå³ç”¨strideä»£æ›¿\n\n\n\n\n\nEarly, influential convolutional architecture for generator\nDiscriminator architecture (empirically determined to give best training stability):\nDonâ€™t use pooling, only strided convolutions\nUse Leaky ReLU activations (sparse gradients cause problems for training)\nUse only one FC layer before the softmax output\nUse batch normalization after most layers (in the generator also)\né™ä½å¯¹è¶…å‚æ•æ„Ÿç¨‹åº¦\n\n\n\n\n\n3.10 DCGAN results\nInterpolation between different points in the z space\nå³æ˜¯è¿ç»­çš„\n\n\n\n\n\nVector arithmetic in the z space\n\n\n\nPose transformation by adding a â€œturnâ€ vector\n\n\n4. Conditional generation\nTo condition the generation of samples on discrete side information (label) ğ‘¦, we need to add ğ‘¦ as an input to both generator and discriminator\nåŠ å…¥ç±»çš„æ ‡ç­¾ï¼ŒåŠ å…¥é™åˆ¶\n\n\n\n\n4.1 BigGAN\nClass-conditional generation of ImageNet images up to\n\n\n\nå¯¹Zç©ºé—´è¿›è¡Œæˆªæ–­ï¼Œé˜²æ­¢ç”±äºåˆ†å¸ƒå¸¦æ¥çš„æ¨¡ç³Šï¼Œå› ä¸ºåªå–äº†ä¸€éƒ¨åˆ†ä½œä¸ºç¼–ç ç©ºé—´ï¼Œä»è€Œæé«˜åˆ†è¾¨ç‡\nä½†ä¹Ÿæœ‰å¯èƒ½é™ä½ä¿çœŸåº¦ï¼Œæ‰€ä»¥éœ€è¦tradeoff\n\n5. Image-to-image translation\n\nProduce modified image $y$ conditioned on input image $x$(note change of notation)\nGenerator receives $x$ as input\nDiscriminator receives an $x, y$ pair and has to decide whether it is real or fake\n\n\n\n\n\nä½œä¸ºä¸€ä¸ªå¯¹ç…§æ¥è¿›è¡Œåˆ¤åˆ«ï¼Œä»¥å¢åŠ æ¡ä»¶\nå³å¸Œæœ›é‹çš„å½¢çŠ¶ä¸€è‡´\n\n\n\n5.1 Translating between maps and aerial photos\n\nDay to night\n\n\n\nEdges to photos\n\n\n5.2 Unpaired image-to-image translation\næœ‰æ—¶å€™æˆ‘ä»¬å¹¶ä¸èƒ½å¾—åˆ°æˆå¯¹çš„æ ·æœ¬\n\nGiven two unordered image collections ğ‘‹ and ğ‘Œ, learn to â€œtranslateâ€ an image from one into the other and vice versa\n\n\n\n\n5.3 CycleGAN\nGiven: domains $X$ and $Y$â€‹\nå°±æ˜¯æˆ‘ä»¬å¸Œæœ›Xå¯ä»¥å˜ä¸ºYï¼ŒYç»è¿‡åå˜æ¢åè¿˜å¯ä»¥ç”ŸæˆY\nå°±å¯ä»¥é™åˆ¶Yçš„å½¢çŠ¶ç±»ä¼¼X\n\n\nTrain two generators $F$ and $G$ and two discriminators $D_{X}$ and $D_{Y}$\n$G$ translates from $X$ to $Y, F$ translates from $Y$ to $X$\n$D_{X}$ recognizes images from $X, D_{Y}$ from $Y$\nCycle consistency: we want $F(G(x)) \\approx x$ and $G(F(y)) \\approx y$\n\n\n\n\n\nIllustration of cycle consistency:\n\n\n\nTranslation between maps and aerial photos\n\n\n\nTasks for which paired data is unavailable\n\n\n5.4 CycleGAN: Limitations\nCannot handle shape changes (e.g., dog to cat)\n\nCan get confused on images outside of the training domains (e.g., horse with rider)\n\nä¸èƒ½å¯¹è®­ç»ƒæ•°æ®ä»¥å¤–çš„åšæ‹Ÿåˆ\n\n\nCannot close the gap with paired translation methods\n\n5.5 Multimodal image-to-image translation5.5.1 Human generation conditioned on pose\n","categories":["CV"]},{"title":"Image Feature Extraction","url":"/2021/08/15/cv/4.1%20Image%20Feature%20Extraction/","content":"Image Feature Extraction \n\n1. Why computer vision is challenging?\nViewpoint variation è§†è§‰è§’åº¦\nIllumination å…‰ç…§\nOcclusion é®æŒ¡\nScale å°ºåº¦\nDeformation å§¿æ€å˜å½¢\nBackground clutter èƒŒæ™¯æ‚ä¹±\nLocal ambiguity å±€éƒ¨è¿·æƒ‘\nObject intra class variation ç›®æ ‡å†…éƒ¨å˜æ¢\n\n2. Motivation for using local features\nOcclusions\nArticulation å…³èŠ‚\n\n\n\nIntra category variations å±€éƒ¨ä¸å˜\n\n\n3. General Approach\nFind a set of distinctive keypoints æ‰¾åˆ°ä¸€ç³»åˆ—å…³é”®ç‚¹\nDefine a region around each keypoint åœ¨å…³é”®ç‚¹å‘¨å›´å®šä¹‰å¯¹åº”çš„åŒºåŸŸ\nExtract and normalize the region content ä»åŒºåŸŸä¸­æå–å†…å®¹å¹¶å½’ä¸€åŒ–\nCompute a local descriptor from the normalized region ç”¨ç‰¹å¾ç®—å­æå–ç‰¹å¾\nMatch local descriptors åŒ¹é…å±€éƒ¨æè¿°ä¿¡æ¯\n\n4. Characteristics of good features\nCompactness and efficiency ç´§å‡‘ä¸”é«˜æ•ˆï¼Œè¦æ±‚å…³é”®ç‚¹è¿œå°‘äºå›¾ç‰‡pixelï¼Œä¸”æå–å¾—ç®—æ³•æ˜¯é«˜æ•ˆçš„ï¼Œå­˜å‚¨é‡å°çš„\nSaliency å…·æœ‰åˆ¤åˆ«åŠ›\nEach feature is distinctive\n\n\nLocality å±€éƒ¨ç‰¹å¾ä¸ä¼šå˜\nRepeatability å¯é‡å¤æ€§\n\n5. Keypoint extraction: Corners\n\n\nå¹³æ»‘éƒ¨åˆ†åŒºåŸŸçš„å„ä¸ªæ–¹å‘æ¢¯åº¦éƒ½ä¸ºé›¶\nè¾¹ç¼˜åŒºåŸŸæœ‰ä¸€ä¸ªæ–¹å‘çš„æ¢¯åº¦ä¸ä¸ºé›¶\nè§’ç‚¹ä½ç½®è‡³å°‘æœ‰ä¸¤ä¸ªæ–¹å‘çš„æ¢¯åº¦å€¼ä¸ä¸ºé›¶\n\n6. Corner Detection\næœ€ç»ˆç»“æœæ˜¯ä¸€ä¸ªçª—å£å¤§å°çš„åƒç´ ï¼Œä¸æ˜¯åªæœ‰ä¸€ä¸ªåƒç´ \n\n6.1 Derivation\nE(u,v)=\\sum_{(x, y)\\in W}[I(x+u, y+v)-I(x, y)]^{2}\nçª—å£ç§»åŠ¨å‰ååƒç´ å€¼å˜åŒ–\nç±»ä¼¼äºæ¬§å¼è·ç¦»\n\n\n\n\nE(u, v)=\\sum_{( x, y )\\in W} w(x,y)[I(x+u, y+v)-I(x, y)]^{2}\nwindow function å–çª—å£ä¸ºçŸ©å½¢æ³¢æˆ–è€…é«˜æ–¯çª—å£\n\n\n\nFirst-order Taylor approximation for small motions [u, v]:\n\n\nI(x+u, y+v) \\approx I(x, y)+I_{x} u+I_{y} v\nä¸€ç»´æ³°å‹’ï¼š\n\n\nf(x_0+h)=f(x_0)+\\frac{f'(x_0)}{1!}h+\\frac{f''(x_0)}{2!}h^2+o(h^2)\näºŒç»´æ³°å‹’ï¼š\n\n\nf(x_0+h,y_0+k)=f(x_0,y_0)+\\frac{f'_x(x_0,y_0)h+f'_y(x_0,y_0)k}{1!}+\\frac{f_{xx}''(x_0,y_0)}{2!}h^2+\\frac{f_{xy}''(x_0,y_0)} {2!}hk+\\frac{f_{yx}''(x_0,y_0)}{2!}hk+\\frac{f_{yy}''(x_0,y_0)}{2!}k^2+...\nä»£å…¥$E(u,v)$ï¼š\n\n\nE(u, v)=\\sum_{(x, y) \\in W}\\left(I_{x} u+I_{y} v\\right)^{2}=\\sum_{(x, y) \\in w} I_{x}^{2} u^{2}+2 I_{x} I_{y} u v+I_{y}^{2} v^{2}\nE(u, v) \\approx u^{2} \\sum_{x, y} I_{x}^{2}+2 u v \\sum_{x, y} I_{x} I_{y}+v^{2} \\sum_{x, y}I_{y}^{2}\n\nE(u, v) \\approx[u, v]\\left[\\begin{array}{cc}\n\\sum_{x,y\\in w} I_{x}^{2} & \\sum_{x,y\\in w} I_{x} I_{y} \\\\\n\\sum_{x,y\\in w} I_{x} l_{y} & \\sum_{x,y\\in w} I_{y}^{2}\n\\end{array}\\right]\\left[\\begin{array}{l}\nu \\\\\nv\n\\end{array}\\right]6.2 ç ”ç©¶$M$â€‹çŸ©é˜µ\nA horizontal slice â€ of ğ¸(ğ‘¢,ğ‘£)is given by the equation of an ellipse: åšå‚ç›´åˆ‡ç‰‡ï¼Œå³ä»¤E=const\n\n\n\\left[\\begin{array}{ll}\nu & v\n\\end{array}\\right] M\\left[\\begin{array}{l}\nu \\\\\nv\n\\end{array}\\right]=\\mathrm{const}\n\nM =\\left[\\begin{array}{cc}\n\\sum_{x,y\\in w} I_{x}^{2} & \\sum_{x,y\\in w} I_{x} I_{y} \\\\\n\\sum_{x,y\\in w} I_{x} l_{y} & \\sum_{x,y\\in w} I_{y}^{2}\n\\end{array}\\right]6.2.1 å‡è®¾çª—å£åªæœxï¼Œyæ–¹å‘ç§»åŠ¨\n$M$â€‹çŸ©é˜µä¸ºå¯¹è§’çŸ©é˜µï¼Œè®°ä¸ºï¼š\n\n\nM =\\left[\\begin{array}{cc}\na & 0\\\\\n0 & b\n\\end{array}\\right]\nå³æ²¡æœ‰æ—‹è½¬è§’åº¦çš„å½±å“ï¼Œè§’ç‚¹åˆšå¥½å’Œxï¼Œyæ–¹å‘å¹³è¡Œ\n\n\n[u, v]\\left[\\begin{array}{cc}\na & 0\\\\\n0 & b\n\\end{array}\\right]\\left[\\begin{array}{l}\nu \\\\\nv\n\\end{array}\\right]=1\n\nau^2+bv^2=1\n\\frac{u^2}{(a^{-\\frac{1}{2}})^2}+\\frac{v^2}{(b^{-\\frac{1}{2}})^2}=1\nè¿™ä¸ªå¼å­è¯´æ˜ï¼Œ$a,b$éƒ½ä¸æ¥è¿‘0ï¼Œåˆ™ä¸ºè§’ç‚¹ï¼Œè¿™è¯´æ˜Eéšu,vå‘ˆç°è‡³å°‘ä¸¤ä¸ªæ–¹å‘çš„å˜åŒ–ã€‚    \nå½“aæˆ–bå…¶ä¸­ä¸€ä¸ªæ¥è¿‘äº0ï¼Œåˆ™ä¸ºè¾¹ç¼˜ï¼Œå› ä¸ºæ­¤æ—¶æ¤­åœ†åå¡Œä¸ºä¸€æ¡ç›´çº¿ï¼Œè¿™è¯´æ˜Eéšç€u,vå˜åŒ–åªæœ‰ä¸€ä¸ªæ–¹å‘ã€‚\nå½“aå’Œbéƒ½å¾ˆæ¥è¿‘äºé›¶ï¼Œåˆ™è¯´æ˜ï¼ŒEéšç€u,våŸºæœ¬ä¸å˜ï¼Œåˆ™è¯´æ˜æ­¤æ—¶è¯¥éƒ¨åˆ†ä¸ºå¹³æ»‘åŒºåŸŸã€‚\n\n6.2.2 å‡è®¾çª—å£åªæœæœ‰ä¸€å®šè½¬è§’\nç”±äºï¼š\n\n\nM =\\left[\\begin{array}{cc}\n\\sum_{x,y\\in w} I_{x}^{2} & \\sum_{x,y\\in w} I_{x} I_{y} \\\\\n\\sum_{x,y\\in w} I_{x} l_{y} & \\sum_{x,y\\in w} I_{y}^{2}\n\\end{array}\\right]\næˆ‘ä»¬å¯ä»¥çŸ¥é“$M$æ˜¯å¯¹ç§°çŸ©é˜µï¼Œæ‰€ä»¥$M$å¯ä»¥è¿›è¡Œæ­£äº¤åˆ†è§£ï¼š\n\n\nM=R^{-1}\\left[\\begin{array}{cc}\n\\lambda_{1} & 0 \\\\\n0 & \\lambda_{2}\n\\end{array}\\right] R\nä¸éš¾å‘ç°ï¼Œ$R$æ˜¯å†³å®šæ—‹è½¬çš„æ—‹è½¬çŸ©é˜µï¼Œ$\\lambda_1,\\lambda_2$ä¸º$M$çš„ç‰¹å¾å€¼ï¼Œæ‰€ä»¥çœŸæ­£å†³å®šè¯¥å¤„æ˜¯å¦ä¸ºè§’ç‚¹çš„æ˜¯$M$çš„ç‰¹å¾å€¼ã€‚\n\n\n\n6.3 æ”¹è¿›\nR=\\operatorname{det}(M)-\\alpha \\operatorname{trace}(M)^{2}=\\lambda_{1} \\lambda_{2}-\\alpha\\left(\\lambda_{1}+\\lambda_{2}\\right)^{2}\nç”¨è¿™ç§æ–¹æ³•ï¼Œå¯ä»¥é¿å…è®¡ç®—çŸ©é˜µçš„ç‰¹å¾å€¼ã€‚\n\n\n\nå¦‚æœ$\\lambda_1,\\lambda_2$å¯ä»¥æ¯”æ‹Ÿï¼Œä¸”å‡ä¸æ¥è¿‘é›¶ï¼Œå¯ä»¥æ¨å‡º$R&gt;0$ï¼Œåˆ™ä¸ºè§’ç‚¹ï¼š\n\n\n\\begin{array}{cc}\nR=\\lambda_{1} \\lambda_{2}-\\alpha\\left(\\lambda_{1}+\\lambda_{2}\\right)^{2} \\\\\n=\\lambda^2-\\alpha(4\\lambda^2)\\\\\n=0.84\\lambda^2 > 0\n\\end{array}\nå¦‚æœ$\\lambda_1,\\lambda_2$â€‹å¯ä»¥æ¯”æ‹Ÿï¼Œä¸”å‡æ¥è¿‘é›¶ï¼Œå¯ä»¥æ¨å‡º$|R|\\approx 0$â€‹â€‹â€‹ï¼Œåˆ™ä¸ºå¹³æ»‘åŒºåŸŸï¼š\n\n\n\\begin{array}{cc}\nR=\\lambda_{1} \\lambda_{2}-\\alpha\\left(\\lambda_{1}+\\lambda_{2}\\right)^{2} \\\\\n=\\lambda^2-\\alpha(4\\lambda^2)\\\\\n=0.84\\lambda^2 \\approx 0\n\\end{array}\nå¦‚æœ$\\lambda_1\\gg\\lambda_2$ï¼Œåˆ™å¯ä»¥æ¨å‡º$R&lt;0$,ä¸ºè¾¹ç¼˜å¤„ï¼š\n\n\nR=\\lambda_1\\lambda_2-\\alpha\\lambda_1^2","categories":["CV"]},{"title":"Image Segmentation","url":"/2021/08/15/cv/6.%20Segmentation/","content":"Image Segmentation\n\n1. Image Segmentation1.1 Def\nldentify groups of pixels that go together\næŠŠå›¾åƒåˆ†å‰²ä¸ºå‡ ä¸ªä¸ç›¸äº¤çš„å•è¿é€šåŒºåŸŸ\n\n\n\n\n1.2 The Goals of Segmentation1.2.1 Separate image into coherent(ç›¸å¹²) â€œobjectsâ€\n\nGroup together similar-looking pixels for efficiency offurther processing\n\n\n1.3 Some Problems\nè¿‡åˆ†å‰²ï¼šåˆ†å‰²åŠ›åº¦è¿‡ç»†\næ¬ åˆ†å‰²ï¼šåˆ†å‰²è¿‡äºç²—ç³™\n\n2.  Clustering\nOne way to think about â€œsegmentationâ€œ is Clustering.\nClustering: group together similar data points and represent them with asingle token\n\n2.2 Methords\nBottom up clustering\n\ntokens belong together because they are locally coherent. (åƒç´ çº§åˆ«ï¼Œåƒç´ ç‰¹å¾ä¸Šç±»ä¼¼)\n\n\nTop down clustering\n\ntokens belong together because they lie on the same visual entity(object, sceneâ€¦) ï¼ˆè¯­ä¹‰çº§åˆ«ï¼ŒåŒæ ·çš„é©¬ã€é¼»å­ç­‰ï¼‰\n\n\nThese two are not mutually exclusive\n\n3. lnspiration from psychology\nMuller-Lyer illusion\nä¸‹é¢çš„ç›´çº¿æ„Ÿè§‰ä¼šæ›´é•¿\n\n\n\n\n3.1 The Gestalt Theory\nGestalt: whole or group\nWhole is greater than sum of its parts\nRelationships among parts can yield new properties/features\né€šè¿‡ç»„åˆå½¢æˆæ–°çš„å…³ç³»\n\n\n\n\n\n\n\nPsychologists identified series of factors that predispose(å€¾å‘) set of elements to be grouped (by human visual system)\nstand at the window and see a house, trees, sky.Theoretically l might say there were 327 brightnessesand nuances of colour. bo l have â€œ327â€? No. I have sky,house, and trees.â€                   Max Wertheimer\n\n\né‚£ä¹ˆå¦‚ä½•æ‰¾åˆ°è¿™ç§æ•´ä½“çš„å…³ç³»å‘¢ï¼Ÿ\n\n3.2 Gestalt Factors\n\nå…±åŒå‘½è¿ï¼šå³æœ‰ç›¸åŒè¿åŠ¨è¶‹åŠ¿\n\n3.3 Continuity through Occlusion Cues é®æŒ¡3.4 Figure-Ground Discrimination\nå›¾åƒèƒŒæ™¯åŒºåˆ«\n\n\n3.5 Grouping phenomena in real life\n4. Clustering for Summarization\n\nç®—ç›¸é‚»ç‚¹åˆ°ä¸­å¿ƒç‚¹çš„è·ç¦»ï¼Œè¿›è¡Œåˆ†ç±»\nGoal: choose three â€œcentersâ€ as the representative intensities, and label every pixel according to which of these centers it is nearest to.\nBest cluster centers are those that minimize Sum of SquareDistance (SSD) between all points and their nearest cluster center $c_i$â€‹\næœ€å°åŒ–æ‰€æœ‰ç‚¹åˆ°æ‰€æœ‰ä¸­å¿ƒè·ç¦»çš„åŠ æƒå’Œ\n\n\n\n\nc^{*}, \\delta^{*}=\\underset{c, \\delta}{\\arg \\min } \\frac{1}{N} \\sum_{j}^{N} \\sum_{i}^{K} \\delta_{i j}\\left(c_{i}-x_{j}\\right)^{2}\n$\\delta_{i j}$: whether $x_j $â€‹is assigned to $c_i$\n\n5. K-means clustering\nBasic idea: randomly initialize the k cluster centers, and iterate between the two steps we just saw.\n\nstep1: Randomly initialize the cluster centers, $c_1,..,c_K$â€‹â€‹â€‹\nstep2: Given cluster centers, determine points in each cluster\nstep3: For each point $x_j$, find the closest $c$;. Put $x_j$into cluster $i_3$. Given points in each cluster, solve for $c$\nstep4: Set $c$ to be the mean of points in cluster $i_4$. lf c; have changed, repeat Step 2-3.\n\n\nAn iterative clustering algorithm\n\nPick K random points ascluster centers (means)- Alternate:\nAssign data instances to closest mean\nAssign each mean to the average of its assigned points\n\n\n\n5.1 Problem\nå¾ˆä¾èµ–äºåˆå§‹å€¼\n\nA local optimum:\n\n\n\n5.2 Pros  and cons5.2.1 Pros\nSimple, fast to compute\n\n5.2.2 Cons/issues\nConverges to local minimum of within-cluster squared error\n\nSetting k?\n\nk æ˜¯ä¸ªè¶…å‚\n\n\nSensitive to initial centers. \n\nå¯¹ä¸€å¼€å§‹åˆå§‹åŒ–çš„ä¸­å¿ƒå¾ˆæ•æ„Ÿ\n\n\nSensitive to outliers\n\n\n\n\nDetects spherical(çƒå½¢) clusters \n\n\n\nAssuming means can be computed\nå¦‚æœä¸€äº›ç‰¹æ€§ä¸èƒ½ç”¨å‡å€¼\n\n\n\n5.3 Qestions5.3.1 local minimum\nWill K-means converge?\næ˜¯æ”¶æ•›çš„ï¼Œå¯ä»¥è¯æ˜\n\n\nTo a global optimum?\nä¸èƒ½\n\n\n\nSolution: Kmeans++\nCan we prevent arbitrarily bad local minima?\nRandomly choose first center.\nPick new center with prob. proportional to (r-c)(Contribution of $x$ to total error) ä»¥è·ç¦»ä¸ºæ¦‚ç‡é€‰æ‹©ä¸‹ä¸€ä¸ªä¸­å¿ƒç‚¹\nRepeat until $k$â€‹â€‹ centers.\n\n\n\n\n\nä¸‹é¢ç»“åˆä¸€ä¸ªç®€å•çš„ä¾‹å­è¯´æ˜K-means++æ˜¯å¦‚ä½•é€‰å–åˆå§‹èšç±»ä¸­å¿ƒçš„ã€‚æ•°æ®é›†ä¸­å…±æœ‰8ä¸ªæ ·æœ¬ï¼Œåˆ†å¸ƒä»¥åŠå¯¹åº”åºå·å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n\n\n\nå‡è®¾ç»è¿‡å›¾2çš„æ­¥éª¤ä¸€å6å·ç‚¹è¢«é€‰æ‹©ä¸ºç¬¬ä¸€ä¸ªåˆå§‹èšç±»ä¸­å¿ƒï¼Œé‚£åœ¨è¿›è¡Œæ­¥éª¤äºŒæ—¶æ¯ä¸ªæ ·æœ¬çš„D(x)å’Œè¢«é€‰æ‹©ä¸ºç¬¬äºŒä¸ªèšç±»ä¸­å¿ƒçš„æ¦‚ç‡å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š\n\n\n\nå…¶ä¸­çš„P(x)å°±æ˜¯æ¯ä¸ªæ ·æœ¬è¢«é€‰ä¸ºä¸‹ä¸€ä¸ªèšç±»ä¸­å¿ƒçš„æ¦‚ç‡ã€‚æœ€åä¸€è¡Œçš„Sumæ˜¯æ¦‚ç‡P(x)çš„ç´¯åŠ å’Œï¼Œç”¨äºè½®ç›˜æ³•é€‰æ‹©å‡ºç¬¬äºŒä¸ªèšç±»ä¸­å¿ƒã€‚æ–¹æ³•æ˜¯éšæœºäº§ç”Ÿå‡ºä¸€ä¸ª0~1ä¹‹é—´çš„éšæœºæ•°ï¼Œåˆ¤æ–­å®ƒå±äºå“ªä¸ªåŒºé—´ï¼Œé‚£ä¹ˆè¯¥åŒºé—´å¯¹åº”çš„åºå·å°±æ˜¯è¢«é€‰æ‹©å‡ºæ¥çš„ç¬¬äºŒä¸ªèšç±»ä¸­å¿ƒäº†ã€‚ä¾‹å¦‚1å·ç‚¹çš„åŒºé—´ä¸º[0,0.2)ï¼Œ2å·ç‚¹çš„åŒºé—´ä¸º[0.2, 0.525)ã€‚\nä»ä¸Šè¡¨å¯ä»¥ç›´è§‚çš„çœ‹åˆ°ç¬¬äºŒä¸ªåˆå§‹èšç±»ä¸­å¿ƒæ˜¯1å·ï¼Œ2å·ï¼Œ3å·ï¼Œ4å·ä¸­çš„ä¸€ä¸ªçš„æ¦‚ç‡ä¸º0.9ã€‚è€Œè¿™4ä¸ªç‚¹æ­£å¥½æ˜¯ç¦»ç¬¬ä¸€ä¸ªåˆå§‹èšç±»ä¸­å¿ƒ6å·ç‚¹è¾ƒè¿œçš„å››ä¸ªç‚¹ã€‚è¿™ä¹ŸéªŒè¯äº†K-meansçš„æ”¹è¿›æ€æƒ³ï¼šå³ç¦»å½“å‰å·²æœ‰èšç±»ä¸­å¿ƒè¾ƒè¿œçš„ç‚¹æœ‰æ›´å¤§çš„æ¦‚ç‡è¢«é€‰ä¸ºä¸‹ä¸€ä¸ªèšç±»ä¸­å¿ƒã€‚å¯ä»¥çœ‹åˆ°ï¼Œè¯¥ä¾‹çš„Kå€¼å–2æ˜¯æ¯”è¾ƒåˆé€‚çš„ã€‚\nå½“Kå€¼å¤§äº2æ—¶ï¼Œæ¯ä¸ªæ ·æœ¬ä¼šæœ‰å¤šä¸ªè·ç¦»ï¼Œéœ€è¦å–æœ€å°çš„é‚£ä¸ªè·ç¦»ä½œä¸ºD(x)ã€‚ä¸€å¼€å§‹åªæœ‰ä¸€ä¸ªä¸­å¿ƒï¼Œä¹‹åä¼šæœ‰ä¸‹ä¸€ä¸ªï¼Œé‚£ä¹ˆæ­¤æ—¶æ¯ä¸ªç‚¹éƒ½è¦éå†ä¸¤ä¸ªä¸­å¿ƒï¼Œåˆ™è·ç¦»å–æœ€å°å€¼å³å¯ï¼Œç‰©ç†æ„ä¹‰å°±æ˜¯å¸Œæœ›ä¸‹ä¸€ä¸ªä¸­å¿ƒå°½å¯èƒ½ç¦»è¿™ä¸¤ä¸ªä¸­å¿ƒè¿œä¸€ç‚¹\nä¸‹é¢æ˜¯é€‰æ‹©ä¸­å¿ƒç‚¹çš„ä»£ç \n\n# coding: utf-8import mathimport randomfrom sklearn import datasetsdef euler_distance(point1: list, point2: list) -&gt; float:    &quot;&quot;&quot;    è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„æ¬§æ‹‰è·ç¦»ï¼Œæ”¯æŒå¤šç»´    &quot;&quot;&quot;    distance = 0.0    for a, b in zip(point1, point2):        distance += math.pow(a - b, 2)    return math.sqrt(distance)def get_closest_dist(point, centroids):    min_dist = math.inf  # åˆå§‹è®¾ä¸ºæ— ç©·å¤§    for i, centroid in enumerate(centroids):        dist = euler_distance(centroid, point)        if dist &lt; min_dist:            min_dist = dist    return min_distdef kpp_centers(data_set: list, k: int) -&gt; list:    &quot;&quot;&quot;    ä»æ•°æ®é›†ä¸­è¿”å› k ä¸ªå¯¹è±¡å¯ä½œä¸ºè´¨å¿ƒ    &quot;&quot;&quot;    cluster_centers = []    cluster_centers.append(random.choice(data_set))    d = [0 for _ in range(len(data_set))]    for _ in range(1, k):        total = 0.0        for i, point in enumerate(data_set):            d[i] = get_closest_dist(point, cluster_centers) # ä¸æœ€è¿‘ä¸€ä¸ªèšç±»ä¸­å¿ƒçš„è·ç¦»            total += d[i]        total *= random.random()        for i, di in enumerate(d): # è½®ç›˜æ³•é€‰å‡ºä¸‹ä¸€ä¸ªèšç±»ä¸­å¿ƒï¼›            total -= di            if total &gt; 0:                continue            cluster_centers.append(data_set[i])            break    return cluster_centersif __name__ == &quot;__main__&quot;:    iris = datasets.load_iris()    print(kpp_centers(iris.data, 4))\n5.3.2 spherical cluster\nWill it always find the true patterns in the data?\nä¸ä¸€å®šï¼Œä»–åªèƒ½æ‰¾åˆ°çƒçŠ¶åˆ†å¸ƒ\nif the patterns are very clear?\n\n\n\nSolution: GMMA probabilistic variant of Kimeans:\n\nE step: â€œsoft assignmentâ€of points to clusters   ï¼ˆæ ‡è®°å±äºæŸä¸ªç±»çš„æ¦‚ç‡ï¼‰\nestimate probability that a point is in a cluster \nå…ˆéšæœºåˆå§‹åŒ–ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œå°±å¯ä»¥è®¡ç®—æ¯ä¸ªç‚¹å½’ç±»çš„æ¦‚ç‡\n\n\n\n\nMstep: update cluster parameters\nmean and variance info (covariance matrix)\nmaximizes the likelihood of the points given the clusters\n\n\n\n\n\nç†è®ºä¸Šè¶³å¤Ÿå¤šçš„é«˜æ–¯åˆ†å¸ƒå¯ä»¥æ‹Ÿåˆä»»æ„æ•°æ®ç‚¹\n\nè¯¦ç»†è§å‚è€ƒé˜…è¯»GMM\n\n\n5.3.3 How to choose the number of clusters?\nTry different numbers of clusters in a validation set and look at performance.\nWe can plot the objective function values for k equals 1 to 6â€¦\nThe abrupt change at k = 2, is highly suggestive of two clustersin the data. This technique for determining the number of clusters is known as â€œknee finding or â€œelbow finding.\n\n\n6. Smoothing Out Cluster Assignments\nèšç±»ç›®æ ‡å†…éƒ¨ä¸è¿ç»­\n\n\n\nå¼•å…¥ç©ºé—´åæ ‡çš„ä¿¡æ¯\nK-means clustering based on intensity or color is essentially vector quantizationï¼ˆé‡åŒ–ï¼‰ of the image attributes\nåŸºäºå¼ºåº¦æˆ–é¢œè‰²çš„Kå‡å€¼èšç±»æœ¬è´¨ä¸Šæ˜¯çŸ¢é‡é‡åŒ–(é‡åŒ–ï¼‰ å›¾åƒå±æ€§çš„åˆ†ç±»\n\n\nClusters donâ€™t have to be spatially coherent ï¼ˆç©ºé—´ç›¸å…³æ€§ï¼‰\n\n\n6.1 Spatial Coherence\nWay to encode both similarity and proximity.\nå®é™…ä¸Šå°±æ˜¯åœ¨åŸæœ¬ä¸‰ç»´å‘é‡çš„åŸºç¡€ä¸Šï¼Œå¤šåŠ ä¸¤ç»´ç©ºé—´ä¿¡æ¯\n\n\n7. Mean-Shift Segmentation\nAn advanced and versatile technique for clustering-based segmentation\n\n7.1 Algorithm æ‰¾åˆ°åŒºåŸŸç©ºé—´å¯†åº¦çš„æå¤§å€¼\néšæœºåˆå§‹åŒ–ä¸€ä¸ªåœ†ï¼Œç„¶åæ‰¾åˆ°ç‚¹çš„é‡å¿ƒï¼Œå†ä»¥è¯¥é‡å¿ƒä¸ºä¸­å¿ƒåšåœ†ï¼Œä»è€Œè¾¾åˆ°æ¼‚ç§»çš„æ•ˆæœ\n\n\n\nåœ¨ä¸€ä¸ª n ç»´ç©ºé—´å†…ï¼Œå­˜åœ¨ä¸€ä¸ªç‚¹ xï¼Œä»¥è¯¥ç‚¹ä¸ºçƒå¿ƒï¼Œä»¥ h ä¸ºåŠå¾„ï¼Œç”Ÿæˆä¸€ä¸ªçƒ $S_h$ï¼Œè®¡ç®—çƒå¿ƒåˆ°çƒå†…æ‰€æœ‰ç‚¹ç”Ÿæˆçš„å‘é‡çš„å‡å€¼ï¼Œæ˜¾ç„¶è¿™ä¸ªå‡å€¼ä¹Ÿæ˜¯ä¸€ä¸ªå‘é‡ï¼Œè¿™ä¸ªå‘é‡å°±æ˜¯ mean shift å‘é‡\n\nå…¬å¼å¦‚ä¸‹:\n\n\n\nM_{h}(x)=\\frac{1}{k} \\sum_{x_{i} \\in S_{h}}\\left(x_{i}-x\\right)\nå¯ä»¥è¿™ä¹ˆç†è§£ä»¥ä¸Šå…¬å¼ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå«mean-shiftçš„ä¸œè¥¿ï¼Œå®ƒç”¨äºè®¡ç®—æ¼‚ç§»è·ç¦»\n\n\n7.2 shift point\næˆ‘ç»™èµ·ä¸ªåå­—ï¼Œå« åç§»ç‚¹ï¼›\næ³¨æ„ï¼Œå‡ ä¹æ²¡æœ‰èµ„æ–™ä¸“é—¨æåˆ°è¿™ä¸ªæ¦‚å¿µï¼Œæˆ‘ä¸ºä»€ä¹ˆè¦è®²å‘¢ï¼Ÿå› ä¸ºæˆ‘ä»¬éœ€è¦æŠŠ shift point å’Œ mean shift åŒºåˆ†å¼€ï¼Œè¿™ä¿©å¯ä¸æ˜¯ä¸€å›äº‹ï¼›\nè€Œåœ¨æˆ‘ä»¬å†™ç®—æ³•æ—¶ï¼Œéœ€è¦çš„æ˜¯ shift pointï¼Œè€Œä¸æ˜¯ mean shift\n\n\n\\hat{M}_n(X)=\\frac{1}{k}(x_i),\\text{shift point}\n7.3 åŸºæœ¬æ€æƒ³\nå¯¹äº æ ·æœ¬ä¸­çš„æ¯ä¸€ä¸ªç‚¹ $x$ï¼Œåšå¦‚ä¸‹æ“ä½œ\n\nä»¥ x ä¸ºèµ·ç‚¹ï¼Œè®¡ç®—ä»–çš„ $\\text{shift point } xâ€™$â€‹ï¼Œç„¶åæŠŠ è¯¥ç‚¹ â€œç§»åŠ¨â€ åˆ° xâ€™.ã€æ³¨æ„ä¸æ˜¯çœŸçš„ç§»åŠ¨ç‚¹ï¼Œè€Œæ˜¯æŠŠ x æ ‡è®°æˆ xâ€™ã€‘\n\nä»¥ $xâ€™ $ä¸ºæ–°èµ·ç‚¹ï¼Œè®¡ç®—ä»–çš„ shift point\n\né‡å¤ å‰ä¸¤æ­¥ï¼Œç›´è‡³ å‰åä¸¤æ¬¡ çš„ mean shift å‘é‡æ»¡è¶³æ¡ä»¶ï¼Œå¦‚ è·ç¦»å¾ˆè¿‘ã€è¿™ä¸€æ­¥æ‰ç”¨åˆ° mean shiftï¼Œä¹Ÿå°±æ˜¯ å‰åä¸¤ä¸ª shift point ç›¸å‡å¾—åˆ° å‘é‡ï¼Œå†è®¡ç®—å‘é‡çš„æ¨¡ã€‘\n\næŠŠ $x$ æ ‡è®°ä¸º æœ€ç»ˆçš„ shift pointï¼Œå³ä¸ºå¯¹åº”çš„ç±»\n\néå†è®¡ç®—æ‰€æœ‰ç‚¹\n\n\nè¿‡ç¨‹å¤§è‡´å¦‚ä¸‹å›¾ï¼š\n\n\nä»ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œmean shift å‘é‡æŒ‡å‘äº†æ›´å¯†é›†çš„åŒºåŸŸï¼Œä¹Ÿå°±æ˜¯è¯´ mean shift ç®—æ³•æ˜¯åœ¨å¯»æ‰¾ æœ€å¯†é›† çš„åŒºåŸŸï¼Œä½œä¸ºæœ€åçš„ç±»åˆ«\n\nå­˜åœ¨é—®é¢˜\n\nåœ¨è®¡ç®— mean shift å‘é‡æ—¶ï¼Œåœ†åœˆå†…æ‰€æœ‰ç‚¹çš„è´¡çŒ®æ˜¯ä¸€æ ·çš„ å³1/kï¼Œè€Œå®é™…ä¸Šç¦»åœ†å¿ƒè¶Šè¿œå¯èƒ½è´¡çŒ®è¶Šå°ï¼Œ\nä¸ºæ­¤ mean shift ç®—æ³•å¼•å…¥æ ¸å‡½æ•°æ¥è¡¨è¾¾è¿™ç§è´¡çŒ®ï¼Œä»£æ›¿ 1/k\n\n\n\n7.4 å¼•å…¥æ ¸å‡½æ•°\næ­¤å¤„ä»¥ é«˜æ–¯æ ¸å‡½æ•° ä¸ºä¾‹\n\n\nN(x)=\\frac{1}{\\sqrt{2 \\pi} h} e^{-\\frac{x^{2}}{2 h^{2}}}\nå…¶ä¸­ h ä»£è¡¨æ ¸å‡½æ•°çš„å¸¦å®½(bandwidth)ã€è¿™ä¸ª h å’Œ é«˜æ–¯åˆ†å¸ƒ é‡Œçš„ æ ‡å‡†å·®Ïƒ ç±»ä¼¼ï¼Œä½†å®ƒä¸æ˜¯ æ ‡å‡†å·®ï¼Œè€Œæ˜¯ äººå·¥æŒ‡å®šçš„ï¼Œä½†æ˜¯èµ·åˆ°çš„ä½œç”¨å’Œ æ ‡å‡†å·®ä¸€æ ·ã€‘\nh è¶Šå°ï¼Œè¡°å‡ä¸º 0 çš„é€Ÿåº¦å°±è¶Šå¿«ï¼Œä¹Ÿå°±æ˜¯è¯´ mean shift å‘é‡å¯¹åº”çš„çƒ Sh è¶Šå°ï¼Œç¨å¾®è¿œç‚¹å°±æ²¡æœ‰è´¡çŒ®äº†ï¼›\näºæ˜¯ï¼Œå¼•å…¥ æ ¸å‡½æ•° çš„ mean shift å‘é‡å˜æˆå¦‚ä¸‹æ ·å­ï¼Œæ­¤æ—¶çš„ Sh å¯ä»¥ä¸ºæ•´ä¸ªæ•°æ®é›†ï¼ˆåŸå› ä¸ºä¸Šå¥ï¼‰\n\n\nM_{h}(x)=\\frac{\\sum_{i=1}^{n} G\\left(\\frac{x_{i}-x}{h_{i}}\\right)\\left(x_{i}-x\\right)}{\\sum_{i=1}^{n} G\\left(\\frac{x_{i}-x}{h_{i}}\\right)}\nä»£ç è§ï¼šMean shift ã€1ã€‘- åŸºæœ¬åŸç† - åŠªåŠ›çš„å­”å­ - åšå®¢å›­ (cnblogs.com)\n\nè¯æ˜ï¼š\n\n\n7.4 å¦‚ä½•èšç±»\nCluster: all data points in the attraction basin of amode\næ¨¡å¼å¸å¼•åŒºä¸­çš„æ‰€æœ‰æ•°æ®ç‚¹\n\n\nAttraction basin (å¸å¼•æ± ): the region for which all trajectoriesï¼ˆè½¨è¿¹ï¼‰ lead to the same mode\nå¯¹äºæŒ‡å®šä¸€ç‰‡åŒºåŸŸï¼Œè¯¥åŒºåŸŸä¸­æ‰€æœ‰ç‚¹æœ€ç»ˆä¼šæ¼‚ç§»åˆ°åŒä¸€ä¸ªç‚¹ï¼Œè¿™ä¸ªåŒºåŸŸè¢«ç§°ä¸ºå¸å¼•åŒº\néå†æ‰€æœ‰æ•°æ®ç‚¹ï¼Œæœ€åæ•°æ®ç‚¹æœ€ç»ˆæ¼‚ç§»åˆ°å“ªä¸€ä¸ªä¸­å¿ƒï¼Œé‚£ä¹ˆæœ€åå°±æ˜¯å±äºå“ªä¸€ä¸ªç±»\n\n\n\n\n7.5 å¦‚ä½•åœ¨æ•°å­—å›¾åƒä¸Šåº”ç”¨ï¼Ÿ\nFind features (color, gradients, texture, etc)\nInitialize windows at individual pixel locations åœ¨å„ä¸ªåƒç´ ä½ç½®åˆå§‹åŒ–window\nPerform mean shift for each window until convergence \nMerge windows that end up near the same â€œpeakâ€ or mode åˆå¹¶å³°å€¼ç‚¹\nå¯ä»¥ç†è§£ä¸ºï¼Œè™½ç„¶ä¸€å¼€å§‹ç”Ÿæˆäº†å¾ˆå¤šwindowï¼Œä½†æ˜¯æœ€ç»ˆå¯¹äºå³°å€¼æ¥è¿‘çš„é‡å¿ƒç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œåˆå¹¶\n\n\n\n\n7.6 speedups\néå†æ‰€æœ‰ç‚¹ï¼Œé€Ÿåº¦å¤ªæ…¢\n\n\n\næˆ‘ä»¬å¯ä»¥å®šä¹‰å¯¹äºåœ†å†…r/céƒ¨åˆ†çš„ç‚¹å’Œä¸­å¿ƒç‚¹éƒ½ä¼šæœ€ç»ˆæ¼‚ç§»åˆ°åŒä¸€ä¸ªç‚¹ï¼Œé‚£ä¹ˆè¿™éƒ¨åˆ†ç‚¹å°±ä¸ç”¨å†éå†\n\n\n\nä¸€å¼€å§‹åˆå§‹åŒ–å¤šä¸ªåœ†ï¼Œç„¶åä¾æ¬¡è¿›è¡Œæ¼‚ç§»ï¼Œä»è€Œå®ç°èšç±»\n\n7.7 Summary Mean-Shift\nPros\n\nGeneral, application-independent tool\nModel-free, does not assume any prior shape (spherical, elliptical, etc.)on data clusters\nJust a single parameter (window size h)\nh has a physical meaning (unlike k-means)Â· \n\n\nFinds variable number of modes\nRobust to outliers\n\n\nCons\n\nOutput depends on window size\nComputationally (relatively) expensive\n\n\n\n8. Graph-based segmentation\n8.1 Efficient graph-based segmentation\n\nRuns in time nearly linear in the number of edges \næ—¶é—´å¤æ‚åº¦å’Œè¾¹æ•°ç›¸å…³\n\n\nEasy to control coarsenessï¼ˆç²—ç³™åº¦ï¼‰ of segmentations\nResults can be unstable\n\n8.2 Segmentation by graph cuts\n\næ–­æ‰æŸäº›è¾¹ï¼ŒæŠŠæ²¡è¿é€šçš„é›†åˆåˆ†ä¸ºä¸¤ç±»\n\n\n\nA graph cut is a set of edges whose removal disconnects the graph\nå›¾å‰²æ˜¯ä¸€ä¸ªä»åŸå›¾æ–­æ‰è”ç³»çš„è¾¹é›†ï¼Œå»æ‰è¯¥è¾¹é›†ï¼Œä¼šä½¿å¾—åŸå›¾ä¸åœ¨è¿é€šå³ä¸ç›¸è¿\n\n\nCost of a cut: sum of weights of cut edges\nå³å›¾å‰²ä¸­æ‰€æœ‰è¾¹çš„æƒå€¼å’Œ\n\n\n\n\n\næ–­æ‰ç›¸ä¼¼åº¦æœ€å°çš„è¾¹\n\n8.3 Measuring affinityï¼ˆäº²å’ŒåŠ›ï¼‰ ï¼ˆå®šä¹‰ç›¸ä¼¼åº¦ï¼‰\nOne possibility:\nç‰¹å¾ä¸Šçš„è·ç¦»å·®å¼‚ï¼Œä¸ç›¸ä¼¼åº¦æˆåæ¯”\n\n\n\n\na f f(x, y)=\\exp (-\\frac{\\|x-y\\|^{2}}{2 \\sigma_{d}^{2}})\n\n8.4 Cuts in a graph: Min cut æœ€å°å‰²\n\nLink Cut: set of links whose removal makes a graph disconnected\ncost of a cut:\n\n\\operatorname{cut}(A, B)=\\sum_{p \\in A, q \\in B} w_{p, q}Find minimum cutï¼š\n\ngives you a segmentation\n\nfast algorithms exist for doing this\næ–­æ‰çš„æƒé‡å€¼ä¹‹å’Œæœ€å°\n\n\n\n8.5 Problem\nMinimum cut tends to cut off very small, isolated components\nå®¹æ˜“é€ æˆå­¤ç«‹ç‚¹åˆ†å‰²ï¼Œå› ä¸ºè¿™äº›ç‚¹å¯èƒ½å’Œå…¶ä»–ç‚¹çš„ç›¸ä¼¼åº¦éƒ½å¾ˆä½ï¼Œæ‰€ä»¥è‡ªç„¶å°±è¢«åˆ‡å‰²èµ°äº†Â·\n\n\n\n\n8.6 Cuts in a graph: Normalized cut\nNormalized Cut\nfix bias of Min Cut by normalizing for size of segments:\nN \\operatorname{cut}(A, B)=\\frac{\\operatorname{cut}(A, B)}{\\operatorname{assoc}(A, V)}+\\frac{\\operatorname{cut}(A, B)}{\\operatorname{assoc}(B, V)}\n$\\operatorname{assoc}(\\mathrm{A}, \\mathrm{V})=$â€‹ sum of weights of all edges that touch $\\mathrm{A}$â€‹\n\nå³é™¤ä»¥å‰²å¼€åï¼Œåˆ†åˆ«å¤„ä»¥ä¸¤ä¸ªå›¾çš„æƒé‡ä¹‹å’Œï¼Œå†ç›¸åŠ \nè¿™æ ·å¯ä»¥ä½¿å¾—ï¼Œåˆ†å‰²åçš„è¿ä¸ªclusterçš„æƒé‡ä¹‹å’Œå°½å¯èƒ½å‡è¡¡\n\n\nNcut value small when we get two clusters with many edges with high weights, and few edges of low weight between them\n\nå°½å¯èƒ½ä½¿å¾—åŒä¸€ç±»å¤šè¾¹\n\n\nApproximate solution for minimizing the Ncut value : generalized eigenvalue problem.\næ±‚è§£æ–¹æ³•ï¼šå¹¿ä¹‰ç‰¹å¾å€¼\n\n\n\n8.7 Normalized cuts: Pro and conPro\nGeneric framework, can be used with many different features and affinity formulations\n\nCon\nHigh storage requirement and time complexity:\ninvolves solving a generalized eigenvalue problem of size $n \\times n$â€‹, where n is the number of pixels\n\n\n\n9. Feature Space\nDepending on what we choose as the feature space, we can group pixels in different ways.\nGrouping pixels based on color similarity\n\n\n\ncolor, brightness, position alone are not enough to distinguish all regionsâ€¦\n\n9.1 Recall: texture representation example\nåˆ†åˆ«è®¡ç®—ä¸€ä¸ªå°çª—å£é‡Œæ°´å¹³æ–¹å‘æ¢¯åº¦çš„å‡å€¼ä»¥åŠå‚ç›´æ–¹å‘æ¢¯åº¦çš„å‡å€¼ï¼Œä½œä¸ºè¿™ä¸ªå°çª—å£çš„ç‰¹å¾ï¼Œå†è¿›è¡Œèšç±»\n\n\n\n9.2 Segmentation with texture features\nFind â€œtextonsâ€ ï¼ˆæ–‡æœ¬ï¼‰ by clustering vectors of filter bank outputs. \næŸ¥æ‰¾â€œå†…å®¹â€ é€šè¿‡å¯¹æ»¤æ³¢å™¨ç»„è¾“å‡ºå‘é‡è¿›è¡Œèšç±»ã€‚\n\n\nDescribe texture in a window based on texton histogram\nå¯¹äºæ¯ä¸ªå°çª—å£ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°å¤šä¸ªfilteråœ¨è¯¥å°çª—å£çš„å¤šä¸ªå€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥filtterä¸ºæ¨ªåæ ‡å»ºç«‹ç›´æ–¹å›¾\n\n\n\n\n9.3 lmage segmentation example\n\nåˆ©ç”¨å¤šç‰¹å¾èåˆï¼Œå®ç°é€šè¿‡ä¸åŒç‰¹å¾åˆ†å‰²çš„æ‰‹æ®µï¼Œèåˆå‡ºè¾ƒå¥½çš„å›¾åƒåˆ†å‰²ç»“æœ\n\n9.4 Segments as primitives for recognition\n\nä¸€è¾†è½¦å¯èƒ½æ–¹ä½å½¢çŠ¶ä¸ä¸€æ ·ï¼Œä¸”ç»å¸¸æœ‰é®æŒ¡ï¼Œä½†æˆ‘ä»¬ä¹Ÿè¦å®Œæˆè¿™ä¸ªä»»åŠ¡\n\n10. Summary\nSegmentation to find object boundaries or mid-level regions,tokens.\nBottom-up segmentation via clustering\nGeneral choices â€” features, affinity functions, and clustering algorith ms\nGrouping also useful for quantization, can create new featuresummaries\nTexton histograms for texture within local regionÂ· \nExample clustering methods\nK-means\nMean shift\nGraph cut, normalized cuts\n\n\n\n","categories":["CV"]},{"title":"fitting","url":"/2021/08/15/cv/5.%20fitting/","content":"fitting\n\n1. Def\nChoose a parametric model to represent a set of features\n\n2. Challenges\nNoise in the measured feature locations\n\nExtraneous dataï¼ˆå¤–ç‚¹ï¼‰: clutter (outliers), multiple lines äº¤å‰å¹²æ‰°\n\nMissing data: occlusions é®æŒ¡\n\n\n3. Overview\nIf we know which points belong to the line, how do we find the â€œoptimalâ€line parameters?\nLeast squares\n\n\nWhat if there are outliers?\nRobust fitting, RANSAC\n\n\nWhat if there are many lines?\nVoting methods: RANSAC, Hough transform\n\n\nWhat if weâ€™re not even sure itâ€™s a line?\nModel selection: Snake (not covered)\n\n\n\n4. Least squares line fitting\nData: $\\left(x_{1}, y_{1}\\right), \\ldots,\\left(x_{n}, y_{n}\\right)$\nLine equation: $y_{i}=m x_{i}+b$\nFind $(m, b)$ to minimize\n\n\nE=\\sum_{i=1}^{n}\\left(y_{i}-m x_{i}-b\\right)^{2}\nE=\\|Y-X B\\|^{2} \\text { where } Y=\\left[\\begin{array}{c}\ny_{1} \\\\\n\\vdots \\\\\ny_{n}\n\\end{array}\\right] \\quad X=\\left[\\begin{array}{cc}\nx_{1} & 1 \\\\\n\\vdots & \\vdots \\\\\nx_{n} & 1\n\\end{array}\\right] \\quad B=\\left[\\begin{array}{c}\nm \\\\\nb\n\\end{array}\\right]\n\næ˜¯æ ·æœ¬ç‚¹å‡åŒ€åˆ†å¸ƒåœ¨ç›´çº¿ä¸¤è¾¹\n\n4.1 Least squares line fitting\n\\begin{array}{l}\nE=\\| Y-X B\\|^{2}\\\\\n=(Y-X B)^{T}(Y-X B)\\\\\n=Y^{T}-2(X B)^{T} Y+(X B)^{T}(X B)\n\\end{array}\n\\begin{aligned}\n&\\frac{d E}{d B}=2 X^{T} X B-2 X^{T} Y=0 \\\\\n&X^{T} X B=X^{T} Y\n\\end{aligned}\nNormal equations: least squares solution to B\n\n\nB=\\left(X^{T} X\\right)^{-1} X^{T} Y4.2 Problem\nNot rotation-invariant\nFails completely for vertical lines\n\n\n4.3 Total least squares\nDistance between point $(x_i, y_i)$â€‹â€‹ and line  åˆ©ç”¨ç‚¹ç›´çº¿çš„è·ç¦»$ax+by=d (a^2+b^2=1): |ax_i + by_i â€“ d|$â€‹â€‹â€‹\n\n\nax+by=d\n\\text{distance}=\\frac{|ax_i+by_i-d|}{\\sqrt{a^2+b^2}}=|ax_i+by_i-d|\nFind $ (a, b, d) $â€‹ to minimize the sum of squared perpendicular distances\n\n\n\nE=\\sum_{i=1}^{n}\\left(a x_{i}+b y_{i}-d\\right)^{2}\n\\frac{\\partial E}{\\partial d}=\\sum_{i=1}^{n}-2\\left(a x_{i}+b y_{i}-d\\right)=0\nd=\\frac{a}{n} \\sum_{i=1}^{n} x_{i}+\\frac{b}{n} \\sum_{i=1}^{n} y_{i}=a \\bar{x}+b \\bar{y}\n\\begin{array}{ll}\\\\\nE=\\sum_{i=1}^{n}\\left(a\\left(x_{i}-\\bar{x}\\right)+b\\left(y_{i}-\\bar{y}\\right)\\right)^{2}\\\\\n\\ \\ \\ =\\left\\|\\left[\\begin{array}{cc}\nx_{1}-\\bar{x} & y_{1}-\\bar{y} \\\\\n\\vdots & \\vdots \\\\\nx_{n}-\\bar{x} & y_{n}-\\bar{y}\n\\end{array}\\right]\\left[\\begin{array}{c}\na \\\\\nb\n\\end{array}\\right]\\right\\|^{2}\\\\\n\\ \\ \\ =(U N)^{T}(U N) \n\\end{array}\n\\frac{d E}{d N}=2\\left(U^{T} U\\right) N=0\n$A$ is a $n \\times n$ matrix, $x$ is a non-zero vector, if\n\n\nA x=\\lambda x, \\quad x \\neq 0\n$x$â€‹ is one eigenvectors of $A$â€‹, and $\\lambda$â€‹ is one of eigenvalues.\n\n\n\\frac{d E}{d N}=2\\left(U^{T} U\\right) N=0\nSolution to $(U^TU)N=0$, s.t. $|N|^2=1$:\n\n\nU=\\left[\\begin{array}{cc}\nx_{1}-\\bar{x} & y_{1}-\\bar{y} \\\\\n\\vdots & \\vdots \\\\\nx_{n}-\\bar{x} & y_{n}-\\bar{y}\n\\end{array}\\right]\nN=\\left[\\begin{array}{cc}\na\\\\\nb\n\\end{array}\\right]\neigenvector of $U^T U$â€‹â€‹ associated with the smallest eigenvalue. å³å¯¹åº”æœ€å°ç‰¹å¾å€¼çš„ç‰¹å¾å‘é‡ä¸ºå…¶è§£\n\n\n\n$(a,b)^T\\dotproduct(x_i-\\bar{x},y_i-\\bar{y})$ç›¸å½“äºæŠ•å½±è·ç¦»\n\n4.5 Least squares as likelihood maximization\nGenerative model: line points are sampled independently and corrupted by Gaussian noise in the direction perpendicular(å‚ç›´çš„) to the line\nå³æ¯ä¸ªç‚¹ä¼šè¢«ç‹¬ç«‹é‡‡æ ·ï¼Œä¸”å…¶åˆ°ç›´çº¿çš„è·ç¦»ç¬¦åˆé«˜æ–¯åˆ†å¸ƒ\n\n\n\n\n\n\nLikelihood of points given line parameters (a, b, d):\n\n\n\\varepsilon=\\frac{(ax_{i}+by_{i}-d)^2}{\\sqrt{a^{2}+b^{2}}} \\Rightarrow \\varepsilon=(a x_{i}+b y_{i}-d)^2\\sim N\\left(0,\\sigma^{2}\\right)\n\\begin{aligned}\nP\\left(x_{1}, y_{1}, \\ldots, x_{n}, y_{n} \\mid a, b, d\\right) &=\\prod_{i=1}^{n} P\\left(x_{i}, y_{i} \\mid a, b, d\\right) \\\\\n& \\propto \\prod_{i=1}^{n} \\exp \\left(-\\frac{\\left(a x_{i}+b y_{i}-d\\right)^{2}}{2 \\sigma^{2}}\\right)\n\\end{aligned}\nLog-likelihood:\n\n\nL\\left(x_{1}, y_{1}, \\ldots, x_{n}, y_{n} \\mid a, b, d\\right)=-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(a x_{i}+b y_{i}-d\\right)^{2}4.6 Problem:\nProblem: squared error heavily penalizes outliers \n\n\n5. Robust estimators\nGeneral approach: find model parameters $\\theta$ that minimize\n\n\n\\sum_{i} \\rho\\left(u_{i}\\left(x_{i}, \\theta\\right) ; \\sigma\\right)\n$u_{i}\\left(x_{i}, \\theta\\right)-$â€‹â€‹ residual of ith point w.r.t. model parameters $\\theta$â€‹â€‹ $\\rho$â€‹â€‹ - robust function with scale parameter $\\sigma$â€‹â€‹â€‹\nå¯ä»¥ç†è§£ä¸ºç»™åŸå…ˆçš„è·ç¦»åŠ äº†ä¸ªrobust function\n\n\n\n\n\nThe robust function Ï behaves like squared distance for small values of the residual u but saturates(å¹³æ»‘) for larger values of u\n\nAttentionï¼š\n\nRobust fitting is a nonlinear optimization problem that must besolved iteratively\nLeast squares solution can be used for initialization \nScale of robust function should be chosen carefully\n\n\n\\rho(u ; \\sigma)=\\frac{u^{2}}{\\sigma^{2}+u^{2}}\n\n$\\sigma$â€‹â€‹ too big: The error value is almost the same for every point and the fit is very poor\n\n\n\n$\\sigma$ too large: Behaves much the same as least squares\n\n6. RANSAC\nRobust fitting can deal with a few outliers ç¦»ç¾¤å€¼ â€”â€” what if we have very many?\nRandom sample consensus (RANSAC):Very general framework for model fitting in the presence of outliers \nOutline\nChoose a small subset of points uniformly at random. éšæœºå‡åŒ€é‡‡æ ·\nFit a model to that subset æ‹Ÿåˆæ¨¡å‹\nFind all remaining points that are â€œcloseâ€ to the model and reject the rest asoutliers(å»é™¤å¤–ç‚¹) è®°å½•æ¨¡å‹çš„å†…ç‚¹æ•°\nDo this many times and choose the best model è¶…è¿‡å†…ç‚¹æ•°é˜ˆå€¼çš„model\n\n\nLeast squares fit\n\n\n\nRandomly select minimal subset of points:\n\n\n\nHypothesize a model å‡è®¾æ¨¡å‹\n\n\n\nCompute error function è®¡ç®—å‰©ä½™ç‚¹åˆ°ç›´çº¿çš„è·ç¦»\n\n\n\nSelect points consistent with model è®°å½•å†…ç‚¹ï¼ˆè®¾ç½®è·ç¦»é˜ˆå€¼ï¼‰\n\n\n\nRepeat hypothesize and verify loop\n\n\n\nUncontaminated(æœªæ±¡æŸ“) sample\n\n\n\nä»è€Œå¾—åˆ°å†…ç‚¹æœ€å¤šçš„æ¨¡å‹ä¸ºæˆ‘ä»¬éœ€è¦çš„æ¨¡å‹\n\nSteps:\n\nRepeat $N$ times:\nDraw $s$ points uniformly at random.Fit line to these s points\nFind inliers to this line among the remaining points (i.e., points whose distance from the line is less than $t$)\nlf there are $d$â€‹ or more inliers, accept the line and refit using allinliers å¦‚æœå†…ç‚¹è¶³å¤Ÿå¤šï¼Œåˆ™ç”¨è¿™äº›å†…ç‚¹é‡æ–°æ‹Ÿåˆï¼Œå¹¶å¾—åˆ°è¿™ä¸ªmodel\næœ‰kä¸ªæ¨¡å‹ï¼Œå†…ç‚¹æ•°ç›®å¤§äºdï¼Œè¿™äº›éƒ½å¯ä»¥è¾“å‡º\n\n6.1 Choosing the parameters\nlnitial number of points $s$\nTypically minimum number needed to fit the model. \n\n\nDistance threshold $t$â€‹\nNumber of iterations $N$\n\nChoose $N$ so that, with probability $p$â€‹, at least one random sample is free from outliers ï¼ˆæ²¡æœ‰å¼‚å¸¸å€¼ï¼‰ (e.g. p=0.99) (outlier ratio: e)\næœ‰0.99çš„ç½®ä¿¡åº¦ï¼Œåœ¨Næ¬¡è¿­ä»£åï¼Œè¿›è¡Œéšæœºé‡‡æ ·ä¸­è‡³å°‘æœ‰ä¸€ä¸ªç‚¹ä¸æ˜¯å¤–ç‚¹\n\n\nN å¦‚ä½•é€‰ï¼Ÿå‡è®¾100æ¬¡è¿­ä»£åï¼Œæˆ‘ä»¬é‡‡æ ·å¾—åˆ°çš„æ˜¯outlierï¼Œé‚£ä¹ˆå¯ä»¥ç”¨å…¬å¼è¡¨ç¤º\n\n\n\n\\begin{array}{l}\n\\left(1-(1-e)^{s}\\right)^{N}=1-p \\\\\nN=\\log (1-p) / \\log \\left(1-(1-e)^{s}\\right)\n\\end{array}\n$(1-e)^s$è¡¨ç¤ºéšæœºé‡‡æ ·sä¸ªç‚¹ï¼Œéƒ½æ˜¯å†…ç‚¹ï¼Œ$(1-(1-e)^s)$â€‹ä¸€æ¬¡è¿­ä»£ä¸­éšæœºé‡‡æ ·çš„ç‚¹æœ‰å¤–ç‚¹\n\nProblem:\n\nOutlier ratio e is often unknown a priori, so pick worst case, e.g. 50%,and adapt if more inliers are found, e.g. 80% would yield e=0.2 å³ä»¥æœ€åæƒ…å†µæ‰¾åˆ°çš„å†…ç‚¹ç™¾åˆ†æ¯”ï¼Œæ¥è®¡ç®—e\n\nAdaptive procedure:\n\n$N=\\infty$, sample_count $=0$â€‹ ä¸€å¼€å§‹åˆå§‹è¿­ä»£æ— ç©·æ¬¡ï¼Œé‡‡æ ·0æ¬¡\n\nWhile $N&gt;$â€‹ sample_count å½“å½“å‰çš„è¿­ä»£æ•°å¤§äºå·²ç»é‡‡æ ·æ•°ï¼Œåˆ™ç»§ç»­è¿ç®—\n\nChoose a sample and count the number of inliers\n\né‡‡æ ·ä¸€ä¸ªæ ·æœ¬ï¼Œå»æ‹Ÿåˆæ¨¡å‹ï¼Œç®—å‡ºå†…ç‚¹\n\nIf inlier ratio is highest of any found so far, set\n $\\mathrm{e}=1-($â€‹ number of inliers $) /($â€‹â€‹ total number of points)\n\nå¦‚æœå†…ç‚¹ç‡å‡é«˜ï¼Œåˆ™æ›´æ–°eï¼Œå› ä¸ºè¿™è¯´æ˜eåº”è¯¥æ›´å°\n\n\nRecompute $N$ from $e$â€‹â€‹â€‹ : æ›´æ–°N\n\n\n\nN=\\log (1-p) / \\log \\left(1-(1-e)^{s}\\right)\nIncrement the sample_count by 1\n\n\n\n\nsample countæŒ‡çš„æ˜¯æ€»çš„æ‹Ÿåˆæ¬¡æ•°ï¼Œå³å¯¹æ¯ä¸ªNè¿›è¡Œæœç´¢ï¼ŒNéšç€æ‹Ÿåˆä¼šé€æ¸ä¸‹é™ï¼Œç›´åˆ°é™åˆ°æ€»æ‹Ÿåˆæ¬¡æ•°ä»¥ä¸‹\n\nlnitial number of points s\n\nTypically minimum number needed to fit the model\n\n\nDistance threshold t\n\nChoose t so probability for inlier is p (e.g.0.95). Zero-mean Gaussian noise with std.dev. o: t2=3.84?.\n\n\nNumber of samples N\n\nChoose N so that, with probability p, at least one random sample is free from outliers (e.g.p=0.99) (outlier ratio: e)\n\n\nConsensus set size d åˆ¤æ–­è¯¥æ¨¡å‹æ˜¯å¦æ­£ç¡®\n\nShould match expected inlier ratio\n\n\n\n6.2 RANSAC pros and cons\nPros\nSimple and general\nApplicable to many different problems\nOften works well in practice\n\n\n\n\nCons\nLots of parameters to tune å‚æ•°è¿‡å¤š\nDoesnâ€™t work well for low inlier ratios (too many iterations,or can fail completely)  å†…ç‚¹å°‘åˆ™å¾ˆéš¾æ”¶æ•›\nCanâ€™t always get a good initialization of the model based on the minimum number of samples å¾ˆéš¾å¾—åˆ°å¥½çš„åˆå§‹å€¼\nRefine by Least Squares\n\n\n\n6.3 å¹³é¢æ‹Ÿåˆ\n\n\\left[\\begin{array}{cc}\nx_a\\\\\ny_a\n\\end{array}\\right]=\n\\left[\\begin{array}{cc}\na & b & c\\\\\nd & e & f\n\\end{array}\\right]\n\\left[\\begin{array}{cc}\nx_b\\\\\ny_b\\\\\n1\n\\end{array}\\right]\nè‡³å°‘è¦ä¸‰ä¸ªç‚¹æ‰èƒ½æ‹Ÿåˆ\n\n\n7. Hough Transform7.1 Voting schemes\nLet each feature vote for all the models that are compatibleï¼ˆå…¼å®¹ï¼‰ with it\nHopefully the noise features will not vote consistently for any single model å™ªç‚¹ä¸ä¼šåœ¨å•ç‹¬çš„æ¨¡å‹ä¸‹æ‹Ÿåˆ\nMissing data doesnâ€™t matter as long as there are enough features remaining to agree on a good model æ•°æ®è¶³å¤Ÿ\n\n\n\n7.2 An early type of voting scheme\nDiscretize parameter space into bins\nFor each feature point in the image, put a vote in every bin in the parameter space that could have generated this point\nFind bins that have the most votes\n\n\n\nåœ¨å‚æ•°ç©ºé—´è¿›è¡ŒæŠ•ç¥¨ï¼Œæ¯ä¸ªç‰¹å¾ç‚¹éƒ½è¦åœ¨å‚æ•°ç©ºé—´æŠ•ç¥¨ï¼ŒæŠ•ç¥¨æœ€å¤šçš„binsï¼Œä¸ºæ‰€éœ€è¦çš„å‚æ•°\n\n7.3 Parameter space representation\nA line in the image corresponds to a point in Hough space\n\n\n\nWhat does a point $(x_0 , y_0 )$ in the image space map to in theHough space?\n\nAnswer: the solutions of $y_0 = m x_0 + b$â€‹\nThis is a line in Hough space\n\nå¯ä»¥ç†è§£ä¸ºï¼Œè¿‡å›¾åƒä¸­çš„ä¸€ç‚¹ï¼Œåœ¨å‚æ•°ç©ºé—´çš„è¡¨è¾¾å¼ä¸ºä¸€æ¡ç›´çº¿\n\n\n\n\n\n\nWhere is the line that contains both $(x_0 , y_0 ) $and $(x_1 , y_1)$â€‹ï¼Ÿ\nIt is the intersection of the lines $b = x_0 m + y_0$â€‹ and $b = x_1 m + y_1$\n\n\n\n\n\nProblems with the ( m,b )\n\nUnbounded parameter domains\nVertical lines require infinite m ï¼ˆmï¼Œbï¼‰æ˜¯æ— é™çš„ï¼Œæ‰€ä»¥ï¼ˆm,bï¼‰çš„èŒƒå›´æ— æ³•é™å®š\n\n\nAlternative: polarï¼ˆæåæ ‡ï¼‰ representation\n\n\n\n\nEach point $(x,y)$ will add a sinusoid(æ­£å¼¦æ³¢) in the $(\\theta,\\rho)$ parameter space\n\n7.4 Algorithm outline\nInitialize accumulatorï¼ˆç´¯åŠ å™¨ï¼‰ H to all zeros\n\nFor each feature point ( x,y ) in the image\n\nFor Î¸ = 0 to 180\n$\\rho=xcos\\theta + ysin\\theta$\n$H(\\theta,\\rho)=H(\\theta,\\rho)+1$\n\n\nend\n\n\nend\n\néå†å›¾åƒæ¯ä¸ªæ•°æ®ç‚¹ä¸$\\theta$â€‹ï¼Œå¾—åˆ°å¤šä¸ª$\\rho$â€‹ï¼Œä»è€Œå¯¹binsè¿›è¡ŒæŠ•ç¥¨\n\n\n\n7.5 Basic illustration\n\\rho=\\rho_0cos(\\theta+\\theta_0)\\ \\ s.t.\\theta_0=\\text{æ–œç‡}\n\\rho_0=\\frac{\\rho} {cos(\\theta+\\theta_0)}\\ for\\ any\\ line\\ through (\\rho,\\theta)\næ‰€ä»¥æˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œä¸€æ¡ç›´çº¿æ˜ å°„åæ˜¯ä¸€ä¸ªç‚¹\nè€Œä¸€ä¸ªç‚¹æ˜ å°„åæ˜¯sec\n\n\n\nOther shapesï¼š\n\n\n\nA more complicated image\n\n\n\nå…·ä½“è¿‡ç¨‹æ˜¯å…ˆè¯†åˆ«å‡ºè¾¹ç¼˜ç‚¹ï¼Œå†åˆ©ç”¨è¾¹ç¼˜ç‚¹è¿›è¡Œæ‹Ÿåˆ\n\n7.6 Effect of noise\n\nPeak gets fuzzy and hard to locate\nç”±äºä¸€ä¸ªç‚¹æ‹Ÿåˆåæ˜¯ä½™å‰²ï¼Œé‚£ä¹ˆå½“æœ‰å™ªéŸ³æ—¶ï¼Œä¼šå¯¼è‡´ï¼Œè¿™å¤šä¸ªç‚¹æ‹Ÿåˆçš„ä½™å‰²æ— æ³•å‡†ç¡®äº¤äºä¸€ä¸ªç‚¹ï¼Œé€ æˆéš¾ä»¥å®šä½\n\nNumber of votes for a line of 20 points with increasing noise:\n\néšç€å™ªéŸ³å¢åŠ ï¼Œé‚£ä¹ˆæŠ•ç¥¨åœ¨ä¸€ä¸ªbinçš„å€¼å°±ä¼šå‡å°‘\n\n7.7 Random points\n\nUniform noise can lead to spurious peaks in the array\n\nå‡åŒ€å™ªå£°ä¼šå¯¼è‡´é˜µåˆ—ä¸­å‡ºç°æ‚æ•£å³°å€¼\n\n\nAs the level of uniform noise increases, the maximum number ofvotes increases too:\n\n\n\n\nå½“éšæœºå™ªå£°å¢åŠ ï¼Œä¼šå¯¼è‡´æœ€å¤§æŠ•ç¥¨å€¼ä¹Ÿå¢åŠ ï¼Œè¿™æ˜¯å› ä¸ºå™ªå£°æ˜¯å‡åŒ€åˆ†å¸ƒçš„ï¼Œç›¸å½“äºä»¥ä¸€å®šæ¯”ä¾‹å¢åŠ å‚æ•°ç©ºé—´æ‰€æœ‰æŠ•ç¥¨\n\n7.8 Dealing with noise\nChoose a good grid / discretization åˆ©ç”¨ç¨å¾®æ‰©å¤§çš„ç½‘æ ¼å¢åŠ å®¹é”™ç‡\nToo coarseï¼ˆç²—ï¼‰: large votes obtained when too many different lines correspond to a single bucket æœ‰å¯èƒ½ä½¿å¾—è®¸å¤šä¸åŒçš„ç›´çº¿æŠ•ç¥¨åˆ°åŒä¸€ä¸ªæ¡¶ï¼ŒåŸå› åœ¨äºæ ¼å­è¿‡ç²—ï¼Œä¼šå¯¼è‡´ä¸¢å¤±åŸæœ¬å›¾åƒä¸­çš„ä¿¡æ¯\nToo fineï¼ˆç»†ï¼‰: miss lines because some points that are not exactly collinear cast votes for different buckets å¯ä»¥è¿™ä¹ˆç†è§£ï¼Œå°±æ˜¯åˆ»ç”»è¿‡äºç²¾ç»†ï¼Œå¯¼è‡´æ— æ³•å®¹å¿ä¸€ç‚¹å™ªéŸ³ï¼Œä»è€Œæ— æ³•æ‰¾åˆ°äº¤ç‚¹\n\n\nIncrement neighboring bins (smoothing in accumulator array) \nå…¶æ„æ€æ˜¯ï¼Œåœ¨å¯¹ä¸€ä¸ªæ ¼å­æŠ•ç¥¨æ—¶ï¼ŒåŒæ—¶å¯¹å…¶é¢†åŸŸè¿›è¡ŒæŠ•ç¥¨ï¼Œä½†æ˜¯å…¶æŠ•ç¥¨æ€»å’Œè¿˜æ˜¯1ï¼Œå¦‚ä¸‹å›¾ï¼š\n\n\n\n\n\nTry to get rid of irrelevant features \nE.g.take only edge points with significant gradient magnitude\n\n\n\n7.9 Incorporatingï¼ˆåˆå¹¶ï¼‰ image gradients\nWhen we detect an edge point, we also know its gradient orientation\nBut this means the line is uniquely determined!\nModified Hough transform:\n\nå› ä¸ºå¯¹äºä¸€ä¸ªè¾¹ç¼˜ç‚¹ï¼Œå…¶å®æˆ‘ä»¬æ˜¯å¯ä»¥å”¯ä¸€ç¡®å®šä»–çš„ç›´çº¿æ–¹å‘çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±ä¸ç”¨å¯¹$\\theta$â€‹è¿›è¡Œé‡åŒ–äº†\nåªéœ€åˆ©ç”¨æ¢¯åº¦çš„è§’åº¦å€¼ï¼Œè¿›è¡Œè®¡ç®—ç›¸åº”çš„$\\rho$ï¼Œå¹¶å¯¹$\\rho$è¿›è¡Œé‡åŒ–å³å¯\n\n\nFor each edge point ( x,y )\n\nÎ¸ = gradient orientation at ( x,yï¼‰\nÏ = x cos Î¸ + y sin Î¸\nH(Î¸, Ï ) = H(Î¸, Ï ) + 1\n\n\nend\n\n7.10 Hough transform for circles\nHow many dimensions will the parameter space have?\nGiven an unoriented edge point, what are all possible bins that it canvote for?\nWhat about an oriented edge point?\n\n\n\nå¯¹äºå®šä¹‰ä¸€ä¸ªåœ†æˆ‘ä»¬éœ€è¦ä¸€ä¸ªåœ†å¿ƒå’ŒåŠå¾„åæ ‡\n\n\n\nè€Œå¯¹äºå›¾ä¸­ä»»æ„ä¸€ä¸ªç‚¹ï¼Œå®ƒæ˜ å°„åˆ°å‚æ•°ç©ºé—´æ˜¯ä¸€ä¸ªåœ†é”¥\n\n\n(x_0-a)^2+(y_0-b)^2=r^2\nç»™å®šç‚¹$(x_0,y_0)$â€‹ï¼Œç”±äºæˆ‘ä»¬å³ä¸çŸ¥é“æ–¹å‘ï¼Œä¹Ÿä¸çŸ¥é“åŠå¾„ï¼Œæ‰€ä»¥å½¢æˆä¸€ä¸ªåœ†é”¥æ–¹ç¨‹ï¼Œå…¶è¿‡$(x_0,y_0,0)$è¿™ä¸€ç‚¹ï¼š\n\n\n(a-x_0)^2+(b-y_0)^2=r^2\nå¦‚æœæˆ‘ä»¬çŸ¥é“åŠå¾„å¤§å°ï¼Œåˆ™é€€åŒ–ä¸ºä¸€ä¸ªåœ†\n\nå¯¹äºä¸€ä¸ªç¡®å®šæ–¹å‘çš„ç‚¹ï¼Œæ˜ å°„ä¸ºä¸¤ä¸ªå°„çº¿ï¼š\n\n\n\n\\left\\{ \\begin{array}{cc}\nx_0=a+rcos\\theta\\\\\ny_0=b+rsin\\theta\n\\end{array}\\right.\ntan\\theta=\\frac{y_0-b}{x_0-a} \\text{ is a constant}\næ‰€ä»¥æ˜¯ä¸¤æ¡è¿‡$(x_0,y_0)$çš„å°„çº¿ï¼Œ\n\n\n\n\næ˜¾ç„¶ï¼Œè¿™æ˜¯å› ä¸ºä¸€ä¸ªç‚¹æ¢¯åº¦çš„å‚ç›´æ–¹å‘æœ‰ä¸¤è¾¹ï¼Œå³å¯ä»¥ç¡®å®šä¸¤ä¸ªåœ†\næˆ‘ä»¬å·²çŸ¥æ¯ä¸ªè¾¹ç¼˜ç‚¹çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä»¥æ­¤è®¡ç®—å‡ºæ¯ä¸ªè¾¹ç¼˜ç‚¹å¯¹åº”çš„åœ†å¿ƒ\n\n\n\\left\\{\\begin{array}{r}\na=x_0-rcos\\theta\\\\\nb=y_0-rsin\\theta\n\\end{array}\\right.\nå†è¿›è¡ŒæŠ•ç¥¨å³å¯\n\n7.11 Application in recognition\nWe want to find a template defined by its reference point (center) and several distinct types of landmark points in stable spatial configuration\nå­¦ä¹ ç‰¹å¾ç‚¹ä¸ä¸­å¿ƒç‚¹ç›¸å¯¹çš„å…³ç³»\n\n\n\n7.10 Hough transform: Pros and cons\nPros\nCan deal with non locality and occlusion å¯ä»¥å¤„ç†éå±€éƒ¨æ€§å’Œé®æŒ¡\nCan detect multiple instances of a model\nSome robustness to noise: noise points unlikely to contribute consistently to any single bin\n\n\nCons\nComplexity of search time increases exponentially with the number of model parameters\nNon target shapes can produce spurious ï¼ˆè™šå‡çš„ï¼‰ peaks in parameter space éç›®æ ‡å½¢çŠ¶å¯èƒ½ä¼šäº§ç”Ÿè™šå‡å½¢çŠ¶(è™šå‡çš„ï¼‰ å‚æ•°ç©ºé—´ä¸­çš„å³°å€¼\nItâ€™s hard to pick a good grid size\n\n\n\n","categories":["CV"]},{"title":"Image Segmentation","url":"/2021/08/15/cv/7.%20Recognition%20&%20Detection/","content":"Image Segmentation\n\nRecognition &amp; Detection1.  Introduction to recognition\n\n1.1 Activity recognition\nWhat are these people doing?\n\n\n\nwalking \nshopping\nrolling a cartsitting\ntalking\nâ€¦\n\n1.2 Categorization vs Single instance recognitionWhere is the crunchyï¼ˆæ¾è„†çš„ï¼‰ nut?\n\n1.3 Visual Recognition\nDesign algorithms that have the capability to:\nClassify images or videos\nDetect and localize objects\nEstimate semantic and geometrical attributes. \nClassify human activities and events\n\n\n\n1.4 Why is it difficult?\nWant to find the object despite possibly large changes inscale, viewpoint, lighting and partial occlusion\n\n\n2. The machine learning framework\n\nTraining: given a training set of labeled examples${(x_1,y_1),â€¦. , (x_N,y_N)}, $â€‹estimate the prediction function $f$ by minimizing the prediction error on the training set\nTesting: apply $f$ to a never before seen test example $x$ and output the predicted value $y = f(x)$â€‹\n\nApply a prediction function to a feature representation of the image to get the desired output:\n\n\n\n2.1 A simple pipeline - Training\n2.2 â€œClassicâ€recognition pipeline\n\nHand-crafted feature representation\n\nçº¹ç†\nè¾¹ç¼˜\nè§’ç‚¹\n\n\nOff-the-shelf trainable classifier\n\n\n3. Bag of words\n3.1 Origin3.1.1 Origin 1: Texture Recognition\nTexture is characterized by the repetition of basic elements or textons\n\n\n\n\nç»Ÿè®¡å›¾åƒä¸­åŒ…å«çº¹ç†åŸºå…ƒçš„é¢‘ç‡ï¼Œä»è€Œä½œä¸ºç‰¹å¾å‘é‡\n\n3.1.2 Origin 2: Bag-of-words models\nOrderless document representation: frequencies of words from a dictionary salton &amp; McGill (1983)\n\n\n3.1.3 Bags of features for object recognition\n\nWorks pretty well for image-level classification and for recognizing object instances\n\n3.2 Bag of features\nFirst, take a bunch of images, extract features, and build up aâ€dictionaryâ€ or â€œvisual vocabularyâ€â€”â€”a list of common features\nGiven a new image, extract features and build a histogram - for each feature, find the closest visual word in the dictionary\n\n3.2.1 Bag of features: outline\nExtract features\n\n\n\nLearn â€œvisual vocabularyâ€\nåªé€‰å–æœ‰ä»£è¡¨æ€§çš„ç‰¹å¾åŸºå…ƒ\n\n\n\n\n\nQuantize features using visual vocabulary\n\nç®—ç›¸ä¼¼åº¦ï¼ŒæŠ•å½±bins\n\n\nRepresent images by frequencies of â€œvisual wordsâ€\n\n\n\n3.2.2 Feature extraction\nRegular grid\nVogel &amp; Schiele, 2003\nFei-Fei &amp;Perona,2005\n\n\n\n\n\nlnterest point detector\nCsurka et al. 2004\nFei-Fei&amp; Perona,2005Sivic et al. 2005\n\n\n\n\n\nOther methods\nRandom sampling (Vidal-Naquet &amp; Ullman, 2002). \nSegmentation-based patches (Barnard et al.2003)\n\n\n\n3.3 Learning the visual vocabulary\n\næŠŠç‰¹å¾ç‚¹è¿›è¡Œèšç±»ï¼Œå¾—åˆ°èšç±»ä¸­å¿ƒï¼Œä»è€Œå¾—åˆ°è§†è§‰è¯æ±‡\nå¯¹äºSIFTï¼Œåˆ™å°†10000ä¸ª128ç»´å‘é‡ç¼©å°ä¸º3ä¸ª128ç»´ï¼Œè¿›è€Œé€šè¿‡ç›´æ–¹å›¾ï¼Œæœ€åå˜æˆä¸€ä¸ªä¸‰ç»´å‘é‡\n\n\n\n3.3.1 From clustering to vector quantization\nClustering is a common method for learning a visual vocabulary or codebook\n\nUnsupervised learning process\nEach cluster center produced by k-means becomes a codevector \nProvided the training set is representative, the codebook will be â€œuniversalâ€\n\n\nThe codebook is used for quantizing features\n\nA vector quantizer takes a feature vector and maps it to the index of the nearest codevector in a codebook\nCodebook = visual vocabulary\nCodevector= visual word\nç®€è¨€ä¹‹ï¼Œå°±æ˜¯é€šè¿‡èšç±»å¾—åˆ°çš„èšç±»ä¸­å¿ƒå°±æ˜¯æˆ‘ä»¬éœ€è¦çš„code vectorï¼Œç„¶åcode vector ç»„æˆcodebookï¼Œå¯¹äºåç»­å›¾ç‰‡çš„è¡¨è¾¾ï¼Œåªè¦å€ŸåŠ©äºé‡åŒ–ï¼Œå³å¯\n\n\n\n\n\n3.3.2 Visual vocabularies\n3.3.3 Visual vocabularies: lssues\nHow to choose vocabulary size?\n\nToo small: visual words not representative of all patches\nToo large: quantization artifacts, overfitting\n\n\nComputational efficiency\n\nVocabulary trees(Nister &amp; Steweniu:s, 2006)\n\n\n\n\n\nè®­ç»ƒé˜¶æ®µï¼Œè¿›è¡Œæ ‘çŠ¶åˆ†ç±»ï¼Œå³é€’å½’è°ƒç”¨k-meansï¼›æµ‹è¯•é˜¶æ®µå…ˆè¿›è¡Œç²—åˆ†ç±»\n\n\n3.3.4 Large-scale image matching\nBag-of-words models have been useful in matching an image to a large database of object instances\n\n\n3.3.5 Bags of features for object recognition\n3.4 What about spatial information?\n\n\nå•çº¯ä½¿ç”¨ä¸Šè¯‰è¡¨ç¤ºæ–¹æ³•ï¼Œä¼šå¤±å»ç©ºé—´ä¿¡æ¯çš„ç‰¹å¾\n\n3.4.1 Spatial pyramids ï¼ˆSpatial Pyramid Matchingï¼‰\n\n\nå°†å›¾åƒåˆ†æˆè‹¥å¹²å—(sub-regions)ï¼Œåˆ†åˆ«ç»Ÿè®¡æ¯ä¸€å­å—çš„ç‰¹å¾ï¼Œæœ€åå°†æ‰€æœ‰å—çš„ç‰¹å¾æ‹¼æ¥èµ·æ¥ï¼Œå½¢æˆå®Œæ•´çš„ç‰¹å¾ã€‚\n\nç®€ä»‹ï¼š\nå‡è®¾å­˜åœ¨ä¸¤ä¸ªç‚¹é›†$X$å’Œ$Y$ï¼ˆ æ¯ä¸ªç‚¹éƒ½æ˜¯$D$ç»´çš„ï¼Œä»¥ä¸‹å°†å®ƒä»¬æ‰€åœ¨çš„ç©ºé—´ç§°ä½œç‰¹å¾ç©ºé—´ï¼‰ã€‚å°†ç‰¹å¾ç©ºé—´åˆ’åˆ†ä¸ºä¸åŒçš„å°ºåº¦$0,â€¦,L$ï¼Œåœ¨å°ºåº¦$l$ä¸‹ç‰¹å¾ç©ºé—´çš„æ¯ä¸€ç»´åˆ’å‡º$2^l$ä¸ªcellsï¼Œé‚£ä¹ˆdç»´çš„ç‰¹å¾ç©ºé—´å°±èƒ½åˆ’å‡º$D=2^{dl}$â€‹ä¸ªbinsï¼›\nä¸¤ä¸ªç‚¹é›†ä¸­çš„ç‚¹è½å…¥åŒä¸€ä¸ªbinå°±ç§°è¿™ä¸¤ä¸ªç‚¹Matchã€‚åœ¨ä¸€ä¸ªbinä¸­matchçš„æ€»æ•°å®šä¹‰ä¸º $min(X_i, Y_i)$â€‹â€‹ï¼Œå…¶ä¸­$X_i$â€‹â€‹å’Œ$Y_i$â€‹â€‹åˆ†åˆ«æ˜¯ä¸¤ä¸ªç‚¹é›†ä¸­è½å…¥ç¬¬$i$â€‹ä¸ªbinçš„ç‚¹çš„æ•°ç›®ï¼›\nç»Ÿè®¡å„ä¸ªå°ºåº¦ä¸‹matchçš„æ€»æ•°$\\mathcal{I}^l$â€‹ï¼ˆå°±ç­‰äºç›´æ–¹å›¾ç›¸äº¤)ã€‚ç”±äºç»†ç²’åº¦çš„binè¢«å¤§ç²’åº¦çš„binæ‰€åŒ…å«ï¼Œä¸ºäº†ä¸é‡å¤è®¡ç®—ï¼Œæ¯ä¸ªå°ºåº¦çš„æœ‰æ•ˆMatchå®šä¹‰ä¸ºmatchçš„å¢é‡$\\mathcal{I}^l-\\mathcal{I}^{l+1}$\nä¸åŒçš„å°ºåº¦ä¸‹çš„matchåº”èµ‹äºˆä¸åŒæƒé‡ï¼Œæ˜¾ç„¶å¤§å°ºåº¦çš„æƒé‡å°ï¼Œè€Œå°å°ºåº¦çš„æƒé‡å¤§ï¼Œå› æ­¤å®šä¹‰æƒé‡ä¸º$\\frac{1}{2^{L-l}}$â€‹\næœ€ç»ˆï¼Œä¸¤ç‚¹é›†åŒ¹é…çš„ç¨‹åº¦å®šä¹‰ä¸ºï¼š\n\n\n\\begin{aligned}\n\\kappa^{L}(X, Y) &=\\mathcal{I}^{L}+\\sum_{\\ell=0}^{L-1} \\frac{1}{2^{L-\\ell}}\\left(\\mathcal{I}^{\\ell}-\\mathcal{I}^{\\ell+1}\\right) \\\\\n&=\\frac{1}{2^{L}} \\mathcal{I}^{0}+\\sum_{\\ell=1}^{L} \\frac{1}{2^{L-\\ell+1}} \\mathcal{I}^{\\ell} \n\\end{aligned}\næˆ‘è§‰å¾—è¦ç‰¹åˆ«è¯´æ˜ä¸€ä¸‹çš„å°±æ˜¯è¿™é‡Œçš„ç‰¹å¾ç©ºé—´ä¸å‰é¢ä¸¤ä¸ªç‚¹é›†çš„ç‚¹æ‰€è¢«æè¿°çš„ç©ºé—´ä¹‹é—´çš„å…³ç³»â€”â€”-æ²¡æœ‰å…³ç³»ï¼Œå¯¹ï¼Œæˆ‘è§‰å¾—æ˜¯æ²¡æœ‰å…³ç³»ï¼Œå› æ­¤å°±æœ‰ä½œè€…çš„SPMï¼š\nå°†å›¾åƒç©ºé—´ç”¨æ„é€ é‡‘å­—å¡”çš„æ–¹æ³•åˆ†è§£ä¸ºå¤šä¸ªscaleçš„binsï¼ˆé€šä¿—åœ°è¯´å°±æ˜¯åˆ‡åˆ†æˆä¸åŒå°ºåº¦çš„æ–¹å½¢ï¼‰\nåƒBOWä¸€æ ·æ„é€ ä¸€æœ¬å¤§å°ä¸ºMçš„dictionaryï¼Œè¿™æ ·æ¯ä¸ªç‰¹å¾éƒ½èƒ½æŠ•å½±åˆ°dictionaryä¸­çš„ä¸€ä¸ªwordä¸Šã€‚å…¶ä¸­å­—å…¸çš„è®­ç»ƒè¿‡ç¨‹æ˜¯åœ¨ç‰¹å¾ç©ºé—´ä¸­å®Œæˆã€‚è®ºæ–‡ä¸­çš„ç‰¹å¾åˆ©ç”¨çš„dense SIFTã€‚\nç»Ÿè®¡æ¯ä¸ªbinä¸­å„ä¸ªwordsçš„æ•°ç›®ï¼Œæœ€ç»ˆä¸¤å¹…å›¾åƒçš„åŒ¹é…ç¨‹åº¦å®šä¹‰ä¸ºï¼š\n\n\n\n\nK^{L}(X, Y)=\\sum_{m=1}^{M} \\kappa^{L}\\left(X_{m}, Y_{m}\\right)\næ³¨æ„ï¼Œå½“L=0æ—¶ï¼Œæ¨¡å‹å°±é€€åŒ–æˆä¸ºBOWäº†ã€‚\n\nSPMä»‹ç»äº†ä¸¤å¹…å›¾åƒåŒ¹é…çš„æ–¹æ³•ã€‚å¦‚è¦ç”¨äºåœºæ™¯åˆ†ç±»ï¼Œæ³¨æ„(2)å¼å°±ç­‰äº$M(L+1)$â€‹ä¸ªç›´æ–¹å›¾ç›¸äº¤è¿ç®—çš„å’Œï¼Œå…¶å®ä¹Ÿå°±ç­‰äºä¸€ä¸ªæ›´å¤§çš„å‘é‡ç›´æ¥è¿›è¡Œç›´æ–¹å›¾ç›¸äº¤è¿ç®—è€Œå·²ã€‚è€Œè¿™ä¸ªå‘é‡ï¼Œå°±ç­‰äºæ¯ä¸ªè¢«åˆ’åˆ†çš„å›¾åƒå­åŒºåŸŸä¸Šçš„visual wordsç›´æ–¹å›¾è¿åœ¨ä¸€èµ·ã€‚è¿™ä¸ªç‰¹å¾ï¼Œå°±æ˜¯ç”¨æ¥åˆ†ç±»çš„ç‰¹å¾ã€‚\n\nä½œè€…åœ¨å®éªŒä¸­è¡¨æ˜ï¼Œä¸åŒLä¸‹ï¼ŒMä»200å–åˆ°400å¯¹åˆ†ç±»æ€§èƒ½å½±å“ä¸å¤§ï¼Œä¹Ÿå°±æ˜¯é™ä½äº†ç ä¹¦çš„å¤§å°å¯¹åˆ†ç±»æ•ˆæœçš„å½±å“ã€‚\n\nåœ¨æœ¬æ–‡æœ€å¼€å§‹ä¹Ÿæåˆ°äº†ï¼Œè¿™ä¸ªæ–¹æ³•å¯ä»¥ä½œä¸ºä¸€ä¸ªæ¨¡æ¿ï¼Œæ¯ä¸ªsub-regionä¸­ç»Ÿè®¡çš„ç›´æ–¹å›¾å¯ä»¥å¤šç§å¤šæ ·ï¼Œç®€å•çš„å¦‚é¢œè‰²ç›´æ–¹å›¾ï¼Œä¹Ÿå¯ä»¥ç”¨HOGï¼Œè¿™å°±å½¢æˆäº†PHOGã€‚SPMçš„matlabä»£ç ä¹Ÿå¯ä»¥ä»ä½œè€…çš„ä¸»é¡µä¸Šä¸‹è½½åˆ°(here)ã€‚åªä¸è¿‡è¿™ç§ç©ºé—´åˆ†ç±»ä¿¡æ¯ä»ç„¶æœ‰å±€é™æ€§â€”â€”-ä¸€å¹…ç›¸åŒçš„å›¾åƒæ—‹è½¬90åº¦ï¼ŒåŒ¹é…çš„ç»“æœå°±ä¸ä¼šå¤ªé«˜äº†ã€‚æ‰€ä»¥æ¨¡å‹éšå«çš„å‡è®¾å°±æ˜¯å›¾åƒéƒ½æ˜¯æ­£ç€å­˜å‚¨çš„ï¼ˆäººéƒ½æ˜¯ç«™ç«‹çš„ï¼Œæ ‘éƒ½æ˜¯ç«™ç«‹çš„â€¦â€¦.ï¼‰ã€‚å¦å¤–ç©ºé—´Pyramidçš„åˆ†å—æ–¹æ³•ä¹Ÿæ²¡æœ‰è€ƒè™‘å›¾åƒä¸­objectçš„ä¿¡æ¯ï¼ˆä»…ä»…æ˜¯åˆ©ç”¨SIFTç‰¹å¾æ¥æè¿°äº†Objectï¼‰ï¼Œè¿™ä¹Ÿæ˜¯ä½œè€…åœ¨æ–‡ä¸­æ‰¿è®¤çš„ç¼ºç‚¹ã€‚DPMï¼Œåº”è¯¥æ˜¯è€ƒè™‘äº†è¿™ä¸ªé—®é¢˜çš„å§ã€‚\n\n\n4. â€œClassicâ€ recognition pipeline\n4.1 Recall: Many classifiers to choose from\nK-nearest neighbor\nSVM\nNeural networks\nNaive Bayes\nLogistic regression\nRandomized Forests\nEtc.\n\n4.2 Generalization\n\nHow well does a learned model generalize from the data it was trained on to a new test set?\n\n4.2.1 Bias-Variance Trade-off\nModels with too few parameters are inaccurate because of a large bias (not enough flexibility).\n\n\n\nModels with too many parameters are inaccurate because of a large variance(too much sensitivity to the sample).\n\n\n4.2.2 Bias versus variance\nComponents of generalization error\nBias: how much the average model over all training sets differ from the true model?\nError due to inaccurate assumptions/simplifications made by the model \n\n\nVariance: how much models estimated from different training sets differ fron each other\n\nUnderfitting: \n\nmodel is too â€œsimpleâ€to represent all the relevant classcharacteristics\nHigh bias and low variance\nHigh training error and high test error\n\n\n\nOverfitting: \n\nmodel is too â€œcomplexâ€ and fits irrelevant characteristics(noise) in the data\n\nLow bias and high variance\n\nLow training error and high test error\n\n\n\nNo classifier is inherently(å¤©ç”Ÿçš„) better than any other: you need to make assumptions to generalize\nErrors\nBias: due to over-simplifications\nVariance: due to inability to perfectlyestimate parameters from limited data\n\n\n\n4.2.3 How to reduce variance?\nChoose a simpler classifier\nRegularize the parameters\nGet more training data\n\n4.3 Remarks\nKnow your data:\n\nHow much supervision do you have?\nHow many training examples can you afford?\nHow noisy?\n\n\nKnow your goal (i.e. task):\n\nAffects your choices of representation\nAffects your choices of learning algorithms\nAffects your choices of evaluation metricss\n\n\nUnderstand the math behind each machine learning algorithm under consideration!\n\n\n5. Object detection5.1 From image classification to object detection\n\n5.2 Window-based detection models\nBuilding an object model\nGiven the representation, train a binary classifier\n\n\n\nä½¿ç”¨ä¸åŒçª—å£è¿›è¡Œéå†æ•´ä¸ªå›¾åƒ\n\n5.3 Window-based object detection: recap\nå¤§è‡´æ€æƒ³æ˜¯ç”Ÿæˆå¾ˆå¤šwindowï¼Œç„¶åç”¨å­¦ä¹ åˆ°çš„åˆ†ç±»å™¨éå†æ¯ä¸ªwindowçš„å›¾åƒï¼Œçœ‹åˆ†ç±»æ­£ç¡®å¾—åˆ†\n\nTraining:\n\nObtain training data\n\nDefine features\n\nDefine classifier\n\nGiven new image:\n\nSlide window\n\nScore by classifier\n\n\n\n5.4 Challenges\nlmages may contain more than one class, multiple instances from the same class\nBounding box localization\nä½ç½®ç²¾åº¦å½±å“åˆ†ç±»\n\n\nEvaluation\nè¯„ä»·æ ‡å‡†ä¸ä¸€æ ·\n\n\n\n\n5.5 Object detection evaluation\nAt test time, predict bounding boxes, class labels, and confidence scores\n\nFor each detection, determine whether it is a true or false positive\n\nPASCAL criterion: Area(GT âˆ© Det)/ Area(GT U Det)&gt;0.5\nå°±æ˜¯äº¤å¹¶æ¯”$IoU$\n\n\nFor multiple detections of the same ground truth box, only one considered a true positive\n\n\nFor each class, plot Recall-Precision curve and compute Average Precision (area under the curve)\n\n\n\n\nPrecision:æŒ‡çš„æ˜¯æ— è¯¯æ£€\nä¿è¯æ£€æµ‹å‡ºæ¥çš„æ˜¯æ­£ç¡®çš„\n\n\n\n\n\\text { Precision }=\\frac{T P}{T P+F P}=\\frac{1}{1+\\frac{FP}{TP}}\nRecall:è¡¨ç¤ºæ— æ¼æ£€\n\nä¿è¯ä¸æ¼æ£€æµ‹æ­£ç¡®çš„ï¼Œä¾‹å¦‚ä¸å¸Œæœ›ä»»ä½•æœ‰ç¼ºé™·çš„æ ·å“æ¼æ‰\n\nä¸‹å¼å¯ä»¥ç†è§£ä¸ºåœ¨æ‰€æœ‰æ­£ç¡®çš„æ ·æœ¬ä¸­ï¼Œä½ é¢„æµ‹ä¸ºæ­£ç¡®çš„æ ·æœ¬å çš„æ¯”é‡ï¼Œæ‰€ä»¥æœ€å¤§åŒ–å¬å›ç‡ä¼šä½¿å¾—ä½ å°½å¯èƒ½é¢„æµ‹åˆ°æ‰€æœ‰çš„æ­£ä¾‹æ ·æœ¬\n\n\n\n\n\n\\text { Recall }=\\frac{T P}{T P+F N}\nä¸¤è€…éœ€è¦trade-off\n\n\n\nAUCçš„ç‰©ç†æ„ä¹‰å°±æ˜¯æƒè¡¡è¿™ä¸¤è€…çš„åº¦é‡\n\n6. Face detection\n\nSlide a window across the image and evaluate a detection model at each location\nThousands of windows to evaluate: efficiency and low false positive rates are essential\nFaces are rare: 0-10 per image\nä¸€å¼ å›¾åƒä¸å¯èƒ½å‡ºç°å¾ˆå¤šå¼ äººè„¸\n\n\n\n6.1 Viola-Jones face detector\n6.2 Boosting intuition\n\nå¯¹äºå¤æ‚çš„ç‰¹å¾ï¼Œå¯èƒ½éœ€è¦å¤æ‚çš„æ›²çº¿å»åˆ†ç±»\næœ‰æ²¡æœ‰ä»€ä¹ˆåŠæ³•ï¼Œç®€åŒ–æ¨¡å‹å¤æ‚åº¦\nç”¨å¤šæ¡ç›´çº¿æ‹Ÿåˆæ›²çº¿\n\n\n\n\n\nç»™åˆ†é”™çš„ç‚¹ï¼Œç»™ä¸€ä¸ªè¾ƒå¤§çš„æƒé‡\nå°±èƒ½åœ¨ä¸‹ä¸€æ¬¡åˆ†ç±»åˆ†å¯¹\n\n\n\n\n\nç»è¿‡æ•°æ¬¡åˆ†ç±»\nå°±å¯ä»¥å¾—åˆ°å¤šä¸ªå¼±åˆ†ç±»å™¨\n\n\n\n\n6.3 Boosting: training\nlnitially, weight each training example equally\nln each boosting round:\nFind the weak learner that achieves the lowest weighted training error\nRaise weights of training examples misclassified by current weak learner\n\n\nCompute final classifier as linear combination of all weaklearners (weight of each learner is directly proportional toits accuracy)\n\nExact formulas for re-weighting and combining weak learners depend on the particular boosting scheme.\n\n\n6.4 Viola-Jones face detectorMain idea:\n\nRepresent local texture with( efficienily computable â€œrectangularâ€ features within window of interest. \nSelect discriminative features to be weak classifiers\n\nUse boosted combination of them as final classifier\n\nForm a cascadeï¼ˆä¸²è”ï¼‰ of such classifiers, rejecting clear negatives quickly\n\n6.5 Viola-Jones detector: features6.5.1 â€œRectangularâ€ filters\nFeature output is difference between adjacent regions\nå·¦è¾¹æ‰€æœ‰åƒç´ ç‚¹çš„å€¼å‡å»å³è¾¹æ‰€æœ‰åƒç´ ç‚¹çš„å€¼\n\n\n\n\n\nè®¡ç®—é‡å¾ˆå¤§ï¼Œå› ä¸ºæ—¢è¦è€ƒè™‘æ¡†çš„å°ºåº¦ä»¥åŠä½ç½®(éå†æ‰€æœ‰åƒç´ ç‚¹)\nè¿™äº›ç‰¹å¾éƒ½å¾ˆç®€å•ï¼Œå°±æ˜¯åˆ†åˆ«å°†ç™½è‰²å’Œé»‘è‰²åŒºåŸŸä¸­çš„æ‰€æœ‰åƒç´ ç›¸åŠ ï¼Œç„¶ååšå·®ã€‚ä¾‹å¦‚å›¾1ä¸­çš„Aç‰¹å¾ï¼Œé¦–å…ˆè®¡ç®—ä¸¤ä¸ªåŒºåŸŸåƒç´ å’Œ$Sum(white),Sum(black).$\n\nç„¶åè®¡ç®—:\n\n\n\nfeature=Sum(white)-Sum(black)\nä½†æ˜¯è€ƒè™‘åˆ°å¤šå°ºåº¦é—®é¢˜ï¼Œå³åˆ©ç”¨ä¸åŒå¤§å°çš„æ‰«æçª—å£å»æ£€æµ‹ä¸åŒå¤§å°çš„äººè„¸ï¼Œè¿™ä¸ªç‰¹å¾featureåº”è¯¥éœ€è¦å½’ä¸€åŒ–ã€‚å³æœ€ç»ˆç‰¹å¾ï¼š\n\n\nfeature'=\\frac{\\text{feature}}{\\text{pixel\\_num}}\n$pixel_num$â€‹æ˜¯é»‘è‰²/ç™½è‰²åŒºåŸŸçš„åƒç´ ç‚¹ä¸ªæ•°ã€‚è¿™æ ·ä¸€æ¥ï¼Œå³ä½¿æ‰«æçª—å£çš„å¤§å°ä¸ä¸€æ ·ï¼Œå¾—åˆ°çš„äººè„¸å¯¹åº”ä½ç½®çš„ç‰¹å¾å€¼ä¹Ÿèƒ½åŸºæœ¬ä¸€è‡´ã€‚å¦å¤–ï¼Œè¯´ä¸€ä¸‹ä¸ºå•¥è¿™ä¸ªå«haar-likeã€‚å› ä¸ºåœ¨haar-waveletä¸­ï¼ŒhaaråŸºå‡½æ•°æ˜¯ä¸‹é¢è¿™æ ·ä¸€ä¸ªä¸œè¥¿ã€‚\n\n\n\\psi(x) \\equiv \\begin{cases}1 & 0 \\leq x","categories":["CV"]},{"title":"Gaussian mixture model","url":"/2021/08/15/cv/GMM%E5%8F%82%E8%80%83%E9%98%85%E8%AF%BB/","content":"Gaussian mixture model\n\nè¯¦è§£EMç®—æ³•ä¸æ··åˆé«˜æ–¯æ¨¡å‹(Gaussian mixture model,GMM)1 å•é«˜æ–¯æ¨¡å‹(Gaussian single model, GSMï¼‰\nç®€å•å›é¡¾ä¸€ä¸‹æ¦‚ç‡è®ºè®²è¿‡çš„é«˜æ–¯æ¨¡å‹ã€‚\né«˜æ–¯æ¨¡å‹æ˜¯ä¸€ç§å¸¸ç”¨çš„å˜é‡åˆ†å¸ƒæ¨¡å‹ï¼Œåœ¨æ•°ç†ç»Ÿè®¡é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ï¼ˆâ€¦â€¦å¥½å§è¯»äº†è¿™ä¹ˆå¤šå¹´ä¹¦æ²¡ç™½è´¹ï¼Œæ•™ç§‘ä¹¦èˆ¬çš„è¯è¯­å·²æ¤å…¥éª¨é«“ï¼‰ã€‚ä¸€ç»´é«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°å¦‚ä¸‹\n\n\nf(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right)\n$\\mu$å’Œ $\\sigma^2$ åˆ†åˆ«æ˜¯é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®ã€‚\nè­¬å¦‚å°†ç”·ç”Ÿèº«é«˜è§†ä¸ºå˜é‡X, å‡è®¾ç”·ç”Ÿçš„èº«é«˜æœä»é«˜æ–¯åˆ†å¸ƒï¼Œåˆ™$X\\sim N(\\mu,\\sigma^2)$â€‹â€‹,å¥³ç”Ÿäº¦å¦‚æ­¤ã€‚åªæ˜¯ç”·å¥³ç”Ÿèº«é«˜åˆ†å¸ƒå¯èƒ½å…·æœ‰ä¸åŒçš„å‡å€¼å’Œæ–¹å·®ã€‚å›¾1æ˜¯ä»è°·æ­Œå›¾åº“ä¸­æœç´¢åˆ°çš„ç”·å¥³ç”Ÿèº«é«˜åˆ†å¸ƒå›¾ï¼Œæ¥æºä¸æ¸…ï¼Œä¸ªäººè§‰å¾—ç”·ç”Ÿçš„å‡å€¼èº«é«˜è™šé«˜â€¦â€¦å››ä¸ªè®°å·åˆ†åˆ«è¡¨ç¤º$3\\sigma$â€‹å‡†åˆ™ã€‚\n\n\n\nå¤šç»´å˜é‡ $X=\\left(x_{1}, x_{2}, \\ldots x_{n}\\right)$ çš„è”åˆæ¦‚ç‡å¯†åº¦å‡½æ•°ä¸º;\n\n\nf(X)=\\frac{1}{(2 \\pi)^{d / 2}|\\Sigma|^{1 / 2}} \\exp \\left[-\\frac{1}{2}(X-u)^{T} \\Sigma^{-1}(X-u)\\right], X=\\left(x_{1}, x_{2} \\ldots x_{n}\\right)\nå…¶ä¸­ï¼šd: å˜é‡ç»´åº¦ã€‚å¯¹äºäºŒç»´é«˜æ–¯åˆ†å¸ƒï¼Œæœ‰ $\\mathrm{d}=2$â€‹;$u=\\left(\\begin{array}{c}u_{1} \\ u_{2} \\ \\ldots \\ u_{n}\\end{array}\\right):$â€‹ å„ç»´å˜é‡çš„å‡å€¼ï¼›\n$\\Sigma$â€‹ : åæ–¹å·®çŸ©é˜µï¼Œæè¿°å„ç»´å˜é‡ä¹‹é—´çš„ç›¸å…³åº¦ã€‚å¯¹äºäºŒç»´é«˜æ–¯åˆ†å¸ƒï¼Œæœ‰:\n\n\n\\Sigma=\\left[\\begin{array}{ll}\n\\delta_{11} & \\delta_{12} \\\\\n\\delta_{21} & \\delta_{22}\n\\end{array}\\right]\n\nå›¾ 2 æ˜¯äºŒç»´é«˜æ–¯åˆ†å¸ƒäº§ç”Ÿçš„æ•°æ®ç¤ºä¾‹ï¼Œå‚æ•°è®¾å®šä¸º: $u=\\left(\\begin{array}{c}0 \\ 0\\end{array}\\right), \\Sigma=\\left[\\begin{array}{cc}1 &amp; 0.8 \\ 0.8 &amp; 5\\end{array}\\right]$. å…³äºäºŒ ç»´é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°è®¾å®šå¯¹ä¸ºé«˜æ–¯æ›²é¢çš„å½±å“ï¼Œè¿™ç¯‡æ–‡ç« äºŒç»´é«˜æ–¯åˆ†å¸ƒï¼ˆTwo-dimensional Gaussian distribution) çš„å‚æ•°åˆ†ææœ‰æåŠï¼Œä¸»è¦æ˜¯ä¸ºäº†ä¸‹æ–‡ç†è§£æ··åˆé«˜æ–¯åˆ†å¸ƒåšé“ºå«ã€‚æœä»äºŒç»´é«˜æ–¯åˆ†å¸ƒçš„æ•° æ®ä¸»è¦é›†ä¸­åœ¨ä¸€ä¸ªä§åœ†å†…éƒ¨, æœä»ä¸‰ç»´çš„æ•°æ®é›†ä¸­åœ¨ä¸€ä¸ªæ¤­çƒå†…éƒ¨ã€‚\n\n2 æ··åˆé«˜æ–¯æ¨¡å‹ï¼ˆGaussian mixture model, GMMï¼‰2.1 ä¸ºä»€ä¹ˆè¦æœ‰æ··åˆé«˜æ–¯æ¨¡å‹\nå…ˆæ¥çœ‹ä¸€ç»„æ•°æ®ã€‚\n\n\n\nå¦‚æœæˆ‘ä»¬å‡è®¾è¿™ç»„æ•°æ®æ˜¯ç”±æŸä¸ªé«˜æ–¯åˆ†å¸ƒäº§ç”Ÿçš„ï¼Œåˆ©ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆåæ–‡è¿˜ä¼šæåŠï¼‰å¯¹è¿™ä¸ªé«˜æ–¯åˆ†å¸ƒåšå‚æ•°ä¼°è®¡ï¼Œå¾—åˆ°ä¸€ä¸ªæœ€ä½³çš„é«˜æ–¯åˆ†å¸ƒæ¨¡å‹å¦‚ä¸‹ã€‚\n\n\n\næœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿä¸€èˆ¬æ¥è®²è¶Šé è¿‘æ¤­åœ†çš„ä¸­å¿ƒæ ·æœ¬å‡ºç°çš„æ¦‚ç‡è¶Šå¤§ï¼Œè¿™æ˜¯ç”±æ¦‚ç‡å¯†åº¦å‡½æ•°å†³å®šçš„ï¼Œä½†æ˜¯è¿™ä¸ªé«˜æ–¯åˆ†å¸ƒçš„æ¤­åœ†ä¸­å¿ƒçš„æ ·æœ¬é‡å´æå°‘ã€‚æ˜¾ç„¶æ ·æœ¬æœä»å•é«˜æ–¯åˆ†å¸ƒçš„å‡è®¾å¹¶ä¸åˆç†ã€‚å•é«˜æ–¯æ¨¡å‹æ— æ³•äº§ç”Ÿè¿™æ ·çš„æ ·æœ¬ã€‚\nå®é™…ä¸Šï¼Œè¿™æ˜¯ç”¨ä¸¤ä¸ªä¸åŒçš„é«˜æ–¯åˆ†å¸ƒæ¨¡å‹äº§ç”Ÿçš„æ•°æ®ã€‚\n\n\n\næ­£å½“å•é«˜æ–¯æ¨¡å‹æŠ“è€³æŒ è…®çš„æ—¶å€™ï¼Œæ··åˆé«˜æ–¯æ¨¡å‹å°±å¤§æ‘‡å¤§æ‘†åœ°è¿›åœºäº†ã€‚å®ƒé€šè¿‡æ±‚è§£ä¸¤ä¸ªé«˜æ–¯æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä¸€å®šçš„æƒé‡å°†ä¸¤ä¸ªé«˜æ–¯æ¨¡å‹èåˆæˆä¸€ä¸ªæ¨¡å‹ï¼Œå³æœ€ç»ˆçš„æ··åˆé«˜æ–¯æ¨¡å‹ã€‚è¿™ä¸ªæ··åˆé«˜æ–¯æ¨¡å‹å¯ä»¥äº§ç”Ÿè¿™æ ·çš„æ ·æœ¬ã€‚\næ›´ä¸€èˆ¬åŒ–çš„æè¿°ä¸ºï¼šå‡è®¾æ··åˆé«˜æ–¯æ¨¡å‹ç”±Kä¸ªé«˜æ–¯æ¨¡å‹ç»„æˆï¼ˆå³æ•°æ®åŒ…å«Kä¸ªç±»ï¼‰ï¼Œåˆ™GMMçš„æ¦‚ç‡å¯†åº¦å‡½æ•°å¦‚ä¸‹\n\n\np(x)=\\sum_{k=1}^{K} p(k) p(x \\mid k)=\\sum_{k=1}^{K} \\pi_{k} N\\left(x \\mid u_{k}, \\Sigma_{k}\\right)\nå…¶ä¸­ï¼Œ $p(x \\mid k)=N\\left(x \\mid u_{k}, \\Sigma_{k}\\right)$ æ˜¯ç¬¬ $\\mathrm{k}$ ä¸ªé«˜æ–¯æ¨¡å‹çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œå¯ä»¥çœ‹æˆé€‰å®šç¬¬ $\\mathrm{k}$ ä¸ªæ¨¡å‹åï¼Œ è¯¥æ¨¡å‹äº§ç”Ÿxçš„æ¦‚ç‡ï¼› $p(k)=\\pi_{k}$ æ˜¯ç¬¬ $\\mathrm{k}$ ä¸ªé«˜æ–¯æ¨¡å‹çš„æƒé‡ï¼Œç§°ä½œé€‰æ‹©ç¬¬ $\\mathrm{k}$ ä¸ªæ¨¡å‹çš„å…ˆéªŒæ¦‚ç‡ï¼Œä¸”æ»¡è¶³ $\\sum_{k=1}^{K} \\pi_{k}=1$\n\næ‰€ä»¥ï¼Œæ··åˆé«˜æ–¯æ¨¡å‹å¹¶ä¸æ˜¯ä»€ä¹ˆæ–°å¥‡çš„ä¸œè¥¿ï¼Œå®ƒçš„æœ¬è´¨å°±æ˜¯èåˆå‡ ä¸ªå•é«˜æ–¯æ¨¡å‹ï¼Œæ¥ä½¿å¾—æ¨¡å‹æ›´åŠ å¤æ‚ï¼Œä»è€Œäº§ç”Ÿæ›´å¤æ‚çš„æ ·æœ¬ã€‚ç†è®ºä¸Šï¼Œå¦‚æœæŸä¸ªæ··åˆé«˜æ–¯æ¨¡å‹èåˆçš„é«˜æ–¯æ¨¡å‹ä¸ªæ•°è¶³å¤Ÿå¤šï¼Œå®ƒä»¬ä¹‹é—´çš„æƒé‡è®¾å®šå¾—è¶³å¤Ÿåˆç†ï¼Œè¿™ä¸ªæ··åˆæ¨¡å‹å¯ä»¥æ‹Ÿåˆä»»æ„åˆ†å¸ƒçš„æ ·æœ¬ã€‚\n\n\n2.2 ç›´è§‚ä¸Šç†è§£æ··åˆé«˜æ–¯æ¨¡å‹\nä¸‹é¢é€šè¿‡å‡ å¼ å›¾ç‰‡æ¥å¸®åŠ©ç†è§£æ··åˆé«˜æ–¯æ¨¡å‹ã€‚\né¦–å…ˆä»ç®€å•çš„ä¸€ç»´æ··åˆé«˜æ–¯æ¨¡å‹è¯´èµ·ã€‚\n\n\n\nåœ¨å›¾6ä¸­ï¼Œ$y_1,y_2$â€‹å’Œ$y_3$â€‹åˆ†åˆ«è¡¨ç¤ºä¸‰ä¸ªä¸€ç»´é«˜æ–¯æ¨¡å‹ï¼Œä»–ä»¬çš„å‚æ•°è®¾å®šå¦‚å›¾æ‰€ç¤ºã€‚y4è¡¨ç¤ºå°†ä¸‰ä¸ªæ¨¡å‹çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ç›´æ¥ç›¸åŠ ï¼Œæ³¨æ„çš„æ˜¯è¿™å¹¶ä¸æ˜¯ä¸€ä¸ªæ··åˆé«˜æ–¯æ¨¡å‹ï¼Œå› ä¸ºä¸æ»¡è¶³$\\sum^K_{k=1}\\pi_k = 1$â€‹â€‹çš„æ¡ä»¶ã€‚è€Œ$y_5$â€‹å’Œ$y_6$â€‹åˆ†åˆ«æ˜¯ç”±ä¸‰ä¸ªç›¸åŒçš„é«˜æ–¯æ¨¡å‹èåˆç”Ÿæˆçš„ä¸åŒæ··åˆæ¨¡å‹ã€‚ç”±æ­¤å¯è§ï¼Œè°ƒæ•´æƒé‡å°†æå¤§å½±å“æ··åˆæ¨¡å‹çš„æ¦‚ç‡å¯†åº¦å‡½æ•°æ›²çº¿ã€‚å¦ä¸€æ–¹é¢ä¹Ÿå¯ä»¥ç›´è§‚åœ°ç†è§£æ··åˆé«˜æ–¯æ¨¡å‹å¯ä»¥æ›´å¥½åœ°æ‹Ÿåˆæ ·æœ¬çš„åŸå› ï¼šå®ƒæœ‰æ›´å¤æ‚æ›´å¤šå˜çš„æ¦‚ç‡å¯†åº¦å‡½æ•°æ›²çº¿ã€‚ç†è®ºä¸Šï¼Œæ··åˆé«˜æ–¯æ¨¡å‹çš„æ¦‚ç‡å¯†åº¦å‡½æ•°æ›²çº¿å¯ä»¥æ˜¯ä»»æ„å½¢çŠ¶çš„éçº¿æ€§å‡½æ•°ã€‚\n\n\nä¸‹é¢å†ç»™å‡ºä¸€ä¸ªäºŒç»´ç©ºé—´3ä¸ªé«˜æ–¯æ¨¡å‹æ··åˆçš„ä¾‹å­ã€‚\n\n\n\n\n\n(a) å›¾è¡¨ç¤ºçš„æ˜¯3ä¸ªé«˜æ–¯æ¨¡å‹çš„æˆªé¢è½®å»“å›¾ï¼Œ3ä¸ªæ¨¡å‹çš„æƒé‡ç³»æ•°å·²åœ¨å›¾ä¸­æ³¨æ˜ï¼Œç”±æˆªé¢è½®å»“å›¾å¯çŸ¥3ä¸ªæ¨¡å‹ä¹‹é—´å­˜åœ¨å¾ˆå¤šé‡å åŒºåŸŸã€‚å…¶å®è¿™ä¹Ÿæ­£æ˜¯æ··åˆé«˜æ–¯æ¨¡å‹æ‰€å¸Œæœ›çš„ã€‚å› ä¸ºå¦‚æœå®ƒä»¬ä¹‹é—´çš„é‡å åŒºåŸŸè¾ƒå°‘ï¼Œé‚£ä¹ˆç”Ÿæˆçš„æ··åˆé«˜æ–¯æ¨¡å‹ä¸€èˆ¬è¾ƒä¸ºç®€å•ï¼Œéš¾ä»¥ç”Ÿæˆè¾ƒä¸ºå¤æ‚çš„æ ·æœ¬ã€‚\nè®¾å®šå¥½äº†3ä¸ªé«˜æ–¯æ¨¡å‹å’Œå®ƒä»¬ä¹‹é—´çš„æƒé‡ç³»æ•°ä¹‹åï¼Œå°±å¯ä»¥ç¡®å®šäºŒç»´æ··åˆé«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°æ›²é¢ï¼Œå¦‚å›¾Â©æ‰€ç¤ºã€‚å›¾(b)æ˜¯å¯¹äºå›¾Â©æ¦‚ç‡å¯†åº¦æ›²é¢çš„æˆªé¢è½®å»“çº¿ã€‚ä»å›¾7ä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œæ•´ä¸ªæ··åˆé«˜æ–¯åˆ†å¸ƒæ›²é¢ç›¸å¯¹æ¯”äºå•é«˜æ–¯åˆ†å¸ƒæ›²é¢å·²ç»å¼‚å¸¸å¤æ‚ã€‚å®é™…ä¸Šï¼Œé€šè¿‡è°ƒæ•´æ··åˆé«˜æ–¯åˆ†å¸ƒçš„ç³»æ•°$(\\pi ,\\mu ,\\Sigma )$ï¼Œå¯ä»¥ä½¿å¾—å›¾Â©çš„æ¦‚ç‡å¯†åº¦æ›²é¢å»æ‹Ÿåˆä»»æ„çš„ä¸‰ç»´æ›²é¢ï¼Œä»è€Œé‡‡æ ·ç”Ÿæˆæ‰€éœ€è¦çš„æ•°æ®æ ·æœ¬ã€‚\n\n3 æå¤§ä¼¼ç„¶ä¼°è®¡(Maximum Likehood Estimate, MLE)ï¼ˆæœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼‰\næœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼ˆlog-likelihood functionï¼‰çš„æ„ä¹‰ã€‚é¦–å…ˆç›´è§‚åŒ–åœ°è§£é‡Šä¸€ä¸‹æœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶å‡½æ•°è¦è§£å†³çš„æ˜¯ä»€ä¹ˆé—®é¢˜ã€‚å‡è®¾æˆ‘ä»¬é‡‡æ ·å¾—åˆ°ä¸€ç»„æ ·æœ¬$y_t$â€‹â€‹ ,è€Œä¸”æˆ‘ä»¬çŸ¥é“å˜é‡Yæœä»é«˜æ–¯åˆ†å¸ƒï¼ˆæœ¬æ–‡åªæåŠé«˜æ–¯åˆ†å¸ƒï¼Œå…¶ä»–å˜é‡åˆ†å¸ƒæ¨¡å‹ç±»ä¼¼ï¼‰ï¼Œæ•°å­¦å½¢å¼è¡¨ç¤ºä¸º$Y \\sim N(\\mu ,\\Sigma )$â€‹é‡‡æ ·çš„æ ·æœ¬å¦‚å›¾8æ‰€ç¤ºï¼Œæˆ‘ä»¬çš„ç›®çš„å°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„é«˜æ–¯åˆ†å¸ƒï¼ˆä¹Ÿå°±æ˜¯ç¡®å®šé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°$(\\mu ,\\Sigma)$,ä½¿å¾—è¿™ä¸ªé«˜æ–¯åˆ†å¸ƒèƒ½äº§ç”Ÿè¿™ç»„æ ·æœ¬çš„å¯èƒ½æ€§å°½å¯èƒ½å¤§ã€‚\n\n\n\né‚£æ€ä¹ˆæ‰¾åˆ°è¿™ä¸ªåˆé€‚çš„é«˜æ–¯åˆ†å¸ƒå‘¢ï¼ˆåœ¨å›¾8ä¸­çš„è¡¨ç¤ºå°±æ˜¯1~4å“ªä¸ªåˆ†å¸ƒè¾ƒä¸ºåˆé€‚ï¼‰ï¼Ÿè¿™æ—¶å€™ä¼¼ç„¶å‡½æ•°å°±é—ªäº®ç™»åœºäº†ã€‚\n\nä¼¼ç„¶å‡½æ•°æ•°å­¦åŒ–ï¼šè®¾æœ‰æ ·æœ¬é›† $Y=y_{1}, y_{2} \\ldots y_{N}$$ p\\left(y_{n} \\mid \\mu, \\Sigma\\right)$ æ˜¯é«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡åˆ†å¸ƒå‡½æ•°ï¼Œè¡¨ç¤º å˜é‡ $Y=y_{n}$ çš„æ¦‚ç‡ã€‚å‡è®¾æ ·æœ¬çš„æŠ½æ ·æ˜¯ç‹¬ç«‹çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬åŒæ—¶æŠ½åˆ°è¿™ $\\mathrm{N}$ ä¸ªæ ·æœ¬çš„æ¦‚ç‡æ˜¯æŠ½åˆ°æ¯ä¸ªæ · æœ¬æ¦‚ç‡çš„ä¹˜ç§¯ï¼Œä¹Ÿå°±æ˜¯æ ·æœ¬é›†Yçš„è”åˆæ¦‚ç‡ã€‚æ­¤è”åˆæ¦‚ç‡å³ä¸ºä¼¼ç„¶å‡½æ•°ï¼š\n\nL(\\mu, \\Sigma)=L\\left(y_{1}, y_{2} \\ldots y_{N} ; \\mu, \\Sigma\\right)=\\prod_{n=1}^{N} p\\left(y_{n} ; \\mu, \\Sigma\\right)\nå¯¹å¼å­(4)è¿›è¡Œæ±‚å¯¼å¹¶ä»¤å¯¼æ•°ä¸º0ï¼ˆå³æœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°ï¼Œä¸€èˆ¬è¿˜ä¼šå…ˆè½¬åŒ–ä¸ºå¯¹æ•°ä¼¼ç„¶å‡½æ•°å†æœ€å¤§åŒ–ï¼‰ï¼Œæ‰€æ±‚å‡ºçš„å‚æ•°å°±æ˜¯æœ€ä½³çš„é«˜æ–¯åˆ†å¸ƒå¯¹åº”çš„å‚æ•°ã€‚\n\næ‰€ä»¥æœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°çš„æ„ä¹‰å°±æ˜¯ï¼šé€šè¿‡ä½¿å¾—æ ·æœ¬é›†çš„è”åˆæ¦‚ç‡æœ€å¤§æ¥å¯¹å‚æ•°è¿›è¡Œä¼°è®¡ï¼Œä»è€Œé€‰æ‹©æœ€ä½³çš„åˆ†å¸ƒæ¨¡å‹ã€‚\nå¯¹äºå›¾8äº§ç”Ÿçš„æ ·æœ¬ç”¨æœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°çš„æ–¹æ³•ï¼Œæœ€ç»ˆå¯ä»¥å¾—åˆ°åºå·1å¯¹åº”çš„é«˜æ–¯åˆ†å¸ƒæ¨¡å‹æ˜¯æœ€ä½³çš„æ¨¡å‹\n\n4. EMç®—æ³•ï¼ˆæœ€å¤§åŒ–Qå‡½æ•°ï¼‰4.1 ä¸ºä»€ä¹ˆè¦æœ‰EMç®—æ³•ï¼ˆEMç®—æ³•ä¸æå¤§ä¼¼ç„¶ä¼°è®¡åˆ†åˆ«é€‚ç”¨äºä»€ä¹ˆé—®é¢˜ï¼‰\nå°è¯•ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡çš„æ–¹æ³•æ¥è§£GMMæ¨¡å‹\nè§£GMMæ¨¡å‹ï¼Œå®é™…ä¸Šå°±æ˜¯ç¡®å®šGMMæ¨¡å‹çš„å‚æ•° $(\\mu ,\\Sigma ,\\pi )$ï¼Œä½¿å¾—ç”±è¿™ç»„å‚æ•°ç¡®å®šçš„GMMæ¨¡å‹æœ€æœ‰å¯èƒ½äº§ç”Ÿé‡‡æ ·çš„æ ·æœ¬ã€‚\nå…ˆè¯•è¯•çœ‹ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡çš„æ–¹æ³•æ¥è§£GMMæ¨¡å‹ä¼šå‡ºç°ä»€ä¹ˆæ ·çš„é—®é¢˜ã€‚\nå¦‚ç¬¬3å°èŠ‚æ‰€è¿°ï¼Œè¦åˆ©ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ±‚è§£æ¨¡å‹æœ€é‡è¦çš„ä¸€æ­¥å°±æ˜¯æ±‚å‡ºä¼¼ç„¶å‡½æ•°ï¼Œå³æ ·æœ¬é›†å‡ºç°çš„è”åˆæ¦‚ç‡ã€‚è€Œå¯¹äºæ··åˆé«˜æ–¯æ¨¡å‹ï¼Œå¦‚ä½•æ±‚è§£æŸä¸ªæ ·æœ¬$y_t$çš„æ¦‚ç‡ï¼Ÿæ˜¾ç„¶æˆ‘ä»¬å¾—å…ˆçŸ¥é“è¿™ä¸ªæ ·æœ¬æ¥æºäºå“ªä¸€ç±»é«˜æ–¯æ¨¡å‹ï¼Œç„¶åæ±‚è¿™ä¸ªé«˜æ–¯æ¨¡å‹ç”Ÿæˆè¿™ä¸ªæ ·æœ¬çš„æ¦‚ç‡$p(y_t)$â€‹\nä½†æ˜¯é—®é¢˜æ¥äº†ï¼šæˆ‘ä»¬åªæœ‰æ ·æœ¬ã€‚ä¸çŸ¥é“æ ·æœ¬åˆ°åº•æ¥æºäºå“ªä¸€ç±»çš„é«˜æ–¯æ¨¡å‹ã€‚é‚£ä¹ˆå¦‚ä½•æ±‚è§£æ ·æœ¬çš„ç”Ÿæˆæ¦‚ç‡$p(y_t)$?\nå…ˆå¼•å…¥ä¸€ä¸ªéšå˜é‡$\\gamma$â€‹â€‹ã€‚å®ƒæ˜¯ä¸€ä¸ªKç»´äºŒå€¼éšæœºå˜é‡ï¼Œåœ¨å®ƒçš„Kç»´å–å€¼ä¸­åªæœ‰æŸä¸ªç‰¹å®šçš„å…ƒç´ $\\gamma _k$çš„å–å€¼ä¸º1ï¼Œå…¶å®ƒå…ƒç´ çš„å–å€¼ä¸º0ã€‚å®é™…ä¸Šï¼Œéšå˜é‡æè¿°çš„å°±æ˜¯ï¼šæ¯ä¸€æ¬¡é‡‡æ ·ï¼Œé€‰æ‹©ç¬¬kä¸ªé«˜æ–¯æ¨¡å‹çš„æ¦‚ç‡ï¼Œæ•…æœ‰ï¼š\n\n\np\\left(\\gamma_{k}=1\\right)=\\pi_{k}\nå½“ç»™å®šäº†$\\gamma$çš„ä¸€ä¸ªç‰¹å®šçš„å€¼ä¹‹åï¼ˆä¹Ÿå°±æ˜¯çŸ¥é“äº†è¿™ä¸ªæ ·æœ¬ä»å“ªä¸€ä¸ªé«˜æ–¯æ¨¡å‹è¿›è¡Œé‡‡æ ·ï¼‰ï¼Œå¯ä»¥å¾—åˆ°æ ·æœ¬yçš„æ¡ä»¶åˆ†å¸ƒæ˜¯ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼Œæ»¡è¶³ï¼š\n\n\np\\left(y \\mid \\gamma_{k}=1\\right)=N\\left(y \\mid \\mu_{k}, \\Sigma_{k}\\right)\nè€Œå®é™…ä¸Šï¼Œæ¯ä¸ªæ ·æœ¬åˆ°åº•æ˜¯ä»è¿™Kä¸ªé«˜æ–¯æ¨¡å‹ä¸­å“ªä¸ªæ¨¡å‹è¿›è¡Œé‡‡æ ·çš„ï¼Œæ˜¯éƒ½æœ‰å¯èƒ½çš„ã€‚æ•…æ ·æœ¬yçš„æ¦‚ç‡ä¸º\n\n\np(y)=\\sum_{\\gamma} p(\\gamma) p(y \\mid \\gamma)=\\sum_{\\mathrm{k}=1}^{K} \\pi_{k} N\\left(y \\mid \\mu_{k}, \\Sigma_{k}\\right)\næ ·æœ¬é›†Y(nä¸ªæ ·æœ¬ç‚¹)çš„è”åˆæ¦‚ç‡ä¸ºï¼š\n\n\n\\begin{array}{l}\nL(\\mu, \\Sigma, \\pi)\\\\\n=L\\left(y_{1}, y_{2} \\ldots y_{N} ; \\mu, \\Sigma, \\pi\\right)\\\\\n=\\prod_{n=1}^{N} p\\left(y_{n} ; \\mu, \\Sigma, \\pi\\right)\\\\\n=\\prod_{n=1}^{N} \\sum_{\\mathrm{k}=1}^{K} \\pi_{k} N\\left(y_{n} \\mid\\mu_{k}, \\Sigma_{k}\\right)\n\\end{array}\nå¯¹æ•°ä¼¼ç„¶å‡½æ•°è¡¨ç¤ºä¸ºï¼š\n\n\n\\ln L(\\mu, \\Sigma, \\pi)=\\sum_{n=1}^{N} \\ln \\sum_{\\mathrm{k}=1}^{K} \\pi_{k} N\\left(y_{n} \\mid \\mu_{k}, \\Sigma_{k}\\right)\nå¥½äº†ï¼Œç„¶åæ±‚å¯¼ï¼Œä»¤å¯¼æ•°ä¸º0ï¼Œå¾—åˆ°æ¨¡å‹å‚æ•°$(\\mu ,\\Sigma ,\\pi)$ã€‚è²Œä¼¼é—®é¢˜å·²ç»è§£å†³äº†ï¼Œå–œå¤§æ™®å¥”ã€‚\nç„¶è€Œä»”ç»†è§‚å¯Ÿå¯ä»¥å‘ç°ï¼Œå¯¹æ•°ä¼¼ç„¶å‡½æ•°é‡Œé¢ï¼Œå¯¹æ•°é‡Œé¢è¿˜æœ‰æ±‚å’Œã€‚å®é™…ä¸Šæ²¡æœ‰åŠæ³•é€šè¿‡æ±‚å¯¼çš„æ–¹æ³•æ¥æ±‚è¿™ä¸ªå¯¹æ•°ä¼¼ç„¶å‡½æ•°çš„æœ€å¤§å€¼ã€‚\nMLEï¼ˆæå¤§ä¼¼ç„¶ä¼°è®¡ï¼‰ç•¥æ˜¾æ²®ä¸§ã€‚è¿™æ—¶å€™EMç®—æ³•èµ°è¿‡æ¥ï¼Œå®‰æ…°ç€è¯´ï¼šå…„å¼Ÿåˆ«å“­ï¼Œè€å“¥å¸®ä½ ã€‚\n\n5. æå¤§ä¼¼ç„¶ä¼°è®¡ä¸EMç®—æ³•é€‚ç”¨é—®é¢˜åˆ†æ\nä¸‹é¢å…ˆé˜è¿°ä¸€ä¸‹æå¤§ä¼¼ç„¶ä¼°è®¡ä¸EMç®—æ³•åˆ†åˆ«é€‚ç”¨äºè§£å†³ä»€ä¹ˆæ ·çš„é—®é¢˜ã€‚\n\n\n\n\nå¦‚æœæˆ‘ä»¬å·²ç»æ¸…æ¥šäº†æŸä¸ªå˜é‡æœä»çš„é«˜æ–¯åˆ†å¸ƒï¼Œè€Œä¸”é€šè¿‡é‡‡æ ·å¾—åˆ°äº†è¿™ä¸ªå˜é‡çš„æ ·æœ¬æ•°æ®ï¼Œæƒ³æ±‚é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œè¿™æ—¶å€™æå¤§ä¼¼ç„¶ä¼°è®¡å¯ä»¥èƒœä»»è¿™ä¸ªä»»åŠ¡ï¼›è€Œå¦‚æœæˆ‘ä»¬è¦æ±‚è§£çš„æ˜¯ä¸€ä¸ªæ··åˆæ¨¡å‹ï¼ŒåªçŸ¥é“æ··åˆæ¨¡å‹ä¸­å„ä¸ªç±»çš„åˆ†å¸ƒæ¨¡å‹ï¼ˆè­¬å¦‚éƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒï¼‰å’Œå¯¹åº”çš„é‡‡æ ·æ•°æ®ï¼Œè€Œä¸çŸ¥é“è¿™äº›é‡‡æ ·æ•°æ®åˆ†åˆ«æ¥æºäºå“ªä¸€ç±»ï¼ˆéšå˜é‡ï¼‰ï¼Œé‚£è¿™æ—¶å€™å°±å¯ä»¥å€Ÿé‰´EMç®—æ³•ã€‚EMç®—æ³•å¯ä»¥ç”¨äºè§£å†³æ•°æ®ç¼ºå¤±çš„å‚æ•°ä¼°è®¡é—®é¢˜ï¼ˆéšå˜é‡çš„å­˜åœ¨å®é™…ä¸Šå°±æ˜¯æ•°æ®ç¼ºå¤±é—®é¢˜ï¼Œç¼ºå¤±äº†å„ä¸ªæ ·æœ¬æ¥æºäºå“ªä¸€ç±»çš„è®°å½•ï¼‰ã€‚\nä¸‹é¢å°†ä»‹ç»EMç®—æ³•çš„ä¸¤ä¸ªæ­¥éª¤ï¼šE-step(expectation-stepï¼ŒæœŸæœ›æ­¥)å’ŒM-step (Maximization-step,æœ€å¤§åŒ–æ­¥);\n\n4.2 E-step\næˆ‘ä»¬ç°æœ‰æ ·æœ¬é›†$Y=(y_1,y_2,â€¦y_T)$ï¼Œé€šè¿‡éšå˜é‡$\\gamma_{t,k}$ï¼ˆè¡¨ç¤º$y_t$è¿™ä¸ªæ ·æœ¬æ¥æºäºç¬¬kä¸ªæ¨¡å‹ï¼‰çš„å¼•å…¥ï¼Œå¯ä»¥å°†æ•°æ®å±•å¼€æˆå®Œå…¨æ•°æ®ï¼š\n\n\n\\left(y_{t}, \\gamma_{t, 1}, \\gamma_{t, 2} \\ldots \\gamma_{t, K}\\right), t=1,2 \\ldots T\næ‰€è°“çš„å®Œå…¨æ•°æ®ï¼Œå°±æ˜¯ä¸ç¼ºå¤±çš„æ•°æ®ã€‚åªæœ‰æ ·æœ¬é›† $Y=\\left(y_{1}, y_{2} \\ldots y_{T}\\right)$ çš„æ•°æ®æ˜¯ä¸å®Œæ•´çš„ï¼Œå­˜åœ¨ä¿¡æ¯ ç¼ºå¤±çš„ã€‚è‹¥ $y_{t}$ ç”±ç¬¬1ç±»é‡‡æ ·è€Œæ¥ï¼Œåˆ™æœ‰ $\\gamma_{t, 1}=1, \\gamma_{t, 2}=0 \\ldots \\gamma_{t, K}=0$ ï¼Œè¡¨ç¤ºä¸º $\\left(y_{t}, 1,0, \\ldots 0\\right)$ ã€‚\næ‰€ä»¥è¦æ±‚èƒ½é‡‡åˆ°è¿™ç»„æ•°æ®çš„å¯èƒ½æ€§ï¼Œéœ€è¦åˆ†ä¸¤æ­¥èµ°ï¼š(1)ç¬¬ $\\mathrm{t}$ ä¸ªæ ·æœ¬ç”±å“ªä¸€ç±»äº§ç”Ÿ? (2)å¦‚æœç¬¬ $\\mathrm{t}$ ä¸ªæ · æœ¬ç”±ç¬¬kç±»äº§ç”Ÿï¼Œé‚£ä¹ˆç¬¬kç±»äº§ç”Ÿç¬¬tä¸ªæ ·æœ¬çš„æ¦‚ç‡ä¸ºå¤šå°‘?\nç»¼åˆè€ƒè™‘ä¸Šé¢ä¸¤æ­¥ï¼Œæœ‰äº†å®Œå…¨æ•°æ®çš„ä¼¼ç„¶å‡½æ•°ï¼š\n\n\n\\begin{aligned}\np(y, y \\mid \\mu, \\Sigma, \\pi)=& \\prod_{t=1}^{T} p\\left(y_{t}, \\gamma_{t, 1}, \\gamma_{t, 2} \\ldots \\gamma_{t, K} \\mid \\mu, \\Sigma, \\pi\\right) \\\\\n&=\\prod_{t=1}^{T} \\prod_{k=1}^{K}\\left(\\pi_{k} N\\left(y_{t} ; \\mu_{k}, \\Sigma_{k}\\right)\\right)^{\\gamma_{t, k}} \\\\\n&=\\prod_{k=1}^{K} \\pi_{k}^{\\sum_{t=1}^{T} \\gamma_{t, k}} \\prod_{t=1}^{T}\\left(N\\left(y_{t} ; \\mu_{k}, \\Sigma_{k}\\right)\\right)^{\\gamma_{t, k}}\n\\end{aligned}\nç¬¬ 1 ä¸ªç­‰å·åˆ°ç¬¬ 2 ä¸ªç­‰å·çš„ç†è§£ï¼šè‹¥ $y_{t}$ ç”±ç¬¬ 1 ç±»é‡‡æ ·è€Œæ¥ï¼Œåˆ™æœ‰ $\\gamma_{t, 1}=1, \\gamma_{t, 2}=0 \\ldots \\gamma_{t, K}=0$,\n\n\n\\begin{array}{l}\np(y_t,\\gamma_{t,1},\\gamma_{t,2}...,\\gamma_{t,K}\\mid \\mu,\\Sigma,\\pi)\\\\\n=\\prod_{i=1}^{K} \\left(\\pi_{k} N\\left(y_{t} ; \\mu_{k}, \\Sigma_{k}\\right)\\right)^{\\gamma_{t, k}} \\\\\n=\\left(\\pi_{1} N\\left(y_{t} ; \\mu_{1}, \\Sigma_{1}\\right)\\right)^{\\gamma_{t, 1}}\\left(\\pi_{2} N\\left(y_{t} ; \\mu_{2}, \\Sigma_{2}\\right)\\right)^{\\gamma_{t, 2}} \\left(\\pi_{K}\\left(\\left(y_{t} ; \\mu_{K}, \\Sigma_{K}\\right)\\right)^{\\gamma_{t, K}}\\right. \\\\\n=\\left(\\pi_{1} N\\left(y_{t} ; \\mu_{1}, \\Sigma_{1}\\right)\\right)^{1}\\left(\\pi_{2} N\\left(y_{t} ; \\mu_{2}, \\Sigma_{2}\\right)\\right)^{0} \\ldots\\left(\\pi_{K} N\\left(y_{t} ; \\mu_{K}, \\Sigma_{K}\\right)\\right)^{0} \\\\\n=\\pi_{1} N\\left(y_{t} ; \\mu_{1}, \\Sigma_{1}\\right)\n\\end{array}\n\\begin{array}{l}\n\\ln p(y, \\gamma \\mid \\mu, \\Sigma, \\pi)\\\\\n=\\sum_{k=1}^{K}\\left(\\sum_{t=1}^{T} \\gamma_{t, k}\\right) \\ln \\pi_{k}\\\\\n+\\sum_{t=1}^{T} \\gamma_{t, k}\\left(-\\ln (2 \\pi)-\\frac{1}{2} \\ln \\left|\\Sigma_{k}\\right|\\right.\\\\\n\\left.-\\frac{1}{2}\\left(y_t-\\mu_{t}\\right)^{T}\\left(\\Sigma_{k}\\right)^{-1}\\left(y_{t}-\\mu_{t}\\right)\\right)\n\\end{array}\nè¿™ä¸€æ­¥åº”è¯¥æ²¡å•¥é—®é¢˜å§ã€‚ã€‚ã€‚æ³¨æ„çš„æ˜¯ï¼Œæ­¤å¤„è€ƒè™‘çš„æ˜¯äºŒç»´é«˜æ–¯åˆ†å¸ƒçš„æƒ…å†µï¼Œå¯¹åº”äºå¼å­(2)ä¸­çš„d=2ã€‚\n\næˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æ‰¾å‡ºä¸€ç»„å‚æ•° $(\\mu , \\Sigma , \\pi *)$ ä½¿å¾— $\\ln p(y, \\gamma \\mid \\mu, \\Sigma, \\pi)$ æœ€å¤§ã€‚é‚£ä¹ˆé—®é¢˜æ¥äº†: $\\ln p(y, \\gamma \\mid \\mu, \\Sigma, \\pi)$ ä¸­å«æœ‰éšå˜é‡ $Y$ ï¼Œ $Y$ çš„å­˜åœ¨ä½¿å¾—æˆ‘ä»¬æ²¡æ³•æœ€å¤§åŒ– $\\ln p(y, \\gamma \\mid \\mu, \\Sigma, \\pi)$ ã€‚å¦‚æœæˆ‘ä»¬çŸ¥é“äº† $Y$, é‚£ä¹ˆæœ€å¤§åŒ– $\\ln p(y, \\gamma \\mid \\mu, \\Sigma, \\pi)$ å°±æ˜¾å¾—æ°´åˆ°æ¸  æˆã€‚\n\nä½†æ˜¯å‘å¿©çš„å°±æ˜¯: æˆ‘ä»¬åªæœ‰é‡‡æ ·æ•°æ® $y_{t}, \\quad$ æœ«çŸ¥ã€‚é‚£ä¹ˆæ€ä¹ˆåŠå‘¢? å¯¹ $/$ æ¥ä¸€ä¸ªä¼°è®¡ã€‚\nçŒœæƒ³æˆ‘ä»¬ç»™äº†ä¸€ç»„èµ·å§‹å‚æ•° $\\left(\\mu^{0}, \\Sigma^{0}, \\pi^{0}\\right)$ æˆ–è€…ä¼˜åŒ–è¿‡çš„ç¬¬æ¬¡è¿­ä»£çš„å‚æ•° $\\left(\\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)$ï¼Œ ä¹Ÿå°±æ˜¯è¯´æ¯ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°æˆ‘ä»¬éƒ½æœ‰äº†ï¼Œ $Y$ åšçš„äº‹ä¸å°±æ˜¯å†³å®šæ¯ä¸ªæ ·æœ¬ç”±å“ªä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒäº§ç”Ÿçš„å˜›ï¼Œæœ‰äº†æ¯ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°é‚£æˆ‘ä»¬å°±å¯ä»¥çŒœæƒ³æ¯ä¸ªæ ·æœ¬æœ€æœ‰å¯èƒ½æ¥æºäºå“ªä¸ªé«˜æ–¯åˆ†å¸ƒæ²¡é”™å§! Done!\nä¸ºæ­¤æˆ‘ä»¬ä¸æœ€å¤§åŒ–\\operatornamen $p(y, y \\mid \\mu, \\Sigma, \\pi)$ (ä¹Ÿæ— æ³•æœ€å¤§åŒ–å®ƒ)ï¼Œè€Œæ˜¯æœ€å¤§åŒ–Qå‡½æ•°ã€‚Qå‡½ æ•°å¦‚ä¸‹:\n\n\n\\begin{aligned}\n&Q\\left(\\mu, \\Sigma, \\pi, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)=E_{\\gamma}\\left[\\ln p(y, \\gamma \\mid \\mu, \\Sigma, \\pi) \\mid Y, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right] \\\\\n&=E_{\\gamma}\\left[\\sum_{k=1}^{K}\\left(\\sum_{t=1}^{T} \\gamma_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right) \\ln \\pi_{k}\\right.\\\\\n&+\\left.\\sum_{t=1}^{T}\\left(y_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)(-\\ln (2 \\pi)-\\right.\\left.\\left.\\frac{1}{2} \\ln \\left|\\Sigma_{k}\\right|-\\frac{1}{2}\\left(y_{t}-\\mu_{t}\\right)^{T}\\left(\\Sigma_{k}\\right)^{-1}\\left(y_{t}-\\mu_{t}\\right)\\right)\\right] \\\\\n&=\\sum_{k=1}^{K}\\left(\\sum_{t=1}^{T} E\\left(\\gamma_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right) \\ln \\pi_{k}\\right.\\\\\n&+\\left.\\sum_{t=1}^{T} E\\left(y_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)(-\\ln (2 \\pi)-\\right.\\left.\\left.\\frac{1}{2} \\ln \\left|\\Sigma_{k}\\right|-\\frac{1}{2}\\left(y_{t}-\\mu_{t}\\right)^{T}\\left(\\Sigma_{k}\\right)^{-1}\\left(y_{t}-\\mu_{t}\\right)\\right)\\right)\n\\end{aligned}\nå…¶ä¸­, $ E\\left(\\gamma_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right) $â€‹å°±æ˜¯å¯¹ $\\gamma$çš„ä¼°è®¡: \n\n\n\\begin{aligned}\n&E\\left(\\gamma_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)=p\\left(\\gamma_{t, k}=1 \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)\\\\\n&=\\frac{p\\left(\\gamma_{t, k}=1, y_{t} \\mid \\mu^{i}, \\Sigma^{i}, \\pi^{\\prime}\\right)}{p\\left(y_{t}\\right)}\\\\\n&=\\frac{p\\left(y_{t} \\mid y_{t, k}=1, \\mu^{2}, \\Sigma^{2}, \\pi^{2}\\right) p\\left(\\gamma_{t, k}=1 \\mid \\mu^{2}, \\Sigma^{2}, \\pi^{i}\\right)}{\\sum_{k=1}^{K} p\\left(y_{t} \\mid \\gamma_{t, k}=1, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right) p\\left(\\gamma_{t, k}=1 \\mid \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)}\\\\\n&=\\frac{\\pi_{k}^{i} N\\left(y_{t} ; \\mu_{k}^{i}, \\Sigma_{k}^{i}\\right)}{\\sum_{k=1}^{K} \\pi_{k}^{i} N\\left(y_{t} ; \\mu_{k}^{i}, \\Sigma_{k}^{i}\\right)}\n\\end{aligned}\nè¿™å…¬å¼æ˜¯ä¸æ˜¯å¾ˆå¯æ€•? ? åˆ«æ€¥ï¼Œå¸¦ä¸Šå‡ ç‚¹å£°æ˜ï¼Œå†å»çœ‹å…¬å¼å°±å¾ˆå¥½ç†è§£äº†!\nQå‡½æ•°æè¿°çš„å…¶å®å°±æ˜¯åœ¨ç»™å®š $\\left(\\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)$ å‚æ•°ä¸‹ï¼Œå…ˆå¯¹æ ·æœ¬ $Y$ åšä¸€ä¸ªæœ€æœ‰å¯èƒ½çš„åˆ’ åˆ† (æ¯ä¸ªæ ·æœ¬æ¥æºäºå„ä¸ªç±»çš„å¯èƒ½æ€§ï¼Œå³å¯¹ $\\gamma$ çš„ä¼°è®¡ $E\\left(\\gamma_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)$ )ï¼Œå†æè¿°èƒ½ å¤Ÿäº§ç”Ÿè¿™ç»„æ ·æœ¬çš„å¯èƒ½æ€§ (Qå‡½æ•°) ;\næœ‰äº†å¯¹äº $\\gamma$ çš„ä¼°è®¡ä¹‹åï¼Œ Qå‡½æ•°åªå’Œæ ·æœ¬æœ‰å…³ (ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„ä¼¼ç„¶å‡½æ•°äº¦å¦‚æ­¤ï¼Œå®Œ å…¨æ•°æ®çš„ä¼¼ç„¶å‡½æ•°è¿˜ä¸ ${ }^{\\mathbf{1}}$ æœ‰å…³)ï¼Œè€Œä¸å†å«æœ‰éšå˜é‡ï¼Œä»è€Œä½¿å¾—æœ€å¤§åŒ–Qå‡½æ•°æˆä¸ºå¯èƒ½;\næœ€å¤§åŒ–Qå‡½æ•°çš„è¿‡ç¨‹å®åˆ™å°±æ˜¯ä½¿å¾—èƒ½å¤Ÿäº§ç”Ÿè¿™ç»„æ ·æœ¬çš„å¯èƒ½æ€§æœ€å¤§ï¼Œä¸æœ€å¤§åŒ–ä¼¼ç„¶ å‡½æ•°çš„æ€è·¯å¦‚å‡ºä¸€è¾™ã€‚\n\n\n\n4.3 M-step\næœ‰ä¸ªQå‡½æ•°ï¼Œå°±å¯ä»¥å¯¹Qå‡½æ•°è¿›è¡Œæœ€å¤§åŒ–ï¼Œå¾—åˆ°ä¸‹ä¸€æ¬¡è¿­ä»£çš„æ¨¡å‹å‚æ•°äº†ï¼Œå³ï¼š\n\n\n\\dot{\\mu}^{+1}, \\Sigma^{i+1}, \\pi^{i+1}=\\arg \\max Q\\left(\\mu, \\Sigma, \\pi, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)å¯¹Qå‡½æ•°è¿›è¡Œæ±‚å¯¼, å¹¶å¦å…¶å¯¼æ•°ä¸º 0, å¯å¾—;\n\n\\mu_{k}^{i+1}=\\frac{\\sum_{t=1}^{T} \\frac{\\pi_{k}^{i} N\\left(y_{t} ; \\mu_{k}^{i}, \\Sigma_{k}^{i}\\right)}{\\sum_{k=1}^{K} \\pi_{k}^{i} N\\left(y_{t} ; \\mu_{k}^{k}, \\Sigma_{k}^{i}\\right)} y_{t}}{E\\left(\\gamma_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)}, k=1,2 \\ldots K\n\\Sigma_{k}^{i+1}=\\frac{\\sum_{t=1}^{T} \\frac{\\pi_{k}^{i} N\\left(y_{t} ; \\mu_{k}^{i}, \\Sigma_{k}^{i}\\right)}{\\sum_{k=1}^{i} N\\left(y_{t}, \\mu_{k}^{i}, \\Sigma_{k}^{i}\\right)}\\left(y_{t}-\\mu_{k}^{i}\\right)^{2}}{E\\left(\\gamma_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)}, k=1,2 \\ldots K\n\\pi_{k}^{i+1}=\\frac{E\\left(y_{t, k} \\mid y_{t}, \\mu^{i}, \\Sigma^{i}, \\pi^{i}\\right)}{T}, k=1,2 \\ldots K\nå…¶ä¸­ $\\mu_{k}^{i+1}, \\Sigma_{k}^{i+1}, \\pi_{k}^{i+1}$ åˆ†åˆ«è¡¨ç¤ºç¬¬ $(\\mathrm{i}+1)$ æ¬¡è¿­ä»£ï¼Œç¬¬ $\\mathrm{k}$ ä¸ªç±»çš„å‡å€¼ï¼Œåæ–¹å·®çŸ©é˜µå’Œæ‰€å çš„æƒé‡ã€‚  \n\n4.4 ä¸€ä¸ªä¾‹å­æ¢³ç†EMç®—æ³•çš„æ•´ä¸ªè¿‡ç¨‹\nEMç®—æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯: é€šè¿‡è¿­ä»£çš„è¿‡ç¨‹æ¥æ‰¾åˆ°ä¸€ç»„æœ€ä¼˜çš„å‚æ•° $(\\mu , \\Sigma , \\pi *)$, ä½¿å¾—è¿™ç»„å‚æ•°è¡¨ ç¤ºçš„æ¨¡å‹æœ€æœ‰å¯èƒ½äº§ç”Ÿç°æœ‰çš„é‡‡æ ·æ•°æ®ã€‚æ¯æ¬¡è¿­ä»£çš„è¿‡ç¨‹å°±æ˜¯å‚æ•°çŸ«æ­£çš„è¿‡ç¨‹ã€‚\n\n\n\nç°å‡è®¾åˆå§‹åŒ–ä¸€ç»„å‚æ•°åœ¨è¿™ç»„å‚æ•°$(\\mu^0,\\Sigma^0,\\pi^0)$ä¸‹ï¼Œ2ç±»äºŒç»´é«˜æ–¯åˆ†å¸ƒå¦‚å›¾11ç»¿è‰²æ¤­åœ†æ‰€ç¤ºã€‚ç„¶ååˆ©ç”¨ç°æœ‰çš„å‚æ•°ï¼ŒE-stepå¼€å§‹å¯¹æ ·æœ¬æ•°æ®è¿›è¡Œåˆ’åˆ†ï¼ˆå¯¹$\\gamma$è¿›è¡Œä¼°è®¡ï¼‰ã€‚è“è‰²çš„æ ·æœ¬å¤§å¤šéƒ½è¢«åˆ’åˆ†ç»™ç¬¬1ç±»æ¨¡å‹ï¼Œæ©˜é»„è‰²çš„æ ·æœ¬å¤§å¤šéƒ½è¢«åˆ’åˆ†ç»™ç¬¬2ç±»æ¨¡å‹ã€‚ä½†æ˜¯ç¬¬1ç±»æ¨¡å‹è¿˜æœ‰ä¼˜åŒ–ç©ºé—´ï¼šç¬¬1ç±»æ¨¡å‹è¿˜ä¸èƒ½ä½¿å¾—è“è‰²æ ·æœ¬å‡ºç°çš„è”åˆæ¦‚ç‡è¾¾åˆ°æœ€å¤§ã€‚ç¬¬2ç±»æ¨¡å‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚M-stepä¾¿ä¼˜åŒ–äº†2ç±»æ¨¡å‹çš„å‚æ•°ï¼Œå¾—åˆ°æ–°çš„å‚æ•°$({\\mu ^1},{\\Sigma ^1},{\\pi ^1})$ï¼Œä½¿å¾—ä¼˜åŒ–å2ç±»é«˜æ–¯åˆ†å¸ƒå¦‚å›¾11çº¢è‰²æ¤­åœ†æ‰€ç¤ºã€‚å…¶ä¸­ï¼Œç¬¬1ç±»æ¨¡å‹ä¸»è¦ä¼˜åŒ–çš„æ˜¯æ¨¡å‹å‡å€¼ï¼ˆå³æ¤­åœ†çš„ä¸­å¿ƒï¼‰ï¼Œç¬¬äºŒç±»æ¨¡å‹ä¸»è¦ä¼˜åŒ–çš„æ˜¯æ¨¡å‹åæ–¹å·®çŸ©é˜µï¼ˆå³æ¤­åœ†çš„é•¿è½´ã€çŸ­è½´å’Œé•¿çŸ­è½´çš„æ–¹å‘ï¼‰ã€‚ç„¶åé‡å¤è¿›è¡ŒE-stepå’ŒM-stepï¼Œç›´åˆ°å‚æ•°$(\\mu ,\\Sigma ,\\pi )$æ”¶æ•›ã€‚\n\næœ€åè°ˆè°ˆæ··åˆé«˜æ–¯æ¨¡å‹çš„å‚æ•°$\\pi$ã€‚\n\næ··åˆé«˜æ–¯æ¨¡å‹çš„å‚æ•°$\\mu ,\\Sigma$æ¯”è¾ƒå¥½ç†è§£ï¼Œç”¨äºæè¿°å„ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å½¢çŠ¶ï¼Œå¯¹äºå®ƒä»¬çš„è°ƒæ•´ä¹Ÿæ¯”è¾ƒç›´è§‚ï¼šä½¿å¾—æœ¬é«˜æ–¯åˆ†å¸ƒèƒ½å¤Ÿæ›´å¥½åœ°æ¥çº³è¢«åˆ’åˆ†åˆ°è¿™ç±»åˆ†å¸ƒçš„æ ·æœ¬ã€‚è€Œä¸ºä»€ä¹ˆè¦æœ‰å‚æ•°Ï€ \\piÏ€ï¼Ÿå®ƒæè¿°çš„æ˜¯å„ä¸ªé«˜æ–¯åˆ†å¸ƒæ‰€å çš„æ¯”é‡ï¼Œå¦‚æœä¸åŠ â€œæ­§è§†â€çš„è¯ï¼ˆæ ·æœ¬æ¥æºäºå„ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å¯èƒ½æ€§ä¸€è‡´ï¼‰ï¼Œåˆ™æœ‰$\\pi_k=\\frac{1}{K}$è€Œå¦‚æœå¯¹äºæŸä¸€ç±»é«˜æ–¯åˆ†å¸ƒï¼ˆå³ä¸ºiï¼‰æœ‰ä¾§é‡çš„è¯ï¼Œåˆ™ç›¸åº”çš„$\\pi_i$è¾ƒå¤§ï¼Œä½“ç°åœ¨å›¾11ä¸­å°±æ˜¯è¢«åˆ†é…ç»™å„ä¸ªç±»çš„æ ·æœ¬æ•°å æ ·æœ¬æ€»æ•°çš„æ¯”ä¾‹ã€‚å¦‚æœä¸€è½®ä¼˜åŒ–åï¼ŒæŸä¸€ç±»é«˜æ–¯åˆ†å¸ƒåˆæ¥çº³äº†æ›´å¤šæ ·æœ¬ï¼Œåˆ™å…¶$\\pi_i$å˜å¤§ï¼Œåä¹‹å˜å°ï¼ˆæ‰€ä»¥å›¾11ä»ç»¿è‰²æ¤­åœ†è°ƒæ•´ä¸ºçº¢è‰²æ¤­åœ†å®é™…ä¸Šä¸¤ä¸ªç±»æ‰€å¯¹åº”çš„æƒé‡ä¹Ÿè¢«ä¼˜åŒ–äº†ï¼‰ã€‚\nè€Œä»æœ¬è´¨ä¸Šæ¥çœ‹å‚æ•°$\\pi$ï¼Œåˆ™æ˜¯ä¸ºäº†æ··åˆé«˜æ–¯æ¨¡å‹èƒ½æœ‰æ›´å¥½çš„æ›²é¢æ‹Ÿåˆèƒ½åŠ›ã€‚å½“å‚æ•°$\\pi$é€€åŒ–ä¸ºæŸä¸€ç±»é«˜æ–¯åˆ†å¸ƒçš„æƒé‡è¿œè¿œå¤§äºå…¶ä»–ç±»é«˜æ–¯åˆ†å¸ƒçš„æ—¶å€™ï¼Œæ··åˆé«˜æ–¯æ¨¡å‹å°±é€€åŒ–æˆäº†å•é«˜æ–¯æ¨¡å‹ï¼\n\n5 æ€»ç»“\nå›¾12å’Œå›¾13æ¢³ç†äº†é«˜æ–¯åˆ†å¸ƒå’Œæ··åˆé«˜æ–¯åˆ†å¸ƒå‚æ•°ä¼°è®¡çš„é€»è¾‘æµç¨‹ã€‚\n\n\n\n\nç›¸å¯¹æ¯”äºé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ä¼°è®¡ï¼Œæ··åˆé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ä¼°è®¡æ›´åŠ å¤æ‚ã€‚ä¸»è¦åŸå› åœ¨äºéšå˜é‡çš„å­˜åœ¨ã€‚è€Œä¸ºä»€ä¹ˆæ··åˆé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ä¼°è®¡éœ€è¦å¤šæ¬¡è¿­ä»£å¾ªç¯è¿›è¡Œï¼Ÿæ˜¯å› ä¸ºEMç®—æ³•ä¸­å¯¹äºÎ³ çš„ä¼°è®¡åˆ©ç”¨çš„æ˜¯åˆå§‹åŒ–æˆ–è€…ç¬¬iæ­¥è¿­ä»£çš„å‚æ•°$({\\mu ^i},{\\Sigma ^i},{\\pi ^i})$â€‹ï¼Œè¿™å¯¹äºæ ·æœ¬çš„åˆ†ç±»åˆ’åˆ†æ˜¯æœ‰è¯¯å·®çš„ã€‚æ‰€ä»¥å®ƒåªèƒ½é€šè¿‡å¤šæ¬¡è¿­ä»£ä¼˜åŒ–å¯»æ‰¾æ›´ä½³çš„å‚æ•°æ¥æŠµæ¶ˆè¿™ä¸€è¯¯å·®ã€‚\nç»ˆäºæŠŠè¿™ç¯‡æ–‡ç« æ¢³ç†å®Œäº†ã€‚ä¸–ç•Œæ¯è¦ç»“æŸäº†ï¼Œä¼ªçƒè¿·ä¹Ÿæƒ³è§è¯ä¸€ä¸‹å† å†›è¯ç”Ÿã€‚è‡³æ­¤ï¼Œæœ¬æ–‡ç»“æŸ\n\n","categories":["CV"]},{"title":"Recovery of 3D structure","url":"/2021/08/15/cv/9.%203D%20structure/","content":"Recovery of 3D structure\n\nRecovery of 3D structure1. Measure three-dimensional information\nCamera model\n\nCamera calibration(æ ‡å®š)\n\nEpipolar geometry\n\n2. Things arenâ€™t always as they appearâ€¦\n\nSingle-view ambiguity\nå¤±å»æ·±åº¦ä¿¡æ¯\n\n\n\n\n\nWhen certain assumptions hold, we can recover structure from a single view\n\n\n\nIn general, we need multi-view geometry\n\n\n3. Review: Pinhole camera model\n\nf = focal length ç„¦è·\no = apertureå…‰åœˆ = pinhole = center of the camera \n\n\n\n\\begin{gathered}\nQ=\\left[\\begin{array}{l}\nX \\\\\nY \\\\\nZ\n\\end{array}\\right] \\rightarrow Q^{\\prime}=\\left[\\begin{array}{l}\nX^{\\prime} \\\\\nY^{\\prime}\n\\end{array}\\right] \\\\\n\\mathfrak{R}^{3} \\rightarrow \\mathfrak{R}^{2}\n\\end{gathered}\n\\begin{aligned}\n&\\mathrm{X}^{\\prime}=f \\frac{X}{Z} \\\\\n&\\mathrm{Y}^{\\prime}=f \\frac{Y}{Z}\n\\end{aligned}\nQuestion: Is this a linear transformation?\nItâ€™s not, because it has X and Z in the equations.\n\n\n\n3.1 Homogeneous coordinates æ¬§å¼åæ ‡ä¸é½æ¬¡åæ ‡äº’è½¬æ¢\n\\begin{aligned}\n&E \\rightarrow H \\\\\n&\\quad(x, y) \\Rightarrow\\left[\\begin{array}{l}\nx \\\\\ny \\\\\n1\n\\end{array}\\right] \\quad(x, y, z) \\Rightarrow\\left[\\begin{array}{l}\nx \\\\\ny \\\\\nz \\\\\n1\n\\end{array}\\right]\n\\end{aligned}\n\\begin{aligned}\n&H \\rightarrow E \\\\\n&\\qquad\\left[\\begin{array}{c}\nx \\\\\ny \\\\\nw\n\\end{array}\\right] \\Rightarrow(x / w, y / w) \\quad\\left[\\begin{array}{c}\nx \\\\\ny \\\\\nz \\\\\nw\n\\end{array}\\right] \\Rightarrow(x / w, y / w, z / w)\n\\end{aligned}3.2 Projective transformation in Homogeneous coordinates\næŠ•å½±å˜æ¢\nå…ˆå°†å…¶è½¬æ¢ä¸ºå…¶æ¬¡åæ ‡ç³»ï¼Œç„¶åå°±å¯ä»¥ç”¨çº¿æ€§å¼å­æ¥è¡¨ç¤ºå˜æ¢å…³ç³»\n\n\n\\begin{gathered}\nQ=\\left[\\begin{array}{l}\nX \\\\\nY \\\\\nZ\n\\end{array}\\right] \\rightarrow \\quad Q^{\\prime}=\\left[\\begin{array}{l}\nX^{\\prime} \\\\\nY^{\\prime}\n\\end{array}\\right] \\quad \\quad  \\\\\n\\mathrm{X}^{\\prime}=f \\frac{X}{Z}\\quad  \n\\mathrm{Y}^{\\prime}=f \\frac{Y}{Z} \\\\\n\\left(\\begin{array}{l}\nX \\\\\nY \\\\\nZ \\\\\n1\n\\end{array}\\right) \\mapsto\\left(\\begin{array}{c}\nf X \\\\\nf Y \\\\\nZ\n\\end{array}\\right)=\\left[\\begin{array}{lll}\nf & & 0 \\\\\n& f & 0 \\\\\n& & 1 & 0\n\\end{array}\\right]\\left(\\begin{array}{c}\nX \\\\\nY \\\\\nZ \\\\\n1\n\\end{array}\\right)=P Q\n\\end{gathered}3.3 Camera calibration(æ ‡å®š)\nç”±äºæ‘„åƒæœºçš„ä½ç½®ä¸å›ºå®šï¼Œæ‰€ä»¥éœ€è¦è®¾ç«‹ä¸€ä¸ªä¸–ç•Œåæ ‡ç³»ã€‚ç„¶åæ‰€æœ‰å˜æ¢åœ¨è¯¥åæ ‡ç³»è¿›è¡Œ\n\n\n\n\nNormalized (camera) coordinate system:camera center is at the originåŸç‚¹, the principal axisis ä¸»è½´ the z-axis,\nCamera calibration: figuring out transformation from world coordinate system to image coordinate system\nè¿™é‡Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å·²ç»æœ‰ä¸¤ä¸ªåæ ‡ç³»ï¼Œåˆ†åˆ«ä¸ºæ‘„åƒæœºåæ ‡ç³»ã€å˜æ¢åçš„åæ ‡ç³»ã€‚ä¸åŒçš„æ˜¯ï¼Œä¸€ä¸ªæ˜¯æ‘„åƒæœºçš„åæ ‡ç³»ï¼ŒåŸç‚¹ä½äºå›¾ç‰‡ä¸»ç‚¹ï¼›å˜æ¢åçš„åæ ‡ç³»ï¼Œå…¶åæ ‡åŸç‚¹åœ¨å›¾ç‰‡çš„å·¦ä¸‹è§’ä¸Šï¼ˆå³ä¸Šè§’ï¼‰\n\n3.3.1 From retina plane to images\nretina plane è§†å¹³é¢\n\n\n\nPrincipal point (p):point where principal axis intersects the image plane\nä¸»è½´äº¤å›¾åƒåæ ‡ç³»çš„ç‚¹å«ä¸»ç‚¹\n\n\nNormalized coordinate system: origin of the image is at the principal point\nè§„èŒƒåçš„åæ ‡ç³»åŸç‚¹åœ¨ä¸»ç‚¹ä¸Š\n\n\nImage coordinate system: origin is in the corner\nå›¾åƒåæ ‡ç³»çš„åŸç‚¹æ˜¯å·¦ä¸‹è§’\n\n\n\n3.3.2 Principal point offset\næˆ‘ä»¬è¿›è¡ŒæŠ•å½±æ—¶ï¼Œä¼šé¦–å…ˆæŠ•å½±åˆ°è§„èŒƒåŒ–åæ ‡ç³»ï¼Œä¹‹åå†å°†è¯¥åæ ‡ç³»å¹³ç§»åˆ°å›¾åƒè§’ç‚¹\n\nå…ˆè¿›è¡Œåæ ‡å¹³ç§»ï¼Œå†è¿›è¡ŒæŠ•å½±å˜æ¢\n\n\n\n\n\\begin{aligned}\n&(X, Y, Z) \\mapsto\\left(f X / Z+p_{x}ï¼Œ f Y / Z+p_{y}\\right)\\\\\n&\\left(\\begin{array}{l}\nX \\\\\nY \\\\\nZ \\\\\n1\n\\end{array}\\right) \\mapsto\\left(\\begin{array}{c}\nf X+Z p_{x} \\\\\nf Y+Z p_{y} \\\\\nZ\n\\end{array}\\right)=\\left[\\begin{array}{ccc}\nf & & p_{x} & 0 \\\\\n& f & p_{y} & 0 \\\\\n&  & 1 & 0\n\\end{array}\\right]\\left(\\begin{array}{l}\nX \\\\\nY \\\\\nZ \\\\\n1\n\\end{array}\\right)\n\\end{aligned}\n\n$\\mathrm{P}=\\mathrm{K}[\\mathrm{I} \\mid 0]$ è§„èŒƒåŒ–çŸ©é˜µ\n\n3.3.3 Pixel coordinates\nPixel size: $\\frac{1}{m_{x}} \\times \\frac{1}{m_{y}}$\n$m_{x}$â€‹â€‹ pixels per meter in horizontal direction \n$m_{y}$â€‹â€‹ pixels per meter in vertical direction\nè§‚å¯Ÿå¼å­ï¼Œæˆ‘ä»¬ä¼šå‘ç°ï¼Œå…¶åªæ˜¯åˆåšäº†ä¾æ¬¡scaleï¼Œæ‰€ä»¥åªéœ€è¦å·¦ä¹˜ä¸€ä¸ªscale transformation matrix\n\n\n(X, Y, Z) \\mapsto m_{x} f X / Z+p_{x}, m_{y} f Y / Z+p_{y}\nK=\\underset{pixels/m}{\\left[\\begin{array}{ccc}\nm_{x} & & \\\\\n& m_{y} & \\\\\n& & 1\n\\end{array}\\right]}\\underset{m}{\\left[\\begin{array}{ccc}\nf & & p_{x} \\\\\n& f & p_{y} \\\\\n& & 1\n\\end{array}\\right]}=\\underset{pixels}{\\left[\\begin{array}{ccc}\n\\alpha_{x} & & \\beta_{x} \\\\\n& \\alpha_{y} & \\beta_{y} \\\\\n& & 1\n\\end{array}\\right]}\næœ‰äº”ä¸ªè‡ªç”±åº¦\n\n3.3.4 Camera rotation and translation3.3.4.1 3D Translation\nx^{\\prime}=x+t x ; y^{\\prime}=y+t y ; z^{\\prime}=z+t z\n\\left[\\begin{array}{l}\nX^{\\prime} \\\\\nY^{\\prime} \\\\\nZ^{\\prime} \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{llll}\n1 & 0 & 0 & t x \\\\\n0 & 1 & 0 & t y \\\\\n0 & 0 & 1 & t z \\\\\n0 & 0 & 0 & 1\n\\end{array}\\right]\\left[\\begin{array}{c}\nX \\\\\nY \\\\\nZ \\\\\n1\n\\end{array}\\right]3.3.4.2 3D Scaling\nX^{\\prime}=X \\times S_x ; Y^{\\prime}=Y \\times S_y ; Z^{\\prime}=Z \\times S_z\n\\left[\\begin{array}{c}\nX^{\\prime} \\\\\nY^{\\prime} \\\\\nZ^{\\prime} \\\\\n1\n\\end{array}\\right]=\\left[\\begin{array}{cccc}\nS_x & 0 & 0 & 0 \\\\\n0 & S_y & 0 & 0 \\\\\n0 & 0 & S_z & 0 \\\\\n0 & 0 & 0 & 1\n\\end{array}\\right]\\left[\\begin{array}{l}\nX \\\\\nY \\\\\nZ \\\\\n1\n\\end{array}\\right]3.3.4.3 3D rotation transformation3D rotation is done around a rotation axis\n\nFundamental rotations â€“ rotate about x, y, or z axes\nCounter-clockwise rotationé€†æ—¶é’ˆæ—‹è½¬ is referred to as positive rotation (when you look down negative axis)\n\n\n\nRotation about Z â€“ similar to 2D rotation\n\n\n\\begin{aligned}\n&x^{\\prime}=x \\cos (\\theta)-y \\sin (\\theta) \\\\\n&y^{\\prime}=x \\sin (\\theta)+y \\cos (\\theta) \\\\\n&z^{\\prime}=z\n\\end{aligned}\n\\left[\\begin{array}{lcll}\n\\cos (\\theta) & -\\sin (\\theta) & 0 & 0 \\\\\n\\sin (\\theta) & \\cos (\\theta) & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{array}\\right]\nRotation about y (z -&gt; y, y -&gt; x, x-&gt;z)\n\n\n\\begin{aligned}\n&z^{\\prime}=z \\cos (\\theta)-x \\sin (\\theta) \\\\\n&x^{\\prime}=z \\sin (\\theta)+x \\cos (\\theta) \\\\\n&y^{\\prime}=y\n\\end{aligned}\n\\left[\\begin{array}{lccc}\n\\cos (\\theta) & 0 & \\sin (\\theta) & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n-\\sin (\\theta) & 0 & \\cos (\\theta) & 0 \\\\\n0 & 0 & 0 & 1\n\\end{array}\\right]\nRotation about x (z -&gt; x, y -&gt; z, x-&gt;y)\n\n\n\\begin{aligned}\n&y^{\\prime}=y \\cos (\\theta)-z \\sin (\\theta) \\\\\n&z^{\\prime}=y \\sin (\\theta)+z \\cos (\\theta) \\\\\n&x^{\\prime}=x \\\\\n&\\left[\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\n0 & \\cos (\\theta) & -\\sin (\\theta) & 0 \\\\\n0 & \\sin (\\theta) & \\cos (\\theta) & 0 \\\\\n0 & 0 & 0 & 1\n\\end{array}\\right]\n\\end{aligned}3.3.5 Composing Transformation\n3.3.6 Camera rotation and translation\nYou can think of object transformations as moving (transforming) its local coordinate frame\nä¸–ç•Œåæ ‡ç³»åˆ°cameraåæ ‡ç³»\n\n\nAll the transformations are performed relative to the current coordinate frame origin and axes\n\n\n\nIn general, the camera coordinate frame will be related to the world coordinate frame by a rotation and a translation\nConversion from world to camera coordinate system (in non-homogeneous coordinates):\n\n\n\n\n\\tilde{X}_{\\text {cam }}=R(\\tilde{X}-\\tilde{C}) \\quad\\left(\\begin{array}{c}\n\\tilde{X}_{\\text {cam }} \\\\\n1\n\\end{array}\\right)=\\left[\\begin{array}{cc}\nR & -R \\widetilde{C} \\\\\n0 & 1\n\\end{array}\\right]\\left(\\begin{array}{c}\n\\tilde{X} \\\\\n1\n\\end{array}\\right)\nå…¶å®å¯ä»¥è¿™ä¹ˆç†è§£è¿™ä¸ªå˜æ¢çŸ©é˜µï¼Œå¯¹äºåç½®é‡ä¼šå—æ—‹è½¬çš„å½±å“ï¼š\n\n\n\\left[\\begin{array}{ll}\nR_{3\\times3} & O_{3\\times 1}\\\\\nO_{1\\times 3} & 1_{1\\times 1}\n\\end{array}\\right]_{4\\times 4}\n\\left[\\begin{array}{ll}\nI_{3\\times3} & -\\widetilde{C}_{3\\times 1}\\\\\nO_{1\\times 3} & 1_{1\\times 1}\n\\end{array}\\right]_{4\\times 4}=\n\\left[\\begin{array}{cc}\nR & -R \\widetilde{C} \\\\\n0 & 1\n\\end{array}\\right]_{4\\times 4}\n\\tilde{X}_{\\text {cam }}=R(\\widetilde{X}-\\widetilde{C}) \\quad X_{\\text {cam }}=\\underset{\\text{3D transformation \nmatrix (4 x 4)}}{\n\\left[\\begin{array}{cc}\nR & -R \\widetilde{C} \\\\ \n0 & 1\\end{array}\\right]} \nX\n2D transformation matrix (3 x 3) ä»æ‘„åƒæœºåæ ‡ç³»å¹³ç§»åˆ°å¦ä¸€ä¸ªåæ ‡ç³»ï¼Œå¹¶åšäº†æŠ•å½±å˜æ¢å’Œå°ºåº¦å˜æ¢\n\n\nK=\\underset{pixels/m}{\\left[\\begin{array}{ccc}\nm_{x} & & \\\\\n& m_{y} & \\\\\n& & 1\n\\end{array}\\right]}\\underset{m}{\\left[\\begin{array}{ccc}\nf & & p_{x} \\\\\n& f & p_{y} \\\\\n& & 1\n\\end{array}\\right]}=\\underset{pixels}{\\left[\\begin{array}{ccc}\n\\alpha_{x} & & \\beta_{x} \\\\\n& \\alpha_{y} & \\beta_{y} \\\\\n& & 1\n\\end{array}\\right]}\nç”¨äºè§†è§’å˜æ¢ï¼Œä»äºŒç»´å˜æ¢è½¬ä¸ºä¸‰ç»´å˜æ¢ï¼Œç›¸å½“äºçŸ©é˜µç»´åº¦å˜æ¢\n\n\n[\\mathrm{I} \\mid 0]\næˆ‘ä»¬å¯ä»¥è¿™ä¹ˆç†è§£ä¸€ä¸‹å¼å­ï¼Œå…¶å…ˆå°†ä¸–ç•Œåæ ‡ç³»è½¬åˆ°äº†æ‘„åƒæœºåæ ‡ç³»ï¼Œå†è¿›è¡Œå¹³ç§»å˜æ¢ï¼Œæœ€åè¿›è¡ŒæŠ•å½±å˜æ¢å’Œå°ºåº¦å˜æ¢\n\n\n\n\n$K$æ‘„åƒæœºå†…éƒ¨å‚æ•°ï¼Œ$[R\\mid t]$å¤–éƒ¨å‚æ•°\n\n\n3.4 Camera parameters\nIntrinsic parameters\nPrincipal point coordinates\n$p_x,p_y$\n\n\nFocal length\n$f$\n\n\nPixel magnification factors\n$m_x,m_y$\n\n\nSkew (non-rectangular pixels)\nRadial distortion ç•¸å˜\nè¶Šè¿œç¦»å…‰åœˆè¶Šå®¹æ˜“å‘ç”Ÿå¼¯æ›²\n\n\n\n\n\n\n\\begin{gathered}\n\\mathbf{P}=\\mathbf{K}\\left[\\begin{array}{ll}\n\\mathbf{R}\\mid \\mathbf{t}\n\\end{array}\\right] \\\\\n\\mathrm{K}=\\left[\\begin{array}{cc}\nm_{x} & \\\\\n& m_{y} & \\\\\n& & 1\n\\end{array}\\right]\\left[\\begin{array}{cc}\nf  & &p_{x} \\\\\n&f & p_{y} \\\\\n& & 1\n\\end{array}\\right]=\\left[\\begin{array}{cc}\n\\alpha_{x} & & \\beta_{x} \\\\\n&\\alpha_{y} & \\beta_{y} \\\\\n& & 1\n\\end{array}\\right]\n\\end{gathered}\n\nExtrinsic parameters\nRotation and translation relative to world coordinate system\nWhat is the projection of the camera center?\n\n\n\n\n\\mathbf{P}=\\mathbf{K}\\left[\\begin{array}{ll}\n\\mathbf{R} \\mid -\\mathbf{R} \\widetilde{\\mathbf{C}}\n\\end{array}\\right]\n$C$æ˜¯æ‘„åƒæœºä¸­å¿ƒåœ¨ä¸–ç•Œåæ ‡ç³»çš„åæ ‡\n\n\n\\mathbf{P} \\mathbf{C}=\\mathbf{K}[\\mathbf{R}\\mid-\\mathbf{R} \\tilde{\\mathbf{C}}]\\left[\\begin{array}{c}\n\\widetilde{\\mathbf{C}} \\\\\n1\n\\end{array}\\right]=0\nThe camera center is the null space of the projection matrix!\næŠ•å½±çŸ©é˜µ:$\\mathbf{P} \\mathbf{C}=\\mathbf{K}[\\mathbf{R}\\mid-\\mathbf{R} \\tilde{\\mathbf{C}}]$â€‹\ncamera center:$\\left[\\begin{array}{c}\\widetilde{\\mathbf{C}} \\\\1\\end{array}\\right]$\nåœ¨æ•°å­¦ä¸­ï¼Œä¸€ä¸ªç®—å­ $A$ çš„é›¶ç©ºé—´æ˜¯æ–¹ç¨‹ $Av = 0$ çš„æ‰€æœ‰è§£ $v$ çš„é›†åˆã€‚å®ƒä¹Ÿå«åš $A$ çš„æ ¸ç©ºé—´ã€‚å¦‚æœç®—å­æ˜¯åœ¨å‘é‡ç©ºé—´ä¸Šçš„çº¿æ€§ç®—å­ï¼Œé›¶ç©ºé—´å°±æ˜¯çº¿æ€§å­ç©ºé—´ã€‚å› æ­¤é›¶ç©ºé—´æ˜¯å‘é‡ç©ºé—´ã€‚\n\n\n\n4. Camera calibration\nå‚æ•°ä¸å¯çŸ¥\n\n\n\\begin{gathered}\n\\lambda \\mathbf{x}=\\mathbf{K}[\\mathbf{R} \\mid \\mathbf{t}] \\mathbf{X} \\\\\n{\\left[\\begin{array}{c}\n\\lambda x \\\\\n\\lambda y \\\\\n\\lambda\n\\end{array}\\right]=\\left[\\begin{array}{ccc}\n* & * & * & * \\\\\n* & * & * & * \\\\\n* & * & * & *\n\\end{array}\\right]\\left[\\begin{array}{l}\nX \\\\\nY \\\\\nZ \\\\\n1\n\\end{array}\\right]}\n\\end{gathered}\nGiven $n$ points with known $3 D$ coordinates $X_{i}$ and known image projections $\\boldsymbol{x}_{i}$â€‹â€‹, estimate the camera parameters\né€šè¿‡å®éªŒï¼Œå¯ä»¥åŒæ—¶æµ‹å¾—3Dåæ ‡å’Œå›¾åƒæŠ•å½±åæ ‡\n\n\n\n\n\n\n\\begin{array}{r}\n\\chi_{i}=P X_{i} \\quad P=\\left[\\begin{array}{l}\nP_{1} \\\\\nP_{2} \\\\\nP_{3}\n\\end{array}\\right] \\\\\n\\text { Pixel: } \\chi_{i}=\\left[\\begin{array}{l}\nx_{i} \\\\\ny_{i}\n\\end{array}\\right]=\\left[\\begin{array}{l}\n\\frac{P_{1} X_{i}}{P_{3} X_{i}} \\\\\n\\frac{P_{2} X_{i}}{P_{3} X_{i}}\n\\end{array}\\right]\n\\end{array}\nä¸Šé¢çš„å¼å­æ˜¯å…ˆåšäº†å˜æ¢ï¼Œç„¶åå°†é½æ¬¡åæ ‡è½¬ä¸ºäº†æ¬§å¼åæ ‡\nTwo linearly independent equations\nP has 11 degrees of freedom\nOne 2D/3D correspondence gives us two linearly  independent equations\n6 correspondences needed for a minimal solution\n\n4.1 Nonlinear method\n\\chi_{i}=P X_{i} \\quad \\chi_{i}=\\left[\\begin{array}{l}\nx_{i} \\\\\ny_{i}\n\\end{array}\\right]=\\left[\\begin{array}{l}\n\\frac{P_{1} X_{i}}{P_{3} X_{i}} \\\\\n\\frac{P_{2} X_{i}}{P_{3} X_{i}}\n\\end{array}\\right] \\quad\\left\\{\\begin{array}{c}\n-x_{i}\\left(P_{3} X_{1}\\right)+P_{1} X_{1}=0 \\\\\n-y_{i}\\left(P_{3} X_{1}\\right)+P_{2} X_{1}=0 \\\\\n-x_{i}\\left(P_{3} X_{n}\\right)+P_{1} X_{n}=0 \\\\\n-y_{i}\\left(P_{3} X_{n}\\right)+P_{2} X_{n}=0\n\\end{array}\\right.\n\\left[\\begin{array}{ccc}\n0^{T} & \\mathbf{X}_{1}^{T} & -y_{1} \\mathbf{X}_{1}^{T} \\\\\n\\mathbf{X}_{1}^{T} & 0^{T} & -x_{1} \\mathbf{X}_{1}^{T} \\\\\n\\cdots & \\cdots & \\cdots \\\\\n0^{T} & \\mathbf{X}_{n}^{T} & -y_{n} \\mathbf{X}_{n}^{T} \\\\\n\\mathbf{X}_{n}^{T} & 0^{T} & -x_{n} \\mathbf{X}_{n}^{T}\n\\end{array}\\right]\\left(\\begin{array}{l}\n\\mathbf{P}_{1}^{\\mathrm{T}} \\\\\n\\mathbf{P}_{2}^{T} \\\\\n\\mathbf{P}_{3}^{T}\n\\end{array}\\right)=0\n\\mathbf{A} \\mathbf{p}=\\mathbf{0}\nHomogeneous least squares:|find $\\mathbf{p}$ minimizing $|\\mathbf{A} \\mathbf{p}|^{2}$\nSolution given by eigenvector of $\\mathbf{A}^{\\mathrm{T}} \\mathbf{A}$â€‹ with smallest eigenvalue\nå¥‡å¼‚å€¼åˆ†è§£ï¼Œæ±‚$p$çš„å€¼\n\n\n\n5. Epipolar geometry5.1 Recovering structure from a single view\nä»å•ä¸ªå›¾ç‰‡ï¼Œå³ä½¿æœ‰çŸ¥è¯†ï¼Œä½†æ˜¯å¾ˆéš¾è¿›è¡Œé‡å»ºï¼Œå› ä¸ºå›¾ç‰‡å…·æœ‰æ­§ä¹‰ï¼Œç¼ºå°‘æ·±åº¦ä¿¡æ¯\n\n\n\nFrom calibration rig: location/pose of the rig, K\nKnowledge about scene: point correspondences, geometry of lines &amp; planes, etcâ€¦\nè¿™äº›çŸ¥è¯†åŒ…æ‹¬ç‚¹çš„ä¾èµ–æ€§ã€çº¿çš„å¹³è¡Œç‰¹å¾ï¼Œå¹³é¢ç­‰\n\n\nIntrinsic ambiguity of the mapping from 3D to image (2D)\nå…·æœ‰å†…éƒ¨æ­§ä¹‰æ€§ï¼Œä¸»è¦åœ¨æŠ•å½±çš„æ—¶å€™ï¼Œä¸¢å¤±äº†æ·±åº¦ä¿¡æ¯\n\n\n\n\n\nTwo eyes help!\n\n\n5.2 A taste of multi-view geometry: Triangulation\n\nGiven projections of a 3D point in two or more images (with known camera matrices), find the coordinates of the point\nç»™å®š3D pointçš„æŠ•å½±åæ ‡ï¼Œè¦æ±‚3Dåæ ‡\n\n\n\n\n\nWe want to intersect the two visual rays corresponding to $x_1$â€‹and $x_2$â€‹â€‹â€‹, but because of noise and numerical errors, they donâ€™t meet exactly\nç†è®ºä¸Šæ˜¯å¯ä»¥çŸ¥é“xçš„ä½ç½®ï¼Œå³ä½¿ä¸çŸ¥é“ï¼Œæœ‰ä¸¤å¼ ç…§ç‰‡ä¹Ÿå¯ä»¥æ‰¾çš„åˆ°ï¼Œä½†æ˜¯å®é™…ä¸Šæœ‰å™ªéŸ³ï¼Œæ‰€ä»¥å¾ˆéš¾æ‰¾åˆ°äº¤ç‚¹\n\n\n$\\text { Find } \\mathrm{X} \\text { that minimizes } d^{2}\\left(\\mathbf{x}_{1}, \\mathbf{P}_{1} \\mathbf{X}\\right)+d^{2}\\left(\\mathbf{x}_{2}, \\mathbf{P}_{2} \\mathbf{X}\\right)$\næœ€å°åŒ–æŠ•å½±è·ç¦»ä¸çœŸå®è·ç¦»\n\n\n\n\n5.3 é—®é¢˜åˆ†ç±»\næ±‚ç›¸æœºå†…å‚\n\n\n\nMotivation: Given a set of known 3D points seen by a camera, compute the camera parameters\n\nCalibration!\n\n\nå®šä½çœŸå®ç©ºé—´ä½ç½®\n\n\n\n\nStructure: Given known cameras and projections of the same 3D point in two or more images, compute the 3D coordinates of that point\nTriangulation!\nç»™å®šåŒä¸€ç‚¹çš„ä¸€äº›æŠ•å½±åæ ‡å’Œç›¸æœºå‚æ•°ç­‰ï¼Œç”¨ä¸‰è§’æ³•æ±‚çœŸå®åæ ‡\n\n\nè¦æ±‚ä¸€å¼ å›¾ç‰‡çš„ç‚¹å¯¹åº”å¦ä¸€å¼ å›¾ç‰‡çš„å¦ä¸€ä¸ªç‚¹\n\n\n\nCorrespondence: Given a point in one image, find the corresponding point in another one.\nçŸ¥é“æ‘„åƒæœºï¼Œä¹ŸçŸ¥é“å›¾ç‰‡ï¼Œè¦æ±‚ä¸€å¼ å›¾ç‰‡çš„ç‚¹å¯¹åº”å¦ä¸€å¼ å›¾ç‰‡çš„å¦ä¸€ä¸ªç‚¹\n\n\n\n5.4 Epipolar geometry\n\nBaselineï¼ˆåŸºçº¿ï¼‰ â€”â€” line connecting the two camera centers\nä¸¤ä¸ªç›¸æœºä¸­å¿ƒçš„è¿çº¿\n\n\nEpipolar Planeï¼ˆæå¹³é¢ï¼‰â€”â€”plane containing baseline and $X$â€‹\nè¿™é‡Œæœ‰ä¸‰ä¸ªåæ ‡ç³»ï¼Œä¸¤ä¸ªæ‘„åƒæœºåæ ‡ç³»ï¼Œä¸€ä¸ªä¸–ç•Œåæ ‡ç³»ï¼Œä¹Ÿå¯ä»¥å°†ä¸–ç•Œåæ ‡ç³»å’Œå…¶ä¸­ä¸€ä¸ªæ‘„åƒæœºåæ ‡ç³»ç§»åˆ°åˆ°é‡åˆ\n\n\nEpipolesï¼ˆæç‚¹ï¼‰ â€”â€”intersections of baseline with image planes\nåŸºçº¿å’Œå›¾ç‰‡çš„äº¤ç‚¹$e$\n\n\nEpipolar Lines â€”â€” intersections of epipolar plane with image planes (always come in corresponding pairs)\næå¹³é¢å’Œå›¾åƒå¹³é¢çš„äº¤çº¿$l,lâ€™$\n\n\n\n\n\nIf we observe a point $x$ in one image, where can the corresponding point $xâ€™$â€‹â€‹ be in the other image?\n\n\n\nPotential matches for $x$â€‹â€‹ have to lie on the corresponding epipolar line $ lâ€™$â€‹.\nPotential matches for $x$â€‹ â€˜ have to lie on the corresponding epipolar line $l$â€‹â€‹â€‹.\næ— è®ºæ˜¯å·²çŸ¥å“ªä¸€ä¸ªç‚¹ï¼Œè¦æ‰¾åŒ¹é…ï¼Œéƒ½åœ¨ç›¸å…³çš„æçº¿ä¸Šï¼Œæ‰€ä»¥åŒ¹é…çš„æ—¶å€™ï¼Œåªè¦éå†æçº¿çš„ç‚¹å°±è¡Œ\nè¿™ä¸ªé—®é¢˜å…¶å®æ˜¯ä¸€ä¸ªä¸‰ç‚¹å…±çº¿é—®é¢˜ï¼šå³è¦è¯æ˜$Oâ€™$å’Œ$X$çš„è¿çº¿ä¸å›¾ç‰‡å¹³é¢çš„äº¤ç‚¹ä¸€å®šåœ¨æçº¿ä¸Š\n\n5.5 Epipolar constraint example\n5.6 Epipolarconstraint: Calibrated case\nç°éªŒè¯åŒ¹é…çš„æŠ•å½±ç‚¹æ˜¯å¦åœ¨äº¤çº¿ä¸Šï¼Œå³å·²çŸ¥$xâ€™$â€‹åæ ‡ï¼ŒéªŒè¯å…¶æ˜¯å¦åœ¨ç›´çº¿ä¸Š\nå…ˆå°†æ‰€æœ‰ç‚¹çš„åæ ‡è½¬åˆ°ä¸–ç•Œåæ ‡ç³»é‡Œè¡¨è¾¾\n\n\n\nK_{\\text {camenical }}=\\left[\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\\right]\nå‡è®¾ä¸–ç•Œåæ ‡ç³»å’Œå…¶ä¸­ä¸€ä¸ªæ‘„å½±åæ ‡ç³»åŸç‚¹é‡åˆ\nIntrinsic and extrinsic parameters of the cameras are known, world coordinate system is set to that of the first camera.\nè¿”å›åˆ°ä¸–ç•Œåæ ‡ç³»å½“ä¸­\nå¯¹äºæ‘„åƒæœºåæ ‡ç³»ä¸Šçš„ä»»æ„ä¸€ç‚¹åæ ‡$xâ€™$ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶å˜æ¢ä¸ºä¸–ç•Œåæ ‡ç³»è¡¨ç¤º\n\n\n\n\nx'=RX_w+t\nx^{\\prime T}\\cdot \\left[t \\times\\left(R x^{}+t\\right)\\right]=0\\quad \\Rightarrow \\quad x^{\\prime T}[t_x]Rx=0\n\\text { Recall: } \\quad \\mathbf{a} \\times \\mathbf{b}=\\left[\\begin{array}{ccc}\n0 & -a_{z} & a_{y} \\\\\na_{z} & 0 & -a_{x} \\\\\n-a_{y} & a_{x} & 0\n\\end{array}\\right]\\left[\\begin{array}{l}\nb_{x} \\\\\nb_{y} \\\\\nb_{z}\n\\end{array}\\right]=\\left[\\mathbf{a}_{\\times}\\right] \\mathbf{b}\n\\boldsymbol{x}^{\\prime T}\\left[\\boldsymbol{t}_{\\times}\\right] \\boldsymbol{R} \\boldsymbol{x}=0 \\quad \\Rightarrow \\quad \\boldsymbol{x}^{\\prime T} E \\boldsymbol{x}=0\n\\boldsymbol{x}^{\\boldsymbol{T}} E \\boldsymbol{x^\\prime}=0\nLecture10 æ›´æ–°è§£æ³•\n\n\n\n\n\nç”±äº$xâ€™$æ˜¯å³è¾¹é‚£ä¸ªæå¹³é¢çš„æ³•å‘é‡ï¼Œæ‰€ä»¥ä¼šå‚ç›´äºæçº¿ï¼Œé‚£ä¹ˆå¯¹äºæ»¡è¶³ä»»æ„$xâ€™$éƒ½å‚ç›´äºæçº¿çš„æ–¹ç¨‹ï¼Œæ˜¾ç„¶å°±æ˜¯æçº¿çš„æ–¹ç¨‹\n$\\boldsymbol{Ex}$â€‹â€‹â€‹â€‹ is the epipolar line associated with $\\boldsymbol{x}\\left(\\boldsymbol{l}^{\\prime}=\\boldsymbol{E} \\boldsymbol{x}\\right)$â€‹â€‹â€‹â€‹\nRecall: a line is given by $a x+b y+c=0$ or $\\mathbf{l}^{T} \\mathbf{x}=0$ where $\\mathbf{l}=\\left[\\begin{array}{l}a \\ b \\ c\\end{array}\\right], \\quad \\mathbf{x}=\\left[\\begin{array}{l}x \\ y \\ 1\\end{array}\\right]$\n\n\n\\boldsymbol{x'}^T \\boldsymbol{E} \\boldsymbol{x}=0\n\n$E \\boldsymbol{x}$â€‹â€‹ is the epipolar line associated with $\\boldsymbol{x}\\left(\\boldsymbol{l}^{\\prime}=\\boldsymbol{E} \\boldsymbol{x}\\right)$â€‹â€‹\n$\\boldsymbol{E}^{T} \\boldsymbol{x}^{\\prime}$ is the epipolar line associated with $\\boldsymbol{x}^{\\prime}\\left(\\boldsymbol{I}=\\boldsymbol{E}^{\\top} \\boldsymbol{x}^{\\prime}\\right)$\n$E \\boldsymbol{e}=0$ and $\\boldsymbol{E}^{\\top} \\boldsymbol{e}^{\\prime}=0$\n$E$â€‹ is singular (rank two)\nå› ä¸º$t_x$çš„rankæ˜¯2\n\n\n$E$â€‹ has five degrees of freedom\nThe calibration matrices $K$ and $K^{\\prime}$ of the two cameras are unknown\nWe can write the epipolar constraint in terms of unknown normalized coordinates:\n\n\n\\hat{\\boldsymbol{x}}^{\\prime T} \\boldsymbol{E} \\hat{\\boldsymbol{x}}=0 \\quad \\hat{\\boldsymbol{x}}=\\boldsymbol{K}^{-1} \\boldsymbol{x}, \\quad \\hat{\\boldsymbol{x}}^{\\prime}=\\boldsymbol{K}^{\\prime-1} \\boldsymbol{x}^{\\prime}\n\\begin{array}\\\\\nx=K[I,O]X\\\\\n\\hat{x}=K^{-1}x=[I,O]X\n\\end{array}\nè¿™é‡Œçš„$[I,O]$ç›¸å½“äºè§†è§’è½¬æ¢ï¼Œç”±é½æ¬¡åæ ‡å˜ä¸ºæ¬§å¼åæ ‡\nä¹˜ä¸€ä¸ªé€†å°±å¯ä»¥å˜åˆ°å¦ä¸€ä¸ªç‚¹çš„è§„èŒƒåŒ–åæ ‡ç³»\n\n\n\\begin{aligned}\n&\\hat{\\boldsymbol{x}}=\\boldsymbol{K}^{-1} \\boldsymbol{x} \\\\\n&\\hat{\\boldsymbol{x}}^{\\prime}=\\boldsymbol{K}^{\\prime-1} \\boldsymbol{x}^{\\prime}\n\\end{aligned}\n(K^{-1}x)^TE(K'^{-1}x')=0\nx^T(K^{-1})^TEK'^{-1}x'=0\n\\hat{\\boldsymbol{x}}^{\\prime T} E \\hat{\\boldsymbol{x}}=0 \\quad \\Rightarrow \\boldsymbol{x}^{\\prime T} \\boldsymbol{F} \\boldsymbol{x}=0 \\quad \\text { with } \\quad \\boldsymbol{F}=\\boldsymbol{K}^{\\prime-T} \\boldsymbol{E} \\boldsymbol{K}^{-1}\n$\\boldsymbol{F} \\boldsymbol{x}$ is the epipolar line associated with $\\boldsymbol{x}\\left(\\boldsymbol{l}^{\\prime}=\\boldsymbol{F} \\boldsymbol{x}\\right)$\n$\\boldsymbol{F}^{\\boldsymbol{T}} \\boldsymbol{x}^{\\boldsymbol{x}}$ is the epipolar line associated with $\\boldsymbol{x}^{\\prime}\\left(\\boldsymbol{l}=\\boldsymbol{F}^{\\boldsymbol{T}} \\boldsymbol{x}^{\\prime}\\right)$\n$\\boldsymbol{F} \\boldsymbol{e}=0$ and $\\boldsymbol{F}^{T} \\boldsymbol{e}^{\\prime}=0$\n$\\boldsymbol{F}$ is singular (rank two)\n$\\boldsymbol{F}$ has seven degrees of freedom\n\n5.7 Estimating the fundamental matrix5.7.1 The eight-point algorithm\n\\boldsymbol{x}=(u, v, 1)^{T}, \\quad \\boldsymbol{x}^{\\prime}=\\left(u^{\\prime}, v^{\\prime}, 1\\right)\n\\left[\\begin{array}{lll}\nu^{\\prime} & v^{\\prime} & 1\n\\end{array}\\right]\\left[\\begin{array}{lll}\nf_{11} & f_{12} & f_{13} \\\\\nf_{21} & f_{22} & f_{23} \\\\\nf_{31} & f_{32} & f_{33}\n\\end{array}\\right]\\left[\\begin{array}{l}\nu \\\\\nv \\\\\n1\n\\end{array}\\right]=0\n\\left[\\begin{array}{llllllll}\nu^{\\prime} u & u^{\\prime} v & u^{\\prime} & v^{\\prime} u & v^{\\prime} v & v^{\\prime} & u & v & 1\n\\end{array}\\right]\\left[\\begin{array}{l}\nf_{11} \\\\\nf_{12} \\\\\nf_{13} \\\\\nf_{21} \\\\\nf_{22} \\\\\nf_{23} \\\\\n\\end{array}\\right]=0\n\nSolve homogeneous linear system using eight or more matches $\\rightarrow F$â€‹\nè¿™é‡Œä¼šéœ€è¦å…«ä¸ªç‚¹ï¼Œæœ€ç»ˆä¼šå˜æˆä¸¤ä¸ªçŸ©é˜µç›¸ä¹˜\nEnforce rank-2 constraint (take SVD of $F$â€‹ and throw out the smallest singular value). Find F that minimizes $|\\mathrm{F}-\\hat{\\mathrm{F}}|=0$â€‹ Subject to detf(F) $=0$â€‹\n\n\n\n","categories":["CV"]},{"title":"Knowledge Graph Construction from Semi-Structured Data and Unstructured Data","url":"/2021/08/15/knowledge%20engineering/11.%20Knowledge%20Graph%20Construction%20from%20Semi-Structured%20Data/","content":"Knowledge Graph Construction from Semi-Structured Data and Unstructured Data\n1. Taxonomy Induction\nA taxonomy is a directed acyclic graph consisting of is-a relations between entities, including conceptual entities and individual entities.\n\nexample: a part of the taxonomy of Books\n\n\n\n\nHere, Taxonomy induction is to induce a taxonomy from the online encyclopedia.\n\nWikipedia has its own categorization system, but categories do not form a taxonomy with a fully-fledged subsumption hierarchy, so it is only a thematically organized thesaurus.\n\n\n\n\nTaxonomy induction from Wikipedia is to refine the Wikipedia category system by removing not-is-a relations. (WikiTaxonomy)\n\n1.1 The first step - Pre-Cleansing:\nRemove the categories used for Wikipedia administration, i.e., remove the categories whose labels contain any of the following strings: wikipedia, wikiprojects, lists, mediawiki, template, user, portal, categories, articles, and pages.\n\nWikipedia organizes many category pairs using patterns: Y X and X by Z (e.g., Miles Davis albums, Albums by artist)\n\nä¸æ˜¯Is-Aå…³ç³»ï¼Œremove\n\n\nThe relation between these categories is defined as is-refined-by, which is to better structure and simplify the categorization system and should be removed.\n\n1.2 The second step - Syntax-based Methodï¼š\nif a category pair share the same lexical head, then there exists an is-a relation between these two categories,\nlexical head è¯æ±‡ä¸­å¿ƒè¯\ne.g., British Computer Scientists is-a Computer Scientists\n\n\nif the lexical head of one of the category occurs in non-head position in the other category, then a not-is-a relation is labeled between these categories. \ncategoriesçš„ä¸­å¿ƒè¯å‡ºç°åœ¨éä¸­å¿ƒè¯çš„ä½ç½®ï¼Œåˆ™ä¸æ˜¯IS-Aå…³ç³»\ne.g., Crime comics not-is-a Crime\n\n\n\n1.3 The third step - Connectivity-based Method ï¼š\nFor each category $c$â€‹, we find the article titled as the category name, e.g., article Microsoft for category Microsoft;\né¦–å…ˆå¯¹äºæ¯ä¸ªcategory cï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°å…¶article\n\n\nOn the found article, we collect all categories whose lexical heads are plural nouns $c a S e t=\\left\\{c a_{1}, c a_{2}, \\ldots, c a_{n}\\right\\} ;$â€‹\nç„¶ååœ¨æˆ‘ä»¬æ‰¾åˆ°çš„articleé¡µé¢ä¸‹ï¼Œæ”¶é›†æ¯ä¸ªcategoryå¯¹åº”çš„ä¸­å¿ƒè¯é›†åˆ\n\n\nFor each $c$ â€˜s super category $s c$ in the category system, we label the relation between $c$ and $s c$ as $i s-a$, if the head lemma of $s c$â€‹ matches the head lemma of at least one category in caset.\nå¯¹äºcçš„ä¸Šçº§ç±»scï¼Œæˆ‘ä»¬å¯ä»¥ä»å…¶åç§°æ‰¾åˆ°ä»–çš„head lemmmaï¼ˆè¯æ ¹ï¼‰\næ¯”å¦‚Human namesçš„ä¸­å¿ƒè¯å°±æ˜¯names\nç„¶åè¿›è¡ŒåŒ¹é…ï¼Œå¦‚æœæŸä¸ªscå’Œcæ˜¯IS-Aå…³ç³»ï¼Œåˆ™å…¶lexical head å’Œhead lemmaæ˜¯ç›¸åŒçš„\n\n\n\n\n\n1.4 The fourth step - Lexico-Syntactic based Methodï¼š\nlexico-syntactic patterns are leveraged to identify is-a and not-is-a relations between categories from large-scale corpora, e.g., all article in Wikipedia.\n\n\n1.5 The fifth step - Inference based Methodï¼š\npropagate the previously found relations based on the properties of transitivity of the is-a relation.\nä¼ é€’æ€§\n\n\n\n\n1.6 Exercise\nPlease extract a taxonomy from the following sentence (denote the answer as A is-a B): \nIBM, AMD, and Intel are High-tech companies using nanotechnology for several years.\nHigh-tech company is-a company\nIBM is-a High-tech company\nAMD is-a High-tech company\nIntel is-a High-tech company\n\n\n\n\n\n1.7 Summary: KG construction from Semi-Structured Data\nOnline encyclopedias are typical semi-structured data for knowledge graph construction.\nWe have introduced techniques on fact extraction, type inference, and taxonomy induction.\nAll introduced techniques have already been used to build real-word knowledge graphs, and shown good effectiveness and practicability.\nThere is no perfect technique on knowledge graph construction, so we need to study more.\n\n2. Knowledge Graph Construction from Unstructured Data (Text)2.1 Basic Tasks\n\né¢å‘æ–‡æœ¬çš„å®ä½“é“¾æ¥æˆ–è€…å‘ç°æ–°çš„å®ä½“\nå…³ç³»æŠ½å–ï¼Œå·²çŸ¥ä¸¤ä¸ªå®ä½“çœ‹æ˜¯å¦æœ‰å…³ç³»/æ§½å¡«å……\näº‹ä»¶æŠ½å–\n\n2.2 Two Specific Tasks in Knowledge Engineering\nGeneral IS-A Relation Extraction \n(benefit to build taxonomies)\n\n\nTerminology/ Term Extraction \næœ¯è¯­æŠ½å–ï¼Œåˆ©äºé¢†åŸŸæ„å»ºçŸ¥è¯†å›¾è°±\n(benefit to domain-specific knowledge graph construction)\n\n\n\n2.3 General is-a Relation Extraction2.3.1 problem1\nThe general is-a relation is the semantic relationship between a more specific word (i.e., hyponymä¸‹ä½è¯) and the more general term (i.e., hypernymä¸Šä½è¯).\n\nhyponym e.g., daisy and rose\nhypernym e.g., flower\n\n\nFeatures of is-a relations:\n\nTransitivity: $A$ is-a $B, B$ is-a $C \\rightarrow A$ is-a $C$e.g., dog is-a mammal, mammal is-a animal $\\rightarrow$ dog is-a anima\nAsymmetry: $A$â€‹ is-a $B \\nrightarrow B$â€‹ is-a $A$â€‹e.g., dog is-a animal $\\nrightarrow$â€‹ animal is-a dog\n\n\nTask Description:\n\nTriple generation: \nInput: a large scale corpus\nå³è¾“å…¥æ˜¯ä¸€å¤§æ®µè¯­æ–™\n\n\n\n\n\n\n\nOutput: triples denoting is-a relations\nBeijing is-a capital, Beijing is-a city, Tianjin is-a city, Hebei is-a province, Shanghai is-a city\n\n\n\n2.3.2 problem2\nTask Description: \nIS-A relation prediction: \nInput: a pair of candidate hyponym and hypernym, and the corresponding vector representations \nè¾“å…¥ä¸ºä¸‹ä½è¯å’Œä¸Šä½è¯ç»„æˆçš„pair\n\n\nOutput: true or false\ne.g., Pair(dog, animal) â†’ true Pair(dog, cat) â†’ false\n\n\n\n\n\n2.4 Methods Classification:\nPattern-based Methods (task: triple generation)\nDistributional Methods (task: is-a relation prediction) \nUnsupervised Distributional Methods \nSupervised Distributional Methods\n\n\n\n2.4.1 Pattern-based Methodsï¼šHearst Patterns\n\nExercise\nPlease extract is-a relations from the following sentence with Hearst Patterns, and derive all is-a relations by the transitivity of the is-a relation.\n\nThere are further opportunities on exporting UK red meat to such countries as China, Japan, Korea, and Southeast Asian countries, including Singapore or Vietnam.\n\nChina is-a country\nJapan is-a country\nKorea is-a country\nSoutheast Asian country is-a country\nSingapore is-a Southeast Asian country\nVietnam is-a Southeast Asian country\nInference:\nSingapore is-a country\nVietnam is-a country\n\n\n\n\n\nWhy Introducing Distributional Methods?\nLimitations of Pattern-based Methods: \nThe coverage and generalization are uncertain: \næ— æ³•æ¨å¹¿\nThe hyponym and hypernym must appear in a sentence at the same time.\nå¬å›ç‡ä½\n\n\n\n\nDistributional Methods aim to solve the problem of co-occurrence sparsity between the hyponym and hypernym.\n\n2.4.2 Unsupervised Distributional Methods\nDistributional Inclusion Hypothesis: \n\nIt assumes that a hyponym only appears in some of its hypernymâ€˜s contexts, but a hypernym appears in all contexts of its hyponyms. \nä¸‹ä½è¯åªå‡ºç°åœ¨ä¸€äº›ä¸Šä½è¯çš„contextsé‡Œï¼Œè€Œä¸Šä½è¯å‡ºç°åœ¨ä¸‹ä½è¯æ‰€æœ‰contextsé‡Œ\ne.g., the concept â€œfruitâ€ has a broader spectrum of contexts than its hyponyms, such as â€appleâ€œ, â€bananaâ€œ and â€œpearâ€.\n\n\nA Classic Asymmetric Distributional Similarity Measure: WeedsPrec.\n\nä¸€ç§æ— ç›‘ç£æå–is-aå…³ç³»çš„æ–¹æ³•\nIt captures the features of $u$, which are included in the set of features for a broader term $v$.\n\n\n\\operatorname{WeedsPrec}(u \\rightarrow v)=\\frac{\\sum_{f \\in F_{u} \\cap F_{v}} W_{u}(f)}{\\sum_{f \\in F_{u}} W_{u}(f)}\nFor each term $u, v$â€‹â€‹â€‹ is candidate hypernym;\n\n$u,v$éƒ½æ˜¯å€™é€‰ä¸Šä½è¯\n\n\n$f$ represents a contextual word with which $u$â€‹ co-occurs;\n\n$f$ä»£è¡¨uçš„context word\n\n\n$F_{u}$ is a set of $f$\n$F_u\\cap F_v$æ˜¯$u,v$èƒŒæ™¯è¯çš„äº¤é›†\n\n\n$W_{u}(\\mathrm{f})$ quantifies the statistical association between the $f$ and $u$, such as Point-Wise Mutual Information (i.e., $P M I(u, f))$.\n\n\nPoint-Wise Mutual Information: \n\ncompute the point-wise mutual information between a word w and a context word c.\n\n\n\n\nP M I(w, c)=\\log \\frac{p(w, c)}{p(w) p(c)}\n$N:$â€‹â€‹â€‹ How many sentences does the corpus contain? \n\n$ f(w) \\leq N:$ How many sentences contain  $w$ ?\n\n$ f(w, c) \\leq f(w):$  How many sentences contain $w$ and $c$ ? \n\n$ f(\\mathrm{c}) \\leq N:$â€‹â€‹ How many sentences contain $c$â€‹â€‹â€‹ ?\n$p(w)=f(w) / N    $\n$p(\\mathrm{c})=f(c) / N  $\n$p(w, c)=f(w, c) / N$\n\nWhen the correlation between two words $w$â€‹ and $c$â€‹ is strong, $P(w, c)$â€‹ will be much larger than $P(w) \\mathrm{P}(c)$â€‹, so $P M I(w, c)$â€‹ is larger.\n\n\n2.5 Supervised Distributional Methods\nRepresent the term pair $(u, v)$ as a combination of $\\boldsymbol{u}$ and $\\boldsymbol{v}$ (vector representations)\nConcat : $u \\oplus v$\nDiff: $v-u$\nSum: $\\quad u+v$\nDot-product: $u \\cdot v$\n\n\ntrain a binary classifier over the representation $(\\boldsymbol{u}, \\boldsymbol{v})$â€‹\n\n2.5.1 Whatâ€™s wrong with simple calculations?\n\nè¿™ç§æ–¹æ³•å¯èƒ½ç”±äºæ•°æ®é›†çš„åŸå› å¯¼è‡´å¹¶æ²¡æœ‰å­¦ä¼šæ¨ç†è€Œæ˜¯è®°ä½æŸä¸ªè¯å°±æ˜¯ä¸Šä½è¯\n\n2.5.2 Project learning\nå­¦ä¹ å¦‚ä½•å°†ä¸‹ä½è¯æ˜ å°„åˆ°ä¸Šä½è¯çš„ç©ºé—´ï¼Œå†è¿›è¡Œåˆ†ç±»\n\nProject learning learns a function to measure how possible there is an is-a relation between two words.\n\nKeyPoint: A projection tensor $T$ is used to project the hyponym vector into the hypernym vector.\n\nâ€‹    ä¸‹ä½è¯æ˜ å°„åˆ°ä¸Šä½è¯\n\n\n\n\n\nInput: Given a query $\\mathbf{q}$â€‹ and a candidate hypernym $\\mathbf{h}$â€‹\nOutput: The possibility that pair(q, h) is an is-a relation\n\nStep1: look up word embeddings $\\mathbf{q}$â€‹ and $\\mathbf{h}$â€‹ through a embedding table\n\nStep2 : Randomly initialize the projection vector $\\boldsymbol{T}(K \\times d \\times d)$â€‹\nStep3: Calculate the similarity vector s:\n\n\ns=q^{T} T_{i} h\nStep4: Map vector $s$ to score $\\mathrm{y}, \\mathbf{F}$ is generally a multilayer perceptron :\n\n\n\\mathrm{y}=\\mathrm{F}(s)3. Terminology/ Term Extraction\nTerminology extraction is associated with some other tasks, such as NER,keyword extraction, etc.\n\nDifferent from other tasks, terminology extraction is highly related to the domain.\n\nTerminology extraction is th key issue of ontology construction, text summarization, knowledge graphs, etc.\n\n\n\n3.1 Definitionâ€”Framework3.1.1 Input Text:\nEg: He did not try to navigate after the first bold flight, for the reaction had taken something out of his soul.\n\n3.1.2 Preprocessing\nTokenization: Tokenization describes splitting paragraphs into sentences, or sentences into individual words.\n\nEg: [â€˜Heâ€™, â€˜didâ€™, â€˜notâ€™, â€˜tryâ€™, â€˜toâ€™, â€˜navigateâ€™, â€˜afterâ€™, â€˜theâ€™, â€˜firstâ€™, â€˜boldâ€™, â€˜flightâ€™, â€˜,â€™, â€˜forâ€™, â€˜theâ€™, â€˜reactionâ€™, â€˜hadâ€™, â€˜takenâ€™, â€˜somethingâ€™, â€˜outâ€™, â€˜ofâ€™, â€˜hisâ€™, â€˜soulâ€™, â€˜.â€™]\n\n\nCleaning(Stopwords):**A majority of the words in a given text are connecting parts of a sentence rather than showing subjects, objects or intent. Word like  â€˜theâ€™ or â€˜andâ€™ can be removed by comparing text to a list of stopword.\n\nEg: [â€˜tryâ€™, â€˜navigateâ€™, â€˜firstâ€™, â€˜boldâ€™, â€˜flightâ€™, â€˜reactionâ€™, â€˜takenâ€™, â€˜somethingâ€™, â€˜soulâ€™, â€˜.â€™]\nPOS: Part of Speech (POS) often requires look at the proceeding and following words and combined with either a rule-based or stochastic method. \nè¯æ€§æ ‡æ³¨\nEg: [(â€˜tryâ€™, â€˜VBâ€™), (â€˜toâ€™, â€˜TOâ€™), (â€˜navigateâ€™, â€˜VBâ€™), (â€˜firstâ€™, â€˜JJâ€™), (â€˜boldâ€™, â€˜JJâ€™), (â€˜flightâ€™, â€˜NNâ€™), (â€˜reactionâ€™, â€˜NNâ€™), (â€˜takenâ€™, â€˜VBNâ€™), (â€˜somethingâ€™, â€˜NNâ€™), (â€˜soulâ€™, â€˜NNâ€˜)]\n\n\nStemming:Stemming is a process where words are reduced to a root by removing inflection through dropping unnecessary characters, usually a suffix.\né€šè¿‡å»é™¤åç¼€æ‰¾è¯æ ¹\nEg: The stemmed form of leafs is: leaf\nEg:The stemmed form of leaves is: leav\n\n\nLemmazation:Lemmazation is an alternative approach from stemming to removing inflection.\næ‰¾è¯æ ¹\nEg: The lemmatized form of leafs is: leaf\nEg: The lemmatized form of leaves is: leaf\n\n\n\n3.1.3 Filtering\nFiltering:\nCommon Dictionary Filtering (Filter by common Chinese dictionary)\nå»é™¤å¸¸ç”¨è¯\nIf Candidate Terms appear in common Chinese dictionary:Delete the Candidate Terms\n\n\n\n\nIrregular Filtering (Filter irregular words)\n\nFor each Candidate Terms in Candidate list, Calculate the frequency of strings appearing in the corpus:$\\mathrm{A}=$ frequency of Candidate Terms striing$B=$ frequency of Candidate Terms string removing the first character$\\mathrm{C}=$ frequency of Candidate Terms string removing the last character Then: score $=$ $\\mathrm{A} /(\\mathrm{B}+\\mathrm{C}-\\mathrm{A})$If score $&lt;$â€‹â€‹â€‹ Threshold: Delete the Candidate Terms\n\n\nExample:A = â€œright of transit passageâ€B = â€right of transitâ€œ                    score = 0.99, keep the Candidate Terms:C = â€œof transit passageâ€.             â€right of transit passageâ€œ\n\n\n3.2 Approaches\nLinguistic-based approaches\nStatistical-based approaches\nGraph-based approaches\n\n3.2.1 Linguistic-based approaches â€” Chunker\nNPsâ€”â€”Noun Phrases:\n\nNPs: Noun Phrases\nA type of phrase whose grammatical function is equivalent to a noun\n\n\nNoun phrases can name a person, place, thing or idea.\nExamples:\nI want a skateboard.\nThe yellow house is for sale.\n\n\nNoun phrases can generally serve as subject, object, attributive and other components in a sentence.\n\n\nTheory\n\nMore than 90% of the terms extracted in corpus are Noun Phrases\n\n\n\n\n\nToolkit\nNLTK RegexpParser: Convert regular expressions into syntax trees\nStep1: Define patterns of NPs\nStep2: Find Candidate Terms using Chunker\nStep3: Candidate Terms Filtering\n\n\n\nStep1: Define patterns of NPs\nä¸€äº›æ¨¡æ¿\n\n\n\n{\\}\n{*+}\n{\\**+}\n{\\*+}\n\n\nStep2: Find Candidate Terms using Chunker\nDefine NP patterns using methods before\nNPChunker = nltk.RegexpParser(patterns)\n\n\nPOS tagging for each sentence\ntagged_words = [nltk.pos_tag(word) for word in train_dataset]\n\n\nUsing NPChunker to get tree and Candidate Terms\ntree = NPChunker.parse(tagged_words)\n\n\n\n\n3.2.2 Statistical-based approaches\nTheory\nCandidate terminology with higher frequency is more likely to be a terminology.\n\n\nStatistical Feature:\nTermhood: Measure the relevance between term and domain.\nTF-IDF\n\n\n\n\nUnithood: Measure the collocation and adhesion within term.\n\nMI(Mutual information)\n\n\nEvaluate the importance of a word to a document.\n\nAssuming word with higher TF value and higher IDF value is more relevant to domain.\nTF: Term frequency.\n\n\n\n\n\\mathrm{TF}=\\frac{\\text { Number of certain word in a document }}{\\text { Number of all words in a document }}\nIDF: Inverse document frequency\n\n\n\\text{IDF}=\\log \\left(\\frac{\\text { Number of all documents in corpu }}{\\text { Number of documents containing the certain word }+1}\\right)\nFormula\nTF-IDF value is directly proportional to the number of occurrences of a word in the document and inversely proportional to the number of occurrences of the word in the whole corpus.\n\n\n\n\nExerciseâ€”â€”TF-IDF\nSuppose there are 100 words in a document, and the word â€œcowâ€ appears three times. The word â€œcowâ€ has appeared in 1,000 documents, and the total number of documents is 10,000,000. What is the TF-IDF score of the word â€œcowâ€?\n\n\n\\begin{array}{ll}\n\\text{TF}=\\frac{3}{100}\\\\\n\\text{IDF}=\\log \\frac{10000000}{1000+1}=3.9996\\\\\nTF\\times IDF=0.119987\n\\end{array}\nä¾‹ï¼šå‡å®šã€Šäºšæ´²çš„ç½‘ç»œæŠ€æœ¯ã€‹ä¸€æ–‡é•¿åº¦ä¸º1000ä¸ªè¯ï¼Œâ€œäºšæ´²â€ã€â€œç½‘ç»œâ€ã€â€œæŠ€æœ¯â€å„å‡ºç°20æ¬¡ï¼Œåˆ™è¿™ä¸‰ä¸ªè¯çš„â€œè¯é¢‘â€ï¼ˆTFï¼‰éƒ½ä¸º0.02ã€‚ ç„¶åï¼Œæœç´¢Googleå‘ç°ï¼ŒåŒ…å«â€œçš„â€å­—çš„ç½‘é¡µå…±æœ‰250äº¿å¼ ï¼ˆå‡å®šè¿™å°±æ˜¯ä¸­æ–‡ç½‘é¡µæ€»æ•°ï¼‰ï¼ŒåŒ…å«â€œäºšæ´²â€çš„ç½‘é¡µå…±æœ‰62.3äº¿å¼ ï¼ŒåŒ…å«â€œç½‘ç»œâ€çš„ç½‘é¡µä¸º0.484äº¿å¼ ï¼ŒåŒ…å«â€œæŠ€æœ¯â€çš„ç½‘é¡µä¸º0.973äº¿å¼ ã€‚è®¡ç®—â€œäºšæ´²â€ã€â€œç½‘ç»œâ€ã€â€œæŠ€æœ¯â€çš„TF-IDFå€¼.\n\n\n\\begin{array}{ll}\n\\text{IDF(äºšæ´²)}=\\lg\\frac{250}{26.3}=0.603\\\\\n\\text{IDF(ç½‘ç»œ)}=\\lg\\frac{250}{0.484}=2.713\\\\\n\\text{IDF(æŠ€æœ¯)}=\\lg\\frac{250}{0.973}=2.410\\\\\n\\text{TF-IDF(äºšæ´²)}=0.603\\times 0.02=0.01206\\\\\n\\text{TF-IDF(ç½‘ç»œ)}=2.713\\times 0.02=0.05426\\\\\n\\text{TF-IDF(æŠ€æœ¯)}=2.410\\times 0.02=0\\\\\n\\end{array}4. Statistical-based approachesâ€”MI4.1 PMI\nA special case of MI. It is used to calculate the degree of association between words in NLP.\nç”¨äºè®¡ç®—ä¸¤ä¸ªè¯çš„è”ç³»ç¨‹åº¦\n\n\n\n\nP M I(x ; y)=\\log _{2} \\frac{p(x, y)}{p(x) p(y)}=\\log _{2} \\frac{p(x \\mid y)}{p(x)}=\\log _{2} \\frac{p(y \\mid x)}{p(y)}\nxy represents $2 \\sim \\mathrm{n}(\\mathrm{n} \\geq 2)$ words. For example, when two words are used, $\\mathrm{x}$ represents the former word and $\\mathrm{y}$ represents the latter word; In three words, $\\mathrm{x}$ represents the first (two) words and y represents the last two (one) words; And so on. $-$â€‹ Usually used for double-word terminology.\n\nxyè¡¨ç¤ºä¸€ä¸ªç»„åˆ,xyæ˜¯å†…éƒ¨çš„è¯\n\n\nWhen the correlation between words $x y$ is strong: $P M I&gt;0$, and when it is weak: $P M I \\approx 0$\n\nA large PMI value means that the combination between words is tight, and the more likely it is to become a terminology.\n\n\n4.2 Exerciseâ€” PMI\nUse the following Co-occurrence Matrix to represent the frequency of simultaneous appearance of two words in text. Calculate the PMI between information and data.\n\n\n\n\\begin{array}{l}\nP(\\text{Information,data})=6/19\\\\\nP(\\text{Information})=11/19\\\\\nP(\\text{data})=7/19\\\\\nPMI(\\text{Information}|\\text{data})=\\log_2\\frac{6/19}{(11/19)\\times(7/19)}=\\log_2\\frac{114}{77}\n\\end{array}5. Graph-based methods5.1 PageRank And TextRank\nPageRank:\nCalculate the importance of webpages based on the link between them.\nå¦‚æœè¿™ä¸ªç½‘é¡µè¢«å¤šæ¬¡é“¾æ¥ï¼Œé‚£ä¹ˆè¿™ä¸ªç½‘é¡µæ›´é‡è¦\n\n\n\n\nTextRank:\nRegard â€˜wordâ€™ as â€˜webpageâ€™Calculate the importance of words based on the \nco-occurrence between them.\nTurn the directed graph in PageRank into an undirected graph.\næŠŠå•è¯å½“æˆç½‘é¡µï¼Œç®—å•è¯çš„é‡è¦æ€§\n\n\nFeature\nTextRank can extract terminologies from a single document without relying on other corpora.\næ— éœ€è®­ç»ƒï¼Œå¯ç›´æ¥æŠ½å–æœ¯è¯­\n\n\n\n\n\n5.2 PageRank5.2.1 PageRankâ€™s Theory\n\nRegard the Internet as a directed graph, with webpages as nodes in the graph and links between webpages as edges in the graph.\nWhen a webpage is linked by many other webpages, it means that this webpage is more important, that is, the PR value (PageRank value) of this webpage will be higher.\nIf a webpage with a high PR value links to another webpage, the PR value of the linked webpage will increase accordingly.\nç®€å•ç†è§£å°±æ˜¯äº’è”ç½‘æ˜¯ä¸€å¼ å·¨å¤§çš„æœ‰å‘å›¾ï¼Œç½‘é¡µè¢«é“¾æ¥è¶Šå¤šé‚£ä¹ˆé‡è¦ç¨‹åº¦è¶Šé«˜ï¼Œå¹¶ä¸”è¿™ç§é‡è¦ç¨‹åº¦å¯ä»¥ä¼ é€’ç»™é‚»å±…\n\n5.2.2 PageRankâ€™s Formula\nDivide the PR value of a webpage equally according to the total number of its links, and take this value as the voting value of the webpage to itsâ€™ linked webpage. Therefore, for webpage $i$â€‹, its PR value can be expressed as:\n$i$â€‹â€‹å¤„çš„PRå€¼ç­‰äºé‚»å±…çš„PRå€¼é™¤ä»¥å…¶è‡ªèº«çš„å‡ºåº¦\n\n\n\n\nP R(\\mathrm{i})=\\sum_{j \\in B_{\\mathrm{i}}} \\frac{P R(\\mathrm{j})}{O u t(j)}\n$P R(\\mathrm{i}): \\mathrm{PR}($â€‹ PageRank )score of webpage i.\n$B_{\\mathrm{i}}$ : Collection of webpages that linked to webpage i.\nOut(i): Out degree of webpage $\\mathrm{i}$â€‹.\n\n5.2.3 Example\nAs shown in the right figure, suppose a set consisting of only four webpages: $A, B, C$â€‹ and $\\mathrm{D}$â€‹. If webpages $\\mathrm{B}, \\mathrm{C}$â€‹ and $\\mathrm{D}$â€‹ are all linked to webpage $\\mathrm{A}$â€‹, and webpages $\\mathrm{B}, \\mathrm{C}$â€‹ and $\\mathrm{D}$â€‹ have no other links, then the PR value of webpage $A$â€‹ will be the sum of the PR values of webpages $B, C$â€‹ and $D$â€‹ :\n\n\nP R(A)=P R(B)+P R(C)+P R(D)\n\nAs shown in the right figure, webpage $B$â€‹ has links to webpage $A$â€‹ and $C$â€‹, webpage $D$â€‹ has links to webpages $A, B$â€‹ and $C$â€‹. Suppose one webpage can only vote for another webpage once. So webpage B will vote for $1 / 2$â€‹ of the linked webpage and webpage $\\mathrm{D}$â€‹ will vote for $1 / 3$â€‹ of the linked webpage. In this case, the PR value of webpage A is:\n\n\nP R(A)=\\frac{P R(B)}{2}+\\frac{P R(C)}{1}+\\frac{P R(D)}{3}\n5.2.4 Extended formula of PageRank\nThe above formula assumes that users only click the link of the current webpage to browse the next webpage, but the random browsing method is more in line with the real situation. Thus, the random browsing model is generated, and the $P R$â€‹â€‹ value of each web page in the random browsing model is calculated by the following formula:\nd é˜»å°¼ç³»æ•°ï¼Œå³æœ‰ä¸€å®šå¯èƒ½éšæœºè·³è½¬é¡µé¢\næœ€ç»ˆPageRankä¼šæ”¶æ•›åˆ°ä¸€ä¸ªç¨³æ€\n\n\n\n\nP R(i)=(1-\\mathrm{d})+d \\times \\sum_{j \\in B i} \\frac{P R(j)}{\\operatorname{Out}(j)}\n$P R$â€‹ value is initially set as $1 / \\mathrm{N}$â€‹.\n\nN: Num of all webpages.\n\nd: Damping coefficient, representing the probability of browsing webpages accordance with the link, default value is $0.85$â€‹.\n1-d: The probability that the viewer randomly browses another webpage.\n\n5.3 Graph-based approachesâ€”TextRank\nPageRank:Construct graph according to the link relationship between webpages.\nTextRank:Construct graph according to the co-occurrence relationship between words.\n\n5.3.1 TextRankâ€™s Formula:\nå…¶ç›¸å½“äºæ„å»ºäº†æœ‰å‘æœ‰æƒå›¾,iç‚¹çš„é‡è¦ç¨‹åº¦ç”±å…¶é‚»å±…å†³å®š\n\n\nW S\\left(\\mathrm{~V}_{\\mathrm{i}}\\right)=(1-d)+d \\times \\sum_{\\mathrm{V}_{\\mathrm{i}} \\epsilon\\left(\\mathrm{V}_{\\mathrm{i}}\\right)} \\frac{w_{j i}}{\\sum_{\\mathrm{V}_{k} \\in O u t\\left(\\mathrm{v}_{j}\\right)} w_{j k}} W S\\left(\\mathrm{~V}_{j}\\right)\n$w_{j i}$ â€‹ :Weight of edge connecting node $\\mathrm{i}$â€‹ and node $\\mathrm{j}$â€‹.\n$W S\\left(\\mathrm{~V}_{\\mathrm{i}}\\right):$ Weight of word $\\mathrm{i}$, initially value is 1 .\n$\\operatorname{Out}\\left(\\mathrm{V}_{\\mathrm{i}}\\right):$ Out degree of word $\\mathrm{i}$.\n\n5.3.2 Steps Of TextRank\nInputText:\næ·¡é»„çš„é•¿è£™, è“¬æ¾çš„å¤´å‘, ç‰µç€æˆ‘çš„æ‰‹çœ‹æœ€æ–°å±•çš„æ²¹ç”»\n\n\nPreprocessing:\n\næ·¡é»„ é•¿è£™ è“¬æ¾ å¤´å‘\nç‰µæˆ‘ æ‰‹ çœ‹æœ€æ–° å±•å‡º æ²¹ç”»\n\n\nConstruct graph $\\mathbf{G}(\\mathbf{V}, \\mathbf{E}): \\mathrm{V}$â€‹ is composed of words generated in the above steps, and then use the co-occurrence relationship to construct an edge between any two nodes. The edge between two nodes is only when their corresponding words cooccur in a window of length $\\mathrm{K}$â€‹. Given $\\mathrm{K}=2$â€‹ :\n\n\n\n\nIteration: Iteratively calculate the weight of each node until convergence according to the formula.\n\n\nW S\\left(\\mathrm{~V}_{\\mathrm{i}}\\right)=(1-d)+d \\times \\sum_{\\mathrm{V}_{\\mathrm{i}} \\epsilon\\left(\\mathrm{V}_{\\mathrm{i}}\\right)} \\frac{w_{j i}}{\\sum_{\\mathrm{V}_{k} \\in \\text { out }\\left(\\mathrm{v}_{j}\\right)} w_{j k}} W S\\left(\\mathrm{~V}_{j}\\right)","categories":["KnowledgeEngineering"]},{"title":"Knowledge Graph Construction from Semi-Structured Data","url":"/2021/08/15/knowledge%20engineering/10.%20Knowledge%20Graph%20Construction%20from%20Semi-Structured%20Data/","content":"Knowledge Graph Construction from Semi-Structured Data\n1. What is semi-structured data?\nSemi-structured data is a form of structured data that does not obey the tabular structure of data models associated with relational databases or other forms of data tables, but nonetheless contains tags or other markers to separate semantic elements and enforce hierarchies of records and fields within the data.\n\nA typical example: online encyclopedias\n\nç™¾ç§‘æ•°æ®\n\n\n\n\n2. Knowledge Graphs Built from Online Encyclopedias\n\nBabelNetä¸–ç•Œæœ€å¤§å¤šè¯­è¨€è¯å…¸\n\n2.1 Modules of Knowledge Graph Construction from Online Encyclopedias\nFact Extraction\nType Inferenceï¼ˆæ¨æ–­ç±»åˆ«ï¼‰\nTaxonomy Induction  ï¼ˆåˆ†ç±»å½’çº³ï¼‰\n\n2.2 Fact Extraction\n\nFacts are factual knowledge represented as triples, each of which is in the form of . \nsubject: an entity (an individual entity or a conceptual entity (i.e., concept))\npredicate: property/relation \nobject: an entity or a literal value\n\n2.2.1 Fact Extraction from Infoboxes\n\n\nEditing Formatï¼šä¸ºæ¸²æŸ“å‰ç¼–è¾‘çš„å½¢å¼ï¼ˆç”¨äºæŠ½å–ï¼‰\nRendered Outputï¼šæ¸²æŸ“ä¹‹åçš„è¾“å‡º\n\n2.2.2 Method\nGeneric Infobox Extraction: do not map synonymous properties,\nä¸è¿›è¡Œèåˆï¼Œå³ä¸åšåŒä¹‰è¯å½’ä¸€åŒ–\ne.g., birthdateä¸dateOfBirth\n\n\nMapping-based Infobox Extraction: map synonymous properties\nå†™äº†å¤§é‡çš„è§„åˆ™ï¼Œ åšåŒä¹‰è¯åŒ¹é…\nRules: http://mappings.dbpedia.org/\n\n\n\n\n\nDBpedia Ontology: 2795 properties, 685 concepts with subClassOf relations.https://wiki.dbpedia.org/services-resources/ontology\nåšå®Œå½’ä¸€åŒ–åå¯ä»¥å¾—åˆ°æœ¬ä½“\n\n\n\n2.2.2.1 Fact Extraction from DRpedia\n\n2.2.2.2 Fact Extraction from YAGO\n\nYAGO also defines infobox heuristics(å¯å‘æ³•) to map infobox properties to YAGO relations.\n\nDifference between YAGO and DBpedia: YAGO uses LEILA to parse literals of different types, such as dates and quantities, and normalizes units of measurement to ISO units.\n\nåˆ©ç”¨LEILAè¿›è¡Œliteralè§£æï¼Œå¹¶å½’ä¸€åˆ°ISOå•ä½\n\n\n\n\n2.2.3 Fact Extraction from Categories\n\næ­£åˆ™è¡¨è¾¾å¼æŠ½å–\n\n\n\nsubject: the article entity\nQiang Yang\n\n\npredicate: the target relation\nbirthOnDate\n\n\nobject: the string captured by the brackets of the regular expression\n1964 births\n\n\næå–å®Œä¹‹åéœ€è¦åšproperty\nNote: Domain and Range checking is necessary.\n\n\n\n\n\nå¦‚å›¾æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç›´æ¥æŠŠpediaçš„ä¸»é¢˜ä½œä¸ºsubjectï¼Œç„¶åä»categoriesé‡Œé¢è¿›è¡Œæ­£åˆ™åŒ–åŒ¹é…ï¼Œä»è€Œå¾—åˆ°predicate å’Œobject\n\n\n\nåŒ¹é…å®Œåéœ€è¦è¿›è¡Œdomainå’Œrangeçš„checking\n\n2.3.4 Exercise\nIn the Wikipedia article page of â€œMo Yanâ€, the categories as follows. Please extract facts from them in turtle using YAGO category maps without domain and range checking, and clarify the subsequent validation steps on the extracted fact.\nYAGO category maps\n\n\n\n\n@prefix expr: &lt;http://www.example.org/resource/&gt;@prefix expp: &lt;http://www.example.org/property/&gt;expr: MoYan expp: bornOnDate &quot;1955&quot;;\t\t\texpp: hasWonPrice expr: Han Chinese Nobel,\t\t\t\t\t\t\t  expr: Nobel,\t\t\t\t\t\t\t  expr: Mao Dun Literature Prize.\n\néœ€è¦check propertyçš„ rangeå’Œdomain\n\n2.3 Type Inference\nOne of the most valuable kinds of knowledge is type information, which refers to the axioms stating that an instance is of a certain type.\n\nBarack Obama rdf:type President of the United StatesItaly rdf:type Country in Europe\n2.3.1 Type Inference: Applications\n\n\nTypeæ˜¯è¿æ¥schemaå’ŒInstanceå±‚çš„é‡è¦å…³ç³»\n\n\n\n\nType Inference in Knowledge Graph Construction: ä¸€ç§æ˜¯ä»0å¼€å§‹çš„æ„å»ºä»»åŠ¡\nå¦å¤–ä¸€ç§æ˜¯æœ‰éƒ¨åˆ†å·²ç»æœ‰typeï¼Œå…¶ä»–çš„æ˜¯åšä¸€ç§ä¸å…¨å·¥ä½œ\n\n\n\n2.3.2 Type Inference from Infoboxes2.3.2.1 Names of infobox templates\nNames of infobox templates are extracted as entity types (DBpedia).\nraw type : Mapping to DBpedia Ontology $\\rightarrow$â€‹ ontology classes\nç›´æ¥ä»Info Box æ‰¾ï¼Œè¿›è¡Œæ˜ å°„\n\n\n\n\n2.3.2.2 concept-instance pairs\nProperty-value pairs in infoboxes are mapped to concept-instance pairs (Zhishi.me).\nEach article in the online encyclopedia is taken as an instance, so all articles form an instance set $I=\\{i_1, i_2,â€¦, i_n\\}$â€‹â€‹;\nEach category (i.e., article category) in the online encyclopedia is treated as aconcept (i.e., class), so all categories compose a concept/class set C={c1, c2,â€¦, cm};\nIn the infobox of each article, a set of property-value pairs can be extracted as$\\{,â€¦ , \\}$â€‹â€‹â€‹.\nå¯ä»¥è¿™ä¹ˆç†è§£åœ¨ç»´åŸºç™¾ç§‘é‡Œæˆ‘ä»¬å¯ä»¥è·å¾—æ¯ç¯‡æ–‡ç« çš„å®ä½“ï¼Œä»¥åŠæ¯ä¸ªç±»åˆ«çš„å®ä½“ï¼Œç„¶åæˆ‘ä»¬åƒé’ˆå¯¹æŸä¸€ç¯‡æ–‡ç« è¿›è¡Œmapï¼Œæˆ‘ä»¬å°±å¯ä»¥ä»é‚£ç¯‡æ–‡ç« çš„InfoBoxé‡Œæ‰¾åˆ°æ‰€æœ‰çš„ property-value pairsï¼Œç„¶åæˆ‘ä»¬å°±å¯ä»¥æ£€æŸ¥propertyæ˜¯å¦åœ¨classesé‡Œï¼Œvalueæ˜¯ä¸æ˜¯åœ¨instance seté‡Œï¼Œå¦‚æœæ˜¯é‚£ä¹ˆå°±æ˜ å°„æˆäº†v type p\n\n\n\n\ninstances\n\n\n\nconcepts\n\n\n\nproperty-value pairs:{&lt;name, Schindlerâ€™s List&gt;, ,â€¦}\n\n\n\nProperty-value pairs in infoboxes are mapped to concept-instance pairs (Zhishi.me).\nFor each property-value pair $$, if $p_k$ belongs to the concept set $C$ and $v_k$ belongs to the instance set $I$, then we infer that $p_k$ is the type of $v_k$.\n\n\n\n\n2.3.3 Type Inference from Categories\nEach article is usually assigned to several categories in online encyclopedias, so these categories can be taken as important candidate types for entities/ instances.\n\nåœ¨pediaä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æœ‰åˆ†é…categoriesä¿¡æ¯ï¼Œè€Œè¿™æ ·çš„ä¿¡æ¯å¯ä»¥ä½œä¸ºå€™é€‰type\n\n\nYAGO is the first work to infer entity types from the categories in Wikipedia by using heuristicsï¼ˆå¯å‘æ³•ï¼‰.\n\n\n\n\n\nYAGO classifies all categories into conceptual ones, which are actually entity types, and non-conceptual ones. \nä½†æ˜¯Categories æœ‰æ­£ç¡®ä¹Ÿæœ‰é”™è¯¯ï¼Œæ‰€ä»¥è¦è¿›è¡Œç­›é€‰\nYAGO parses each category name like Naturalized citizens of Germany into a pre-modifier (Naturalized), a head (citizens) and a post-modifier (Germany); \nå¤§è‡´æ„æ€å°±æ˜¯æŠŠæ¯ä¸ªcatygoriesè§£ææˆpre-modifier+head+post-modifierå½¢å¼\n\n\nIf the head is not an acronymç¼©å†™ (e.g., NYC) and is a pluralå¤æ•° word, then the given category is a candidate conceptual category; \nFor each of the candidate conceptual categories, if it contains a non-conceptual word (manually summarized by YAGO), then it may be an administrative category (e.g., Articles with unsourced statements), \nå¦‚æœå€™é€‰è¯é‡Œé¢åŒ…å«äº†ä¸€äº›YAGOæ€»ç»“çš„éæ¦‚å¿µæ€§è¯ï¼Œé‚£ä¹ˆåº”è¯¥èˆå¼ƒæ‰\n\n\nor a relational category (e.g., 1987 births), or a thematic category (Physics), and it will be filtered out.\nå…³ç³»æ€§çš„è¯ä»¥åŠç†è®ºè¯\n\n\n\n\n\n\n\nå¦‚å›¾æˆ‘ä»¬å¯ä»¥å‘ç°å¤§éƒ¨åˆ†å¤æ•°ä¸­å¿ƒè¯éƒ½æ˜¯æ­£ç¡®çš„category\n\n2.3.3.1 Problems:\nThe heuristics cannot be applied in some languages (e.g. Chinese and Japanese), in which nouns have no explicit singular or plural forms. \nå¯¹äºæ²¡æœ‰å¤æ•°çš„è¯­è¨€ä¸åˆ©ï¼›\n\n\nThe heuristics cannot catch the semantic associations between instances and classes (i.e., categories), which may lead to mistakes in the process of type inference.\næ²¡æœ‰è€ƒè™‘è¯­ä¹‰å…³ç³»ï¼Œå¯èƒ½é€ æˆæ˜ å°„é”™è¯¯ï¼Œå› ä¸ºå¹¶ä¸æ˜¯æ‰€æœ‰å¤æ•°çš„éƒ½æ˜¯categoryï¼Œå¦‚å›¾æ‰€ç¤º\n\n\n\n\n2.3.3.2 MulType\nTo solve the above problems, MulType mines a language-independent feature: attribute (i.e., property) to perform language-independent type inference.\n\nThe assumption of the method: \n\nGiven the attributes (i.e., properties) â€œactors, release date, directorâ€ of an instance, we intuitively infer its type as â€œMovieâ€. \nactor ç­‰å…·æœ‰ä»£è¡¨æ€§ï¼Œå¯ä»¥æ¨æ–­\n\n\nGiven the attributes â€œname, foreign nameâ€ of an instance, we cannot infer its type by intuition.\nname foreign name æ²¡æœ‰åŒºåˆ†åº¦ï¼Œæ— æ³•æ¨æ–­\n\n\nä»£è¡¨å±æ€§å‡è®¾\nMulType uses attributes to build semantic associations between instances and classes (i.e., categories), and presents an attribute-driven type inference assumption: In Wikipedia, if an instance contains representative attributes of one of its classes (i.e., categories), there may exist a rdf:type relation from the instance to the category with a high probability.\nå¦‚æœä¸€ä¸ªå®ä½“åŒ…å«ä¸€ä¸ªç±»çš„ä»£è¡¨å±æ€§ï¼Œé‚£ä¹ˆä»–æœ‰å¾ˆé«˜çš„æ¦‚ç‡æ˜¯è¿™ä¸ªç±»\n\n\n\n\n\n2.3.3.3 process\nBased on the above assumption, MulType extracts type information in two steps: attribute extraction and type information generation.\n\n\n\nAttribute extraction:\nInstance attribute extraction: Extract instance attributes directly from infoboxes (see Figure (a)). \nClass attribute extraction: Extract class attributes from infobox templates (see Figure(b)), which are templates that provide standardized information (i.e., attributes) across related articles.\nNot enough! There are only thousands of infobox templates.\n\n\n\n\n\n2.3.3.4 Class attribute extraction:\nDefinition 1: Infobox Template based Extraction Rule (IT-ER). Given an infobox template it and a class $c$, the local names of it and $c$ are respectively denoted as $n(i t)$ and $n(c) .$ All the attributes of it can be propagatedä¼ æ’­ to $c$ if\n$n($â€‹ it $)$â€‹ and $n(c)$â€‹ are the same (ignoring case and the difference in singular and plural forms for some languages),\nor â€œCategory:n(it)â€ can redirect to $c$â€‹,\nor $n($â€‹ it $)$â€‹ can redirect to $n(c)$â€‹ or $n(c)$â€‹ can redirect to $n($â€‹ it $)$â€‹.\n\n\nå¯ä»¥è¿™ä¹ˆç†è§£ï¼Œä¸ºäº†ä»æ¨¡æ¿è¿›è¡ŒæŠ½å–å…³ç³»ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡ŒåŒ¹é…ï¼ŒåŒ¹é…å…¶å®å°±æ˜¯çœ‹æ¨¡æ¿çš„local nameå’Œç±»åˆ«çš„local nameï¼Œå¦‚æœâ€œä¸€æ ·â€ï¼Œåˆ™å¯ä»¥è®²æ¨¡æ¿çš„æ‰€æœ‰å±æ€§ä¼ é€’åˆ°æŸä¸€ç±»åˆ«\n\nExamples: \n1) Infobox templateâ€œTemplate:Infobox islandsâ€and classâ€œCategory:Islandsâ€have the same local nameâ€œislandsâ€;\n\nsame local name \n\n2) The singular forms ofâ€œn(Category:Countries)â€ (i.e.,â€œCountryâ€) andâ€œn(Template:Infobox country)â€ (i.e.,â€œcountryâ€) are the same when ignoring case;\n\nå¿½ç•¥å¤§å°å†™\n\n3) If we submit the query â€œCategory:n(Template:Infobox university)â€to Wikipedia, it can be redirected toâ€œCategory:Universities and collegesâ€;\n\nå¯¹äºä¸¤ä¸ªcategoryå¦‚æœæœ‰ä»å®šå‘çš„å…³ç³»ï¼Œé‚£ä¹ˆè¿™ä¸¤è€…çš„å±æ€§æ˜¯ä¸€æ ·çš„\n\n\n\nâ€œn(Category: States of The United States)â€can redirect toâ€œn(Template:Infobox U.S. state)â€.\næ¨¡æ¿å’Œcategoryæœ‰é‡å®šå‘å…³ç³»ï¼Œå…·ä½“æ¥çœ‹ï¼Œæˆ‘ä»¬å¯ä»¥ä»WIKIçš„ä¸»é¢˜ä¸‹é¢çš„å°å­—çœ‹åˆ°è¿™ç§å…³ç³»\n\n\n\n\nTop-Down\n\nDefinition 2: Top-Down Hierarchy-based Extraction Rule (TDH-ER). If a class c has no attribute extracted from infobox templates, and it has super-classes with attributes, then all the attributesof its super-classes should be inherited by c.\n\nå¯¹äºé‚£äº›æ— æ³•ä»æ¨¡æ¿çš„åˆ°å±æ€§çš„ç±»ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä»–çš„çˆ¶ç±»è¿›è¡Œç»§æ‰¿\n\n\nThis is inspired by the inheritance in object-oriented programming that one class can inherit all the attributes of its super-class. \n\nExample: class Manager inherits the attribute name and gender from class Person.\n\n\nSets(one set corresponds to one language) of isA relations between classes are collected from open knowledge bases, including DBpedia, Yago, BabelNet, WikiTaxonomy and Zhishi.schema, in order to refine the class hierarchies of different languages in Wikipedia.\næˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€äº›çŸ¥è¯†ç™¾ç§‘æœé›†çš„isAå…³ç³»æ¥å»ºç«‹è¿™ç§å±‚æ¬¡ç»“æ„\n\n\n\nBottom-Up\n\nDefinition 3: Bottom-Up Hierarchy-based Extraction Rule(BUH-ER). Ilf a class c has no attribute extracted from infobox templates, and it has hyponymsï¼ˆä¸‹ä¹‰è¯ï¼‰ (include instances and sub-classes) with attributes, then the attributes can be propagated to c when they are shared by more than half of these hyponyms.\n\nå¯¹äºä¸€äº›ä¸Šä½è¯ï¼Œå®ƒå¯ä»¥ä»ä¸‹ä½è¯æ‹¿åˆ°å±æ€§ï¼Œä½†å¿…é¡»æœ‰åŠæ•°ä¸‹ä½è¯æ‹¥æœ‰è¿™ä¸ªå±æ€§\n\n\nThis is based on the idea that a class is traditionally a placeholder for a set of instances sharing similar attributes (Dowty, Wall, &amp; Peters, 1981).\n\nDowty, D. R., Wall, R., &amp; Peters, S. (1981). Introduction to Montague semantics. Springer Netherlands.\n\n\n\n\n\n\næœ‰è§£å†³70%çš„é¡µé¢æ²¡æœ‰InfoBoxï¼Œå…¶æ¬¡InfoBoxçš„å¹¶ä¸å®Œæ•´\n\n2.3.3.5 acquire the most similar instances\nè¿™é‡Œæ˜¯æƒ³è¦é€šè¿‡è¿‘ä¹‰è¯æ¥å®Œæˆtypeä»»åŠ¡ï¼Œå› ä¸ºå¹¶ä¸æ˜¯æ‰€æœ‰å®ä¾‹éƒ½æœ‰infoboxï¼Œé‚£ä¹ˆå°±æ— æ³•é€šè¿‡å®ä¾‹æ¥æå–attribute\nType Information Generation \n\n\nAcquisition of Most Similar Instances: \nå¾—åˆ°æ›´å¤šç›¸ä¼¼çš„å®ä½“\n\n\nInfoboxes are not always contained by the corresponding article pages of instances. \nä¿¡æ¯æ¡†å¹¶ä¸æ€»æ˜¯åŒ…å«åœ¨å®ä¾‹çš„ç›¸åº”æ–‡ç« é¡µé¢ä¸­ã€‚\n\n\nThe information in existing infoboxes may be not complete.\nç¼ºäº†çš„å±æ€§å¯ä»¥ä»ç›¸ä¼¼è¯é‡Œæ‹¿\n\n\n\n\ntry to leverage the attributes of most similar instances to complement the given instanceâ€™s attributes\n\nExample: The city Zhenjiang misses the attribute mayor, but its similar instance Changzhou has the attribute mayor, which can be borrowed by Zhenjiang.\n\n\nTo acquire the most similar instances that have attributes, different similarity metrics can be used to measure the similarity degree between instances. \n\nGiven two instances $i_1$â€‹â€‹ and $i_2$â€‹â€‹, the Context Similarity Metric is computed as\n\n\n\\operatorname{CSM}\\left(i_{1}, i_{2}\\right)=\\frac{v\\left(i_{1}\\right) \\times v\\left(i_{2}\\right)}{\\left|v\\left(i_{1}\\right)\\right| \\times\\left|v\\left(i_{2}\\right)\\right|}\nwhere $v(i)$ is the vector representation of instance $i$â€‹. Such vector representations can be trained by pre-trained models on the whole Wikipedia.\n\nå¤§è‡´æ„æ€æ˜¯æŠŠè¯word embeddingæˆvectorï¼Œå†è®¡ç®—ç›¸ä¼¼åº¦\n\n\nGiven two instances $i_1$â€‹â€‹ and $i_2$â€‹â€‹, the Existing Classes Similarity Metric is computed as\n\n\n\n\\operatorname{ECSM}\\left(i_{1}, i_{2}\\right)=\\frac{\\mid E C \\operatorname{set}\\left(\\left(i_{1}\\right) \\cap E C \\operatorname{set}\\left(i_{2}\\right) \\mid\\right.}{\\left|E \\operatorname{Cset}\\left(i_{1}\\right) \\cup E C \\operatorname{set}\\left(i_{2}\\right)\\right|}\nç±»ä¼¼äºJaccardç›¸ä¼¼åº¦\nwhere $v(i)$ is the set of classes (i.e., categories) in the Wikipedia article pages for each instance.\nå°±æ˜¯æ¯ä¸ªarticleé‡Œcategoriesçš„é›†åˆ\n\n\n\n\nExample of Existing Classes Similarity Metric : suppose two instances $i_1= \\text{IntelliJ IDEA}, i_2= \\text{Apache XMLBeans}$â€‹\n\n$\\text{ECSM}(i_1,i_2)=1/8=0.125$\n\nTo combine the Context Similarity Metric and Existing Classes Similarity Metric, an Integrated Instance Similar Score is defined by maximizing the product of these two metrics:\n\n\n\\operatorname{IISS}\\left(i_{1}, i_{2}\\right)=\\left(\\operatorname{CSM}\\left(i_{1}, i_{2}\\right)+1\\right) \\times\\left(\\operatorname{ECSM}\\left(i_{1}, i_{2}\\right)+1\\right)\nWe add 1 to each value of both the metrics before the multiplication to avoid a 0 Integrated Instance Similar Score. If there does not exist an instance satisfying $\\operatorname{IISS}\\left(i_{1}, i_{2}\\right)&gt;1$, the instance $i_{1}$â€‹ will not get any similar instance.\nå¦‚æœæœ‰å¾ˆå¤š&gt;1ï¼Œåˆ™å¯ä»¥åšä¸€ä¸ªæ’åºï¼Œç„¶åå–top5\n\n\n\n2.3.4 Type Information Generation\nType Inference with Random Graph Walk: \nAfter extracting attributes of instances and classes, each instance, its attributes and the classes in its corresponding Wikipedia article page naturally form a graph, in which the given instance and its classes are linked by shared attributes. \nTo compute the probability of the class being the type of the given instance leveraging the graph structure, a random graph walk model is used to infer the types of each given instance.\n\n\n\n\n\nthe initial built graph of instance $i$â€‹â€‹\n\n2.3.4.1 Type Inference with Random Graph Walk:\nAfter adding most similar instances of $i$â€‹ that have attributes into the built graph\næŠŠæœ€ç›¸ä¼¼çš„å®ä½“åŠ å…¥å›¾ä¸­\n\n\n\n\n\nthe attribute-driven type inference assumption: \nIn Wikipedia, if an instance contains representative attributes of one of its classes (i.e., categories), there may exist a rdf:type relation from the instance to the category with a high probability. \nå¦‚æœä¸€ä¸ªå®ä½“æ‹¥æœ‰ä¸€ä¸ªç±»çš„ä»£è¡¨å±æ€§ï¼Œé‚£æœ‰ä¸€ä¸ªè¾ƒé«˜æ¦‚ç‡å±äºè¿™ä¸ªç±»åˆ«\n\n\nTo model the above assumption in the random graph walk model, it is supposed that if some class can be reached by more of its representative attributes on the built graph of each instance, then the probability of the class being the type of the given instance is higher.\næ‹¥æœ‰è¶Šå¤šä¸€ä¸ªç±»çš„ä»£è¡¨ç‰¹å¾ï¼Œæ¦‚ç‡è¶Šå¤§\n\n\nä½¿ç”¨random graph walkæ¥çœ‹å“ªäº›å¯ä»¥å°½å¯èƒ½èµ°åˆ°category\n\n2.3.4.2\nTransition Probability Starting from the Given Instance. Given an instance $i$â€‹, the transition probability $P_{L A}$â€‹ from $i$â€‹ to one of its attributes $a_{j}^{i}$â€‹ in the built graph is\n\n\nå°±æ˜¯ä¸€ä¸ªåŠ æƒ\n\n\nP_{I A}\\left(i, a_{j}^{i}\\right)=\\alpha \\cdot \\frac{W_{e i g h t}\\left(a_{j}^{i}\\right)}{\\sum_{j=1}^{n} W e i g h t\\left(a_{j}^{i}\\right)}\nwhere $\\alpha \\in[0,1]$â€‹â€‹ is a constant, Weight $\\left(a_{j}^{i}\\right)$â€‹â€‹ is the reciprocal value of the frequency that $\\left(a_{j}^{i}\\right)$â€‹â€‹â€‹â€‹ occurs in the attribute sets of all the classes in Wikipedia.\nThe fewer classes an attribute is shared by, the more representative this attribute is.\nThe lower frequency of an attribute, the higher the weight.\n\n2.3.4.3\nTransition Probability Starting from the Given Instance. Given an instance $i$, the transition probability $P_{I S}$ from $i$ to one of its most similar instance $s_{r}^{i}$ in the built graph is defined as\n\n\nP_{I S}\\left(i, s_{r}^{i}\\right)=(1-\\alpha) \\cdot \\frac{\\operatorname{IISS}\\left(i, s_{r}^{i}\\right)}{\\operatorname{IISS}(i, *)}\nå®ä½“åˆ°ç›¸ä¼¼è¯çš„æ¦‚ç‡\n$\\text { where } \\alpha \\in[0,1] \\text { is a constant, } I I S S\\left(i, s_{}^{i}\\right) \\text { is the Integrated Instance Similar Score between }$â€‹ $i$â€‹ and $s_{r}^{i}, \\operatorname{IISS}(i, )$â€‹ is the sum of Integrated Instance Similar Score between $i$â€‹â€‹â€‹â€‹ and each of its most similar instances.\n\n2.3.4.4\nTransition Probability Starting from an Attribute. Given an instance $i$, the transition probability $P_{A C}$ from the attribute $a_{j}^{i}$ to a class $c_{k}^{i}$â€‹ in the built graph is defined as\n\n\nP_{A C}\\left(a_{j}^{i}, c_{k}^{i}\\right)=\\frac{1}{\\left|N_{C}\\right|}\nä¸€ä¸ªå±æ€§è¢«è¶Šå°‘çš„ç±»æ‹¥æœ‰ï¼Œåˆ™ä»£è¡¨æ€§è¶Šé«˜\n\na1 10000 ä¸ªç±»æœ‰ -&gt; 1/10000\na2 100ä¸ªç±»æœ‰ $\\rightarrow$ 1/100\næˆ‘ä»¬çš„ç›®çš„æ˜¯æ˜¯ä¸ºäº†ä»iå‡ºå‘èƒ½èµ°åˆ°æ­£ç¡®çš„typeï¼Œæˆ‘ä»¬å¸Œæœ›èµ°åˆ°æœ€å…·ä»£è¡¨æ€§çš„å±æ€§ï¼Œé€šè¿‡å…·æœ‰ä»£è¡¨æ€§çš„å±æ€§èµ°åˆ°æœ€ç»ˆçš„typeï¼Œé‚£ä¹ˆiå°±æœ‰è¶Šå¤§å¯èƒ½æ€§å±äºæŸä¸ªtype\n\n\nWhen walking a step from an instance to an attribute, the walk tends to choose the most representative attribute so that it has better chance to walk to the correct classes, i.e., types.\n\nå®ä½“æ¸¸èµ°æ—¶å€¾å‘äºèµ°æœ€å…·ä»£è¡¨æ€§ç‰¹å¾çš„è·¯å¾„ï¼Œä»è€Œæ‰¾åˆ°æ­£ç¡®çš„class\n\n\nwhere $N_{C}$â€‹ is the number of the classes that have edges connecting $a_{j}^{i}$â€‹ in the built graph.\nFor example, $P_{A C}\\left(a_{1}, c_{2}\\right)=P_{A C}\\left(a_{3}, c_{2}\\right)=0.5$â€‹\n\n\n\nç”¨$a_j$â€‹åˆ°$c_i$â€‹â€‹çš„å˜æ•°çš„å€’æ•°æ¥è¡¨ç¤ºè¾¹çš„æ¦‚ç‡\n\n2.3.4.5 processa. Starting from an instance $i$, the walk may get to an attribute $a_{j}^{i}$ either by the directed edge from $i$ to $a_{j}^{i}$ with the transition probability $P_{I A}\\left(i, a_{i}^{i}\\right)$ or by two steps through one of $i$ â€˜s most similar instances $s_{r}^{i}$ with the transition probabilities. $P_{L S}\\left(i, s_{n}^{i}\\right)$ and $P_{L A}\\left(s_{x}^{i}, a_{i}^{i}\\right) .$â€‹â€‹\nb. Starting from an attribute $a_{j}^{i}$, walk a random step to one of the classes $c_{k}^{i}$ with the transition probability $P_{A C}\\left(a_{j}^{i}, c_{k}^{i}\\right)$.c. Based on the random walk process, the probability starting from the instance $i$ to a class $c_{k}^{i}$ is computed as\n\n\\begin{aligned}\nP_{r g w}\\left(i, c_{k}^{i}\\right)=& \\sum_{j=1}^{n^{+}} P_{I A}\\left(i, a_{j}^{i}\\right) \\cdot P_{A C}\\left(a_{j}^{i}, c_{k}^{i}\\right)+\\\\\n& \\sum_{r=1}^{t} P_{I S}\\left(i, s_{r}^{i}\\right) \\cdot \\sum_{j=1}^{n^{+}} P_{I A}\\left(s_{r}^{i}, a_{j}^{i}\\right) \\cdot P_{A C}\\left(a_{j}^{i}, c_{k}^{i}\\right)\n\\end{aligned}d. After normalizing $P_{r g w}\\left(i, c_{k}^{i}\\right)$, if it is greater than a threshold, then $c_{l}^{i}$ is inferred as $i$ â€˜s type.\n3. Type Inference from Text\nTwo steps on type inference from text: \n\nType extraction, which extracts the types of each entity from the first sentence of its corresponding article. \nä¸ºç»´åŸºç™¾ç§‘ç¬¬ä¸€å¥è¯è¿›è¡ŒæŠ½å–\nThe first sentence in each article gives a textual definition of each entity, and it usually provides important type information.\n\n\nType disambiguation, which links extracted types to correct Wikipedia entities. \nSince the types extracted in the first step are just plain strings, the second step aims to assign real senses to these types.\næŠŠæå–çš„ä¿¡æ¯æ˜ å°„åˆ°classçš„å®ä½“ï¼Œè¿™æ ·å°±è¾¾åˆ°äº†æ¶ˆæ­§\n\n\n\n\nType inference with a lightweight Syntactic Pattern: Type Extraction \n\nä¸ºç»´åŸºç™¾ç§‘ç¬¬ä¸€å¥è¯è¿›è¡ŒæŠ½å–\nTo extract entity types from the first sentences in Wikipedia articles, LHD directly applies a simple syntactic pattern as follows\n\n\n\n\n\nwhere A is a sequence of any tokens, and B denotes candidate types.\nType inference with a lightweight Syntactic Pattern: Type Extraction \nOnly using the pattern to extract entity types is effective but the precision cannot be guaranteed. Thus, several heuristics are proposed to improve the extraction quality.\nç®€å•ä½†æ˜¯æœ‰å™ªéŸ³ï¼Œæ¶ˆé™¤å™ªéŸ³\n\n\n\n\n\nSearch Linker. This linker takes the extracted type as the input, and leverages the Wikipedia Search API to return the disambiguated Wikipedia article.\nç”¨è¿™ä¸ªAPIå»æ£€æŸ¥\n\n\n\nExercise1)Given the Wikipedia article page of â€œIntelliJ IDEAâ€, including the first sentence, categories, and the infobox. Please write correct types from them (directly use plain strings).\n\n\nç¬¬ä¸€å¥è¯ï¼šintegrated development environment(IDE)\ncategoriesï¼šFree integrated development environmentsï¼ŒIntegrated development environments, Java development toolsï¼ŒProducts\nInfoboxï¼šSoftware\n\n4. Taxonomy Inductionï¼ˆåˆ†ç±»å½’çº³ï¼‰4.1 directed acyclic graph\nA taxonomy is a directed acyclic graph consisting of is-a relations between entities, including conceptual entities and individual entities.\n\nexample: a part of the taxonomy of Google products\n\n\n\n4.2 not form a taxonomy\nHere, Taxonomy induction is to induce a taxonomy from the online encyclopedia.\n\n\n\n\nWikipedia has its own categorization system, but categories do not form a taxonomy with a fully-fledged subsumption hierarchy, so it is only a thematically organized thesaurus.\nè¿™é‡Œæ„æ€æ˜¯è®²pediaçš„å±‚çº§å…³ç³»å¯èƒ½å’Œæˆ‘ä»¬æƒ³è¦çš„IsAå…³ç³»ä¸ä¸€æ ·ï¼Œæ‰€ä»¥éœ€è¦é‡æ–°ç”Ÿæˆ\n\n\n\n\n\nè“è‰²æ¡†ä¸æ˜¯æ­£ç¡®çš„ä¸‹ä½è¯\n\n4.3 Solution\nTaxonomy induction from Wikipedia is to refine the Wikipedia category system by removing not-is-a relations. (WikiTaxonomy)\n\nThe first step - Pre-Cleansing: \n\né¢„å¤„ç†ï¼Œæ€»ç»“pediaé‚£äº›ç”¨äºç®¡ç†çš„è¯æ¡ï¼Œåº”è¯¥åˆ å»\nRemove the categories used for Wikipedia administration, i.e., remove the categories whose labels contain any of the following strings: wikipedia, wikiprojects, lists, mediawiki, template, user, portal, categories, articles, and pages. \nWikipedia organizes many category pairs using patterns: Y X and X by Z (e.g., Miles Davis albums, Albums by artist)\npattens å»ç»„ç»‡çš„è¿™äº›pairåªæ˜¯ä¸ºäº†ç®¡ç†ï¼Œå¹¶ä¸æ˜¯IsA\n\nThe relation between these categories is defined as is-refined-by, which is to better structure and simplify the categorization system and should be removed.\n\n\n\nThe second step - Syntax-based Methodï¼š \n\nåŸºäºè¯­æ³•çš„æ–¹æ³•\nif a category pair share the same lexical head, then there exists an is-a relation between these two categories, \nä¸­å¿ƒè¯ä¸€æ ·ï¼Œå°±æœ‰IsA\ne.g., British Computer Scientists is-a Computer Scientists \n\n\nif the lexical head of one of the category occurs in non-head position in the other category, then a not-is-a relation is labeled between these categories. \nå¦‚æœå…¶ä¸­ä¸€ä¸ªç±»åˆ«çš„è¯å¤´å‡ºç°åœ¨å¦ä¸€ä¸ªç±»åˆ«çš„éè¯å¤´ä½ç½®ï¼Œé‚£ä¹ˆè¿™äº›ç±»åˆ«ä¹‹é—´çš„å…³ç³»å°±è¢«æ ‡è®°ä¸ºnot-is-aå…³ç³»ã€‚\ne.g., Crime comics not-is-a Crime\n\n\n\n\nThe third step - Connectivity-based Method ï¼š\n\n\n\nFor each category $c$, we find the article titled as the category name, e.g., article Microsoft for category Microsoft;\nOn the found article, we collect all categories whose lexical heads are plural nouns caSet $=\\left\\{c a_{1}, c a_{2}, \\ldots, c a_{n}\\right\\}$\nFor each $c$ â€˜s super category $s c$ in the category system, we label the relation between $c$ and $s c$ as $i s-a$, if the head lemma of $s c$ matches the head lemma of at least one category in caSet.\n\n\n\nThe fourth step - Lexico-Syntactic based Methodï¼š \nlexico-syntactic patterns are leveraged to identify is-a and not-is-a relations between categories from large-scale corpora, e.g., all article in Wikipedia.\n\n\n\n\n\nThe fifth step - Inference based Methodï¼š \npropagate the previously found relations based on the properties of transitivity of the is-a relation.\n\n\n\n\n4.4 Exercise\nPlease extract a taxonomy from the following sentence (denote the answer as A is-a B):\nIBM, AMD, and Intel are High-tech companies using nanotechnology for several years.\nHigh-tech is-a company\nIBM is-a High-tech company\nAMD is-a High-tech company\nIntel is-a High-tech company\n\n\n\n","categories":["KnowledgeEngineering"]},{"title":"Knowledge Graph Querying","url":"/2021/08/15/knowledge%20engineering/13.%20Knowledge%20Graph%20Querying/","content":"Knowledge Graph Querying\n1. RDF Query Language: SPARQL\nW3C Stack\nSPARQL is an RDF query language, that is, a semantic query language for databases, able to retrieve and manipulate data stored in RDF format.\n\n\n\nSPARQL stands for\n\n(originally) Simple Protocol and RDF Query Language.\n(now) SPARQL Protocol and RDF Query Language.\n\n\nHow to get information from RDF graphs by SPARQL?\n\nPattern matching\nPattern: describe subgraphs of the queried RDF graph\nMatching: match the pattern to the subgraphs to contribute an answer\nBuilding blocks: graph patterns (i.e. RDF graphs with variables)\n\n\n\n\n\n\n\n\nå­å›¾ä¸çŸ¥è¯†å›¾è°±åšåŒ¹é…ï¼ŒæŠŠçŸ¥è¯†å›¾è°±ä¸­æ‰€æœ‰ä½äºä¸­å¿ƒçš„è¯æ‹¿è¿‡æ¥\n\n1.1 SPARQL Example\n1.2 Components of SPARQL Queries\n\nPrologue\n\nPrefix definitions for compact URIs;\nAttention (difference w.r.t. Turtle): No period (â€œ.â€) character as separator.\n\n\nQuery Form\n\nSELECT, DESCRIBE, CONSTRUCT or ASK\n\n\nDataset specification\n\nFrom\nSpecify the RDF dataset to be querying\n\n\nQuery pattern\n\nWHERE clause specifies the graph pattern to be matched\næŒ‡æ˜ä»€ä¹ˆæ ·çš„è¯­å¥éœ€è¦è¢«åŒ¹é…\n\n\nSolution modifiers\n\nOrder: put the solutions in order; \nProjection: choose certain variables; \næŒ‡å®šè¿”å›ç‰¹å®šå˜è„¸ç»“æœ\n\n\nDistinct: ensure solutions in the sequence are unique; \nç¡®ä¿è¿”å›ç»“æœæ˜¯å”¯ä¸€\n\n\nReduced: permit elimination of some non-unique solutions; \né˜²æ­¢åˆ é™¤é‡å¤\n\n\nOffset: control where the solutions start from in the overall sequence of solutions; \nä»ç¬¬nä¸ªè¿”å›\n\n\nLimit: restrict the number of solutions.\né™åˆ¶è¿”å›æ•°é‡\n\n\n\n\n\n2. SPARQL\nSPARQL Syntax (RDF term syntax)\nSyntax for IRI\nSyntax for literals\nSyntax for variables\nSyntax for blank nodes\nGraph Patterns for Query Pattern\nTriple Pattern\nDifferent Graph Patterns\n\n\n\n2.1 SPARQL Syntax: RDF Term Syntax\nSyntax for IRI\nIRIs are a generalization of URIs and are fully compatible with URIs and URLs.\nThe following fragments are some of the different ways to write the same IRI:\n\n\n\n\n\nä¸€æ—¦å®šä¹‰BASEï¼Œé‚£ä¹ˆæ‰€æœ‰çš„éƒ½æ˜¯è¿™ä¸€ä¸ªï¼›PREFIXåˆ™ä¸åŒ\n\nThe general syntax for literals\n\nA string (enclosed in either double quotes, â€œâ€¦â€, or single quotes, â€˜â€¦â€™);\nWith either an optional language tag (introduced by @) or an optional datatype IRI or prefixed name (introduced by ^^).\n\n\n\n\n\nå­—ç¬¦ä¸²ç”¨å•å¼•å·æˆ–åŒå¼•å·çš†å¯\n\nSyntax for query variables\n\nQuery variables in SPARQL queries have the global scope\nUse of a given variable name anywhere in a query identifies the same variable.\n\n\nVariables are prefixed by either â€œ?â€ or â€œ\\$â€;\nThe â€œ?â€ or â€œ\\$â€‹â€ is not part of the variable name.\n\n\n\n\n\n\n\næŸ¥æ‰¾æ‰€æœ‰è°“è¯­æ˜¯nameçš„ä¸‰å…ƒç»„ï¼Œè¿”å›å…¶å¹¶äº\n\nSyntax for blank nodes\n\nç©ºèŠ‚ç‚¹å°±æ˜¯è¡¨ç¤ºå˜é‡\nBlank nodes in graph patterns act as non-distinguished variables, not as references to specific blank nodes in the data being queried.\nBlank nodes are indicated by either the label form, such as â€œ_:abcâ€, or the abbreviated form â€œ[]â€.\nA blank node that is used in only one place in the query syntax can be indicated with [].\n\n\nThe same blank node label cannot be used in two different basic graph patterns in the same query.\n\n\n\n\n\nTriple Patterns\nare basic units of graph patterns;\nare written as a whitespace-separated list of a subject, predicate and object;\nThere are abbreviated ways of writing some common triple patterns;\nThe following examples express the same query:\n\n\n\n\nTriple Patterns: Predicate-Object Lists\n\nTriple patterns with a common subject can be written so that the subject is only written once and is used for more than one triple pattern by employing the â€œ;â€ notation.\nå…±ç”¨ä¸»è¯­\n\n\nExercise\nPlease rewrite the following triple pattern by using the same subject only once.\n\n?a int:number 123789 .?a int:pair 34567.?a int:id 666777 .\n?a int:number 123789ï¼›   int:pair 34567ï¼›   int:id 666777 .\n\nTriple Patterns: Object Lists\nIf triple patterns share both subject and predicate, the objects may be separated by â€œ,â€.\n\n\n\n\nExercise\nPlease rewrite the following triple pattern by using the same subject and predicate only once.\n\n?a string:name â€˜Bobâ€™.?a string:name â€™Bobbyâ€™.?a string:name â€˜Boobâ€™.?a string:name â€˜Bob_â€™.\n?a string:name â€˜Bobâ€™,â€™Bobbyâ€™,â€˜Boobâ€™,â€˜Bob_â€™.\n2.2 Graph Patterns\nSPARQL is based around graph pattern matching.\nDifferent types of graph patterns for the query pattern (WHERE clause):\nBasic Graph Patterns, where a set of triple patterns must match;\nGroup Graph Pattern, where a set of graph patterns must all match;\nOptional Graph patterns, where additional patterns may extend the solution;\nAlternative (Union) Graph Pattern, where two or more possible patterns are tried;\n\n\n\n2.2.1 Basic graph patternsTriple patterns are similar to RDF triples, but any component can be aquery variable.\n?x foaf:name ?name .\n\nMatching a triple pattern to a graph: bindings between variables andRDF terms.\n\nMatching of basic graph patterns:\n\nA Pattern Solution of Graph Pattern GP on graph G is any substitution S such that S(GP) is a subgraph of G. \nSimple queries \nMultiple matches \nMatching RDF literals \nBlank node labels in query results\n\n\n\n\nSimple queries\n\n\n\n\næ³¨æ„è¿”å›è¦æœ‰åˆ—å\n\nExerciseGiven the dataset and the SPARQL query as follows, please write the query results.\n# Graph: http://example/addresses@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .&lt;http://example/president25&gt; foaf:givenName &quot;Bill&quot; .&lt;http://example/president25&gt; foaf:familyName &quot;McKinley&quot; .&lt;http://example/president27&gt; foaf:givenName &quot;Bill&quot; .&lt;http://example/president27&gt; foaf:familyName &quot;Taft&quot; .&lt;http://example/president42&gt; foaf:givenName &quot;Bill&quot; .&lt;http://example/president42&gt; foaf:familyName &quot;Clinton&quot; .\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;SELECT ?name ?familyWHERE &#123; ?x foaf:givenName ?name .?x foaf:familyName ?family .&#125;\n\n\n\n\nname\nfamily\n\n\n\n\nâ€œBillâ€\nâ€œMcKinleyâ€\n\n\nâ€œBillâ€\nâ€œTaftâ€\n\n\nâ€œBillâ€\nâ€œClintonâ€\n\n\n\n\n\nMultiple Matches\n\n\nExercise\nGiven the dataset and the SPARQL query as follows, please write the query results.\n\n# Graph: http://example/addresses@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .&lt;http://example/president25&gt; foaf:givenName &quot;Bill&quot; .&lt;http://example/president25&gt; foaf:familyName &quot;McKinley&quot; .&lt;http://example/president27&gt; foaf:givenName â€œBob&quot; .&lt;http://example/president27&gt; foaf:id 159486.&lt;http://example/president42&gt; foaf:givenName â€œMarry&quot; .&lt;http://example/president42&gt; foaf:familyName &quot;Clinton&quot; .\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;SELECT ?name ?familyWHERE &#123; ?x foaf:givenName ?name .?x foaf:familyName ?family .&#125;\n\n\n\n\nname\nfamily\n\n\n\n\nâ€œBillâ€\nâ€œMcKinleyâ€\n\n\nâ€œMarryâ€\nâ€œClintonâ€\n\n\n\n\n\nMatching RDF literals\n\n@prefix dt: &lt;http://example.org/datatype#&gt; .@prefix ns: &lt;http://example.org/ns#&gt; .@prefix : &lt;http://example.org/ns#&gt; .@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .:x ns:p &quot;cat&quot;@en .:y ns:p &quot;42&quot;^^xsd:integer .:z ns:p &quot;abc&quot;^^dt:specialDatatype .\n\nç¬¬ä¸€ç§æ˜¯æ‰¾ä¸åˆ°ç»“æœçš„ï¼Œå› ä¸ºä¸åŠ @æ˜¯ä¸ä¸€æ ·çš„æ„ä¹‰\n\n\n\nBlank node labels in query results\n\nThere need not be any relation between a label in the form of a blank node in the result set and a blank node in the data graph with the same label.\n\n\nBlank node labels in query results\n\nThere need not be any relation between a label in the form of a blank node in the result set and a blank node in the data graph with the same label.\n\n\n\n\n2.2.2 Group Graph Patterns\nIn a SPARQL query string, a group graph pattern is delimited with braces: {}.\n\n\n\nBesides triple patterns, group graph pattern can contain constraints\nSyntax: Keyword FILTER followed by a filter expression\n\n\n\n\n\n\n\n\nname\nfamily\n\n\n\n\nâ€œBillâ€\nâ€œMcKinleyâ€\n\n\n\n\n2.2.3 Optional Graph Patterns\nIf the optional part does not match, it creates no bindings but does not eliminate the solution.\nOptional patterns may result in unbound variables\n\n\n\nExercise\nGiven the dataset and the SPARQL query as follows, please write the query results.\n\n\n\n\n\nAnswer\n\n\n\n\n\nname\nfamily\n\n\n\n\nâ€œBillâ€\nâ€œMcKinleyâ€\n\n\nâ€œBobâ€\n\n\n\nâ€œMarryâ€\n\n\n\n\n\nConstraints in Optional Pattern Matching\n\n\n\nMultiple Optional Graph Patterns\n\n\n2.2.4 Alternative(Union) Graph Patterns\nCombine graph patterns so that one of several alternative graph patterns may match.\n\n\nExercise\nPlease write the SPARQL query on â€œlist all volcanos located in Italy or Norwayâ€ given the following data.\n\ndepedia:Mount_Etna\trdf:type\tumbel-sc:Volcano;\t\t\t\t\trdfs:label \t&quot;Etna&quot;;\t\t\t\t\tp:location\tdbpedia:Italy.depedia:Mount_Baker\trdf:type\tumbel-sc:Volcano;\t\t\t\t\tp:location\tdbpedia:United_States.depedia:Beerenberg\trdf:type\tumbel-sc:Volcano;\t\t\t\t\trdfs:label\t&quot;Beerenberg&quot;@en;\t\t\t\t\tp:location\tdbpedia:Norway.\n\nAnswer\n\nSELECT ?volcano rdf:type umbel-sc:Volcano.WHERE &#123;    &#123;?Mount p:location dbpedia:Italy.&#125;    UNION &#123;?Mount p:location dbpedia:Norway.&#125;&#125;\n2.3 Dataset specification\nSPARQL queries are executed over an RDF dataset:\n\nOne default graph and\nZero or more named graphs (identified by an IRI).\n\n\nEvaluation of patterns w.r.t. the active graph (initially the default graph),i.e., the graph used for matching graph patterns;\n\nGRAPH clause is used for making a named graph the active graph.\n\n\n\n\nåŠ äº†Graph å­å¥å°±ä¼šåœ¨é‚£ä¹ˆgraphæŸ¥è¯¢ï¼Œå¦åˆ™å°±ä¼šåœ¨defaltæŸ¥è¯¢\n\n\n\n2.4 Query Forms\nSELECT \nResult: sequence of solutions (i.e., sets of variable bindings); \nSelected variables separated by space (not by comma!);\nAsterisk character (â€œ*â€) selects all variables in the pattern.\n\n\n\n\nExercise\nGiven the dataset and the SPARQL query as follows, please write the query results.\nDataset\n\n# Default graph (stored at http://example.org/dft.ttl)@prefix dc: &lt;http://purl.org/dc/elements/1.1/&gt; .&lt;http://example.org/bob&gt; dc:publisher &quot;Bob Hacker&quot; .&lt;http://example.org/alice&gt; dc:publisher &quot;Alice Hacker&quot; .# Named graph: http://example.org/bob@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; ._:a foaf:name &quot;Bob&quot; ._:a foaf:mbox &lt;mailto:bob@oldcorp.example.org&gt; .# Named graph: http://example.org/alice@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; ._:a foaf:name &quot;Alice&quot; ._:a foaf:mbox &lt;mailto:alice@work.example.org&gt; .\n\nSPARQL query\nFROMNAMDå¯ä»¥çœç•¥ï¼Œå› ä¸ºæ ‡æ˜äº†GRAPH ?g\n\n\n\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt;SELECT ?who ?g ?mboxFROM &lt;http://example.org/dft.ttl&gt;FROM NAMED &lt;http://example.org/alice&gt;FROM NAMED &lt;http://example.org/bob&gt;WHERE&#123;?g dc:publisher ?who .GRAPH ?g &#123; ?x foaf:mbox ?mbox &#125;&#125;\n\nAnswer:| who   | g     | mbox || â€”â€”â€” | â€”â€”â€”â€”â€” | â€”â€”â€”â€”â€” || â€œBob Hackerâ€ | \\http://example.org/bob | \\&#x62;&#111;&#x62;&#64;&#111;&#108;&#x64;&#x63;&#x6f;&#x72;&#x70;&#46;&#101;&#x78;&#97;&#x6d;&#112;&#108;&#x65;&#x2e;&#x6f;&#114;&#x67;&#92;|| â€œAlice Hackerâ€ |  \\http://example.org/alice |  |\n\n2.5 DESCRIBE\nResult: an RDF graph (i.e., all RDF triples) that describes the resources found;\nThe DESCRIBE clause can take IRIs to identify the resources.\nThe resources to be described can also be taken from the bindings to a query variable in a result set.\n\n\n\n2.6 CONSTRUCT\nResult: an RDF graph constructed from a template;\n\nTemplate: a graph pattern with the variables from the query pattern.\n\nå°†æ¨¡æ¿çš„å˜é‡æ¢æ‰ï¼Œå…¶ä½™ä¸å˜\n\n\n\ndbpedia:Mount_Etna rdfs:label â€œEtnaâ€;\nâ€‹                                       rdf:type myTypes:VolcanosOutsideTheUS.\n\ndbpedia:Beerenberg rdfs:label â€œBeerenbergâ€@en;\nâ€‹                                       rdf:type myTypes:VolcanosOutsideTheUS.\n\n\n2.7 ASK\nCheck whether there is at least one result;\nResult: true or false.\n\n\n2.8 DELETE/INSERT\nINSERT\nInsert the new RDF triples into the existing RDF graph.\n\n\n\n\n\nDELETE\nDelete some triples in the RDF graph.\n\n\n\n\n\nDELETE/INSERT\nRemove or add triples from/to the Graph Store based on bindings for a query pattern specified in a where clause.\n\n\nWITH è¡¨ç¤ºæ•°æ®é›†\n\nå…ˆåšæŸ¥è¯¢ï¼Œåœ¨å†æŸ¥è¯¢é‡Œåšæ’å…¥åˆ é™¤\n\n\n\nExercise\nGiven the dataset and the SPARQL query as follows, please write the query results.\n\nQ1@prefix org: &lt;http://example.com/ns#&gt; ._:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 ._:b org:employeeName &quot;Bob&quot; ._:b org:employeeId 67890 .\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;PREFIX org: &lt;http://example.com/ns#&gt;DELETE &#123;?person ?p ?o .&#125;where &#123;?person org:employeeId ?id .FILTER (?id &gt; 50000)?person ?p ?o .&#125;\n\nåˆ é™¤åï¼š\n\n_:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 .\n2. Q2@prefix org: &lt;http://example.com/ns#&gt; .# Graph: http://person_:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 ._:b org:employeeName &quot;Bob&quot; ._:b org:employeeId 67890 .# Graph: http://person2_:c org:employeeId 13579\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;PREFIX org: &lt;http://example.com/ns#&gt;INSERT &#123;GRAPH &lt;http://person2&gt; &#123;?person ?p ?o .&#125;&#125;where &#123;Graph: &lt;http://person&gt;&#123;?person org:employeeId ?id .FILTER (?id &lt; 50000)?person ?p ?o .&#125;&#125;\n@prefix org: &lt;http://example.com/ns#&gt; .# Graph: http://person_:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 ._:b org:employeeName &quot;Bob&quot; ._:b org:employeeId 67890 .# Graph: http://person2_:c org:employeeId 13579 ._:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 .\n2.9 CLEAR\nRemove all the triples in the specified graph(s) in the Graph Store.\n\n\n2.10 MOVE\nMove all data from an input graph into a destination graph.\n\n\n2.11 Solution Modifiers\nOnly for SELECT queries;\n\nModify the result set as a whole (not single solutions);\n\nKeywords: DISTINCT, ORDER BY, LIMIT, OFFSET.\n\nDISTINCT\nRemove duplicates from the result set.\n\n\n\n\nORDER BY\nOrder the results.\n\n\n\nASC for ascending (default) and DESC (e.g., DESC(?name)) for descending.\n\n\nLIMIT\nlimits the number of result:\nåªè¿”å›5ä¸ª\n\n\n\n\nOFFSET\nposition/index of the first reported results:\n\n\n\nOrder of the result should be predictable (combine with ORDER BY)\n\nBINDINGS\n\n\nVALUE\nadd data to the query directly.\nå¢åŠ é™åˆ¶\n\n\n\n\nAGGREGATES\nallows for the grouping of solutions and\n\nthe computation of values over the groups.\n\n\n\n\nGROUP BY groups the solutions; (i.e., students who attend the same lecture)\n\nCOUNT is an aggregate function that counts the solutions within a group; (i.e., number of students in the lecture) \n\nHAVING filters aggregated values\nQuestion: Please use natural language to explain this SPARQL query!\næŸ¥é€‰è¯¾äººæ•°è¶…è¿‡5äººçš„è¯¾\n\n\n\nNEGATION:\n\n\nQuestion: Please use natural language to explain the above SPARQL queries!\n\n","categories":["KnowledgeEngineering"]},{"title":"Knowledge Graph Alignment","url":"/2021/08/15/knowledge%20engineering/12.%20Knowledge%20Graph%20Alignment/","content":"Knowledge Graph Alignment\n1. Why do we need Knowledge Graph Alignment?\nKnowledge graph construction needs to fuse the data from multiple sources!\n\n\n\nIdentifying the same entity with different descriptions from multiple sources is the key of knowledge graph alignment!\n\n\n\næˆ‘ä»¬å¸Œæœ›æŠŠä¸åŒæºçš„åŒä¸€ä¿¡æ¯è¿›è¡Œèåˆ\n\nThe Same Entity in Multiple Sources\n\nKnowledge graph alignment identifies relationships between classes (equivalence, subClassOf, and etc.), properties (equivalence, subPropertyOf, and etc.), and instances (sameAs).\n\n\n\nKnowledge Graph Alignment consists of: \nontology matching (i.e., schema matching), \ninstance matching.\n\n\n\n2. Ontology Matching (æœ¬ä½“åŒ¹é…)ï¼š\nIt is the process of finding correspondences (i.e., relationships) between classes (or properties) of different ontologies.\nåœ¨ä¸åŒçš„æœ¬ä½“å¯»æ‰¾åŒ¹é…çš„ç±»åˆ«å’Œå±æ€§\nä½œç”¨åœ¨classå’Œpropertyä¸Š\n\n\n\n\n2.1 Benefits of Ontology Matching\nCreating global ontologies from local ontologies\næ•´åˆå…¨å±€æœ¬ä½“\n\n\nReuse information between ontologies\nå…¨å±€æœ¬ä½“æ˜¯å…¬è®¤çš„çŸ¥è¯†ï¼Œåˆ™ä¸ç”¨å†é‡æ–°å»º\n\n\nDealing with heterogeneity\nå¤„ç†å¼‚æ„æ€§\n\n\nQueries across multiple distributed resources\nåˆ©äºåœ¨å¤šä¸ªåˆ†å¸ƒå¼æ¡ä»¶ä¸‹åšæŸ¥è¯¢\n\n\n\n2.2 Ontology Matching Process\nDefinition (Matching process) The matching process can be seen as a function $f$â€‹â€‹â€‹ which, from a pair of ontologies to match $o$â€‹â€‹â€‹ and $oâ€™$â€‹â€‹â€‹, an input alignment $A$â€‹â€‹â€‹, a set of parameters $p$â€‹â€‹â€‹ and a set of resources $r$â€‹â€‹â€‹, returns an alignment $A$â€‹â€‹â€‹ â€˜ between these ontologies:\n\n\nA^{\\prime}=f\\left(o, o^{\\prime}, A, p, r\\right)\n\n\nparameters: weight, thresholdâ€¦ resources: common \nsense knowledge, domain-specific thesauriâ€¦\n\n2.3 Ontology Matching Techniques\nElement-level matching techniques\nAnalysing entities or instances in isolation \nIgnoring their relations with other entities or their instances\nä¸ä¼šè€ƒè™‘å®ä½“å¤–éƒ¨çš„å…³ç³»ï¼Œåªè€ƒè™‘è¯ä¹‹é—´çš„å†…éƒ¨å…³ç³»\n\n\nStructure-level techniques\nAnalysing how entities or their instances appear together in a structure (e.g. by representing ontologies as a graph)\nä¼šè€ƒè™‘å®ä½“å‘¨å›´çš„å…³ç³»ï¼Œä¾‹å¦‚$IsA$\n\n\n\n2.4 Element-level Matching Techniques: String-based2.4.1 Prefix\ntakes as input two strings and checks whether the first string starts with the second onenet $=$ network; but also hot $=$â€‹ hotel \nåˆ©ç”¨å‰ç¼€è¿›è¡ŒåŒ¹é…ï¼Œå¦‚æœå‡ºç°å‰ç¼€å®Œå…¨ç­‰äºå¦ä¸€ä¸ªè¯ï¼Œåˆ™å½¢æˆåŒ¹é…\n\n2.4.2 Suffix\ntakes as input two strings and checks whether the first string ends with the second one\nID = PID; but also word $=$â€‹ sword\nåç¼€åŒ¹é…\n\n2.4.3 Edit distance - Levenshtein distance is used here\ntakes as input two strings and calculates the number of edition operations, (e.g., insertions, deletions, substitutions) of characters required to transform one string into another\nnormalized by length of the maximum string\n\n\n\nè¿™é‡Œeditorä¿®æ­£ä¸º$2/7$\n\n2.4.4 N-gram\ntakes as input two strings and calculates the number of common n-grams (i.e., sequences of $n$ characters) between them, normalized by $\\max ($ length $($ string 1$)$, length $($ string 2$))$\nExample:\ntrigrams(nikon) $=\\{$ nik, iko, kon $\\}$\ntrigrams(nike) $=\\{$ nik, ike $\\}$\n$\\operatorname{sim}($ nikon, nike $)=1 / 3$â€‹â€‹\n\n\n\n2.4.5 Exercise\nCompute the trigram based similarity between two strings University and Universe\n\ntrigrams(University)={Uni,niv,ive,ver,ers,rsi,sit,ity}\n\ntrigrams(Universe)={Uni,niv,ive,ver,ers,rse}\n\n$\\text{sim(University,Universe)}=5/8$\n\n\n2.5 Element-level Matching Techniques2.5.1 Language-basedTokenization\n\nparses names into tokens by recognizing punctuation, cases\nHands-Free_Kits $\\rightarrow\\langle$ hands, free, kits $\\rangle$Lemmatization\nanalyses morphologically tokens in order to find all their possible basic formsKits $\\rightarrow$ Kit\n\nElimination\n\ndiscards â€œemptyâ€ tokens that are articles, prepositions, conjunctions, etc.\na, the, by, type of, their, from\n\n2.5.2 Resource-basedWordNet\n\nA $\\sqsubseteq B$ if $A$ is a hyponym of $B$â€‹\nBrand $\\sqsubseteq$ Name$A=B$â€‹ if they are synonyms\n\n\nQuantity $=$â€‹ Amount\n$A \\perp B$ if they are antonymsåä¹‰è¯ or the siblings in the part of hierarchy\nMicroprocessors $\\perp \\mathrm{PC}$â€‹ Board\n\n\n\n2.5.3 Constraint-based\nDatatype comparison\n\ninteger &lt; real\n\nå¯èƒ½æ˜¯subçš„å…³ç³»\n\n\ndate $\\in[1 / 4 / 200530 / 6 / 2005]&lt;$ date $[$ year $=2005]$$\\{a, c, g, t\\}[1-10]&lt;\\{a, c, g, u, t\\}+$\n\n\n\nMultiplicity comparison$\\left[\\begin{array}{ll}1 &amp; 1\\end{array}\\right]&lt;\\left[\\begin{array}{ll}0 &amp; 10\\end{array}\\right]$â€‹ \nMultiplicity:[minCardinality maxCardinality] of a property\nå®Œå…¨ä¸ç›¸äº¤ï¼Œå¯èƒ½å°±æ˜¯ä¸æƒ³å…³\n\n\nCan be turned into a distance by estimating the ratio of domain coverage of each datatype.\n\nå¦‚æœæ•´æ•°\n\n\n2.6 Structure-level Matching Techniques\nGraph-based Techniques: \nconsider the input ontologies as labeled graphs; \nif two nodes from two ontologies are similar, their neighbors may also be somehow similar (similar subclasses, superclasses, and properties).\n\n\nTaxonomy-based Techniques: \nare also graph algorithms which consider only is-a relations between classes; \nis-a links connect terms that are already similar, therefore their neighbors may be somehow similar.\n\n\nModel-based Techniques \nhandle the input ontologies based on its semantic interpretation (e.g, model-theoretic semantics); \nif two classes (or properties) are the same, then they share the same interpretation.\n\n\nInstance-based Techniques: \ncompare sets of instances of classes to decide if these classes match or not (i.e., exist equivalence or subClassOf relations).\nç”¨å®ä¾‹é›†åˆå»æ¯”è¾ƒï¼Œå¦‚æœå®Œå…¨ç›¸åŒåˆ™å°±æ˜¯equivalence\n\n\n\n2.6.1 Exercise\nCompute the Jaccard similarity between the first-order neighbor classes of the classes Car and Automobile from different ontologies.\n\n\n\n\\begin{array}{l}\nA\\cup B=\\{\\text{Vehicle},\\text{Jeep},\\text{Truck},\\text{Van}\\}\\\\\nA\\cap B=\\{\\text{Vehicle},\\text{Truck}\\}\\\\\n\\text{Jaccard}(\\text{Car},\\text{Automobile})=\\frac{|A\\cap B|}{|A\\cup B|}=\\frac{1}{2}\n\\end{array}2.7 Matcher Composition\nSequential composition of matchers\n\n\n\nProblem: error accumulation and low coverage\nç¬¬ä¸€ä¸ªæ­£ç¡®ç‡0.95ï¼Œé‚£ä¹ˆä¸€ç›´ä¹˜ä¼šè¶Šæ¥è¶Šå°1\n\n\n\n2.8 Parallel composition of matchers\n\nå¯ä»¥å¾—åˆ°ç»“æœåè¿›è¡ŒæŠ•ç¥¨æˆ–è€…åªæ˜¯å¾—åˆ°ç‰¹å¾å†é€è¿›æœºå™¨å­¦ä¹ æ¨¡å‹\ne.g.A single similarity measure composed by the similarity obtained from their names, the similarity of their superclasses, the similarity of their instances and that of their properties\n\n\n\n3. A Real-World Case: Book Ontology Matching\nGiven two ontologies $O_{1}$â€‹ and $O_{2}$â€‹, generate candidate matched classes by pairing any two classes from the two ontologies. A pair of candidate matched classes is denoted as $\\left(C_{1 \\mathrm{k}}, C_{2 \\mathrm{P}}\\right)$â€‹, and note that $\\left(C_{2 \\mathrm{p}}, C_{1 \\mathrm{k}}\\right)$â€‹â€‹â€‹â€‹ is a different pair since we need to measure the asymmetric similarities between classes.\nå¯»æ‰¾éå¯¹ç§°ç›¸ä¼¼åº¦\n\n\n\n3.1 String Similarity\nC L \\operatorname{sim}\\left(C_{1 k}, C_{2 p}\\right)=\\frac{\\operatorname{LCS}\\left(I\\left(C_{1 k}\\right), I\\left(C_{2 p}\\right)\\right)}{\\left|I\\left(C_{1 k}\\right)\\right|}\nwhere LCS means the length of the longest common substring, $l(\\cdot)$â€‹ returns the label of the class, and $|\\cdot|$â€‹ returns the length of the input label.\n\n\n3.2 Neighbor Class Set Similarity\n\\operatorname{NCSsim}\\left(C_{1 k}, C_{2 p}\\right)=\\frac{\\left|N C S\\left(C_{1 k}\\right) \\cap N C S\\left(C_{2 p}\\right)\\right|}{\\left|N C S\\left(C_{1 k}\\right)\\right|}\nwhere $\\left|\\mathrm{NCS}\\left(C_{1 \\mathrm{k}}\\right) \\cap \\mathrm{NCS}\\left(C_{2 \\mathrm{p}}\\right)\\right|$ is the size of the intersection of $\\mathrm{NCS}\\left(C_{1 \\mathrm{k}}\\right)$ and $\\operatorname{NCS}\\left(C_{2 \\mathrm{p}}\\right), N C S(\\cdot)$ returns the set of first-order neighbor classes in the given ontology.\n\n\n3.3 Neighbor Class Set Similarity\nWe submit the label l(C) of a snippets as the textual context;\nå…ˆæŠŠæœ¬ä½“æ‰”åˆ°æœç´¢å¼•æ“å¾—åˆ°ä»–çš„é•¿æ–‡æœ¬\n\n\nIn the top-k returned snippets of Web pages, the words co-occurred with l(C) in the same sentence are extracted;\næŠŠæœç´¢ä¸­çš„topkä¸ªabstractæœé›†ï¼Œç„¶åæŠ½å–å…±ç°è¯\n\n\nAfter removing the stopwords and the words with low frequency (e.g., less than 3), TF-IDF is adopted for weighting each word $u$â€‹ :\nå¯¹äºæ‰€æœ‰å…±ç°è¯å¯ä»¥è®¡ç®—tf-idf\nå³åˆå¹¶æ‰€æœ‰çš„abstractå¯ä»¥è®¡ç®—tfï¼Œä»¥åŠè®¡ç®—documentçš„freq\n\n\n\n\nw_{u}=t f_{u} \\cdot i d f_{u}\nTextual Context Similarity.\nThe textual context vector representation of a class $C$ is denoted as: $\\mathrm{TC}(\\mathrm{C})=&lt;\\mathrm{w}_{1}(\\mathrm{C}), \\mathrm{w}_{2}(\\mathrm{C}), \\ldots, \\mathrm{w}_{\\mathrm{n}}(\\mathrm{C})&gt;$, and $n$ is the number of all words.\nThe textual context similarity between classes $C_{1 \\mathrm{k}}$ and $C_{2 \\mathrm{p}}$â€‹ is computed as:\nå†…ç§¯é™¤ä»¥æ¨¡\n\n\n\n\n\n\nT C \\operatorname{sim}\\left(C_{1 k}, C_{2 p}\\right)=\\frac{\\sum_{v=1}^{n} T C\\left(C_{1 k}\\right)_{v} \\cdot T C\\left(C_{2 p}\\right)_{v}}{\\sum_{v=1}^{n} T C\\left(C_{1 k}\\right)_{v}{ }^{2}}3.4 Instance Set Similarity\n\\operatorname{ISSim}\\left(C_{1 k}, C_{2 p}\\right)=\\frac{\\left.\\mid \\operatorname{IS(C}_{1 k}\\right) \\cap \\operatorname{IS}\\left(C_{2 p}\\right) \\mid}{\\left.\\mid \\operatorname{IS(C}_{1 k}\\right) \\mid}\nwhere $I S(\\cdot)$â€‹ returns the instance set of the class, and we can identify the same book instances using the ISBN number in the book domain.\n\n\n3.5 Exercise3.5.1\nGiven two ontologies as follows, compute the String Similarity, Neighbor Class Set Similarity, Instance Set Similarity (introduced in the real-world case: book ontology matching) on the class pairs (book, Textbook) and (Textbook, book), respectively.\n\n\n\nStringSimilarity\nlen(book)=4,len(Textbook)=8\nsubstring(book, Textbook)=book\nlen(substring)=4\nstrIngSimilarity(book, Textbook)=4/4=1\nstrIngSimilarity(Textbook, book)=4/8=1/2\n\n\nNeighbor Class Set Similarity\nNeighbor(book)={literature,volume}\nNeighbor(Textbook)={volume,Engineering,Science}\nNeighbor Class Set Similarity(book, Textbook)=1/2\nNeighbor Class Set Similarity(Textbook, book)=1/3\n\n\nInstance Set Similarity\nInstance(book)={Red Sorghum,Introduction to Algorithm}\nInstance(Textbook)={Red Sorghum}\nInstance Set Similarity(book, Textbook)=1/2\nInstance Set Similarity(Textbook, book)=1\nGiven two ontologies $O_{1}$â€‹ and $O_{2}$â€‹, generate candidate matched classes by pairing any two classes from the two ontologies. A pair of candidate matched classes is denoted as $\\left(C_{1 \\mathrm{k}}, C_{2 \\mathrm{P}}\\right)$â€‹, and note that $\\left(C_{2 \\mathrm{p}}, C_{1 \\mathrm{k}}\\right)$â€‹ is a different pair since we need to measure the asymmetric similarities between classes.\n\n\n\n3.5.2\nQuestion: now we have String Similarity, Neighbor Class Set Similarity, Textual Context Similarity, and Instance Set Similarity, please tell which one belongs to the element-level matching techniques? Which one is a structure-level matching technique?\nString Similarity,Textual Context Similarity element-level matching techniques\nNeighbor Class Set Similarity, Instance Set Similarity structure-level matching technique\n\n\n\n3.6 Aggregate these similarities:self-training\nAggregate these similarities by a semi-supervised learning strategy: self-training, for binary classification on subClassOf relations: \n\nIn each iteration, self-training accepts the labeled data as training data and learns a classifier. \nThen the classifier is applied to the unlabeled data and adds class pairs of high confidence to the labeled data to train a new classifier for the next iteration. \nThe whole process will terminate if the difference between the predicted labels of the class pairs given by classifiers in the two consecutive iterations is smaller than a threshold or the maximal number of iterations is achieved.\nç”¨å°‘é‡æ•°æ®è®­ç»ƒå¾—å¼±åˆ†ç±»å™¨ï¼Œä»è€Œé¢„æµ‹æ— æ ‡ç­¾æ•°æ®ï¼Œå¾—åˆ°é«˜ç½®ä¿¡åº¦å¾—æ•°æ®ä¹‹åå†ç»§ç»­è®­ç»ƒï¼Œç»ˆæ­¢æ¡ä»¶ï¼šåˆ°è¾¾æŒ‡å®šepochæˆ–è€…æ ‡ç­¾æ•°æ®ä¸å†æ”¹å˜\n\n\nThe binary classifier can use SVM, Random Forest, Neural Networks, and etc.\n\nä¼ ç»Ÿæ–¹æ³•SVMï¼ŒRandom Forestçš„æ•ˆæœæœ€å¥½\n\n\nIn each iteration, rules are applied to filter out misclassified relations.\n\næ¯æ¬¡è¿­ä»£è¿‡ç¨‹ç”¨è®¾å®šçš„è§„åˆ™è¿‡æ»¤æ‰é”™è¯¯åˆ†ç±»\n\n\nRULE 1:\n\nGiven two book classes $C_{1 \\mathrm{k}}$â€‹ and $C_{2 \\mathrm{p}}$â€‹, if the label string $l\\left(C_{1 \\mathrm{k}}\\right)$â€‹ is the suffix of the label string $l\\left(C_{2 \\mathrm{p}}\\right)$â€‹, and $l\\left(C_{2 \\mathrm{p}}\\right)$â€‹ does not contain â€œä¸â€, â€œå’Œâ€, and â€œ\\&amp;â€, then $C_{2 \\mathrm{p}}$â€‹ is the subclass of $C_{1 \\mathrm{k}}$â€‹â€‹â€‹.\nExample: ä¼ä¸šç®¡ç† subClassOf ç®¡ç†\nå¦‚æœæœºå™¨å­¦ä¹ è¯¯åˆ†ç±»äº†å³ç»™äº†å¾ˆä½çš„ç½®ä¿¡åº¦ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™æ¡è§„åˆ™è¿›è¡Œä¿®æ­£\n\n\nRULE 2;\n\nGiven two book classes $C_{1 \\mathrm{k}}$ and $C_{2 \\mathrm{p}}$, if the label string $l\\left(C_{2 \\mathrm{p}}\\right)$ contains â€œä¸â€ or â€œå’Œâ€ or â€œ\\&amp;â€, then using these symbols as separators to segment the label string $l\\left(C_{2 \\mathrm{p}}\\right)$. If one of the segmented strings and $l\\left(C_{1 \\mathrm{k}}\\right)$ are the same, then $C_{1 \\mathrm{k}}$ is the subclass of $C_{2 \\mathrm{p}}$â€‹â€‹â€‹.\nå…ˆåˆ†å‰²å†çœ‹åŒ…å«å…³ç³»\nExample: è®¡ç®—æœº subClassOf è®¡ç®—æœºä¸äº’è”ç½‘\n\n\n\nWith generated subClassOf relations, how to get equivalent classes?\n\nA=B -: A subclassOf B and B subclassOf A\n\n3.7 OAEI\n\n\nKnowledge Graph Alignment consists of: \n\nontology matching (i.e., schema matching), \ninstance matching.\n\n\nInstance Matching (å®ä¾‹åŒ¹é…)ï¼šIt is the process of finding different instances of the same real-world objects.\n\n\n\n\n\nå¹³å‡å››ä¸ªå®ä½“æœ‰4ä¸ªurl\n\n4. Instance Matching with Knowledge Graph Embedding\nEmbedding maps discrete variables to continuous vector representations;\nEmbedding learning techniques has achieved great progress in CV, NLP, Speech Recognition, and etc.;\nKnowledge Graph Embedding aims to map entities and relations to continuous vector representations.\n\n\n\nConventional approaches are challenged by the symbolic, linguistic and schematic heterogeneity of independently-created KGs\nEmbedding-based approaches measure entity similarities based on entity embeddings\nThree key modules\nKG embedding\nAlignment inference\nHow they interact\n\n\n\n\n\n\n\nKnowledge graph embedding: TransE\n\n\n\nè®­ç»ƒå¤šä¸ªTranseï¼Œæ¥åšä¸‰å…ƒç»„å¯¹é½\n\nCorpora: (partially-aligned) multilingual KGs\n\nEnabling: inferable embeddings of multilingual semantics\n\nCan be applied to:\n\nKnowledge alignment\nCross-lingual Q&amp;A\nMultilingual chat-bots\n\n\n\n\n4.1 MTransE\n\nKnowledge modelå’ŒTranseä¸€æ ·\nAlignment modelä¸ºäº†ç¼©å°éœ€è¦åŒ¹é…çš„ä¸åŒè¯­è¨€çš„ä¸‰å…ƒç»„\n\n4.2 Different alignment techniques\n\n5. Instance Matching with Rules\nThe Same Entity in Multiple Sources\n\n\n\n\nseedsæ˜¯é¢„å…ˆå¾—åˆ°çš„ä¸€äº›æ ‡ç­¾æ•°æ®\n\nAutomatically discovering and refining dataset-specific matching rules in iterations\n\nDeriving these rules by finding the most discriminative datacharacteristics for a given data source pair.\n\n\n\n5.1 Seeds - Lightweight Entity Matching\nPunctuation Cleaning:\nSpace Shuttle Endeavour $\\approx$â€‹ Space Shuttle â€œEndeavourâ€\nå»æ‰æ ‡ç‚¹åï¼Œå¦‚æœå­—ç¬¦ä¸²å®Œå…¨ç›¸åŒï¼Œåˆ™å¯ä»¥è®¤ä¸ºè¿™ä¸¤ä¸ªå®ä½“æ˜¯å®Œå…¨åŒ¹é…çš„\n\n\n\n\n\nRedirects Information:\n\né‡å®šå‘ï¼šç™¾åº¦ç™¾ç§‘ä¼šè‡ªåŠ¨å°†ç½‘é¡µé‡å®šå‘åˆ°å¦ä¸€ä¸ªé¡µé¢ï¼Œè¯¥é¡µé¢çš„æ ‡é¢˜æ˜¯é‡å®šå‘ä¿¡æ¯\nA redirects to B means A and B are synonyms\n\n\nMining Properties Equivalences\n\nå½“æˆ‘ä»¬å·²çŸ¥ä¸¤ä¸ªå®ä½“ç­‰ä»·ï¼Œè€Œè¿™ä¸¤ä¸ªå®ä½“éƒ½æœ‰å¤šä¸ªå±æ€§å€¼å¯¹ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åšå±æ€§åŒ¹é…\n\n\n\n\n\nFor each pair of existing matched instances, their property-value pairs are merged.\nåœ¨ä¸€å¯¹å®ä¾‹å¯ä»¥æ‰¾åˆ°å¾ˆå¤šè¿™æ ·çš„å±æ€§å¯¹\n\n\n\n\n\nMatching rule (frequent set mining):\n\nç®—æ³•ï¼šAssociation Rule Mining æŠŠé¢‘ç¹å‡ºç°çš„å±æ€§å€¼å¯¹æ”¾åœ¨ä¸€èµ·ï¼Œä½œä¸ºå®ä¾‹ç­‰ä»·è§„åˆ™ï¼Œå¦‚ä»¥ä¸‹çš„ä¾‹å­\nbaidu:x and hudong:x are matched, iff.\nvalueOf(baidu:æ ‡ç­¾) = valueOf(hudong:ä¸­æ–‡å­¦å)\nand\nvalueOf(baidu:æ‹‰ä¸å­¦å) = valueOf(hudong:äºŒåæ³•)\nand\nvalueOf(baidu:çº²) = valueOf(hudong:çº²)\n\n\nThe Wrapper Algorithm\n\nä¸€å¼€å§‹ç”¨è½»é‡çº§ç®—æ³•ï¼Œä»è€ŒæŒ–æ˜å‡ºè§„åˆ™\nç„¶åå†é€šè¿‡è§„åˆ™è¿›è¡Œå®ä¾‹åŒ¹é…ï¼Œä¸æ–­è¿­ä»£\n\n\n\n\n\nThe wrapper is an implementation of Expectation-Maximization iterations.\nè¿™é‡Œä½¿ç”¨EMç®—æ³•ï¼Œå¯ä»¥è¿™ä¹ˆç†è§£ï¼Œè¿™é‡Œçš„åŒ¹é…å°±æ˜¯æˆ‘ä»¬è¦çš„å‚æ•°ï¼ˆæœªçŸ¥ï¼‰ï¼Œè€Œè§„åˆ™å°±æ˜¯æˆ‘ä»¬è¦é¢„æµ‹çš„åˆ†å¸ƒ\nThe E-step\nä¼°è®¡missing data\nThe E-step estimates the missing data (matches) using the observed data and the current estimate for the parameters (matching rules).\n\n\nThe M-step\nThe M-step computes parameters maximizing the likelihood function as the data estimated in E-step are used in lieu of the actual missing data.\nM: matches\n$\\Theta$: parameters\n\n\nL(\\theta ; M)=\\operatorname{Pr}(M \\mid \\theta)\nç»™å®šå½“å‰è§„åˆ™çš„æƒ…å†µä¸‹ï¼Œå®ä¾‹åŒ¹é…å‡ºç°çš„æ¦‚ç‡\n\nThe Likelihood Function\n\nL(\\theta ; M) \\approx \\frac{\\mid \\text { ConnectedComponent }(M) \\mid}{|\\operatorname{Edge}(M)|}\nAssuming that no equivalent instances exist in a single data source, we can infer that an instance is equivalent to at most one another from the other data source.\nIncorrect matches in $M$ may result in a node connecting to more than one other node, which is contrary to the assumption.\n\n\n\nå¦‚æœLé«˜ï¼Œé‚£ä¹ˆè§„åˆ™çš„ç½®ä¿¡åº¦å°±é«˜ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥æŠŠè¿™ä¸ªè§„åˆ™åŠ å…¥åˆ°è§„åˆ™é›†\n\nPrecisions\n\n\n\n\nSampling a certain number of output matches.\n\nThe X-axis indicates the proportions of selected seeds in complete reference matches.\n\n\nQuestionWhat are the advantages and disadvantages of the embedding-based method and rule-based method for instance matching?\n\nå¦‚æœæ•°æ®è´¨é‡ä¸é«˜ï¼Œembeddingå¯¹å™ªå£°çš„å®¹å¿æ€§é«˜\nå¦‚æœæ•°æ®è´¨é‡é«˜ï¼Œé‚£ä¹ˆç”¨è§„åˆ™çš„æ–¹æ³•å°±ä¼šå¸¦æ¥æ›´é«˜çš„å‡†ç¡®ç‡\n\n","categories":["KnowledgeEngineering"]},{"title":"review1","url":"/2021/08/15/knowledge%20engineering/8.%20Review/","content":"review1\n1. XML Namespaces1.1 Naming conflicts exist in different XML documentsXML document_1&lt;table&gt;&lt;tr&gt;\t&lt;td&gt;Apples&lt;/td&gt;    &lt;td&gt;Bananas&lt;/td&gt;&lt;/ tr&gt;&lt;/table&gt;\nXML document_2&lt;table&gt;\t&lt;name&gt;African Coffee Table&lt;/name&gt;    &lt;width&gt;8G&lt; /width&gt;&lt;length&gt;120&lt;/length&gt;&lt; /table&gt;\n1.2 Solution : Adding prefixes as namespacesXML document_1&lt;h:table&gt;\t&lt;h:tr&gt;\t\t&lt;h:td&gt;Apples&lt;/h:td&gt;        &lt;h:td&gt;Bananas&lt;/h:td&gt;    &lt;/h:tr&gt;&lt;/h:table&gt;\nXML document_2&lt; f:table&gt;\t&lt;f:name &gt;African Coffee lable&lt;/f:name&gt;    &lt;f:width&gt;80&lt;/f:width&gt;\t&lt;f:length&gt;120&lt;/f:length&gt;&lt;/f:table&gt;\n\n1.3 XML Namespace Syntax:\n\nURI è‹±æ–‡å­—ç¬¦   IRIä»»ä½•ç¼–ç \n\n2. RDF\nthe data model of Semantic Technologies and of the Semantic Web;\n\nstructures metadata about Web sites, pages, etc.:\n\nPage author, creator, publisher, editor,â€¦\n\nData about them: email,phone, job,â€¦\n\n\n\n\n\ncan be used for machine-readable data exchange;\n\nis introduced in W3C Recommendation of 1999 (Version 1.O);- uses XML as main syntax for serialization.\n\n\n\n\nARDF knowledge base: a directed labeled graph, i.e., Knowledge Graph\n\n\n2.1 RDF Triple (Statement)\n\nSubjects: Resource or blank node\nPredicates: Resource\nObject: Resource, literal or blank node\n\nLiterals are:\n\ndata values;\nencoded as strings;\ninterpreted by datatypes;\ntreated the same as strings without datatypes, called plain literal;\nA plain literal may have a language tag;\nDatatypes are not defined by RDF, but usually from XML Schema.\n\n\n\nTyped Literals:\nâ€œBeantown3â€™^^xsd:stringâ€œ\nThe Bay Stateâ€^^xsd:stringPlain literal and literals with language tags:\nâ€œFranceâ€â€˜Franceâ€@en\n â€œFranceâ€â€˜@frâ€œæ³•å›½â€@zhâ€œ\nâ€œFrankreichâ€@de\nEqualities for Literals:â€œ0013^^xsd:integer =â€œ13â€^^xsd:integerâ€œ123.0^^xsd:decimal= â€œ00123â€1^^xsd:integer (based on data type hierarchy)\nExercise\nDoes the datatypeâ€œå¾·å›½â€equals toâ€œå¾·å›½â€@ zh ?\n\nä¸ä¸€æ ·\n\nBlank node: unnamed resource or complex node\n\nThe set of blank nodes, the set of all lRls (named resources)and the set of all literals are pairwise disjoint;\nRepresentation of blank nodes is syntax-dependent:underline+colon+ID (Turtle syntax):_:xyz,_:bn;\nThe scope of the lD of a blank node is only the document towhich it belongs.\n\n2.2 RDF: N-ary RelationsExample:\nprefix ex: &lt;http://lexample.org/&gt; .ex: Chutneyex:hasIngredient &quot;1lb green mango&quot;,\t\t\t\t\t\t&quot;1tsp. Cayenne pepper&quot; .\n\n@prefix ex :&lt;http://lexample.orgl&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .ex:Chxtney ex:hasIngredient ex:ingredient1 . ex:ingredient1 rdf:value ex:greenMango;\t\t\t   ex:amount  &quot;11b&quot; .\n\n&lt;rdf:Description rdf:about=&quot;http://example.org/Chutney&quot;&gt;\t&lt;ex:hasIngredignt rdf:nodeID=&quot;id1&quot;/&gt;&lt;/rdf:Description&gt;&lt;rdf:Description rdf:nodeID=&quot;id1&quot;&gt;\t&lt;ex:ingredient rdf:resource=&quot;http://example.org/greenMango&quot;/&gt;\t&lt;ex:amount&gt;1lb&lt;/ex:amount&gt;&lt;/rdf:Description&gt;\n&lt;rdf:Description rdf:about=&quot;http://example.org/Chutney&quot;&gt;\t&lt;ex:hasIngredient rdf:parseType=&quot;Resource&quot;&gt;\t\t&lt;ex:ingredient rdf:resource=&quot;http://example.org/greenMango&quot;/&gt;        &lt;ex:amount&gt;1lb&lt;/ex:amount&gt;\t&lt;/ex:hasIngredient&gt;&lt;/rdf:Description&gt;\n\nsw:John sw:is_a sw:professors ;\t\tsw:has_name &quot;John Doeâ€;\t\tsw:has_id â€œ987654321&quot;.sw:John sw:is_a sw:professors .sw:John sw:has_name â€œJohn Doeâ€.sw:John sw:has_id 987654321.\n\n\n\n\n3. RDFS\nprovides a data-modeling vocabulary for RDF data;\nis an extension of the basic RDF vocabulary;\ntries to provide consistent explanations for RDF data;- allows for specifying schema knowledge;\nMothers are female\nOnly persons write books\nis a part of the W3C Recommendation.\n\n\nWhy do we need RDFS when there already exists XML Schema?\nXML Schema only defines syntax without semantics;\nXML Schema cannot reference â€œthingsâ€outside the document.\n\n\n\n3.1 RDFS: Class and InstanceGiven a triple:\nex:SemanticWeb rdf:type ex:Textbook .\nwhich characterizesâ€œFoundations of Semantic Web Technologiesâ€as aninstance of the class â€œTextbookâ€.\n\nAresource can be the member of more than one class\n\nex:SemanticWeb rdf:type ex:Book .\n\nlnstance and class names cannot be distinguished syntactically with lRls.. \n\nRDFS helps explicitly state that a resource denotes a class:\nex:book rdf:type rdfs:Class .\n\nrdfs:Class is theâ€œclass of all classesâ€ .\n\n\n3.2 Class Hierarchy (Taxonomy)\n3.3 Property and Property Hierarchy\nAllow to state that a certain property can only be between things of a certain class:\ne.g. when a is married to b, then both a and b are Persons\n\n\n\nex:isMarriedTo rdfs:domain ex:Person.ex:isMarriedTo rdfs:range ex:Person\n\nDatatypes can also be used for adding property restrictions:\n\nex:hasAge rdfs:range xsd:nonNegativeInteger\n3.4 RDFS: Reification\nHow to graphically represent a sentence by means of the blank node?\n\n\n\n3.5 Example: Reasoning with RDFS\n4. Constituents of a DL Knowledge Base\n4.1 Description Logic: ALC\nALC: the simplest DL\n\n\n\ncomplex concepts are defined as follows: \n\n\nâŠ¥ and T are conceptsï¼› \n\nFor concepts C and D, Â¬C, CâŠ“D, and CâŠ”D are concepts; \n\nFor a role r and a concept C, âˆƒr.C and âˆ€r.C are concepts \n\n\n\nExample: Student âŠ“ âˆ€attendsCourse.MasterCourse\nIt describes the concept comprising : all students that attend only master courses.\n\n\n\n4.2 Example: Are the following valid DL concepts\nğ´âˆ€ğ‘….ğµ \n(ğ´â¨…ğµ)â¨†ğ¶\n(âˆƒğ‘….ğ´)â¨…ğµ\nÂ¬ğ´â¨†ğ¶Â¬\n\n\nÃ—âˆšâˆšÃ—\n\n4.2.1 TBox:\nFor concepts C, D, a general concept inclusion (GCI) axiom has the form: C âŠ‘ D \nCâ‰¡D is an abbreviation for C âŠ‘ D and D âŠ‘ C. \na TBox (terminological Box) consists of a set of GCIs.\n\n\n\n\n4.2.2 ABox:\nan ALC ABox assertion can be of one of the following forms: \nC(a), called concept assertion \nr(a, b), called role assertion - an ABox consists of a set of ABox assertions\n\n\n\n(1) Any student must attend at least one lecture.        Student âŠ‘ âˆƒAttend.Lecture\nStudents are those who attend at least one lecture?\n\nä¸å¯¹çš„ï¼Œå› ä¸ºè¿™ä¸ªareè¡¨ç¤ºæ˜¯å®Œå…¨ç›¸ç­‰çš„å…³ç³»ï¼Œä½†æ˜¯åé¢é‚£ä¸ªconceptçš„èŒƒå›´æ›´å¤§\n\n(2) John is a brother of Mary.        Brother(John,Mary)(3) Parents are exactly those who are mothers or fathers.        Parent â‰¡ Mother âŠ” Father\n\n\n\n\n\nA set of axioms (knowledge base) is satisfiable (or consistent) if it has a model.\nIt is unsatisfiable (inconsistent) if it does not have a model.\nInconsistency is often caused by modeling errors.\nUnicorn âŠ‘ Fictitious \nUnicorn âŠ‘ Animal \nAnimal âŠ‘Â¬Fictitious\n\n\n\n5. Deductive Reasoning: Backward Reasoning\nBackward reasoning (Backward chaining) is an inference method described colloquially as working backward from the goal.\nIt is often used in entailment checking or query answering in KG.\nIt uses the rules to rewrite the query in several ways and the initial query is entailed if a rewritten query maps to the initial facts.\n\nExample1:Rule: If you are human, then you are mortal. \nHuman(x)â†’Mortal(x)Question: Is Socrates a mortal? \nSolution: Check whether Mortal(Scorates) or Human(Scorates) is true.\n\n\n5.1 Other Tasks in Logical Reasoning: Inconsistency CheckingIncoherent ontology: ontology with at least one unsatisfiable concept. Example: PhDStudent âŠ‘ Student, PhDStudent âŠ‘ Employee, Student âŠ‘EmployeeInconsistent ontology: ontology without a model. Example: PhDStudent âŠ‘ Student, PhDStudent âŠ‘ Employee, Student âŠ‘Employee, PhDStudent(John)\n\n6. TransE: Take Relation as Translation\nFor a fact (head, relation, tail), take the relation as a translation operator from the head to the tail .\n\n\n\nTransE \nFor each triple , h is translated to t by r.\n\n\n\n\n\n\nQuestion\n\n\n7. RDB2RDFDirect Mapping\n\n\n7.1 RDB2RDF: R2RML\nR2RML is a language for specifying mappings from relational to RDF data.\nA mapping takes as input a logical table, i.e.,\na database table\na database view (a virtual table collecting data from relational tables), or\nan SQL query (called an â€œR2RML viewâ€ because it is like an SQL view but does not modify the database)\n\n\n\nA triples map has three parts: - the input logical table \na subject map \nseveral predicate-object maps (combining predicate and object maps).\n\n\n\n\n\n\n\n\n\n\n8. Exercise\nPlease represent the following sentences graphically by means of blank nodes.Jonathon says cherries taste sweet.1æœˆ14æ—¥ï¼Œå›½å®¶è¯ç›‘å±€å®£å¸ƒé…šé…ç‰‡åœæ­¢ç”Ÿäº§.\n\n\n\nWhat can be inferred from the following triples using RDFS semantics?\nex:Undergraduate_student rdfs:subClassOf ex:Student .ex:Postgraduate_student rdfs:subClassOf ex:Student .ex:Professor rdfs:subClassOf ex: Academic_staff .ex:Academic_staff rdfs:subClassOf ex:University_staff .ex:Teach rdfs:domain ex:Academic_staff .ex:Teach rdfs:range ex:Student .ex:Supervise rdfs:domain ex:Professor .ex:Supervise rdfs:range ex:Postgraduate_student .ex:John ex:Supervise ex:Mary .\nex:Professor rdfs:subClassOf ex: University_staff .ex:John rdf:type ex:Professor .ex:Mary rdf:type ex:Postgraudate_student .ex:John rdf:type ex:Academic_staff .ex:John rdf:type ex:University_staff .ex:Mary rdf:type ex:Student .\n\nExpress the following sentences in Description Logics.\n\n\nLi is a student of SEU.Any person who is enrolled in a university is a college student.\n\n\nAre the following valid OWL axioms? If not, why? (class: A,B,C,D, role: R)\n\n\nAâ¨…(Bâ¨† âˆƒR)\n\n(âˆ€R.Aâ¨†B)â¨…A\n\n(Aâ¨…B)Â¬Câ¨†D\n\n\n\n5) Please write the corresponding RDF triples (in Turtle) of the following sentence: â€œGrandpas are the men who are grandparentsâ€. Specific classes are defined in the namespacehttp://semanticweb.org/. Prefixes are given as follows:@prefix sw: http://semanticweb.org/ .@prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# .@prefix owl: http://www.w3.org/2002/07/owl# .\n_:x  rdf:type  owl:class  ;     owl:intersectionOf  (sw:Man  sw:Grandparent)  ;     owl:equivalentClass  sw:Grandpa .\n\nGive a model of the following ontology\n\n\nProfessorâŠ‘FacultyMember,\n\nProfessor(Guilin Qi),\n\nhasAffiliation(Guilin Qi, SEU),\n\nStudentOf(Zhang, Guilin Qi)\n\n\nA model: \n\nâˆ†={a,b,c}\n\nI(Guilin Qi)=a, I(SEU)=b, I(Zhang)=c\n\nI( Professor)={a}, I(FacultyMember)={a},\n\nI(hasAffiliation)={(a,b)},\n\nI(StudentOf)={(c,a)},\n\n\n\nGiven the following KG, use query rewriting on the query Person(x) (this query is used for checking whether x is a person) .\n\n\n\nGiven a relational database and RDF triples, please write corresponding R2RML triples maps which can map the given RDB to RDF.\n\n\n&lt;http://data.example.com/student/001&gt; rdf:type ex:Student ;                                                                ex:id &quot;001&quot; ;                                                                ex:name &quot;Wang&quot; ;                                                                ex:major &lt;http://data.example.com/major/211&gt; .&lt;http://data.example.com/student/002&gt; rdf:type ex:Student ;                                                                ex:id &quot;002&quot; ;                                                                ex:name &quot;Wu&quot; .&lt;http://data.example.com/major/211&gt; rdf:type ex:Major ;                                                             ex:name &quot;AI&quot; .\n","categories":["KnowledgeEngineering"]},{"title":"Knowledge Graph Construction","url":"/2021/08/15/knowledge%20engineering/7.%20Knowledge%20Graph%20Construction/","content":"Knowledge Graph Construction\nKnowledge Graph Construction1. Previous Exercises1.Every teacher must teach someone\n\nCorrect Answer: TeacherâŠ‘âˆƒğ‘‡each.Human\n\n\n\nEvery finger is a bodypart and is a part-of hand.\n\n\nFinger âŠ‘ BodyPart â¨… âˆƒPart_of.Hand\n\n\n\nZhang is a teacher of SEU\n\n\nTeacher(Zhang, SEU)\n\n\n2.Give a model of the following ontology:\n\nPhDstudent âŠ” Undergraduatgestudent âŠ‘ Student,\n\nPhDstudent(John),\n\nUndergraduatgestudent(Jack),\n\nSister(Lisa,Jack),\n\nEmployee(Lisa)\n\nCorrect Answer:\n\nA model: Î”={ jo,l,ja}\nI(John)= jo, I(Lisa)=1, I(Jack)= ja\nI( PhDstudent)={ jo},\nI(Employee)={I},\nI( Undergraduatgestudent)={ja},\nI(Student)={ ja.jo}\nI(Sister)={(l,ja)}\n\n3.Write the inferred axioms using description logics after conducting classification in forward reasoning on the following axioms.:\n\nEndocarditis âŠ‘ Heart_Disease \n\nMiocardial_Infarction âŠ‘ Heart_Disease \n\nHeart_Disease âŠ‘ Disease \n\nEnterococcal_Endocarditis âŠ‘ Endocarditis\nCorrect Answer:\n\nEndocarditis âŠ‘ Disease \n\nMiocardial_Infarction âŠ‘ Disease \nEnterococcal_Endocarditis âŠ‘ Heart_Disease \nEnterococcal_Endocarditis âŠ‘ Disease\n\n2. Knowledge Graph Construction\nKnowledge Graph Construction: Extracting knowledge from heterogeneous data sources to form a knowledge graph.\n\n\n\nåŒ…è£…å™¨ï¼Œè‡ªåŠ¨æŠŠåŠç»“æ„åŒ–æ•°æ®çˆ¬å–å‡ºæ¥\n\n2.1 Knowledge Graph Construction from Structured Data\nBasics of Relational Database\nRDB2RDF: Direct Mapping &amp; R2RML\nTriple Extraction from Relational Web Tables\n\n3. Basics of Relational Databases3.1 Structuring data\nWe all structure the information we work with:\n\nSo we can find what we need, when we need it\nTo facilitateï¼ˆä¿ƒè¿›ï¼‰ evaluation, comparison, and analysis\n\n\nThe structure you select influences\n\nThe kinds of information you collect\nHow it is possible to interrogate(æŸ¥è¯¢) your data\nThe extent to which you can take advantage of your computerâ€™s data-handling abilities\nHow easy it is to share data with others\n\n\nOptions for structuring &amp; analyzing data\n\n\n\n\nA table of bibliographic(è‘—ä¹¦ç›®å½•çš„) data (not a table in relational database )\ntableä¼šå¯¹æ•°æ®é‡å¤å­˜å‚¨\n\n\n\n\n\n3.2 An alternative approach\nå…ˆåšä¸€ä¸ªä½œè€…è¡¨ï¼Œé€šè¿‡æ˜ å°„å…³ç³»ï¼Œå°†ä¸€äº›ä¿¡æ¯åˆ†å¼€è¡¨ç¤º\n\n\n\n\nå†åˆ†è¡¨ï¼ŒæŠŠå‡ºç‰ˆä¿¡æ¯åˆ†å¼€\n\n\n\né™å®šå¥½Typeçš„ç§ç±»ï¼Œä½¿å¾—å¯ä»¥ä¸å¦ä¸€å¼ è¡¨æœ‰æ•ˆå®šä½\n\n\n\nTo solve the above problems, we can design a relational database to store data\n\n3.3 relational database\nDatabase terms:\nA database is a collection of data\nData is organized into one or more tables\nEach row is a record\nEach column is a field\n\n\n\n\n\nDeciding on Fields\n\nPrinciples of designing database terms:\nThink of all the facts that will be collected è€ƒè™‘æ‰€æœ‰æƒ…å†µ\nplenty of fields è€ƒè™‘æ‰€æœ‰column\nconsult widely å…±è¯†\nsmall facts, â€œatomicâ€ åŠ›åº¦è¦æ¯”è¾ƒç»†ï¼Œå¸Œæœ›ä¿¡æ¯å°½é‡æ¸…æ™°ï¼Œæ¯”å¦‚å­¦ç”Ÿå§“åè€Œä¸æ˜¯å­¦ç”Ÿä¿¡æ¯\ndifficult to add later å†åŠ ä¸€ä¸ªå­—æ®µç‰¹åˆ«å›°éš¾\n\n\n\n\nSet data types\n\n\n\n3.4 Exampleï¼š\nAn example of designing a relational database:\n\nStudy of 18th century book trade \nWhat things are we interested in?\nPublications\nPublishers\nPeople\n\n\n\n\nAnd what information might we want to know about each of these things?\n\nNames\nDates\nPlaces\n\n\nDesign three tables at first:\n\n\n\n\nJoins between tables: Primary Key å”¯ä¸€æ ‡è¯†\n\nEach table needs a primary key æ„å‘³ç€idï¼Œè¦æ˜¾å¼å®šä¹‰\nChoose (at least) one field that only contains unique values Commonly an auto-incrementing whole (integer) number\n\n\nJoins between tables: relate two tables by primary keys and foreign keys\n\nä¸€ä¸ªpublisherå¯èƒ½å¯¹åº”å¤šä¸ªpublicationï¼Œå°±æ˜¯ä¸€å¯¹å¤šï¼Œå¯ä»¥è®¾ç½®è°æ˜¯è°çš„å¤–é”®\n\n\n\nå¤šä¸ªäººå¯èƒ½å‚ä¸å†™åŒä¸€æœ¬ä¹¦ï¼Œä¸€ä¸ªpersonå¯èƒ½å†™å¾ˆå¤šæœ¬ä¹¦ï¼Œæ‰€ä»¥personå’Œpublicationæ˜¯å¤šå¯¹å¤šçš„ã€‚æ— æ³•å¯¹å¤šå¯¹å¤šçš„å…³ç³»å»ºç«‹è®¡ç®—æœºå¯è¯†åˆ«çš„æ˜ å°„å…³ç³»ï¼Œæ‰€ä»¥éœ€è¦æ–°å»ºä¸€å¼ è¡¨ï¼Œè¿™å¼ è¡¨è®°å½•äº†æ‰€æœ‰Authorä¸Publicationçš„è®°å½•\n\né‚£ä¹ˆå°±å¯ä»¥éšå¼è¡¨è¾¾Personå’ŒPublicationçš„å…³ç³»\n\n\n\n3.5 Database design: workflow\nChoose fields\nAre they atomic?\nAre there plenty?\n\n\nGive each field a data type\nAre they consistent?\n\n\nArrange the fields into tables\nDo all the fields in the same table describe the same item?\n\n\nSet primary key fields\nA different primary key for each table?\nis this a field with no duplicate values?\n\n\nDraw relationships between tables\n\nWhich field relates each pair of tables?\nMark 1-to-many, many-to-many,1-to-1 relationships\n\n\nReview, reflect, challenge\nTalk through the design with someone else\n\n\n\n3.6 Once youâ€™ve created your database\nAsk questions by constructing queries\nFind the records that meet certain criteria\nSearch, sort, count, and filter data\nPerform basic mathematical and statistical operations Export data for other types of analysis \n\n\nExport data for other types of analysis\n\nQuery example1: \n\nselect id, cityname, country, population, longtitude, latitude from City\n\nQuery Results\n\n\n\nQuery example2: \n\nselect id, cityname, country, population, longtitude, latitude from City where cityname=â€˜Tiraneâ€™\n\nQuery Results\n\n\nResults may resemble another table or spreadsheet\nBut the contents are customized(å®šåˆ¶) to your requirements\n\n3.7 When to use a relational database\nYour data can be organized in tabular form\n\ne.g., information about things that share common properties (organized in one column field) \n\n\nYou are interested in multiple types of entity . \n\nAnd the relationships between them\nEntities may be concrete(å…·ä½“çš„) or more abstract \n\n\nYou want to identify instances of things that meet certain criteria (query) \n\nYou want to be able to present one dataset in multiple different waysQuery results can be exported and used elsewhere\n\n\n3.8 Benefits of relational databases\nMore accurate representation of complex data\n\nAnd helps avoid duplication of information \n\n\nPermits flexible querying\n\nWider range of questions possible than with a spreadsheet (multiple tables)\nUseful if you are unsure which questions you will want to ask \n\n\nSuitable for collaborative use\n\nMultiple people can access and use the same database\nCan encourage (or enforce) consistency in data entry \n\n\nTechnology has been around for several decades\n\nWidely supported and well understood\n\n\n\n4. RDB2RDF: Direct Mapping4.1 What is RDB2RDF?\n4.2 Two W3C RDB2RDF Standards:\nDirect Mapping\nR2RML\n\nTools: \n\nFree: D2R, Virtuoso, Morph, r2rml4net, db2triples, ultrawrap, Quest; \nCommercial: Virtuoso, ultrawrap, Oracle SW.\n\n4.3 w3C RDB2RDF Standards\nStandards to map relational data to RDF\nA Direct Mapping of Relational Data to RDF\nDefault automatic mapping of relational data to RDF\n\n\nR2RML: RDB to RDF Mapping Language\nCustomizable language to map relational data to RDF\n\n\n\n\n\n4.4 Create URIs following some simple rules:\nMap\ntable to class ï¼ˆå¯¹åº”turtleè¯­è¨€typeï¼‰\ncolumn to property (å±æ€§-&gt;è°“è¯)\nrow to resource ï¼ˆä¸€æ¡è®°å½•ï¼‰\ncell to literal value ï¼ˆturtleä¸­çš„å®å€¼ï¼‰\nin addition cell to URI \nif there is a foreign key constraint\n\n\n\n\nWe need IRIs for identifying\nthe resource class corresponding to a table\nthe resources represented by the table rows \nthe properties of the resources corresponding to table cells\nthe references due to foreign keys\n\n\nBase IRI \n\nfor the whole graph/dataset, \ne.g. @base http://foo.example/DB/ .\n\n\nTable name $\\rightarrow$â€‹â€‹ Class name, \ne.g. People $\\rightarrow$â€‹â€‹â€‹ \\ è¡¨ç¤ºç±»åˆ«\n\n\nRow with PK $\\rightarrow$â€‹â€‹ Resource with PK, \ne.g,  è¿™ä¸ªè¡¨ç¤ºä¸€ä¸ªinstanceï¼Œå°±æ˜¯ä¸€ä¸ªå®ä¾‹ï¼Œ\\\n\n\nTable row $\\rightarrow$â€‹ Property, \ne.g.,    ï¼ˆ\\ï¼‰\n\n\nTable cells: what if NULL? ç›´æ¥çœç•¥\nForeign key reference $\\rightarrow$â€‹â€‹â€‹â€‹ additional property, e.g.,  (\\)\n\n\nProvide a base IRI http://foo.example/DB/ !\n\n\n@base &lt;http://foo.example/DB/&gt; . @prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;. &lt;People/ID=7&gt; rdf:type &lt;People&gt; . #æŸæ¡è®°å½•çš„ç±»åˆ«&lt;People/ID=7&gt; &lt;People#ID&gt; &quot;7&quot; .  #å…·ä½“å±æ€§&lt;People/ID=7&gt; &lt;People#fname&gt; &quot;Bob&quot; . &lt;People/ID=7&gt; &lt;People#addr&gt; &quot;18&quot; . &lt;People/ID=7&gt; &lt;People#ref-addr&gt; &lt;Addresses/ID=18&gt; . #åˆ©ç”¨å¤–é”®å…³è”æ˜ å°„ä¸¤å¼ è¡¨çš„è®°å½•&lt;People/ID=8&gt; rdf:type &lt;People&gt; . &lt;People/ID=8&gt; &lt;People#ID&gt; &quot;8&quot; . &lt;People/ID=8&gt; &lt;People#fname&gt; &quot;Sue&quot; . &lt;Addresses/ID=18&gt; rdf:type &lt;Addresses&gt; . &lt;Addresses/ID=18&gt; &lt;Addresses#ID&gt; &quot;18&quot; . &lt;Addresses/ID=18&gt; &lt;Addresses#city&gt; &quot;Cambridge&quot; . &lt;Addresses/ID=18&gt; &lt;Addresses#state&gt; &quot;MA&quot; .\n4.5 ExercisePlease use direct mapping to map the following two relational tables to RDF triples with the base IRI http://foo.example/DB/ and prefix rdfï¼šhttp://www.w3.org/1999/02/22-rdf-syntax-ns# .\n\n@base &lt;http://foo.example/DB/&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;.&lt;Student/ID=001&gt; rdf:type &lt;Student&gt; .&lt;Student/ID=001&gt; &lt;Student#ID&gt; &quot;001&quot; .&lt;Student/ID=001&gt; &lt;Student#sname&gt; &quot;Zhang&quot; .&lt;Student/ID=001&gt; &lt;Student#major&gt; &quot;101&quot; .&lt;Student/ID=001&gt; &lt;Student#ref-major&gt; &lt;Major/ID=101&gt; .&lt;Major/ID=101&gt; rdf:type &lt;Major&gt; .&lt;Major/ID=101&gt; &lt;Major#ID&gt; &quot;101&quot; .&lt;Major/ID=101&gt; &lt;Major#mname&gt; &quot;CS&quot; .&lt;Major/ID=101&gt; &lt;Major#address&gt; &quot;CS_Building&quot; .\n5. RDB2RDF: R2RML\n\nR2RML is a language for specifying mappings from relational to RDF data.\n\n5.1 DV\nå¯ä»¥ç†è§£ä¸ºç‰©ç†è¡¨çš„ä¸€ä¸ªè™šè¡¨ï¼Œæ²¡æœ‰å®é™…ç‰©ç†å†…å­˜\n\nA mapping takes as input a logical table, i.e.,\n\na database table\na database view (a virtual table collecting data from relational tables), or an SQL query (called an â€œR2RML viewâ€ because it is like an SQL view but does not modify the database)\n\n\n\n\nExample: database view\n\n5.2 A triples map5.2.1 Def\nA logical table is mapped to a set of triples by a rule called triples map.\n\n5.2.2 A triples map has three parts:\nthe input logical table \na subject map \nseveral predicate-object maps (combining predicate and object maps).\n\n5.3 Example:\nExample:@prefix rr: &lt;http:l//www.w3.org/ns/r2rml#&gt; .&lt;TriplesMap1&gt;a rr:TriplesMap;       #&lt;TriplesMap1&gt;å‰æ²¡æœ‰â€˜#â€™æ—¶è¦åŠ è¿™ä¸€å¥rr:logicalTable [rr:tableName &quot;Person&quot;];rr:subjectMap[\trr:template &quot;http://www.ex.com/Person/ID=&#123;ID&#125;&quot;;                 #ID=&#123;ID&#125;  ç›´æ¥&#123;ID&#125;éƒ½æ˜¯å¯ä»¥çš„  çœ‹ä½ è‡ªå·±æ€ä¹ˆå®šä¹‰template\trr:class &lt;http://www.ex.com/Person&gt;;#è¡¨ç¤ºä»urlæ‹¿class];rr:predicateObjectMap [\trr:predicate &lt;http:7/www.ex.com/Person#NAME&gt;; #è¡¨ç¤ºä»urlæ‹¿predicate    rr:objectMap [rr:column &quot;NAME&quot;]; #è¡¨ç¤ºä»dbä¸­å–].\nè§£æï¼š\n#What is being mappedrr:logicalTable [rr:tableName &quot;Person&quot;]; #å®šä¹‰rrçš„æŒ‡å‘\n#ç›¸å½“äº&lt;Subject URI&gt; rdf:type &lt;Class URI&gt;rr:subjectMap[\trr:template &quot;http://www.ex.com/Person/ID=&#123;ID&#125;&quot;; #predicate URI                #Customized Subject URI\trr:class &lt;http://www.ex.com/Person&gt;;                 #Customized Class];\nrr:predicateObjectMap [\trr:predicate &lt;http:7/www.ex.com/Person#NAME&gt;; #Predicate URI    rr:objectMap [rr:column &quot;NAME&quot;]; #Object Literal].\n5.4 R2RML Examples5.4.1\nDB\n\n\n\nSet of RDF triples\n\n&lt;http://data.example.com/employee/7369&gt; rdf:type ex:Employee.&lt;http://data.example.com/employee/7369&gt; ex:name &quot;SMITH&quot;.&lt;http://data.example.com/employee/7369&gt; ex:department &lt;http://data.example.com/department/10&gt;.&lt;http://data.example.com/department/10&gt; rdf:type ex:Department.&lt;http://data.example.com/department/10&gt; ex:name &quot;APPSERVER&quot;.&lt;http://data.example.com/department/10&gt; ex:location &quot;NEW YORK&quot;.&lt;http://data.example.com/department/10&gt; ex:staff 1.\n\nR2RML\n\n@prefix rr: &lt;http://www.w3.org/ns/r2rml#&gt;.@prefix ex: &lt;http://example.com/ns#&gt;.&lt;#TriplesMap1&gt;rr:logicalTable [ rr:tableName &quot;EMP&quot; ];rr:subjectMap [\trr:template &quot;http://data.example.com/employee/&#123;EMPNO&#125;&quot;;\trr:class ex:Employee;];rr:predicateObjectMap [\trr:predicate ex:name;\trr:objectMap [ rr:column &quot;ENAME&quot; ];].\n\n5.4.2 View Definition\n&lt;#DeptTableView&gt; rr:sqlQuery &quot;&quot;&quot;SELECT DEPTNO,\tDNAME,\tLOC,\t(SELECT COUNT(*) FROM EMP WHERE EMP.DEPTNO=DEPT.DEPTNO) AS STAFF #æŸ¥è¯¢ä¸¤å¼ è¡¨ä¸­åŒä¸€ä¸ªå­—æ®µç›¸åŒçš„ä¸ªæ•°FROM DEPT;&quot;&quot;&quot;.\n5.4.3 Mapping to a View Definition&lt;#TriplesMap2&gt; rr:logicalTable &lt;#DeptTableView&gt;;rr:subjectMap [     rr:template &quot;http://data.example.com/department/&#123;DEPTNO&#125;&quot;; \trr:class ex:Department; ]; rr:predicateObjectMap [ \trr:predicate ex:name; #å¯¹äºrdfçš„Property\trr:objectMap [ rr:column &quot;DNAME&quot; ]; ]; rr:predicateObjectMap [ \trr:predicate ex:location; \trr:objectMap [ rr:column &quot;LOC&quot; ]; ]; rr:predicateObjectMap [ \trr:predicate ex:staff; \trr:objectMap [ rr:column &quot;STAFF&quot; ]; ].\n\n5.4.4 Linking Two Logical Tables\n@prefix rr: &lt;http://www.w3.org/ns/r2rml#&gt;.@prefix ex: &lt;http://example.com/ns#&gt;.&lt;#TriplesMap1&gt;rr:predicateObjectMap [\trr:predicate ex:department; #ä¸rdfå¯¹åº”\trr:objectMap [#å®šä¹‰å®¾è¯­æ˜ å°„ï¼Œåœ¨ç¬¬äºŒå¼ è¡¨æ‰¾\t\trr:parentTriplesMap &lt;#TriplesMap2&gt;; #å»map2å»æ‰¾subjectæ¥å½“å®¾è¯­\t\trr:joinCondition [#è¡¨ç¤ºè¿™äº›å±æ€§æ˜¯ç›¸åŒçš„\t\t\trr:child &quot;DEPTNO&quot;;#triple2å°±æ˜¯child\t\t\trr:parent &quot;DEPTNO&quot;;#triple1å°±æ˜¯parent\t\t];\t];].\n\nAdditional predicate object map for &lt;#TriplesMap1&gt;\nObject map retrieves subject from parent triples map by joining along a foreign key relationship\nIt joins\nthe current row of the logical table\nwith the row of the logical table of &lt;#TriplesMap1&gt; that satisfies the join condition å°±æ˜¯è¯´Map1çš„æ¯ä¸€è¡Œæ˜ å°„éƒ½æ»¡è¶³è¿™ä¸ªæ¡ä»¶\n\n\nNote:\nchild = referencing map\nparent = referenced map\n\n\n\n5.5 ExercisePlease write the R2RML triples map to map the following relational database to RDF triples with prefix rr: http://www.w3.org/ns/r2rml# and prefix ex: http://example.com/ns#(for classes and properties).\n\nRDF Triples\n&lt;http://data.example.com/student/001&gt; ex:name &quot;Zhang&quot;. &lt;http://data.example.com/student/002&gt; ex:name &quot;Wang&quot;.\n@prefix rr:&lt;http://www.w3.org/ns/r2rml#&gt; .@prefix rr:&lt;http://example.com/ns#&gt; .&lt;#TriplesMap1&gt;\trr:logicalTable [rr:tabelName &quot;RDB&quot;];\trr:subjectMap[\t\trr:template &quot;http://data.example.com/student/&#123;ID&#125;&quot;;\t\trr:class ex:Student;\t];\trr:predicateObjectMap[\t\trr:predicate ex:name; \t\trr:objectMap [rr:column &quot;Name&quot;];\t].\n6. Summary: RDB2RDF\nRDB2RDF is to map the content of Relational Databases to RDF.\nTwo W3C RDB2RDF standards: Direct Mapping and R2RML\nThe direct mapping defines a simple and intuitive transformation from RDB to RDF.\nR2RML is a language for expressing customized mappings (using external ontology vocabularies) from RDB to RDF.\n\n","categories":["KnowledgeEngineering"]},{"title":"Triple Extraction from Relational Web Tables","url":"/2021/08/15/knowledge%20engineering/9.Triple%20Extraction%20from%20Relational%20Web%20Tables/","content":"Triple Extraction from Relational Web Tables\n1. Tables are Everywhere on the Web\n1.1 Statistics on Web Tables\nWeb Tables : In 2008, the WebTables systems (developed by Google) extracts 14.1 billion HTML tables and finds 154 million are high-quality tables (1.1%).\nWeb Tables: The Web Data Commons project extracts 233 million Web tables from HTML pages in 2015.\nWikipedia Tables: In 2019, the Wikipedia snapshot contains more than 3 million tables from more than 520 thousand Wikipedia articles.\n\n1.2 Web Table Types\n1.3 Relational TableDef\nArelational table describes a set of entities in the core column(s)(ç›¸å½“äºä¸»é”®) along with their attributes in the remaining columns.\n\n\n1.4 Steps of Triple Extraction\nEntity Linking: Mention to Entity\n\nä½¿å¾—å¯ä»¥æ‰¾åˆ°çœŸæ­£çš„ä¿¡æ¯\n\n\nColumn Typing: Column to Class (i.e., Type)\n\nç»™columnåˆ†ç±»\n\n\nRelation Extraction: Semantic Association between Columns to Relation\n\næ¨å‡ºåˆ—ä¹‹é—´çš„å…³ç³»\n\n\n\n\n2. Entity Linking2.1 What is Entity Linking (EL) in Web Tables?\nMapping the string mentions in table cells to their referent entities in a given knowledge base (KB).\n\n\n2.2 Detailed Steps of Entity Linking (Assumption: strings in a cell are a mention):\nCandidate Generation:\nIdentifying candidate referent entities of each string mention in table cells when given a knowledge base.\n\n\nEntity Disambiguation:\nChoosing only one entity from the candidate set as the referent entity of each string mention.\n\n\n\n2.3 Entity Linking: Candidate Generation2.3.1 Dictionary-based method\ncollecting all (string, entity) pairs from anchor texts, redirect pages, and disambiguation pages in Wikipedia; \nranking based on co-occurrence frequency.ï¼ˆæˆå¯¹å‡ºç°æ¦‚ç‡ï¼‰\n\nå¯ä»¥ç†è§£ä¸ºé€šè¿‡å·²çŸ¥çš„å®ä½“é“¾æ¥æ¥å­¦ä¹ å‡ºè¡¨æ ¼é‡Œçš„é“¾æ¥\n\n\nä¾‹å¦‚ï¼š\nJordanâ€”â€”-basketball player\nâ€‹            â€”â€”-professor\nâ€‹            â€”â€”-actor\n\nå‡ºç°çš„é¢‘ç‡å¹¶ä¸ä¸€æ ·ï¼Œå¯ä»¥åšä¸€ä¸ªæ’åº\n\n\n2.3.2 String similarity based methodDefï¼š\ncomputing string similarities between mentions and entities\n\nLevenshtein distance\nEdit distance: Levenshtein distance\nThe Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other.\n\n\n\n\n\nJaccard similarity\nJaccard similarity J(A, B) measures the similarity between finite sample set A and B.\n\n\nJ(A, B)=\\frac{|A\\cap B|}{|A\\cup B|}\n\nExercise\nCompute the Levenshtein distance between â€œkittenâ€ and â€œsittingâ€.\n1+1+1=3\n\n\nCompute the Jaccard similarity between â€œUniversity of California, Davisâ€ and â€œUniversity of California, Berkeleyâ€in word level.\n\n\nA\\cup B=\\{University, of, California, Davis, Berkeley\\}\nA\\cap B=\\{University, of, California\\}\nJ(A, B)=\\frac{|A\\cup B|}{|A\\cap B|}=\\frac{3}{5}\nCompute the Jaccard similarity between â€œEnglishâ€and â€œEnglandâ€based on character-level trigrams.\n\n\nA=\\{Eng, ngl, gli, lis, ish\\}\nB=\\{Eng, ngl, gla, lan, and\\}\nJ(A, B)=\\frac{|A\\cap B|}{|A\\cup B|}=\\frac{2}{8}=\\frac{1}{4}2.3.3 Synonym-based method\ncombine with the dictionary-based method or string similarity based method\nuse a knowledge graph containing rich synonym information, e.g., BabelNet, WordNet\n\nWith the above methods, Top-K candidate referent entities for each mention can be obtained.2.4 Entity Disambiguation2.4.1 DefLocal Disambiguation \n\nOnly use the contextual information of the given mention and target entity for disambiguation without considering the effects of other referent entities in the same table.\n\nGlobal (Collective) Disambiguation \n\nLeverage the semantic associations between candidate referent entities to jointly disambiguate all entities for the mentions in a table.\nä¸åŒmentioné‡Œçš„å®ä½“å¯ä»¥å¸®åŠ©é“¾æ¥\n\n\n\n2.4.2 Local Disambiguation: A Generative Model\nThe classic generative model is originally proposed to entity linking in text, but it can be applied to Web tables.\nå‡è®¾Mentionå¦‚ä¸‹è¿°ç”Ÿæˆè¿‡ç¨‹ï¼š\n\n\n\nThe generative process for text: three steps\nChoose the referent entity e from the knowledge base with P(e), e.g., â€œMichael Jeffrey Jordanâ€;\nChoose a name s with ğ‘ƒ(ğ‘ â”‚ğ‘’), e.g., â€œJordanâ€;\nChoose a context c with ğ‘ƒ(ğ‘â”‚ğ‘’), e.g., â€œjoins Bulls in 1984â€.\n\n\n\n\n\nBased on the above generative story, the probability of a name mention m (its context is c and its name is s) referring to a specific entity e can be expressed as (assume that s and c are independent given e)\ns|e ä¸ c|e æ¡ä»¶ç‹¬ç«‹\n\n\n\n\nğ‘ƒ(ğ‘š,ğ‘’)=ğ‘ƒ(ğ‘ ,ğ‘,ğ‘’)=ğ‘ƒ(ğ‘’)ğ‘ƒ(ğ‘ â”‚ğ‘’)ğ‘ƒ(ğ‘â”‚ğ‘’)\nwhere P(e) corresponds to the popularity knowledge, \n\nP(s|e) corresponds to the name knowledge , and \nP(c|e) corresponds to the context knowledge.\n\n\nGiven a name mention m, to perform entity disambiguation, we need to find the entity e which maximizes the probability P(e|m), i.e.,\n\n\n\nğ‘’=argmax_ğ‘’\\frac{P(m,e)}{P(m)}=argmax_eğ‘ƒ(ğ‘’)ğ‘ƒ(ğ‘ |ğ‘’)ğ‘ƒ(ğ‘|ğ‘’)\nTraining data: \na set of annotated name mentions $ğ‘€=\\{ğ‘š_1,ğ‘š_2,â€¦,ğ‘š_ğ‘›\\}$â€‹â€‹â€‹, each m is a triple $ğ‘š=\\{ğ‘ ,ğ‘’,ğ‘\\}$â€‹â€‹; \nexample for text\n\n\n\n\n\ntable: Annotated Web tables from Web Data Commons project.\nåªéœ€å°†contextæ¢ä¸€ä¸‹\n\n\n\nEntity popular model:\nP(e) reflects the popularity knowledge of the entity e; \nif e1 is more popular than e2, then $P(e_1)&gt;P(e_2)$;\n\n\n\nA more popular entity $e_1$ usually appears more times than a less popular entity $e_2$â€‹ in a large text corpusï¼ˆè¿™é‡ŒæŒ‡çš„æ˜¯çŸ¥è¯†åº“ï¼‰, i.e., the frequency of occurrence $count(e_1)&gt;count(e_2)$â€‹, e.g., in Wikipedia,\nè¿™é‡Œåº”è¯¥æ˜¯çœ‹mentionsåˆ°çŸ¥è¯†åº“é‡Œæ˜ å°„å®ä½“æ•°æ¥å†³å®š\n\n\n\n\n\nThus, we model the popularity knowledge asï¼š\n\n\nP(e)=\\frac{count(e)+1}{N+|M|}\nwhere $count(e)$ is the count of the name mentions whose referent entities are e in the training data,  ï¼ˆå¯¹åº”æ‰€æœ‰mentionä¸­åœ¨çŸ¥è¯†åº“æ˜ å°„çš„å®ä½“æ˜¯eçš„ä¸ªæ•°ï¼‰\nN is the number of all entities \nand |M| is the total name mention size.ï¼ˆç”¨äºå¹³æ»‘ï¼Œä½¿å¾—æ‰€æœ‰å®ä½“è‡³å°‘æœ‰ä¸€ä¸ªå¾ˆå°çš„base probï¼‰\n\nThe estimation is further smoothed using the simple add-one smoothingmethod for the zero probability problem.\n\n\nEntity name model:\nP(s|e) encodes the name knowledge of entities;\n\nfor a specific entity e, its more frequently used name should be assigned a higher P(s|e), and a zero P(s|e) value should be assigned to those never used names.\n\n\n\n\nafter collecting all (entity, name) pairs from the name mention data set, then the maximum likelihood estimation is used to estimate the entity name model as\nä¸åŒäºå®ä½“è®­ç»ƒï¼Œè¿™æ—¶å€™è®­ç»ƒé›†æ˜¯ä¸€ä¸ªpairï¼Œä¹‹å‰çš„å®ä½“è®­ç»ƒåªè¦ä»çŸ¥è¯†åº“é‡Œæ‰¾åˆ°æ‰€æœ‰å®ä½“å°±è¡Œ\n\n\n\n\nP(s \\mid e)=\\frac{\\operatorname{count}(e, s)}{\\sum_{s} \\operatorname{count}(e, s)}\nwhere the count(e,s) is the count of the name mention s whose referent entity is e.\n\nProblem: it cannot deal with unseen names.\n\n\n\nunseen names include:\n\n\naliases åˆ«è¯: â€œNew Yorkâ€ $\\rightarrow$â€‹ â€œBig Appleâ€ ;\nacronyms ç®€å†™: â€œMichael Jeffrey Jordanâ€ $\\rightarrow$ â€œMJâ€ ;\nmisspellings: â€œBarack Obamaâ€ $\\rightarrow$ â€œBarack Opamaâ€ .\n\n\nto solve this problem, apply the statistical translation model (IBM Model 1) to capture all possible name variations of the given word by translation operations as1) It is retained (translated into itself);2) It is translated into its acronym;3) It is omittedï¼ˆçœç•¥ï¼‰(translated into the word NULL);4) It is translated into another word (misspelling or alias).\n\n\n\nP(s|e) can be modeled as\n\n\n\nwhere $\\varepsilon$ is a normalization factor, $f$ is the full name of entity e, $l_{s}$ and $l_{f}$ are respectively the lengths of $s$ and $f, s_{i}$ is the $i$-th word of $s$, and $f_{j}$ is the $j$-th word of $f$â€‹.\n\nè¿™ä¹ˆç†è§£å°±æ˜¯$f_j$æ˜¯full name ç¬¬jä¸ªwordï¼Œfull name å°±æ˜¯åŸæ¥è®­ç»ƒä¸­å‡ºç°çš„wordï¼Œè€Œ$s_i$â€‹æ˜¯å˜æ¢åå‡ºç°çš„ç¬¬iä¸ªword\n\n\nunseen names include:\n\n\n\naliases: â€œNew Yorkâ€ $\\rightarrow$ â€œBig Appleâ€ ;\nacronyms: â€œMichael Jeffrey Jordanâ€ $\\rightarrow$ â€œMJâ€ ;\nmisspellings: â€œBarack Obamaâ€ $\\rightarrow$ â€œBarack Opamaâ€ .\n\n\nEntity context model (use text to explain):$P(c \\mid e)$â€‹â€‹ encodes the context knowledge of entities;\n\nif the entity $e$â€‹â€‹ frequently appears in the context $c$â€‹â€‹, then $P(c \\mid e)$â€‹â€‹â€‹ should be higher; \nå¦‚æœä¸€ä¸ªå®ä½“ä¸çŸ¥è¯†åº“é‡Œå‡ºç°çš„ä¸Šä¸‹æ–‡é¢‘ç¹ä¸€è‡´ï¼Œåˆ™æ¦‚ç‡å¤§\n\n\ne.g.,\n$C_1$: _wins NBA MVP.\n$C_2$: _is a researcher in machine learning.\n\n\nP(C_1 \\mid \\text{Michael Jeffrey Jordan} )>P(C_2 \\mid \\text{Michael Jeffrey Jordan} )Entity context model (use text to explain):\n\nthe context of each name mention $m$â€‹ is the words surrounding $m$â€‹;\nthe context knowledge of an entity $e$â€‹ is encoded in an unigram language model $M_{e} .$â€‹\nè¿™ä¹ˆç†è§£ï¼Œæˆ‘ä»¬æŠŠå¯¹äºæŸä¸ªå®ä½“çš„contextæ‹†å¼€æˆwordçº§åˆ«ï¼Œæ ¹æ®ä¸€å…ƒè¯­æ³•ï¼Œå°±å¯ä»¥è®¡ç®—æ¯ä¸ªwordçš„æ¦‚ç‡ï¼Œä»è€Œå½¢æˆé›†åˆ\nM_{e}=\\left\\{P_{e}(t)\\right\\}where $P_{e}(t)$â€‹ is the probability of the term $t$â€‹ appearing in the context of $e$â€‹. The term can be a word, a named entity, or a Wikipedia entity.\n\n\n\nEntity context model (use text to explain):\n\ngiven a context $c$â€‹â€‹ containing $\\mathrm{n}$â€‹â€‹ terms $t_{1}, t_{2} \\ldots t_{n}$â€‹â€‹, the entity context model estimates the probability $P(c \\mid e)$â€‹â€‹ as\nP(c \\mid e)=P\\left(t_{1} t_{2} \\ldots t_{n} \\mid M_{e}\\right)=P_{e}\\left(t_{1}\\right) P_{e}\\left(t_{2}\\right) \\ldots P_{e}\\left(t_{n}\\right)\naccording to the annotated name mention data set $M, P_{e}(t)$â€‹ can be estimated by the maximum likelihood estimation:\nP_{e_{-} M L}(t)=\\frac{\\operatorname{Count}_{e}(t)}{\\sum_{t} \\operatorname{Count}_{e}(t)}\nwhere $Count _{e}(t)$ is the frequency of occurrences of a term $t$ in the contexts of the name mentions whose referent entity is $e$â€‹â€‹â€‹.\nä»$e$çš„æ‰€æœ‰contextæ”¶é›†æ‰€æœ‰çš„termï¼Œè¿™æ ·å°±å¯ä»¥ç»Ÿè®¡æ¯ä¸€ä¸ªtermçš„é¢‘ç‡\n\n\n\nEntity context model (use text to explain):\n\ndue to the sparse data problem, $P_{e}(t)$ is smoothed by Jelinek-Mercer smoothing method as\nP_{e}(t)=\\lambda P_{e_{M L}}(t)+(1-\\lambda) P_{g}(t)\nwhere $P_{g}(t)$â€‹ is a general language model estimated using the whole Wikipedia data.\n\n2.4.3 More Features in Entity DisambiguationWeb Table Features:\nFeatures found in the table (T) or outside the table (C) \nè¡¨æ ¼å¤–åŒæ ·å¯ä»¥æ‰¾åˆ°å¾ˆå¤šèµ„æº\n\n\nSingle table features (TS) refer to a value in a single cell while multiple features combine values coming from more than one cell (TM)\n\n\n\n2.4.4 Global Disambiguation: A Graph Model\nWhy global disambiguation works? \nsuppose we have three mentions which are needed to perform entity linking\n\n\n\n\n\nå‡è®¾æœ‰ä¸‰ä¸ªmentionéœ€è¦åšå®ä½“é“¾æ¥ï¼Œå€ŸåŠ©ä»–ä»¬çš„å€™é€‰å®ä½“çš„è¯­ä¹‰å…³è”ï¼Œå¯ä»¥æ¶ˆé™¤local ambiguation\n\nBuilding an Entity Disambiguation Graph for each given table. Each graph consists of:\n\nMention Nodes, Entity Nodes \nMention-Entity Edges: undirected edges between mentions and its candidate referent entities, \nEntity-Entity Edges: undirected edges between entities.\n\n\n\n\nEntity Disambiguationâ€”Computing EL Impact Factors.\nTwo EL impact factors are as follows:\nimportance of each mention; \nsemantic relatedness between different nodes.\næµ‹é‡ä¸åŒèŠ‚ç‚¹çš„è¯­ä¹‰ç›¸å…³åº¦\n\n\n\n\nEach node or edge in a constructed Entity Disambiguation Graph is assigned with a probability .\nFor mention-entity edges, their probabilities refer to the semantic relatedness between mentions and entities, called Mention-Entity Semantic Relatedness.\nFor entity-entity edges, their probabilities are seen as the semantic relatedness between entities, called Entity-Entity Semantic Relatedness\n\n\n\nMention-Entity Semantic Relatedness\nTwo features are used to measure Mention-Entity Semantic Relatedness $S R_{m e}(m, e)$â€‹ between the given mention $m$â€‹ and entity $e$â€‹.\n\n\nString Similarity Feature strSim(m,e): depending on the Levenshtein distance between the string labels of $m$â€‹â€‹ and $e$â€‹â€‹.\n\nå°±ç®—mentionå’Œå®ä½“çš„ç›¸ä¼¼åº¦\n\n\nMention-Entity Context Similarity Feature $contSim _{\\text {me }}(m, e)$â€‹â€‹ :\n\nè®¡ç®—mentionå’Œentityçš„èƒŒæ™¯ç›¸ä¼¼åº¦\n\nThe context of mention $m$â€‹â€‹ is denoted as menContext (m) :a) Collecting other mentions in the row or column where $m$â€‹â€‹â€‹â€‹ locates.\n\nåŒè¡Œä¸åˆ—è¯çš„é›†åˆ\n\nb) Segmenting all the collected mentions into a set of words.\n\n\n  The context of entity $e$ is denoted as entContext(e):  a) Collecting all the RDF triples which $e$ exists in.  b) Segmenting all the objects (e is the subject) and subjects (e is the object) into a set of words.\n\nä»çŸ¥è¯†åº“é‡Œæ‰¾æ‰€æœ‰åŒ…å«eçš„ä¸‰å…ƒç»„ï¼Œä»è€Œç»„æˆç›¸åº”çš„èƒŒæ™¯é›†åˆ\n$contSim_{m e}(m, e)$â€‹â€‹â€‹â€‹ is computed by the Jaccard similarity between menContext (m) and entContext ( e ).\n\nä½¿ç”¨Jaccard similarityè®¡ç®—ç›¸ä¼¼åº¦\n\n\n\nS R_{m e}(m, e)=0.99 \\times\\left(\\alpha_{1} \\cdot \\operatorname{strSim}(m, e)+\\beta_{1} \\cdot \\operatorname{contSim}_{m e}(m, e)\\right)+0.01Entity Disambiguation-Computing EL Impact Factors.Two features are used to measure Entity-Entity Semantic Relatedness $S R_{e e}\\left(e_{1}, e_{2}\\right)$ between entities $e_{1}$ and $e_{2}$\n1) Triple Relation Feature $\\operatorname{I_{SRDF}}\\left(e_{1}, e_{2}\\right)$â€‹ : verifying whether $e_{1}$â€‹ and $e_{2}$â€‹â€‹ are in the same triple.2) Entity-Entity Context Similarity Feature contSim $_{e e}\\left(e_{1}, e_{2}\\right):$â€‹    cont Sim $_{\\text {ee }}\\left(e_{1}, e_{2}\\right)$â€‹ is computed by the $\\operatorname{Jaccard}$â€‹ similarity between entContext $\\left(e_{1}\\right)$â€‹ and entContext $\\left(e_{2}\\right)$â€‹â€‹.\n\nS R_{e e}\\left(e_{1}, e_{2}\\right)=0.99 \\times\\left(\\alpha_{2} \\cdot I_{S R D F}\\left(e_{1}, e_{2}\\right)+\\beta_{2} \\cdot \\operatorname{contSim}_{e e}\\left(e_{1}, e_{2}\\right)\\right)+0.01Entity Disambiguation-Iterative Probability Propagation.\nIterative probability propagation is used for combining different $\\boldsymbol{E} \\boldsymbol{L}$ impact factors for the $E L$ decisions.\nGiven an Entity Disambiguation Graph $G$ with $n$ nodes, we denote $G$ as an $n \\times n$ adjacency matrix $A, A_{i j}$ is the normalized semantic relatedness between node $i$ and node $j$, and $A_{i j}=A_{j i}$â€‹.\n\nWe define an $n \\times 1$ vector $r$ to record the probabilities assigned to all the nodes, and iteratively compute $r$ with the following formula until convergence.\n\n\n\n2.4.5 A Test on Zhishi.meâ€”Consisting of Three Chinese Linked KBs.\nApplying our proposed approach to more than 70,000Web tables with each single KB in Zhishi.me.\nFor each mention, and if any two identified entities from different KBs do not have the samesAs relation, then there exists a conflict here.2) å¯¹äºæ¯æ¡mentionï¼Œå¦‚æœæœ‰ä¸¤ä¸ªç›¸åŒçš„å®ä½“æ¥è‡ªä¸åŒçš„çŸ¥è¯†åº“ï¼Œä½†æ˜¯ä»–ä»¬æ²¡æœ‰ç›¸åŒçš„å…³ç³»ï¼Œé‚£ä¹ˆå°±ä¼šäº§ç”Ÿå†²çª\nAccording to the statistics, there exist conflicts in the EL results of38.94% mentions.\nå•ä¸€çŸ¥è¯†åº“çš„å®ä½“æ˜ å°„é—®é¢˜ï¼Œè¿™å…¶å®å¯ä»¥ç†è§£å°±æ˜¯ï¼Œä½ ä¸€å¼€å§‹åœ¨åšå®ä½“é“¾æ¥çš„æ—¶å€™ï¼Œå¦‚æœåªç”¨åˆ°ä¸€ä¸ªçŸ¥è¯†åº“ï¼Œé‚£ä¹ˆç”±äºè¿™ä¸ªçŸ¥è¯†åº“\n\n\n\nReasons of ConflictsReason 1: The samesAs relations are incomplete between KBs.\nSolution: \n\nCompleting samesAs relations with a supervised learning model using synonym feature, string similarity feature and entity-entity context similarity feature.\n\nReason 2: For some KBs, some potential correct referent entities do not rank the highest.\n\næ²¡æœ‰æ’åºå¯¹\n\nSolution: \n\nGrouping the entities representing the same individual into differentsets using the existing and newly learned samesAs relations.\n\næŠŠç›¸åŒçš„å®ä½“ç»„æˆä¸€ä¸ªé›†åˆ\n\n\nComputing the average ranking, the highest ranking and the number of the entities in each set, and then applying three heuristic rules to solving conflicts.\n\nè®¡ç®—æ¯ä¸ªé›†åˆçš„å¹³å‡rangkingï¼Œå†æ’åº\n\n\n\nDetail RulesRule 1: If both the average ranking and the highest ranking of the entities in a set rank the highest, and the number of the entities in this set is not less than half of the number of KBs, then we choose this set as the final EL results for the given mention.\nRule 2: If there exist two or more sets that the average ranking and the highest ranking of the setsâ€™ corresponding entities are the same and rank the highest, also the number of the entities in each of these sets is not less than half of the number of KBs, then we choose one set at random as the final EL results for the given mention.\nRule 3: If the number of the entities in each set is less than half of the number of KBs, the original EL results of the given mention remain unchanged.\n\næ€»ç»“å°±æ˜¯åªæœ‰å½“ç›¸åŒçš„å®ä½“å‡ºç°åˆ°ä¸€å®šæ•°é‡ï¼Œæ‰ä½¿ç”¨è¿™ä¸ªç‰¹æ®Šè§„åˆ™\n\n\n\nå¯¹äºä¸€ä¸ªmentionæˆ‘ä»¬å»å„ä¸ªKBæ‰¾ç›¸åŒçš„å€™é€‰å®ä½“\n\n\n3.  Column Typing: Column to Class (i.e., Type)\n\n\nåˆ©ç”¨åŒä¸€åˆ—æŸä¸€ä¸ªmentionçš„å®ä½“ç±»å‹ä½œä¸ºè¯¥mentionçš„å®ä½“ç±»å‹\næˆ–è€…åˆ©ç”¨Tableæœ¬èº«headçš„ä¿¡æ¯æ¯”å¦‚city\n\n4. Relation ExtractionDefinition\nRelation extraction refers to the task of associating a pair of columns in atable with the relation that holds between their contents and / or extractingrelationship information from tabular data and representing them in astructured format (e.g., as subject-predicate-object triples).\n\nFor binary relationships, the relationship between columns A and B islabeled with R if a substantial number of pairs of values from A and Boccur in the relations database.\n\n\n\n\nåˆ©ç”¨çŸ¥è¯†åº“ä¸­æœ¬æ¥å­˜åœ¨çš„ä¸‰å…ƒç»„ï¼Œæ¥æ¨æµ‹å‡ºæœªçŸ¥çš„ä¸‰å…ƒç»„\n\n","categories":["KnowledgeEngineering"]},{"title":"QA","url":"/2021/08/15/nlp%20learning/Chapter11_QA/","content":"QA\n\n1.Why is QA back centre stage of AI?\nThe way of Human machine information interaction has changed\n\nThe rapid development of mobile and wearable devices requires effective and accurate information service in the form of natural language\n\n\n1. QAç³»ç»Ÿå¸¸è§çš„é—®é¢˜ç±»å‹ï¼š\nFactoid questions åŸºäºäº‹å®å‹çš„é—®é¢˜\nWho wrote â€œthe Universal Declaration of Human Rightsâ€?\nHow many calories are there in two slices of apple pie?\nWhat is the average age of the onset of autism?\n\n\nComplex(narrative) questions: å¤æ‚ï¼ˆæè¿°æ€§ï¼‰é—®é¢˜\nIn children with an acute febrie illness, what is the effcacy of acetaminophen in reducing\nWhat do scholars think about Jeffersonâ€™s position ondealing with pirates?\n\n\n\n2. QAå¸¸è§æ–¹æ³•ï¼š\nIR-based approaches\nTREC; IBM Watson; Google\n\n\nKnowledge-based and Hybrid approaches\nIBM Watson; Apple Siri; Wolfram Alpha; TrueKnowledge Evi\n\n\nCommunity-based question answering\nçŸ¥ä¹ã€Quora\nä¼—åŒ…\n\n\n\n3. IR-based Factoid QA\n\nQuestion Processing  é—®é¢˜å¤„ç† \nDetect question type, answer type, focus, relations\næ£€æµ‹é—®é¢˜ç±»å‹ã€ç­”æ¡ˆç±»å‹ã€æ ¸å¿ƒè¯ã€å…³ç³»\nå§šæ˜ã€èº«é«˜â€”â€”&gt;ä¾èµ–\n\n\nFormulate queries to send to a search engine\nå½¢æˆqueriesè¾“å…¥æœç´¢å¼•æ“\n\n\nPassage Retrieval æ–‡æœ¬æŸ¥æ‰¾ \nRetrieve ranked documents æ£€ç´¢æ’åæ–‡æ¡£\næŸ¥è¯¢å§šæ˜ã€å‡é«˜\nTF-IDF\n\n\nåˆ†è§£æˆåˆé€‚çš„æ®µè½ã€å¹¶ä¸”é‡æ–°æ’åº Break into suitable passages and rerank\nNERã€è¯æ€§æ ‡æ³¨\næœç´¢æ‰€æœ‰æ•°å­—ï¼Œå¯¹æ‰€æœ‰æ•°å­—è¿›è¡Œæ’åº\n\n\n\n\nç­”æ¡ˆå¤„ç† Answer Processing\næå–å€™é€‰ç­”æ¡ˆ Extract candidate answers\næ’åºå€™é€‰é¡¹ Rank candidates\nusing evidence from the text and external sources \n\n\n\n\n\n3.1 Question Procesing\nAnswer Type Detection\nDecide the named entity type (person, place) of the answer\nå¤§è‡´å°±æ˜¯åˆ¤æ–­ç­”æ¡ˆçš„å‘½åå®ä½“æ˜¯ä»€ä¹ˆ\n\n\nQuery Formulation\nChoose query keywords for the IR system\nåˆ©ç”¨IRç³»ç»Ÿé€‰æ‹©é—®ç­”ä¸­çš„å…³é”®è¯\n\n\nQuestion Type classification\n\nIs this a definition question, a math question, a list question?\nç­”æ¡ˆç±»å‹è¯†åˆ«ï¼Œå³çœ‹è¿™ä¸ªç­”æ¡ˆæ•´ä½“å†…å®¹å±äºä»€ä¹ˆç±»å‹\n\n\nFocus Detection\n\nFind the question words that are replaced by the answer\næ‰¾å‡ºè¢«ç­”æ¡ˆæ›¿æ¢çš„ç–‘é—®è¯\n\n\nRelation Extraction\n\nFind relations between entities in the question\næŸ¥æ‰¾é—®é¢˜ä¸­å®ä½“ä¹‹é—´çš„å…³ç³»\n\n\nExample\n\nQuestion: Please return the two states you could be reentering if youâ€™re crossing Floridaâ€™s northern border å¦‚æœä½ ç©¿è¶Šä½›ç½—é‡Œè¾¾å·ã€åŒ—éƒ¨è¾¹ç•Œï¼Œè¯·è¿”å›ä½ å¯èƒ½é‡æ–°è¿›å…¥çš„ä¸¤ä¸ªå·\n\nAnswer Type: US state\nQuery: two states, border, Florida, north\nFocus: the two states\nRelations: borders(Florida, ?x, north)\n\n\n\n3.2 Answer Type Detection: Named Entities\nWho founded Virgin Airlines?\n\nPERSON\n\n\nWhat Canadian city has the largest population?\n\nCITY.\n\n\n\n3.2.1 Answer Type Taxonomy\n6 coarse classes\nABBEVIATION, ENTITY, DESCRIPTION, HUMAN, LOCATION, NUMERIC\nç¼©å†™ã€å®ä½“ã€æè¿°ã€äººå‘˜ã€ä½ç½®ã€æ•°å­—\n\n\n50 finer classes\nLOCATION: city, country, mountainâ€¦\nHUMAN: group, individual, title, description\nENTITY: animal, body, color, currencyâ€¦\n\n\n\n\n\n3.2.2 Methods\nHand written rules\nMachine Learning\nHybrids\n\nHand written rules\nRegular expression based rules can get some cases: åŸºäºæ­£åˆ™è¡¨è¾¾å¼çš„è§„åˆ™å¯ä»¥è·å¾—æŸäº›æƒ…å†µï¼š\nWho { is|was|are|were } PERSON\nPERSON (YEAR YEAR)\n\n\nOther rules use the question headword å…¶ä»–è§„åˆ™ä½¿ç”¨ç–‘é—®è¯\n(the headword of the first noun phrase after the wh-word) ï¼ˆwhå•è¯åç¬¬ä¸€ä¸ªåè¯çŸ­è¯­çš„ä¸­å¿ƒè¯ï¼‰\nWhich city in China has the largest number of foreign financial companies?\nWhat is the state flower of California?\n\n\n\nMachine Learning\nDefine a taxonomy of question types\nAnnotate training data for each question type\nTrain classifiers for each question class using a rich set of features.\n\nfeatures include those hand written rules!\n\n\nFeatures for Answer Type Detection\n\nQuestion words and phrases ç–‘é—®è¯å’Œã€çŸ­è¯­\nPart of speech tags è¯æ€§æ ‡è®°\nParse features (headwords) åˆ†æåŠŸèƒ½ï¼ˆæ ‡é¢˜è¯ï¼‰\nNamed Entities å‘½åå®ä½“\nSemantically related words è¯­ä¹‰ç›¸å…³è¯\n\n\n\n3.3 Query Formulation\nSelect all non stop words in quotations é€‰æ‹©æŠ¥ä»·å•ä¸­çš„æ‰€æœ‰éåœç”¨è¯\nSelect all NNP words in recognized named entities é€‰æ‹©å·²è¯†åˆ«å‘½åå®ä½“ä¸­çš„æ‰€æœ‰NNPå­—\nSelect all complex nominals with their adjectival modifiers é€‰æ‹©æ‰€æœ‰å¸¦å½¢å®¹è¯ä¿®é¥°ç¬¦çš„å¤æ•°åè¯\nSelect all other complex nominals é€‰æ‹©æ‰€æœ‰å…¶ä»–å¤æ‚åè¯\nSelect all nouns with their adjectival modifiers é€‰æ‹©æ‰€æœ‰åè¯åŠå…¶å½¢å®¹è¯ä¿®é¥°è¯­\nSelect all other nouns é€‰æ‹©æ‰€æœ‰å…¶ä»–åè¯\nSelect all verbs é€‰æ‹©æ‰€æœ‰åŠ¨è¯\nSelect all adverbs é€‰æ‹©æ‰€æœ‰å‰¯è¯\nSelect the QFW word (skipped in all previous steps) é€‰æ‹©QFWå­—ï¼ˆåœ¨å‰é¢çš„æ‰€æœ‰æ­¥éª¤ä¸­è·³è¿‡ï¼‰\nSelect all other words é€‰æ‹©æ‰€æœ‰å…¶ä»–å•è¯\n\n3.4 Choosing keywords from the query\n3.5 Passage Retrieval\nStep 1: IR engine retrieves documents using query terms IRå¼•æ“ä½¿ç”¨æŸ¥è¯¢ç³»ç»Ÿæœ¯è¯­æ£€ç´¢æ–‡æ¡£\n\nStep 2: Segment the documents into shorter units å°†æ–‡æ¡£åˆ†å‰²ä¸ºè¾ƒçŸ­çš„å•å…ƒ\n\nsomething like paragraphs\n\n\nStep 3: Passage ranking æ–‡ç« æ’å\n\nUse answer type to help rerank passages ä½¿ç”¨ç­”æ¡ˆç±»å‹å¸®åŠ©é‡æ–°é˜…è¯»æ–‡ç« \n\n\n\n3.5.1 Features for Passage Ranking\nNumber of Named Entities of the right type in passage  æ®µè½ä¸­æ­£ç¡®ç±»å‹çš„å‘½åå®ä½“æ•°\nNumber of query words in passage æ®µè½ä¸­çš„æŸ¥è¯¢å­—çš„æ•°é‡\nNumber of question N grams also in passage æ®µè½ä¸­Nè¯çš„æ•°é‡\nProximity of query keywords to each other in passage æŸ¥è¯¢å…³é”®å­—åœ¨æ®µè½ä¸­ç›¸äº’çš„ç›¸ä¼¼åº¦\nLongest sequence of question words æœ€é•¿çš„ç–‘é—®è¯åºåˆ—\nRank of the document containing passage åŒ…å«æ®µè½çš„æ–‡æ¡£çš„æ–‡ç« \n\n3.6 Answer Extraction\nRun an answer type named entity tagger on the passages åœ¨æ®µè½ä¸­æ£€æµ‹ç­”æ¡ˆå®ä½“ç±»å‹çš„è¯\nEach answer type requires a named entity tagger that detects it æ¯ä¸ªç­”æ¡ˆç±»å‹éƒ½è¦æœ‰ä¸€ä¸ªæ ‡è®°ç”¨äºæ£€æµ‹\nIf answer type is CITY, tagger has to tag CITY\nCan be full NER, simple regular expressions, or hybrid\n\n\n\n\nReturn the string with the right type: \nWho is the prime minister of India (PERSON) Manmohan Singh , Prime Minister of India, had told left leaders that the deal would not be renegotiated\nHow tall is Mt. Everest? (LENGTH) The official height of Mount Everest is29035 feet\n\n\n\n3.7 Ranking Candidate Answers\nBut what if there are multiple candidate answers!\n\nQ: Who was Queen Victoriaâ€™s second son?\n\nAnswer Type: Person\nPassage:\nThe Marie biscuit is named after Marie Alexandrovna , the daughter of Czar Alexander II of Russia and wife of Alfred, the second son of Queen Victoria and Prince Albert\n\n\n\nUse machine learning:Features for ranking candidate answers\nAnswer type match : Candidate contains a phrase with the correct answer type.\nPattern match : Regular expression pattern matches the candidate.\nQuestion keywords: # of question keywords in the\nKeyword distance: Distance in words between the candidate and query keywords\nNovelty factor: A word in the candidate is not in the \n\nApposition features: The candidate is an appositive to question terms\n\nPunctuation location: The candidate is immediately followed by a comma, period, \nquotation marks, semicolon, or exclamation mark.\nSequences of question terms: The length of the longest sequence of question terms that occurs in the candidate answer.\n\nCandidate Answer scoring in IBM Watson\nEach candidate answer gets scores from &gt;50 components\n(from unstructured text, semi structured text, triple stores)\nlogical form (parse) match between question and candidate\né—®é¢˜å’Œå€™é€‰äººä¹‹é—´çš„é€»è¾‘å½¢å¼ï¼ˆè§£æï¼‰åŒ¹é…\n\n\npassage source reliability\næ–‡ç« æºçš„å¯é æ€§\n\n\ngeospatial location\nCalifornia is southwest of Montanaâ€\n\n\ntemporal relationships\ntaxonomic classification\n\n\n\n3.8 Common Evaluation Metrics\nAccuracy (does answer match gold labeled answer?)\nMean Reciprocal Rank å¹³å‡å€’æ•°æ’å\nFor each query return a ranked list of M candidate answers. å¯¹äºæ¯ä¸ªæŸ¥è¯¢ï¼Œè¿”å›Mä¸ªå€™é€‰ç­”æ¡ˆçš„æ’åºåˆ—è¡¨ã€‚\nQuery score is 1/Rank of the first correct answer æŸ¥è¯¢åˆ†æ•°ä¸ºæŸ¥åˆ°ç¬¬ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆæ’åçš„å€’æ•°\nIf first answer is correct: 1\nelse if second answer is correct: Â½\nelse if third answer is correct: â…“, etc.\nScore is 0 if none of the M answers are correct\n\n\nTake the mean over all N queries\n\n\n\n\nMRR=\\frac{\\sum_{i=1}^N\\frac{1}{rank_i}}{N}\nRelevance ç›¸å…³åº¦ The level in which the answer addresses users information needs\nCorrectness æ­£ç¡®åº¦ The level in which the answer is factually correct\nConciseness ç²¾ç‚¼åº¦ ç­”æ¡ˆä¸åŒ…å«ä¸ç›¸å…³ä¿¡æ¯\nCompleteness å®Œå¤‡åº¦ ç­”æ¡ˆåº”è¯¥å®Œæ•´\nSimplicity ç®€å•åº¦ ç­”æ¡ˆæ˜“äºè§£é‡Š\nJustification åˆç†åº¦ Sufficient context should be provided to support the data consumer in the determination of the query correctness\n\n\nRight The answer is correct and complete\nInexact The answer is incomplete or incorrect\nUnsupported The answer does not have an appropriate evidence/justification\nWrongï¼š The answer is not appropriate for the question\n\n4. Knowledge-based QA\næ„å»ºæŸ¥è¯¢çš„è¯­ä¹‰è¡¨ç¤º Build a semantic representation of the query \n\nTimes, dates, locations, entities, numeric quantities\n\n\nä»è¯¥è¯­ä¹‰æ˜ å°„åˆ°æŸ¥è¯¢ç»“æ„åŒ–æ•°æ®æˆ–èµ„æº Map from this semantics to query structured data or resources\n\nGeospatial databases\nOntologies (Wikipedia infoboxes , dbPedia , WordNet , Yago\nRestaurant review sources and reservation services\nScientific databases\n\n\n\n4.1 Two challenges\n\n\nè¯æ³•é¸¿æ²Ÿ Lexical Gap Example\næ„å»ºå‡ºæ¥çš„è¯ä¸ä¸€å®šå’ŒçŸ¥è¯†åº“çš„å®ä½“ç›¸åŒ The constructed words are not necessarily the same as the entities of the knowledge base\n\n\nè¯­ä¹‰é¸¿æ²Ÿ\næ„å»ºå‡ºæ¥çš„å›¾ä¸ä¸€å®šå’ŒçŸ¥è¯†åº“åŒ¹é…  The constructed graph does not necessarily match the knowledge base\n\n\n\n4.1.1 Lexical Gap Example\nWhich Greek cities have more than 1 million inhabitants?\n\nSELECT DISTINCT ?uriWHERE {\t?uri rdf:type dbo:City\t?uri dbo:country res:Greece\t?uri dbo:populationTotal ?p\tFILTER (?p &gt; 1000000)}\n\nThere are expressions with a fixed, dataset independent meaning.\næœ‰äº›è¡¨è¾¾å¼å…·æœ‰å›ºå®šçš„ã€ä¸æ•°æ®é›†æ— å…³çš„å«ä¹‰ã€‚ most, one\n\n\nWho produced the most films?\n\nSELECT DISTINCT ?uriWHERE {?x rdf:type dbo:Film?x dbo:producer uri}ORDER BY DESC(COUNT(?x))OFFSET 0 LIMIT 1\n\nChallenges (Semantic gap):\n\nThe semantic gap [ between natural language and knowledge graphs\n\n\n\n4.1.2 Semantic Gap Example\nDifferent datasets usually follow different schemas, thus provide different ways of answering an information need\n\n\n\nThe meaning of expressions like the verbs to be to have and prepositions of with etc strongly depends on the linguistic context\n\n\n4.2 Pattern/Template based KN QA\nMotivation\nIn order to understand a user question, we need to understand\n\n\n\n\n4.3 Methods\nAn approach that combines both an analysis of the semantic structure and a mapping of words to URIs ä¸€ç§ç»“åˆè¯­ä¹‰ç»“æ„åˆ†æå’Œå•è¯åˆ°URIæ˜ å°„çš„æ–¹æ³•\n\nTemplate generation æ¨¡æ¿ç”Ÿæˆ\nParse question to produce a SPARQL template that directly mirrors the structure of the question, including filters and aggregation operationsè§£æé—®é¢˜ä»¥ç”Ÿæˆç›´æ¥åæ˜ é—®é¢˜ç»“æ„çš„SPARQLæ¨¡æ¿ï¼ŒåŒ…æ‹¬è¿‡æ»¤å’Œèšåˆæ“ä½œ\n\n\nTemplate instantiation æ¨¡æ¿å®ä¾‹åŒ–\nInstantiate SPARQL template by matching natural language expressions with ontology concepts using statistical entity identification and predicate detection é€šè¿‡ä½¿ç”¨ç»Ÿè®¡å®ä½“è¯†åˆ«å’Œè°“è¯æ£€æµ‹å°†è‡ªç„¶è¯­è¨€è¡¨è¾¾å¼ä¸æœ¬ä½“æ¦‚å¿µåŒ¹é…æ¥å®ä¾‹åŒ–SPARQLæ¨¡æ¿\n\n\n\n\nQuestion Who produced the most films?\n\n\n\n\nStep 1: Template generation Linguistic processing\né¦–å…ˆï¼Œè·å–è‡ªç„¶è¯­è¨€é—®é¢˜çš„ POS tags ä¿¡æ¯\nå…¶æ¬¡ï¼ŒåŸºäº POS tags, è¯­æ³•è§„åˆ™è¡¨ç¤ºé—®å¥\nç„¶ååˆ©ç”¨ domain dependent è¯æ±‡å’Œ domain independent è¯æ±‡è¾…åŠ©åˆ†æé—®é¢˜\næœ€åï¼Œå°†è¯­ä¹‰è¡¨ç¤ºè½¬åŒ–ä¸ºä¸€ä¸ª SPARQL æ¨¡æ¿\n\n\ndomain independent : who, the most\ndomain dependent : produced/VBD, films/NNS\n\n\n\nStep2: Template matching and instantiation NER\næœ‰äº† SPARQL æ¨¡æ¿ä»¥å éœ€è¦è¿›è¡Œå®ä¾‹åŒ–ä¸å…·ä½“çš„è‡ªç„¶è¯­è¨€é—®å¥ç›¸åŒ¹é… ã€‚ å³å°†è‡ªç„¶è¯­è¨€é—®å¥ä¸çŸ¥è¯†åº“ä¸­çš„æœ¬ä½“æ¦‚å¿µç›¸æ˜ å°„çš„è¿‡ç¨‹\nå¯¹äº resources å’Œ classes, å®ä½“è¯†åˆ«å¸¸ç”¨æ–¹æ³•\nç”¨ WordNet å®šä¹‰çŸ¥è¯†åº“ä¸­æ ‡ç­¾çš„åŒä¹‰è¯\nè®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ ( Levenshtein å’Œå­ä¸²ç›¸ä¼¼åº¦\n\n\nå¯¹äº property labels, å°†è¿˜éœ€è¦ä¸å­˜å‚¨åœ¨ BOA æ¨¡å¼åº“ä¸­çš„è‡ªç„¶è¯­è¨€è¡¨ç¤ºè¿›è¡Œæ¯”è¾ƒ\næœ€é«˜æ’ä½çš„å®ä½“å°†ä½œä¸ºå¡«å……æŸ¥è¯¢æ§½ä½çš„å€™é€‰ç­”æ¡ˆ\n\n\n\n\n\nWho produced the most films??c CLASS [films]&lt;http://dbpedia.org/ontology/Film&gt;&lt;http://dbpedia.org/ontology/FilmFestival&gt;...?p PROPERTY [produced]&lt;http://dbpedia.org/ontology/producer&gt;&lt;http://dbpedia.org/property/producer&gt;&lt;http://dbpedia.org/ontology/wineProduced&gt;\n\nStep 3:Ranking\næ¯ä¸ª entity æ ¹æ® string similarity å’Œ prominence è·å¾—ä¸€ä¸ªæ‰“åˆ†\nä¸€ä¸ª query æ¨¡æ¿çš„åˆ†å€¼æ ¹æ®å¡«å…… slots çš„å¤šä¸ª entities çš„å¹³å‡æ‰“åˆ†\nå¦å¤– éœ€è¦æ£€æŸ¥ type ç±»å‹\nå¯¹äºæ‰€æœ‰çš„ä¸‰å…ƒç»„ ?x rdf type &lt; å¯¹äºæŸ¥è¯¢ä¸‰å…ƒç»„ ?x p e å’Œ e p ?x éœ€è¦æ£€æŸ¥ p çš„ domain/range æ˜¯å¦ä¸ &lt; ä¸€è‡´\n\n\nå¯¹äºå…¨éƒ¨çš„æŸ¥è¯¢é›†åˆ ä»…è¿”å›æ‰“åˆ†æœ€é«˜çš„\n\n\n\nSELECT DISTINCT ?x WHERE {?x &lt;http://dbpedia.org/ontology/producer&gt; ?y .?y rdf:type &lt;http://dbpedia.org/ontology/Film&gt; .}ORDER BY DESC(COUNT(?y)) LIMIT 1Score: 0.76SELECT DISTINCT ?x WHERE {?x &lt;http://dbpedia.org/ontology/producer&gt; ?y .?y rdf:type &lt;http://dbpedia.org/ontology/FilmFestival&gt;.}ORDER BY DESC(COUNT(?y)) LIMIT 1Score: 0.60\n4.4 Parsing based KB QA\nå¤§æ¦‚å’Œä¸Šé¢ä¸åŒçš„æ˜¯å…ˆå°†æŸ¥è¯¢è¯­å¥è§£æï¼Œå³è¯­ä¹‰è§£æï¼Œæœ€åæ„å»ºæŸ¥è¯¢ï¼›ä¸åŒäºä¸Šé¢æ¨¡æ¿ç”¨åˆ°äº†å…³ç³»æŠ½å–ã€å¥æ³•åˆ†æã€è¯­ä¹‰ç»„åˆ TODO\n\nPhrase mapping\n\nQuery Struecture (Logical Form) Computing\nQuery Evaluation\nAnswers Ranking\n\n\n\n\n\n\nSemantic Parsing on Freebase from Question Answer Pairs. EMNLP 2013\n\n\n\n5. Hybrid approaches (IBM Watson)\nBuild a shallow semantic representation of the query\n\næ„å»ºæŸ¥è¯¢çš„æµ…å±‚è¯­ä¹‰è¡¨ç¤º\n\n\nGenerate answer candidates using IR methods\n\nä½¿ç”¨IRæ–¹æ³•ç”Ÿæˆå€™é€‰ç­”æ¡ˆ\nAugmented with ontologies and semi structured data\nå¢åŠ äº†æœ¬ä½“å’ŒåŠç»“æ„åŒ–æ•°æ®\n\n\nScore each candidate using richer knowledge sources\n\nä½¿ç”¨æ›´ä¸°å¯Œçš„çŸ¥è¯†æ¥æºä¸ºæ¯ä¸ªå€™é€‰äººæ‰“åˆ†\nGeospatial databases åœ°ç†ç©ºé—´æ•°æ®åº“\nTemporal reasoning æ—¶é—´æ¨ç†\nTaxonomical classification å±‚æ¬¡åˆ†ç±»\n\n\n\n6. End to End(deep learning) based KB QA\nOnly for Single Relation and Simple Question\n\nStep1: Candidates generation\n\nFind main entity by Entity Linking æŒ‰å®ä½“é“¾æ¥æŸ¥æ‰¾ä¸»å®ä½“\nAll entities around the main entity in KG are candidates KGä¸­ä¸»å®ä½“å‘¨å›´çš„æ‰€æœ‰å®ä½“éƒ½æ˜¯å€™é€‰å®ä½“\n\n\nStep2: Ranking\n\n\n\n\n\n\n\n7. Dealing with unexpected thingsâ€¦\n\nCaused by Processing\nPoor Ranking\nHarsh Query Constraints\nMisunderstanding of Query\n\n\nCaused by Data\nInaccurate Facts\nIncomplete Data\n\n\n\n\n\n7.1 Search KG in Embedding Space\n\n\n","categories":["nlp"]},{"title":"Regular Expression","url":"/2021/08/15/nlp%20learning/Chapter1_regularexpressions/","content":"æ­£åˆ™è¡¨è¾¾å¼æ“ä½œ\n\nreâ€”- æ­£åˆ™è¡¨è¾¾å¼æ“ä½œ\næ­£åˆ™è¡¨è¾¾å¼å¯ä»¥æ‹¼æ¥ï¼›å¦‚æœ A å’Œ B éƒ½æ˜¯æ­£åˆ™è¡¨è¾¾å¼ï¼Œåˆ™ AB ä¹Ÿæ˜¯æ­£åˆ™è¡¨è¾¾å¼ã€‚\næ­£åˆ™è¡¨è¾¾å¼å¯ä»¥åŒ…å«æ™®é€šæˆ–è€…ç‰¹æ®Šå­—ç¬¦ã€‚ç»å¤§éƒ¨åˆ†æ™®é€šå­—ç¬¦ï¼Œæ¯”å¦‚ 'A', 'a', æˆ–è€… '0'ï¼Œéƒ½æ˜¯æœ€ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚å®ƒä»¬å°±åŒ¹é…è‡ªèº«ã€‚ä½ å¯ä»¥æ‹¼æ¥æ™®é€šå­—ç¬¦ï¼Œæ‰€ä»¥ last åŒ¹é…å­—ç¬¦ä¸² 'last'. \næœ‰äº›å­—ç¬¦ï¼Œæ¯”å¦‚ '|' æˆ–è€… '('ï¼Œå±äºç‰¹æ®Šå­—ç¬¦ã€‚ ç‰¹æ®Šå­—ç¬¦æ—¢å¯ä»¥è¡¨ç¤ºå®ƒçš„æ™®é€šå«ä¹‰ï¼Œ ä¹Ÿå¯ä»¥å½±å“å®ƒæ—è¾¹çš„æ­£åˆ™è¡¨è¾¾å¼çš„è§£é‡Šã€‚\né‡å¤ä¿®é¥°ç¬¦ (*, +, ?, {m,n}, ç­‰) ä¸èƒ½ç›´æ¥åµŒå¥—ã€‚è¿™æ ·é¿å…äº†éè´ªå©ªåç¼€ ? ä¿®é¥°ç¬¦ï¼Œå’Œå…¶ä»–å®ç°ä¸­çš„ä¿®é¥°ç¬¦äº§ç”Ÿçš„å¤šä¹‰æ€§ã€‚è¦åº”ç”¨ä¸€ä¸ªå†…å±‚é‡å¤åµŒå¥—ï¼Œå¯ä»¥ä½¿ç”¨æ‹¬å·ã€‚ æ¯”å¦‚ï¼Œè¡¨è¾¾å¼ (?:a{6})* åŒ¹é…6ä¸ª 'a' å­—ç¬¦é‡å¤ä»»æ„æ¬¡æ•°ã€‚\n\nç‰¹æ®Šå­—ç¬¦æœ‰ï¼š\n.\n(ç‚¹) åœ¨é»˜è®¤æ¨¡å¼ï¼ŒåŒ¹é…é™¤äº†æ¢è¡Œçš„ä»»æ„å­—ç¬¦ã€‚å¦‚æœæŒ‡å®šäº†æ ‡ç­¾ DOTALL ï¼Œå®ƒå°†åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦çš„ä»»æ„å­—ç¬¦ã€‚\n\n^\n(æ’å…¥ç¬¦å·) åŒ¹é…å­—ç¬¦ä¸²çš„å¼€å¤´ï¼Œ å¹¶ä¸”åœ¨ [MULTILINE] æ¨¡å¼ä¹ŸåŒ¹é…æ¢è¡Œåçš„é¦–ä¸ªç¬¦å·ã€‚\n\n$\nåŒ¹é…å­—ç¬¦ä¸²å°¾æˆ–è€…åœ¨å­—ç¬¦ä¸²å°¾çš„æ¢è¡Œç¬¦çš„å‰ä¸€ä¸ªå­—ç¬¦ï¼Œåœ¨ MULTILINEæ¨¡å¼ä¸‹ä¹Ÿä¼šåŒ¹é…æ¢è¡Œç¬¦ä¹‹å‰çš„æ–‡æœ¬ã€‚ foo åŒ¹é… â€˜fooâ€™ å’Œ â€˜foobarâ€™ï¼Œä½†æ­£åˆ™è¡¨è¾¾å¼ foo$ åªåŒ¹é… â€˜fooâ€™ã€‚ æ›´æœ‰è¶£çš„æ˜¯ï¼Œåœ¨ 'foo1\\nfoo2\\n' ä¸­æœç´¢ foo.$ï¼Œé€šå¸¸åŒ¹é… â€˜foo2â€™ï¼Œä½†åœ¨ [MULTILINE]æ¨¡å¼ä¸‹å¯ä»¥åŒ¹é…åˆ° â€˜foo1â€™ï¼›åœ¨ 'foo\\n' ä¸­æœç´¢ $ ä¼šæ‰¾åˆ°ä¸¤ä¸ªï¼ˆç©ºçš„ï¼‰åŒ¹é…ï¼šä¸€ä¸ªåœ¨æ¢è¡Œç¬¦ä¹‹å‰ï¼Œä¸€ä¸ªåœ¨å­—ç¬¦ä¸²çš„æœ«å°¾ã€‚\n\n*\nå¯¹å®ƒå‰é¢çš„æ­£åˆ™å¼åŒ¹é…0åˆ°ä»»æ„æ¬¡é‡å¤ï¼Œ å°½é‡å¤šçš„åŒ¹é…å­—ç¬¦ä¸²ã€‚ ab* ä¼šåŒ¹é… 'a'ï¼Œ'ab'ï¼Œæˆ–è€… 'a' åé¢è·Ÿéšä»»æ„ä¸ª 'b'ã€‚\n\n+\nå¯¹å®ƒå‰é¢çš„æ­£åˆ™å¼åŒ¹é…1åˆ°ä»»æ„æ¬¡é‡å¤ã€‚ ab+ ä¼šåŒ¹é… 'a' åé¢è·Ÿéš1ä¸ªä»¥ä¸Šåˆ°ä»»æ„ä¸ª 'b'ï¼Œå®ƒä¸ä¼šåŒ¹é… 'a'ã€‚\n\n?\nå¯¹å®ƒå‰é¢çš„æ­£åˆ™å¼åŒ¹é…0åˆ°1æ¬¡é‡å¤ã€‚ ab? ä¼šåŒ¹é… 'a' æˆ–è€… 'ab'\n\n*?, +?, ??\n'*', '+'ï¼Œå’Œ '?' ä¿®é¥°ç¬¦éƒ½æ˜¯ è´ªå©ªçš„ï¼›å®ƒä»¬åœ¨å­—ç¬¦ä¸²è¿›è¡Œå°½å¯èƒ½å¤šçš„åŒ¹é…ã€‚æœ‰æ—¶å€™å¹¶ä¸éœ€è¦è¿™ç§è¡Œä¸ºã€‚å¦‚æœæ­£åˆ™å¼ &lt;.*&gt; å¸Œæœ›æ‰¾åˆ° '&lt;a&gt; b &lt;c&gt;'ï¼Œå®ƒå°†ä¼šåŒ¹é…æ•´ä¸ªå­—ç¬¦ä¸²ï¼Œè€Œä¸ä»…æ˜¯ '&lt;a&gt;'ã€‚åœ¨ä¿®é¥°ç¬¦ä¹‹åæ·»åŠ  ? å°†ä½¿æ ·å¼ä»¥ éè´ªå©ªæ–¹å¼æˆ–è€… :dfn:æœ€å° æ–¹å¼è¿›è¡ŒåŒ¹é…ï¼› å°½é‡ å°‘ çš„å­—ç¬¦å°†ä¼šè¢«åŒ¹é…ã€‚ ä½¿ç”¨æ­£åˆ™å¼ &lt;.*?&gt; å°†ä¼šä»…ä»…åŒ¹é… '&lt;a&gt;'ã€‚\n\n{m}\nå¯¹å…¶ä¹‹å‰çš„æ­£åˆ™å¼æŒ‡å®šåŒ¹é… m ä¸ªé‡å¤ï¼›å°‘äº m çš„è¯å°±ä¼šå¯¼è‡´åŒ¹é…å¤±è´¥ã€‚æ¯”å¦‚ï¼Œ a{6} å°†åŒ¹é…6ä¸ª 'a' , ä½†æ˜¯ä¸èƒ½æ˜¯5ä¸ªã€‚\n\n{m,n}\nå¯¹æ­£åˆ™å¼è¿›è¡Œ m åˆ° n æ¬¡åŒ¹é…ï¼Œåœ¨ m å’Œ n ä¹‹é—´å–å°½é‡å¤šã€‚ æ¯”å¦‚ï¼Œa{3,5} å°†åŒ¹é… 3 åˆ° 5ä¸ª 'a'ã€‚å¿½ç•¥ m æ„ä¸ºæŒ‡å®šä¸‹ç•Œä¸º0ï¼Œå¿½ç•¥ n æŒ‡å®šä¸Šç•Œä¸ºæ— é™æ¬¡ã€‚ æ¯”å¦‚ a{4,}b å°†åŒ¹é… 'aaaab' æˆ–è€…1000ä¸ª 'a' å°¾éšä¸€ä¸ª 'b'ï¼Œä½†ä¸èƒ½åŒ¹é… 'aaab'ã€‚é€—å·ä¸èƒ½çœç•¥ï¼Œå¦åˆ™æ— æ³•è¾¨åˆ«ä¿®é¥°ç¬¦åº”è¯¥å¿½ç•¥å“ªä¸ªè¾¹ç•Œã€‚\n\n{m,n}?\nå‰ä¸€ä¸ªä¿®é¥°ç¬¦çš„éè´ªå©ªæ¨¡å¼ï¼ŒåªåŒ¹é…å°½é‡å°‘çš„å­—ç¬¦æ¬¡æ•°ã€‚æ¯”å¦‚ï¼Œå¯¹äº 'aaaaaa'ï¼Œ a{3,5} åŒ¹é… 5ä¸ª 'a' ï¼Œè€Œ a{3,5}? åªåŒ¹é…3ä¸ª 'a'ã€‚\n\n\n\n\\\nè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼ˆå…è®¸ä½ åŒ¹é… '*', '?', æˆ–è€…æ­¤ç±»å…¶ä»–ï¼‰ï¼Œæˆ–è€…è¡¨ç¤ºä¸€ä¸ªç‰¹æ®Šåºåˆ—ï¼›ç‰¹æ®Šåºåˆ—ä¹‹åè¿›è¡Œè®¨è®ºã€‚å¦‚æœä½ æ²¡æœ‰ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²ï¼ˆ r'raw' ï¼‰æ¥è¡¨è¾¾æ ·å¼ï¼Œè¦ç‰¢è®°Pythonä¹Ÿä½¿ç”¨åæ–œæ ä½œä¸ºè½¬ä¹‰åºåˆ—ï¼›å¦‚æœè½¬ä¹‰åºåˆ—ä¸è¢«Pythonçš„åˆ†æå™¨è¯†åˆ«ï¼Œåæ–œæ å’Œå­—ç¬¦æ‰èƒ½å‡ºç°åœ¨å­—ç¬¦ä¸²ä¸­ã€‚å¦‚æœPythonå¯ä»¥è¯†åˆ«è¿™ä¸ªåºåˆ—ï¼Œé‚£ä¹ˆåæ–œæ å°±åº”è¯¥é‡å¤ä¸¤æ¬¡ã€‚è¿™å°†å¯¼è‡´ç†è§£éšœç¢ï¼Œæ‰€ä»¥é«˜åº¦æ¨èï¼Œå°±ç®—æ˜¯æœ€ç®€å•çš„è¡¨è¾¾å¼ï¼Œä¹Ÿè¦ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²ã€‚\n\n[]\nç”¨äºè¡¨ç¤ºä¸€ä¸ªå­—ç¬¦é›†åˆã€‚åœ¨ä¸€ä¸ªé›†åˆä¸­ï¼š\n\nå­—ç¬¦å¯ä»¥å•ç‹¬åˆ—å‡ºï¼Œæ¯”å¦‚ [amk] åŒ¹é… 'a'ï¼Œ 'm'ï¼Œ æˆ–è€… 'k'ã€‚\n\nå¯ä»¥è¡¨ç¤ºå­—ç¬¦èŒƒå›´ï¼Œé€šè¿‡ç”¨ '-' å°†ä¸¤ä¸ªå­—ç¬¦è¿èµ·æ¥ã€‚æ¯”å¦‚ [a-z] å°†åŒ¹é…ä»»ä½•å°å†™ASCIIå­—ç¬¦ï¼Œ [0-5][0-9] å°†åŒ¹é…ä» 00 åˆ° 59 çš„ä¸¤ä½æ•°å­—ï¼Œ [0-9A-Fa-f] å°†åŒ¹é…ä»»ä½•åå…­è¿›åˆ¶æ•°ä½ã€‚ å¦‚æœ - è¿›è¡Œäº†è½¬ä¹‰ ï¼ˆæ¯”å¦‚ [a\\-z]ï¼‰æˆ–è€…å®ƒçš„ä½ç½®åœ¨é¦–ä½æˆ–è€…æœ«å°¾ï¼ˆå¦‚ [-a] æˆ– [a-]ï¼‰ï¼Œå®ƒå°±åªè¡¨ç¤ºæ™®é€šå­—ç¬¦ '-'ã€‚\n\nç‰¹æ®Šå­—ç¬¦åœ¨é›†åˆä¸­ï¼Œå¤±å»å®ƒçš„ç‰¹æ®Šå«ä¹‰ã€‚æ¯”å¦‚ [(+*)] åªä¼šåŒ¹é…è¿™å‡ ä¸ªæ–‡æ³•å­—ç¬¦ '(', '+', '*', or ')'ã€‚\n\nå­—ç¬¦ç±»å¦‚ \\w æˆ–è€… \\S (å¦‚ä¸‹å®šä¹‰) åœ¨é›†åˆå†…å¯ä»¥æ¥å—ï¼Œå®ƒä»¬å¯ä»¥åŒ¹é…çš„å­—ç¬¦ç”± [ASCII]æ¨¡å¼å†³å®šã€‚\n\nä¸åœ¨é›†åˆèŒƒå›´å†…çš„å­—ç¬¦å¯ä»¥é€šè¿‡ å–å æ¥è¿›è¡ŒåŒ¹é…ã€‚å¦‚æœé›†åˆé¦–å­—ç¬¦æ˜¯ '^' ï¼Œæ‰€æœ‰ ä¸ åœ¨é›†åˆå†…çš„å­—ç¬¦å°†ä¼šè¢«åŒ¹é…ï¼Œæ¯”å¦‚ [^5] å°†åŒ¹é…æ‰€æœ‰å­—ç¬¦ï¼Œé™¤äº† '5'ï¼Œ [^^] å°†åŒ¹é…æ‰€æœ‰å­—ç¬¦ï¼Œé™¤äº† '^'. ^ å¦‚æœä¸åœ¨é›†åˆé¦–ä½ï¼Œå°±æ²¡æœ‰ç‰¹æ®Šå«ä¹‰ã€‚\n\nåœ¨é›†åˆå†…è¦åŒ¹é…ä¸€ä¸ªå­—ç¬¦ ']'ï¼Œæœ‰ä¸¤ç§æ–¹æ³•ï¼Œè¦ä¹ˆå°±åœ¨å®ƒä¹‹å‰åŠ ä¸Šåæ–œæ ï¼Œè¦ä¹ˆå°±æŠŠå®ƒæ”¾åˆ°é›†åˆé¦–ä½ã€‚æ¯”å¦‚ï¼Œ [()[\\]{}] å’Œ []()[{}] éƒ½å¯ä»¥åŒ¹é…æ‹¬å·\n\n\n|\n`A|Bï¼Œ A å’Œ B å¯ä»¥æ˜¯ä»»æ„æ­£åˆ™è¡¨è¾¾å¼ï¼Œåˆ›å»ºä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒ¹é… A æˆ–è€… B. ä»»æ„ä¸ªæ­£åˆ™è¡¨è¾¾å¼å¯ä»¥ç”¨ '|' è¿æ¥ã€‚å®ƒä¹Ÿå¯ä»¥åœ¨ç»„åˆï¼ˆè§ä¸‹åˆ—ï¼‰å†…ä½¿ç”¨ã€‚æ‰«æç›®æ ‡å­—ç¬¦ä¸²æ—¶ï¼Œ '|' åˆ†éš”å¼€çš„æ­£åˆ™æ ·å¼ä»å·¦åˆ°å³è¿›è¡ŒåŒ¹é…ã€‚å½“ä¸€ä¸ªæ ·å¼å®Œå…¨åŒ¹é…æ—¶ï¼Œè¿™ä¸ªåˆ†æ”¯å°±è¢«æ¥å—ã€‚æ„æ€å°±æ˜¯ï¼Œä¸€æ—¦ A åŒ¹é…æˆåŠŸï¼Œ B å°±ä¸å†è¿›è¡ŒåŒ¹é…ï¼Œå³ä¾¿å®ƒèƒ½äº§ç”Ÿä¸€ä¸ªæ›´å¥½çš„åŒ¹é…ã€‚æˆ–è€…è¯´ï¼Œ'|' æ“ä½œç¬¦ç»ä¸è´ªå©ªã€‚ å¦‚æœè¦åŒ¹é… '|' å­—ç¬¦ï¼Œä½¿ç”¨ \\|ï¼Œ æˆ–è€…æŠŠå®ƒåŒ…å«åœ¨å­—ç¬¦é›†é‡Œï¼Œæ¯”å¦‚ [|].\n\n(...)ï¼ˆç»„åˆï¼‰ï¼ŒåŒ¹é…æ‹¬å·å†…çš„ä»»æ„æ­£åˆ™è¡¨è¾¾å¼ï¼Œå¹¶æ ‡è¯†å‡ºç»„åˆçš„å¼€å§‹å’Œç»“å°¾ã€‚åŒ¹é…å®Œæˆåï¼Œç»„åˆçš„å†…å®¹å¯ä»¥è¢«è·å–ï¼Œå¹¶å¯ä»¥åœ¨ä¹‹åç”¨ \\number è½¬ä¹‰åºåˆ—è¿›è¡Œå†æ¬¡åŒ¹é…ï¼Œä¹‹åè¿›è¡Œè¯¦ç»†è¯´æ˜ã€‚è¦åŒ¹é…å­—ç¬¦ '(' æˆ–è€… ')', ç”¨ \\( æˆ– \\), æˆ–è€…æŠŠå®ƒä»¬åŒ…å«åœ¨å­—ç¬¦é›†åˆé‡Œ: [(], `[)]``\n\n(?â€¦)\nè¿™æ˜¯ä¸ªæ‰©å±•æ ‡è®°æ³• ï¼ˆä¸€ä¸ª '?' è·Ÿéš '(' å¹¶æ— å«ä¹‰ï¼‰ã€‚ '?' åé¢çš„ç¬¬ä¸€ä¸ªå­—ç¬¦å†³å®šäº†è¿™ä¸ªæ„å»ºé‡‡ç”¨ä»€ä¹ˆæ ·çš„è¯­æ³•ã€‚\n\n`(?aiLmsux)\n( 'a', 'i', 'L', 'm', 's', 'u', 'x' ä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ª) è¿™ä¸ªç»„åˆåŒ¹é…ä¸€ä¸ªç©ºå­—ç¬¦ä¸²ï¼›\n\n(?:â€¦)\næ­£åˆ™æ‹¬å·çš„éæ•è·ç‰ˆæœ¬ã€‚ åŒ¹é…åœ¨æ‹¬å·å†…çš„ä»»ä½•æ­£åˆ™è¡¨è¾¾å¼ï¼Œä½†è¯¥åˆ†ç»„æ‰€åŒ¹é…çš„å­å­—ç¬¦ä¸² ä¸èƒ½ åœ¨æ‰§è¡ŒåŒ¹é…åè¢«è·å–æˆ–æ˜¯ä¹‹ååœ¨æ¨¡å¼ä¸­è¢«å¼•ç”¨ã€‚\n\n(?aiLmsux-imsx:â€¦)\n('a', 'i', 'L', 'm', 's', 'u', 'x' ä¸­çš„0æˆ–è€…å¤šä¸ªï¼Œ ä¹‹åå¯é€‰è·Ÿéš '-' åœ¨åé¢è·Ÿéš 'i' , 'm' , 's' , 'x' ä¸­çš„ä¸€åˆ°å¤šä¸ª .) \n\n(?#â€¦)\næ³¨é‡Šï¼›é‡Œé¢çš„å†…å®¹ä¼šè¢«å¿½ç•¥ã€‚\n\n\\number:\\1\nåŒ¹é…æ•°å­—ä»£è¡¨çš„ç»„åˆã€‚æ¯ä¸ªæ‹¬å·æ˜¯ä¸€ä¸ªç»„åˆï¼Œç»„åˆä»1å¼€å§‹ç¼–å·ã€‚æ¯”å¦‚ (.+) \\1 åŒ¹é… 'the the' æˆ–è€… '55 55', ä½†ä¸ä¼šåŒ¹é… 'thethe' (æ³¨æ„ç»„åˆåé¢çš„ç©ºæ ¼)ã€‚è¿™ä¸ªç‰¹æ®Šåºåˆ—åªèƒ½ç”¨äºåŒ¹é…å‰é¢99ä¸ªç»„åˆã€‚å¦‚æœ number çš„ç¬¬ä¸€ä¸ªæ•°ä½æ˜¯0ï¼Œ æˆ–è€… number æ˜¯ä¸‰ä¸ªå…«è¿›åˆ¶æ•°ï¼Œå®ƒå°†ä¸ä¼šè¢«çœ‹ä½œæ˜¯ä¸€ä¸ªç»„åˆï¼Œè€Œæ˜¯å…«è¿›åˆ¶çš„æ•°å­—å€¼ã€‚åœ¨ '[' å’Œ ']' å­—ç¬¦é›†åˆå†…ï¼Œä»»ä½•æ•°å­—è½¬ä¹‰éƒ½è¢«çœ‹ä½œæ˜¯å­—ç¬¦ã€‚\n\n\\b\nåŒ¹é…ç©ºå­—ç¬¦ä¸²ï¼Œä½†åªåœ¨å•è¯å¼€å§‹æˆ–ç»“å°¾çš„ä½ç½®ã€‚ä¸€ä¸ªå•è¯è¢«å®šä¹‰ä¸ºä¸€ä¸ªå•è¯å­—ç¬¦çš„åºåˆ—ã€‚æ³¨æ„ï¼Œé€šå¸¸ \\b å®šä¹‰ä¸º \\w å’Œ \\W å­—ç¬¦ä¹‹é—´ï¼Œæˆ–è€… \\w å’Œå­—ç¬¦ä¸²å¼€å§‹/ç»“å°¾çš„è¾¹ç•Œï¼Œ æ„æ€å°±æ˜¯ r'\\bfoo\\b' åŒ¹é… 'foo', 'foo.', '(foo)', 'bar foo baz' ä½†ä¸åŒ¹é… 'foobar' æˆ–è€… 'foo3'ã€‚\nk = re.findall(r'\\bfoo\\b', 'foo')print(k)k = re.findall(r'\\bfoo\\b', '(foo)')print(k)k = re.findall(r'\\bfoo\\b', 'foo.')print(k)k = re.findall(r'\\bfoo\\b', 'bar foo bar')print(k)k = re.findall(r'\\bfoo\\b', 'foo3')print(k)\noutput:  [â€˜fooâ€™] [â€˜fooâ€™] [â€˜fooâ€™] [â€˜fooâ€™] []\n\\s\n\nå¯¹äº Unicode (str) æ ·å¼ï¼š\nåŒ¹é…ä»»ä½•Unicodeç©ºç™½å­—ç¬¦ï¼ˆåŒ…æ‹¬ [ \\t\\n\\r\\f\\v] ï¼Œè¿˜æœ‰å¾ˆå¤šå…¶ä»–å­—ç¬¦ï¼Œæ¯”å¦‚ä¸åŒè¯­è¨€æ’ç‰ˆè§„åˆ™çº¦å®šçš„ä¸æ¢è¡Œç©ºæ ¼ï¼‰ã€‚å¦‚æœ ASCII è¢«è®¾ç½®ï¼Œå°±åªåŒ¹é… [ \\t\\n\\r\\f\\v] ã€‚\n\nå¯¹äº8ä½(bytes)æ ·å¼ï¼š\nåŒ¹é…ASCIIä¸­çš„ç©ºç™½å­—ç¬¦ï¼Œå°±æ˜¯ [ \\t\\n\\r\\f\\v] ã€‚\n\n\n\n\\w\n\nå¯¹äº Unicode (str) æ ·å¼ï¼š\nåŒ¹é…Unicodeè¯è¯­çš„å­—ç¬¦ï¼ŒåŒ…å«äº†å¯ä»¥æ„æˆè¯è¯­çš„ç»å¤§éƒ¨åˆ†å­—ç¬¦ï¼Œä¹ŸåŒ…æ‹¬æ•°å­—å’Œä¸‹åˆ’çº¿ã€‚å¦‚æœè®¾ç½®äº† ASCII æ ‡å¿—ï¼Œå°±åªåŒ¹é… [a-zA-Z0-9_] ã€‚\n\nå¯¹äº8ä½(bytes)æ ·å¼ï¼š\nåŒ¹é…ASCIIå­—ç¬¦ä¸­çš„æ•°å­—å’Œå­—æ¯å’Œä¸‹åˆ’çº¿ï¼Œå°±æ˜¯ [a-zA-Z0-9_] ã€‚å¦‚æœè®¾ç½®äº† [LOCALE] æ ‡è®°ï¼Œå°±åŒ¹é…å½“å‰è¯­è¨€åŒºåŸŸçš„æ•°å­—å’Œå­—æ¯å’Œä¸‹åˆ’çº¿ã€‚\n\n\n\n\nRe.  ç›¸å…³å‡½æ•°\nre.``compile(pattern, flags=0)\nå°†æ­£åˆ™è¡¨è¾¾å¼çš„æ ·å¼ç¼–è¯‘ä¸ºä¸€ä¸ª æ­£åˆ™è¡¨è¾¾å¼å¯¹è±¡ ï¼ˆæ­£åˆ™å¯¹è±¡ï¼‰ï¼Œå¯ä»¥ç”¨äºåŒ¹é…ï¼Œé€šè¿‡è¿™ä¸ªå¯¹è±¡çš„æ–¹æ³• [match()], [search()]ä»¥åŠå…¶ä»–å¦‚ä¸‹æè¿°ã€‚\nè¿™ä¸ªè¡¨è¾¾å¼çš„è¡Œä¸ºå¯ä»¥é€šè¿‡æŒ‡å®š æ ‡è®° çš„å€¼æ¥æ”¹å˜ã€‚å€¼å¯ä»¥æ˜¯ä»¥ä¸‹ä»»æ„å˜é‡ï¼Œå¯ä»¥é€šè¿‡ä½çš„ORæ“ä½œæ¥ç»“åˆï¼ˆ | æ“ä½œç¬¦ï¼‰ã€‚\nåºåˆ—\nprog = re.compile(pattern)result = prog.match(string)\nç­‰ä»·äº\nresult = re.match(pattern, string)\nå¦‚æœéœ€è¦å¤šæ¬¡ä½¿ç”¨è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼çš„è¯ï¼Œä½¿ç”¨ [re.compile()] å’Œä¿å­˜è¿™ä¸ªæ­£åˆ™å¯¹è±¡ä»¥ä¾¿å¤ç”¨ï¼Œå¯ä»¥è®©ç¨‹åºæ›´åŠ é«˜æ•ˆã€‚\næ³¨è§£:é€šè¿‡ [re.compile()]ç¼–è¯‘åçš„æ ·å¼ï¼Œå’Œæ¨¡å—çº§çš„å‡½æ•°ä¼šè¢«ç¼“å­˜ï¼Œ æ‰€ä»¥å°‘æ•°çš„æ­£åˆ™è¡¨è¾¾å¼ä½¿ç”¨æ— éœ€è€ƒè™‘ç¼–è¯‘çš„é—®é¢˜ã€‚\n\nre.search(pattern, string, flags=0)\næ‰«ææ•´ä¸ª å­—ç¬¦ä¸² æ‰¾åˆ°åŒ¹é…æ ·å¼çš„ç¬¬ä¸€ä¸ªä½ç½®ï¼Œå¹¶è¿”å›ä¸€ä¸ªç›¸åº”çš„ [åŒ¹é…å¯¹è±¡]ã€‚å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œå°±è¿”å›ä¸€ä¸ª None ï¼› æ³¨æ„è¿™å’Œæ‰¾åˆ°ä¸€ä¸ªé›¶é•¿åº¦åŒ¹é…æ˜¯ä¸åŒçš„ã€‚\n\nre.match(pattern, string, flags=0)\nå¦‚æœ string å¼€å§‹çš„0æˆ–è€…å¤šä¸ªå­—ç¬¦åŒ¹é…åˆ°äº†æ­£åˆ™è¡¨è¾¾å¼æ ·å¼ï¼Œå°±è¿”å›ä¸€ä¸ªç›¸åº”çš„ [åŒ¹é…å¯¹è±¡]ã€‚ å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œå°±è¿”å› None ï¼›æ³¨æ„å®ƒè·Ÿé›¶é•¿åº¦åŒ¹é…æ˜¯ä¸åŒçš„\n\nfullmatch(pattern, string, flags=0)\nå¦‚æœæ•´ä¸ª string åŒ¹é…åˆ°æ­£åˆ™è¡¨è¾¾å¼æ ·å¼ï¼Œå°±è¿”å›ä¸€ä¸ªç›¸åº”çš„ [åŒ¹é…å¯¹è±¡] ã€‚ å¦åˆ™å°±è¿”å›ä¸€ä¸ª None ï¼›æ³¨æ„è¿™è·Ÿé›¶é•¿åº¦åŒ¹é…æ˜¯ä¸åŒçš„ã€‚\n\nsplit(pattern, string, maxsplit=0, flags=0)\nç”¨ pattern åˆ†å¼€ string ã€‚ å¦‚æœåœ¨ pattern ä¸­æ•è·åˆ°æ‹¬å·ï¼Œé‚£ä¹ˆæ‰€æœ‰çš„ç»„é‡Œçš„æ–‡å­—ä¹Ÿä¼šåŒ…å«åœ¨åˆ—è¡¨é‡Œã€‚å¦‚æœ maxsplit éé›¶ï¼Œ æœ€å¤šè¿›è¡Œ maxsplit æ¬¡åˆ†éš”ï¼Œ å‰©ä¸‹çš„å­—ç¬¦å…¨éƒ¨è¿”å›åˆ°åˆ—è¡¨çš„æœ€åä¸€ä¸ªå…ƒç´ ã€‚\n\nre.split()åˆ‡å‰²åŠŸèƒ½éå¸¸å¼ºå¤§\nå•å­—ç¬¦åˆ‡å‰²\nä¸¤ä¸ªå­—ç¬¦ä»¥ä¸Šåˆ‡å‰²éœ€è¦æ”¾åœ¨ [ ] ä¸­\næ‰€æœ‰ç©ºç™½å­—ç¬¦åˆ‡å‰²\nä½¿ç”¨æ‹¬å·æ•è·åˆ†ç»„ï¼Œé»˜è®¤ä¿ç•™åˆ†å‰²ç¬¦\nä¸æƒ³ä¿ç•™åˆ†éš”ç¬¦ï¼Œä»¥ï¼ˆ?:â€¦ï¼‰çš„å½¢å¼æŒ‡å®š\n\n\nre.findall(pattern, string, flags=0)\nå¯¹ string è¿”å›ä¸€ä¸ªä¸é‡å¤çš„ pattern çš„åŒ¹é…åˆ—è¡¨ï¼Œ string ä»å·¦åˆ°å³è¿›è¡Œæ‰«æï¼ŒåŒ¹é…æŒ‰æ‰¾åˆ°çš„é¡ºåºè¿”å›ã€‚å¦‚æœæ ·å¼é‡Œå­˜åœ¨ä¸€åˆ°å¤šä¸ªç»„ï¼Œå°±è¿”å›ä¸€ä¸ªç»„åˆåˆ—è¡¨ï¼›å°±æ˜¯ä¸€ä¸ªå…ƒç»„çš„åˆ—è¡¨ï¼ˆå¦‚æœæ ·å¼é‡Œæœ‰è¶…è¿‡ä¸€ä¸ªç»„åˆçš„è¯ï¼‰ã€‚ç©ºåŒ¹é…ä¹Ÿä¼šåŒ…å«åœ¨ç»“æœé‡Œã€‚\n\nre.sub(pattern, repl, string, count=0, flags=0)\nè¿”å›é€šè¿‡ä½¿ç”¨ repl æ›¿æ¢åœ¨ string æœ€å·¦è¾¹éé‡å å‡ºç°çš„ pattern è€Œè·å¾—çš„å­—ç¬¦ä¸²ã€‚ å¦‚æœæ ·å¼æ²¡æœ‰æ‰¾åˆ°ï¼Œåˆ™ä¸åŠ æ”¹å˜åœ°è¿”å› stringã€‚ repl å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å‡½æ•°ï¼›å¦‚ä¸ºå­—ç¬¦ä¸²ï¼Œåˆ™å…¶ä¸­ä»»ä½•åæ–œæ è½¬ä¹‰åºåˆ—éƒ½ä¼šè¢«å¤„ç†ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œ\\n ä¼šè¢«è½¬æ¢ä¸ºä¸€ä¸ªæ¢è¡Œç¬¦ï¼Œ\\r ä¼šè¢«è½¬æ¢ä¸ºä¸€ä¸ªå›è½¦é™„ï¼Œä¾æ­¤ç±»æ¨ã€‚ æœªçŸ¥çš„ ASCII å­—ç¬¦è½¬ä¹‰åºåˆ—ä¿ç•™åœ¨æœªæ¥ä½¿ç”¨ï¼Œä¼šè¢«å½“ä½œé”™è¯¯æ¥å¤„ç†ã€‚ å…¶ä»–æœªçŸ¥è½¬ä¹‰åºåˆ—ä¾‹å¦‚ \\&amp; ä¼šä¿æŒåŸæ ·ã€‚ å‘åå¼•ç”¨åƒæ˜¯ \\6 ä¼šç”¨æ ·å¼ä¸­ç¬¬ 6 ç»„æ‰€åŒ¹é…åˆ°çš„å­å­—ç¬¦ä¸²æ¥æ›¿æ¢ã€‚ ä¾‹å¦‚\n\n\nä¸Šè¯¾ç¬”è®°&amp;é‡ç‚¹\n\n\n\n\n\n\n\n\n\ntxt = 'Column 1 Column 2 Column 3 Column 3546   Column 3s   're.findall('Column [0-9]+ *', txt)\n\nre.search('(Column [0-9]+ *)*', txt)\n\nre.findall('(Column [0-9]+ *)+', txt)\n\nä¸Šè¯¾ç¤ºä¾‹import retxt = \"Tie best singer ever is Jay Chouï¼ŒThe ticket price for his concert is $100\"x = re.findall('[A-Z]', txt)if(x):    print('find success', x)x = re.search('a\\^b', 'sdasd a^b sab')print(x)\n\ntxt2 = 'The best thing is  love, the other is hate'm = re.findall('the', txt2)print(m)m = re.findall('[tT]he', txt2)print(m)m = re.findall('\\\\b[tT]he\\\\b', txt2)print(m)m = re.findall(r'\\b[tT]he\\b', txt2)print(m)m = re.findall('[^a-zA-Z][tT]he[^a-zA-Z]', txt2)print(m)m = re.findall(r'[^a-zA-Z][tT]he[^a-zA-Z]', txt2)print(m)\n\ntxt3 = '025-12345678 #è¿™æ˜¯ä¸€ä¸ªå—äº¬ç”µè¯å·ç 'n = re.sub('#.*$','', txt3)print(n)\n\ntxt4 = 'guppy guppies'd = re.findall('guppy|ies', txt4)print(d)d = re.findall('gupp(y|ies)', txt4)print(d) #æ˜¾ç¤ºæœ€ä¼˜å…ˆåŒ¹é…d = re.match('gupp(y|ies)', txt4)print(d)d = re.findall('guppy|guppies', txt4)print(d) #æ˜¾ç¤ºæœ€ä¼˜å…ˆåŒ¹é…\n\ntxt4 = 'once upon a time'l = re.match('[a-z]*', txt4)print(l)\n\nFinate State Automata\n\n\n\n\n\n","categories":["nlp"]},{"title":"Word Vector","url":"/2021/08/15/nlp%20learning/Chapter5_Word%20Vector/","content":"Word Vector\n\n\n1. Logistic Regression for x\nInput:\na document \na fixed set of classes â€‹\n\n\nOutput: a predicted class â€‹\n\nInput observation: vector \nWeights: one per feature: â€‹\n\nSometimes we call the weights \n\nOutput: a predicted class â€‹\n(multinomial logistic regression: â€‹\n2. Making  with sigmoids\n\\hat{y}= \\begin{cases}1 & \\text { if } P(y=1 \\mid x)>0.5 & \\text { if } \\mathrm{w} \\cdot \\mathrm{x}+\\mathrm{b}>0 \\\\ 0 & \\text { otherwise } & \\text { if } \\mathrm{w} \\cdot \\mathrm{x}+\\mathrm{b} \\leq 0\\end{cases}\n\\begin{aligned}\nP(y=1) &=\\sigma(w \\cdot x+b) \\\\\n&=\\frac{1}{1+\\exp (-(w \\cdot x+b))} \\\\\nP(y=0) &=1-\\sigma(w \\cdot x+b) \\\\\n&=1-\\frac{1}{1+\\exp (-(w \\cdot x+b))} \\\\\n&=\\frac{\\exp (-(w \\cdot x+b))}{1+\\exp (-(w \\cdot x+b))}\n\\end{aligned}\nL(\\beta)=\\prod^n_{i=1}y_iP(Y=y_i|X=x_i;\\beta)\\\\\n\\begin{array}{l}\nlogL(\\beta)=\\sum^n_{i=1}y_ilogP(Y=1|X=x_i;\\beta)+(1-y_i)logP(Y=0|X=x_i;\\beta)\\\\\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\sum^n_{i=1}\ny_ilog(\\frac{1}{1+e^{-\\beta^Tx}})+(1-y_i)log(\\frac{e^{-\\beta^Tx}}{1+e^{-\\beta^Tx}})\\\\\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\sum^n_{i=1}\ny_i(log(\\frac{1}{1+e^{-\\beta^Tx}})-log(\\frac{e^{-\\beta^Tx}}{1+e^{-\\beta^Tx}}))+log(\\frac{e^{-\\beta^Tx}}{1+e^{-\\beta^Tx}})\\\\\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\sum^n_{i=1}\ny_i\\beta^Tx-log(1+e^{\\beta^Tx})\n\\end{array}\n\\begin{array}{ll}\n\\bigtriangledown_\\beta L(\\beta)=\\sum^n_{i=1}(y_i x - \\frac{x_ie^{\\beta^Tx_i}}{1+e^{\\beta^Tx_i}})\\\\\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \n=\\sum^n_{i=1}x_i(y_i - \\sigma(\\beta^Tx_i))\n\\end{array}For SGD:\n\n\\begin{array}{ll}\\\\\n\\beta^{(k+1)}=\\beta^{(k)}-\\alpha \\bigtriangledown L(\\beta)\\\\\n\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \n=\\beta^{(k)}-\\sum^{min\\_batch}_{i=1}x_i(y_i - \\sigma(\\beta^Tx_i))\n\\end{array}\n\nTraining: we learn weights w and b using stochastic gradient descent and cross-entropy loss.\n\n3. How to present the word\n\næŠŠæ‰€æœ‰ç§¯æçš„è¯æœé›†èµ·æ¥ï¼Œå°è¯•ç”¨é¢‘ç‡å¯¹å•è¯è¿›è¡Œè¡¨è¾¾\n\nSuppose \n\n\n\n\\begin{aligned}\np(+|x)=P(Y=1|x) & = s (\\begin{array}{l}\nW {x+b})\n\\end{array} \\\\\n&=s([2.5,-5.0,-1.2,0.5,2.0,0.7]\\dotproduct[3,2,1,3,0,4.19]+0.1) \\\\\n&=s(0.833) \\\\\n&=0.70 \\\\\np(-|x)=P(Y=0 | x) &=1-s(W  x+b) \\\\\n=& 0.30\n\\end{aligned}\n\nClassification problem : \nx: watermelons\ny : which class belongs to\n\n\n\n\n\n\nç”¨æ‹‰å¹³çš„å‘é‡æ¥è¡¨è¾¾è¿™ä¸ªå›¾åƒ\n\n\n\nç”¨å·²æœ‰çš„æ–‡æœ¬å»è®­ç»ƒå‡ºè¯å‘é‡\n\n\n3.1 One-Hot\n\nç”¨å•è¯çš„åœ¨é›†åˆçš„ä½ç½®æ¥è¡¨ç¤ºå•è¯\n\nProblem1\nåŒä¹‰è¯çš„è¡¨è¾¾ï¼Œè™½ç„¶ä½¿ç”¨ä¸Šå®Œå…¨ç›¸åŒï¼Œä½†è¿˜æ˜¯æœ‰ç»†å¾®å·®åˆ«\n\n\n\nbigå’Œlargeè™½ç„¶å¾ˆç›¸ä¼¼ï¼Œä½†æ˜¯ç”¨æ³•è¿˜æ˜¯æœ‰ç»†å¾®çš„å·®åˆ«ï¼Œä¸èƒ½å®Œå…¨ç­‰åŒ\n\n\n\nå­—ç¬¦çº§åˆ«çš„ç›¸ä¼¼æ€§å’Œè¯çš„ç›¸ä¼¼æ€§æ˜¯æœ‰å·®å¼‚çš„ï¼Œå¯¹äºç‹¬çƒ­å½¢å¼ï¼Œä½¿ç”¨å†…ç§¯ï¼Œä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼æ€§éƒ½æ˜¯0ï¼Œåˆ™æ— æ³•ç”¨å†…ç§¯è¡¡é‡ä¸¤ä¸ªè¯çš„ç›¸ä¼¼æ€§\n\n\n\nä»¥å‰ï¼Œå¯ä»¥ç”¨ä¸€ä¸ªæ ‘çŠ¶ç»“æ„æ¥æ„å»ºè¯å‘é‡ï¼Œæ¯ä¸ªè¯éƒ½æœ‰å…¶å¯¹åº”çš„ä¸Šä½è¯ï¼Œé€šè¿‡æ¯”è¾ƒè¿™ä¸¤ä¸ªèŠ‚ç‚¹æ‰¾åˆ°å…±åŒçš„çˆ¶äº²æ‰€ç»å†çš„è·¯å¾„ï¼Œæ¥è¿›è¡Œåˆ¤åˆ«\nä½†æ˜¯æ„å»ºä¸€æ£µåˆç†çš„æ ‘ï¼Œéœ€è¦å¤§é‡ä¸“å®¶çŸ¥è¯†ï¼Œå¹¶ä¸”æ ‘çš„ç»“æ„å¾ˆå¥½ä¼˜åŒ–ï¼›å¦ä¸€æ–¹é¢ç”±äºè¯­è¨€å˜åŒ–è¿…é€Ÿï¼Œè¿™æ£µæ ‘å¿…é¡»ç»å¸¸æ›´æ–°\n\nProblem2\né€ æˆå¤§é‡çš„ç©ºé—´æµªè´¹\n\n\n3.2 Distributional RepresentationDef:\nä½ç»´çš„ï¼Œç¨ å¯†çš„è¯å‘é‡è¡¨è¾¾\n\nTurney &amp; Pantel (2010)â€œIf units of text have similar vectors in a text frequency matrix, then they tend to have similar meanings.â€\n\n\nWhen a word w appears in a text, its context is the set of words that appear nearby (within a fixed-size window):\n\nUse the many contexts of w to build up a representation of w\n\nç”¨contextè¡¨ç¤ºä¸­å¿ƒè¯\nExampleï¼š\n\néšç€å›½å¤–æ–°å† æ‚£è€…æ•°é‡çš„çŒ›å¢,è®©åŸæœ¬æ¾äº†ä¸€å£æ°”çš„æˆ‘ä»¬ï¼Œå†æ¬¡ç´§å¼ èµ·æ¥ã€‚\n\næ²»ç–—ä¸€åˆ—æ–°å† è½»ç—‡æ‚£è€…çš„è´¹ç”¨åœ¨1ä¸‡å…ƒä¸Šä¸‹ã€‚\n\nè‚†è™çš„æ–°å† ç—…æ¯’ç©¶ç«Ÿé•¿ä»€ä¹ˆæ ·?\n\nåŸºå› æµ‹åºç­‰ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œæ–°å† ç—…æ¯’ä¸SARSå† çŠ¶ç—…æ¯’åŒå±å† çŠ¶ç—…æ¯’ç§‘çš„Î²å±å† çŠ¶ç—…æ¯’\n\n\n\n\n\n\nWord Vectors\nWe will build a dense vector for each word, chosen so that it is similar to vectors of words that appear in similar contexts.\nNote: word vectors are sometimes called word embeddings. They are a distributed representation.\n\n4. Similarity\n\\begin{aligned}\n&\\text { euclidean }(u, v)=\\sqrt{\\sum_{i=1}^{n}\\left|u_{i}-v_{i}\\right|^{2}} \\\\\n&\\operatorname{cosine}(u, v)=1-\\frac{\\sum_{i=1}^{n} u_{i} \\times v_{i}}{\\|u\\|_{2} \\times\\|v\\|_{2}}\n\\end{aligned}\n\n\nä¸€èˆ¬å…ˆå½’ä¸€åŒ–å†ä½¿åº¦é‡ç›¸ä¼¼åº¦\n\nä½¿ç”¨cosineçš„åŸå› ï¼š\næ¬§æ°è·ç¦»èƒ½å¤Ÿä½“ç°ä¸ªä½“æ•°å€¼ç‰¹å¾çš„ç»å¯¹å·®å¼‚ï¼Œæ‰€ä»¥æ›´å¤šçš„ç”¨äºéœ€è¦ä»ç»´åº¦çš„æ•°å€¼å¤§å°ä¸­ä½“ç°å·®å¼‚çš„åˆ†æï¼Œå¦‚ä½¿ç”¨ç”¨æˆ·è¡Œä¸ºæŒ‡æ ‡åˆ†æç”¨æˆ·ä»·å€¼çš„ç›¸ä¼¼åº¦æˆ–å·®å¼‚ã€‚\nä½™å¼¦è·ç¦»æ›´å¤šçš„æ˜¯ä»æ–¹å‘ä¸ŠåŒºåˆ†å·®å¼‚ï¼Œè€Œå¯¹ç»å¯¹çš„æ•°å€¼ä¸æ•æ„Ÿï¼Œæ›´å¤šçš„ç”¨äºä½¿ç”¨ç”¨æˆ·å¯¹å†…å®¹è¯„åˆ†æ¥åŒºåˆ†å…´è¶£çš„ç›¸ä¼¼åº¦å’Œå·®å¼‚ï¼ŒåŒæ—¶ä¿®æ­£äº†ç”¨æˆ·é—´å¯èƒ½å­˜åœ¨çš„åº¦é‡æ ‡å‡†ä¸ç»Ÿä¸€çš„é—®é¢˜ï¼ˆå› ä¸ºä½™å¼¦è·ç¦»å¯¹ç»å¯¹æ•°å€¼ä¸æ•æ„Ÿï¼‰ã€‚\n\nã€ä¸‹é¢ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œæ¥è¯´æ˜ä½™å¼¦è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ã€‘\nExampleï¼šå¥å­Aï¼šè¿™åªçš®é´å·ç å¤§äº†ã€‚é‚£åªå·ç åˆé€‚\nå¥å­Bï¼šè¿™åªçš®é´å·ç ä¸å°ï¼Œé‚£åªæ›´åˆé€‚\n\næ€æ ·è®¡ç®—ä¸Šé¢ä¸¤å¥è¯çš„ç›¸ä¼¼ç¨‹åº¦ï¼Ÿ\n\nåŸºæœ¬æ€è·¯æ˜¯ï¼šå¦‚æœè¿™ä¸¤å¥è¯çš„ç”¨è¯è¶Šç›¸ä¼¼ï¼Œå®ƒä»¬çš„å†…å®¹å°±åº”è¯¥è¶Šç›¸ä¼¼ã€‚å› æ­¤ï¼Œå¯ä»¥ä»è¯é¢‘å…¥æ‰‹ï¼Œè®¡ç®—å®ƒä»¬çš„ç›¸ä¼¼ç¨‹åº¦ã€‚\n\nç¬¬ä¸€æ­¥ï¼Œåˆ†è¯ã€‚\n\n\nå¥å­Aï¼šè¿™åª/çš®é´/å·ç /å¤§äº†ã€‚é‚£åª/å·ç /åˆé€‚ã€‚\nå¥å­Bï¼šè¿™åª/çš®é´/å·ç /ä¸/å°ï¼Œé‚£åª/æ›´/åˆé€‚ã€‚\n\nç¬¬äºŒæ­¥ï¼Œåˆ—å‡ºæ‰€æœ‰çš„è¯ã€‚\n\nè¿™åªï¼Œçš®é´ï¼Œå·ç ï¼Œå¤§äº†ã€‚é‚£åªï¼Œåˆé€‚ï¼Œä¸ï¼Œå°ï¼Œå¾ˆ\n\nç¬¬ä¸‰æ­¥ï¼Œè®¡ç®—è¯é¢‘ã€‚\n\nå¥å­Aï¼šè¿™åª1ï¼Œçš®é´1ï¼Œå·ç 2ï¼Œå¤§äº†1ã€‚é‚£åª1ï¼Œåˆé€‚1ï¼Œä¸0ï¼Œå°0ï¼Œæ›´0\nå¥å­Bï¼šè¿™åª1ï¼Œçš®é´1ï¼Œå·ç 1ï¼Œå¤§äº†0ã€‚é‚£åª1ï¼Œåˆé€‚1ï¼Œä¸1ï¼Œå°1ï¼Œæ›´1\n\nç¬¬å››æ­¥ï¼Œå†™å‡ºè¯é¢‘å‘é‡ã€‚\n\nã€€ã€€å¥å­Aï¼š(1ï¼Œ1ï¼Œ2ï¼Œ1ï¼Œ1ï¼Œ1ï¼Œ0ï¼Œ0ï¼Œ0)\nã€€ã€€å¥å­Bï¼š(1ï¼Œ1ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ1ï¼Œ1ï¼Œ1ï¼Œ1)\n\nåˆ°è¿™é‡Œï¼Œé—®é¢˜å°±å˜æˆäº†å¦‚ä½•è®¡ç®—è¿™ä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼ç¨‹åº¦ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå®ƒä»¬æƒ³è±¡æˆç©ºé—´ä¸­çš„ä¸¤æ¡çº¿æ®µï¼Œéƒ½æ˜¯ä»åŸç‚¹ï¼ˆ[0, 0, â€¦]ï¼‰å‡ºå‘ï¼ŒæŒ‡å‘ä¸åŒçš„æ–¹å‘ã€‚ä¸¤æ¡çº¿æ®µä¹‹é—´å½¢æˆä¸€ä¸ªå¤¹è§’ï¼Œå¦‚æœå¤¹è§’ä¸º0åº¦ï¼Œæ„å‘³ç€æ–¹å‘ç›¸åŒã€çº¿æ®µé‡åˆ,è¿™æ˜¯è¡¨ç¤ºä¸¤ä¸ªå‘é‡ä»£è¡¨çš„æ–‡æœ¬å®Œå…¨ç›¸ç­‰ï¼›å¦‚æœå¤¹è§’ä¸º90åº¦ï¼Œæ„å‘³ç€å½¢æˆç›´è§’ï¼Œæ–¹å‘å®Œå…¨ä¸ç›¸ä¼¼ï¼›å¦‚æœå¤¹è§’ä¸º180åº¦ï¼Œæ„å‘³ç€æ–¹å‘æ­£å¥½ç›¸åã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¤¹è§’çš„å¤§å°ï¼Œæ¥åˆ¤æ–­å‘é‡çš„ç›¸ä¼¼ç¨‹åº¦ã€‚å¤¹è§’è¶Šå°ï¼Œå°±ä»£è¡¨è¶Šç›¸ä¼¼ã€‚\n\nè®¡ç®—ç»“æœä¸­å¤¹è§’çš„ä½™å¼¦å€¼ä¸º0.81éå¸¸æ¥è¿‘äº1ï¼Œæ‰€ä»¥ï¼Œä¸Šé¢çš„å¥å­Aå’Œå¥å­Bæ˜¯åŸºæœ¬ç›¸ä¼¼çš„\n\n\nç”±æ­¤ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—çš„å¤„ç†æµç¨‹æ˜¯:\nOther metrics\nMatching coefficient\n\n\n\\operatorname{matching}(u, v)=\\sum_{i=1}^{n} \\min \\left(u_{i}, v_{i}\\right)\nJaccard distance\n\n\n\\operatorname{jaccard}(u, v)=1-\\frac{\\operatorname{matchin} \\mathbf{g}(u, v)}{\\sum_{i=1}^{n} \\max \\left(u_{i}, v_{i}\\right)}\nDice distance\n\n\n\\text { dice }(u, v)=1-\\frac{2 \\times \\operatorname{matching}(u, v)}{\\sum_{i=1}^{n} u_{i}+v_{i}}\nOverlap\n\n\n\\operatorname{overlap}(u, v)=1-\\frac{\\text { matching }(u, v)}{\\min \\left(\\sum_{i=1}^{n} u_{i}, \\sum_{i=1}^{n} v_{i}\\right)}\n\nè¯æ˜ä¸Šè¯‰è·ç¦»æ˜¯å¦æ»¡è¶³è¿™ä¸ªæ€§è´¨\n\n5. Word2Vec Modelldea:\nWe have a large corpus of text\nEvery word in a fixed vocabulary is represented by a vector.\nGo through each position t in the text, which has a center word c and context (â€œoutsideâ€) words o\nUse the similarity of the word vectors for c and o to calculate the probability of o given c (or vice versa)\nKeep adjusting the word vectors to maximize this probability\nMikolov, T., Sutskever, l., Chen, K., Corrado, G.S.and Dean,J., 2013. Distributed representations of words and phrasesand their compositionality.In Advances in neural information processing systems (pp.3111-3119).\n\n\n\nExample: windows and process for computing the â€‹\n5.1 Two model variants:\nSkip-grams (SG)Predict context (â€œoutsideâ€) words (position independent) given center word\n\nContinuous Bag of Words (CBOW)Predict center word from (bag of) context words\n\n\n6. SG6.1 Example\nThe quick brown fox jumps over the lazy dog\n\n\n\n\nFor each position â€‹â€‹, predict context words within awindow of fixed size , given center word ;.\nç¬¬ä¸€ä¸ªè¿ä¹˜è¦æ‰«ææ•´ä¸ªæ–‡æ¡£ï¼Œç¬¬äºŒä¸ªè¿ä¹˜æ˜¯æ»‘åŠ¨çª—å£çš„é•¿åº¦\n is all variablesto be optimized\n\n\n\\text { Likelihood }=L(\\theta)=\\prod_{t=1}^{T} \\prod_{-m \\leq j \\leq m \\atop j \\neq 0} P\\left(w_{t+j} \\mid w_{t} ; \\theta\\right)\nThe objective function is the (average) negative log likelihood:\nsometimes called cost or loss function\n\n\n\n\nJ(\\theta)=-\\frac{1}{T} \\log L(\\theta)=-\\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-m \\leq j \\leq m \\atop j \\neq 0} \\log P\\left(w_{t+j} \\mid w_{t} ; \\theta\\right)\nMinimizing objective function â€‹ Maximizing predictive accuracy\n\nå½’ä¸€åŒ–ï¼Œæ¶ˆé™¤è¯è¡¨é•¿åº¦çš„å½±å“\n\nNote: å¯¹äºä¸€ä¸ªè¯ï¼Œå®ƒæ—¢å¯èƒ½æ˜¯ä¸­é—´è¯ï¼Œä¹Ÿå¯èƒ½æ˜¯èƒŒæ™¯è¯\n\n\nQuestion: How to calculate ?\nAnswer: We will use two vectors per word w:\nâ€‹ when w is a center word\nâ€‹â€‹  when w is a context word\n\n\nThen for a center word c and a context word o:\n\n\nP(o \\mid c)=\\frac{\\exp \\left(u_{o}^{T} v_{c}\\right)}{\\sum_{w \\in V} \\exp \\left(u_{w}^{T} v_{c}\\right)}(1) Dot product compares similarity of  and â€‹â€‹.\n\nu^{T} v=u . v=\\sum_{i=1}^{n} u_{i} v_{i}â€‹    Larger dot product = larger probability\n(2) Exponentiation makes anything positive\n(3) Normalize over entire vocabulary to give probability distribution\n\nThis is an example of the softmax function \n\\operatorname{softmax}\\left(x_{i}\\right)=\\frac{\\exp \\left(x_{i}\\right)}{\\sum_{j=1}^{n} \\exp \\left(x_{j}\\right)}=p_{i}\nThe softmax function maps arbitrary values  to a probability distribution \nâ€œmaxâ€ because amplifies probability of largest â€‹\nâ€œsoftâ€ because still assigns some probability to smaller â€‹\nFrequently used in Deep Learning\n\n\n\n\n\n6.3 Word2Vec: skip-gram modelfake task\nå€ŸåŠ©å‡çš„åˆ†ç±»ä»»åŠ¡ï¼Œä»è€Œå­¦åˆ°ä¸å…¶ä»–ä»»åŠ¡ç›¸ä¼¼æ€§çš„å‚æ•°\n\n\n\nè¾“å…¥ä¸€ä¸ªè¯»çƒ­å‘é‡ï¼Œå¾—åˆ°10000ä¸ªç¥ç»å…ƒï¼ˆå³ä¸€ä¸ª10000ç»´å‘é‡ï¼‰ï¼Œæ¯ä¸ªç¥ç»å…ƒå¯¹åº”ä¸€ä¸ªè¯çš„æ¦‚ç‡\nå³ç›¸å½“äºåœ¨åšä¸€ä¸ªç»™å®šä¸€ä¸ªè¯ï¼Œé¢„æµ‹å¦ä¸€ä¸ªè¯çš„ä»»åŠ¡\nè€Œè¿™å…¶ä¸­å­¦ä¹ çš„éšè—å±‚çš„å‚æ•°å…¶å®å°±æ˜¯è¯å‘é‡ï¼Œæˆ–è€…è¯´è¿™ä¸ªå­¦ä¹ åˆ°çš„å‚æ•°ä¸è¯çš„æ¦‚ç‡åˆ†å¸ƒå…·æœ‰åŒæºåˆ†å¸ƒ\n\nProcess\n\n\né¦–å…ˆä»éšè—å±‚çŸ©é˜µæŒ‘å‡ºç›¸åº”çš„ä¸­å¿ƒè¯å‘é‡c\n\n\n\nç„¶åç”¨ä¸­å¿ƒè¯å‘é‡ï¼ˆ300dimï¼‰ä¹˜ä»¥åˆšæ‰çš„éšè—å±‚çŸ©é˜µï¼Œå°±å¯ä»¥å¾—åˆ°ï¼ˆ10000dimï¼‰å¯¹åº”æ¯ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒ\n\n\n\næ¥ç€ï¼Œæˆ‘ä»¬å¯¹äºç»™å®šçª—å£é•¿åº¦ï¼Œåˆ†åˆ«åœ¨å…¶å¯¹åº”çš„èƒŒæ™¯è¯ä½ç½®ä½¿ç”¨softmaxï¼Œä»è€Œå¾—åˆ°è¿™äº›èƒŒæ™¯è¯çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒï¼Œå†ä½¿ç”¨äº¤å‰ç†µ\n\n\n\nCBOW AND SG\n6.4 Problem\nç”±äºåˆ†ç±»ä»»åŠ¡çš„å·¨å¤§æ€§ï¼ˆæ¯æ¬¡è¦å¯¹æ‰€æœ‰è¯å‘é‡åšå†…ç§¯ï¼‰ï¼Œè®¡ç®—é‡å·¨å¤§\nè¿™å°†ä¼šå¯¼è‡´\nRunning gradient descent on a neural network that large is going to be slow.\nNeed a huge amount of training data in order to tune that many weights and avoid over fitting.\n\n\n\n\n7. Solusion\nSubsampling frequent words to decrease the number of training examples.\nModifying the optimization objective with a technique they called â€œNegative Samplingâ€ , which causes each training sample to update only a small percentage of the modelâ€™s weights.\nWord pairs and â€œphasesâ€\n\n7.1 Subsampling\nSubsampling frequent words to decrease the number of training examples.\n\n\n\nå¯¹äºé¢‘ç‡è¾ƒé«˜çš„è¯ï¼Œä¸ç”¨é‡‡æ ·\n\n\n\nè‡ªåŠ¨è°ƒæ•´é‡‡æ ·çš„å…¬å¼ï¼Œç»å¸¸å‡ºç°çš„å•è¯é‡‡æ ·æ¦‚ç‡å°ï¼Œä¸å¸¸å‡ºç°çš„æ¦‚ç‡å¤§\n\n\n7.2 Negative Sampling\nTraining a neural network means taking a training example and adjusting all of the neuron weights slightly so that it predicts that training sample more accurately.\nNegative sampling addresses this issue by having each training sample only modify a small percentage of the weights , rather than all of them.\né€šè¿‡ç¼©å°æœ€åçš„outputï¼Œæ¥ä½¿å¾—è®¡ç®—é‡ä¸‹é™ï¼Œå¹¶ä½¿å¾—å‚æ•°æ¯æ¬¡å˜åŒ–ä¸ä¼šç‰¹åˆ«å¤§\n\n\n\n\n\nThe â€œnegative samplesâ€ are chosen using a â€œunigram distributionâ€. Essentially , the probability for selecting a word as a negative sample is related to its frequency, with more frequent words being more likely to be selected as negative samples.\n\n\n3. Word pairs and â€œphasesâ€.\nThe authors pointed out that a word pair like â€œBoston Globeâ€(a newspaper) has a much different meaning than the individual words â€œBostonâ€ and â€œGlobeâ€.So it makes sense totreat â€œBoston Globeâ€, wherever it occurs in the text, as asingle word with its own word vector representation.\n\n8. How to evaluate the generated embeddings?\nSmall windows (C=+| 2) : nearest words are syntacticall similar words in same taxonomy æœ€è¿‘çš„å•è¯æ˜¯è¯­æ³•ç›¸ä¼¼åœ¨ç›¸åŒåˆ†ç±»æ³•ä¸­çš„å•è¯\nLarge windows (c= +|- 5): nearest words are related words in samle semantic field æœ€è¿‘è¯æ˜¯è¯­ä¹‰åœºä¸­çš„ç›¸å…³è¯\n\n\n\nè·ç¦»å¹³ç§»æ€§ï¼Œé€šè¿‡å¹³ç§»æ“ä½œçš„è®¡ç®—ï¼Œè§‚æµ‹ç”Ÿæˆçš„è·ç¦»çš„ç›¸ä¼¼æ€§\ndoctor-man+woman=nurse\n\n\n\n\n\nå¯è§†åŒ–ï¼Œsvdï¼Œtsvgï¼Œå‹ç¼©åˆ°äºŒç»´å›¾åƒå»è§‚æµ‹\n\n\n\nå¹¶æ²¡æœ‰è€ƒè™‘åä¹‰è¯çš„ç°è±¡ï¼Œè¿™æœ‰å¯èƒ½ä½¿å¾—ç›¸ä¼¼æ€§ä¸èƒ½å¾ˆå¥½åœ°åº¦é‡è¯­ä¹‰çš„ç›¸ä¼¼\n\n\n\næ— æ³•å¾ˆå¥½åº¦é‡ä¸€äº›å±‚æ¬¡å…³ç³»\n\n9. Other interesting things:\nç”¨è¯å‘é‡çœ‹æ–‡åŒ–\n\nä¸åŒè¯­è¨€å­¦çš„è¯­ä¹‰æœ‰å·®å¼‚ï¼Œå¯èƒ½ä¼šå¸¦æ¥ç¿»è¯‘ä¸ä¸€è‡´çš„é—®é¢˜\n\n\næ··åˆembeddingï¼Œä½¿å¾—è¯­ä¹‰æ›´åŠ ä¸°å¯Œ\n\n\n","categories":["nlp"]},{"title":"sequence labelling and relation extraction","url":"/2021/08/15/nlp%20learning/Chapter6_IE/","content":"sequence labelling and relation extraction\n\n1. IE1.1 Simplily Introduction\n\n\nä»æœ‰é™æ–‡æœ¬æ‰¾åˆ°ç›¸å…³æ–‡æœ¬ï¼Œå¹¶ä»æ–‡æœ¬æ”¶é›†ä¿¡æ¯ï¼Œæœ€åè¡¨ç¤ºå‡ºæ¥ã€‚\n\nIE systems extract clear, factual information\n\nRoughly: Who did what to whom when?\n\n\nE.g..\nGathering earningsï¼Œprofits, headquarters, etc. from company reports\nThe headquarters of Alibaba Group, and the global headquarters of the combined Alibaba Group,are located in Hangzhou.\nheadquarters(â€œAlibaba Groupâ€,â€Hangzhouâ€)\nè¡¨è¾¾æˆç»“æ„åŒ–å½¢å¼\n\n\n\n\n\n\nLearn drug-gene product interactions from medical research literature\n\n1.2 Low-level information extraction\nIs now available  and I think popular  in applications like textapp. mail app, etc.\n\nOften seems to be based on regular expressions and name lists\n\n\n\n\n1.3 Named Entity Recognition (NER)\nvery important sub-task: find and classify names in text,\nFor exampleï¼š\n\n\n\näººåã€ç»„ç»‡/æœºæ„åã€åœ°ç†ä½ç½®ã€æ—¶é—´/æ—¥æœŸå­—ç¬¦å€¼ã€é‡‘é¢å€¼ã€é¢†åŸŸå®ä½“\n\n1.4 The uses:\nNamed entities can be indexed,linked off, etc.\nSentiment can be attributed to companies or products.\nå½’å› äº§å“ä½¿ç”¨çš„æƒ…ç»ª\n\n\n\nA lot of IE relations are associations between named entities.. For question answering, answers are often named entities.\n\n1.5 Concretely:ï¼ˆå…·ä½“åœ°ï¼‰\nMany web pages tag various entities, with links to topic pages, etc.\n\n\n\nGooglel Appleâ€¦. smart recognizers for document content\né€šè¿‡å‘½åå®ä½“è¯†åˆ«ï¼Œç»™æ–°é—»é˜…è¯»å¸¦æ¥æ›´å¥½çš„ä½“éªŒï¼Œå³ç»™æ£€ç´¢åˆ°çš„å®ä½“åŠ å…¥ç›¸åº”çš„urlé“¾æ¥\n\n\n\n\n\nRecall and precision are straightforward for tasks like IR and text categorization,where there is only one grain sizeï¼ˆæ™¶ç²’å°ºå¯¸ï¼‰ (documents)\n\nThe measure behaves a bit funnily for IE/NEP. when there are(boundary errors (which are common):\n\nç´«é‡‘å±±æ£®æ—å…¬å›­ä½äºå—äº¬å¸‚ç„æ­¦åŒº.\nfirst Bank of China\næœ‰å¯èƒ½åªè¯†åˆ«å‡ºBank of China\nThis counts as both a fp and a fn   è¿™å°†å¯¼è‡´fpå’Œfnä¸Šå‡\n\n\n\n\nSelecting nothing would have been better? \n\nSome other metrics (e.g., Muc scorer) give partial credit(according to complex rules)\n\n\n1.6 Sequence Models for Named Entity Recognition\n\nTraining\nCollect a set of representative training documents\nLabel each token for its entity class or other (O)\nDesign feature extractors appropriate to the text and classes\nTrain a sequence classifier to predict the labels from the data\n\n\nTesting/Classifying\nReceive a set of testing documents\nRun sequence model inference to label each token\nAppropriately output the recognized entities\n\n\n\n\n\nç¬¬ä¸€ç§encodingä¼šå‡ºç°è¾¹ç•Œé—®é¢˜ï¼Œæ¯”å¦‚Mengqiu Huangè¿™ä¸ªäººåº”è¯¥æ˜¯ä¸€ä¸ªæ•´ä½“ï¼Œä½†è¯†åˆ«æ—¶ä¼šè¢«åˆ†æˆä¸¤éƒ¨åˆ†\nCä¸ªç±»åˆ«ï¼Œé‚£ä¹ˆlabelæœ‰C+1ç§ï¼Œå¯¹äºè¿ç®—çš„ç©ºé—´ç›¸æ¯”äºç¬¬äºŒç§å°\né€ æˆè¿™ç§åŸå› æ˜¯ä¸€ä¸‹å­å‡ºç°ä¸‰ä¸ªPERï¼Œæ— æ³•åˆ¤åˆ«æ˜¯å¦èƒ½æ‰“åŒ…æˆä¸€ä¸ªå®ä½“ï¼Œä½†æ˜¯é€šå¸¸æ„ä¹‰ä¸Šè®²ï¼Œç´§æŒ¨ç€çš„å®ä½“ä¸æ˜¯åŒä¸€ä¸ªç±»åˆ«ï¼Œæ‰€ä»¥IOå¯¹äºå¤§æ ·æœ¬æ›´é€‚åˆã€‚\n\n\nç¬¬äºŒç§ï¼Œå½“è¯»åˆ°Beginæ˜¯å¼€å§‹ï¼Œè¯»åˆ°Iï¼Œåˆ™æ˜¯ç´§æ¥ä¸Šä¸€ä¸ª\n\næœ‰2C+1ä¸ªlabelï¼Œæ•ˆç‡æ¯”è¾ƒä½ï¼Œä½†å¸¦æ¥äº†æ›´é«˜çš„å‡†ç¡®ç‡\n\n\næ›´å¤šæ¨¡å‹ï¼šIOBE,IOBSï¼Œä½†æ˜¯è¦è€ƒè™‘è®­ç»ƒå¼€é”€äºå‡†ç¡®ç‡çš„æƒè¡¡\n\n\n1.7 Features1.7.1 Features for sequence labeling åºåˆ—æ ‡ç­¾çš„ç‰¹å¾\nWords\nCurrent word\nPrevious/next word (context)\n\n\nOther kinds of inferred linguistic classification.  è¯­ä¹‰çº§åˆ«ç‰¹å¾ã€è¯­æ³•çº§åˆ«ç‰¹å¾\nPart-of-speech tags\n\n\nLabel context\nPrevious (and perhaps next) label   ï¼ˆçš„ç‰¹å¾ï¼‰\n\n\n\n1.7.2 Features: Word substrings\n\nåªè¦å‡ºç°xazoå°±æ˜¯è¯ï¼Œå‡ºç°fieldå°±æ˜¯åœ°ç‚¹ï¼Œå‡ºç°å†’å·å°±æ˜¯ç”µå½±\nè¿™ç§ç»´åº¦çš„ç‰¹å¾å¯¹ä¸‹æ¸¸ä»»åŠ¡ååˆ†æœ‰æ•ˆ\n\n\n\n1.7.3 Word Shapes\nMap words to simplified representation that encodes attributes such as length, capitalizationï¼Œnumerals ,Greek letters,internal punctuation, etc.\nä¸åŒå½¢çŠ¶çš„è¯å°±è•´å«äº†ä¿¡æ¯\n\n\n1.8 Maximum entropy Markov models (MEMMs) or Conditional Markov models1.8.1 Sequence problems\nMany problems in NLP have data which is a sequence of characters,wordsï¼Œphrases,lines, or sentences â€¦.\nwe can think of our task as one of labeling each item\n\n\n\nè¿›æ¥ä¸€ä¸ªåºåˆ—ï¼Œå¯¹æ¯ä¸€ä¸ªæ–‡æœ¬å—è¿›è¡Œè¯†åˆ«\n\n1.8.2 MEMM Inference in Systems\nFor a Conditional Markov Model(CMM) a.k.a. a Maximum Entropy Markov Model (MEMM), the classifier makes a single decision at a time, conditioned on evidence from observations and previous decisions\nA larger space of sequences is usually explored  via search\n\n1.8.3 Scoring individual labeling decisions is no more complex than standard classification decisions\nWe have some assumed labels to use for prior positions\n\nWe use features of those and the observed data (which can includecurrent, previous, and next words) to predict the current label \n\n\n\n\n\nå°½å¯èƒ½ä¿è¯ä½¿ç”¨è´ªå¿ƒçš„ç­–ç•¥ï¼Œæ¯æ¬¡éƒ½æ˜¯ä½¿å¾—å½“å‰çš„è¯æœ€å¤§\n\n1.9 Search1.9.1 Greedy Inference\nGreedy inference:\nWe just start at the left, and use our classifier at each position to assign a label\nThe classifier can depend on previous labeling decisions as well as observed data\n\nAdvantages:\nFast, no extra memory requirements \nVery easy to implement\nWith rich features including observations to the right, it may perform quite well\n\nDisadvantage:\nGreedy. \nWe make commit errors we cannot recover from\n\n1.9.2 Beam Search\nBeam inference:\nAt each position keep the top k complete sequences.\nExtend each sequence in each local way.\nThe extensions compete for the k slots at the next position.\n\nAdvantages:\nFast; beam sizes of 3-5 are almost as good as exact inference in many cases.\nEasy to implement (no dynamic programming required).\n\nDisadvantage:\nInexact: the globally best sequence can fall off the beam.\n\n\n\n1.9.3 Viterbi Inference\niterbi inference:\nDynamic programming or memoization.\nRequires small window of state influence (e.g., past two states are relevant).\n\nAdvantages:\nExact: the global best sequence is returned.\n\nDisadvantage:\nHarder to implement long-distance state-state interactions (but beaminference tends not to allow long-distance resurrection of sequences any way).\n\n1.10 CRFså‚è€ƒèµ„æ–™ï¼šCRFæ¡ä»¶éšæœºåœºçš„åŸç†ã€ä¾‹å­ã€å…¬å¼æ¨å¯¼å’Œåº”ç”¨ - çŸ¥ä¹ (zhihu.com)\n\nAnother sequence model: Conditional Random Fields (CRFs)\nA whole-sequence conditional model rather than a chaining of local models.\n\n\nP(c \\mid d, \\lambda)=\\frac{\\exp \\sum \\lambda_{i} f_{i}(c, d)}{\\sum_{c^{\\prime}} \\exp \\sum_{i} \\lambda_{i} f_{i}\\left(c^{\\prime}, d\\right)}\nThe space of câ€™s is now the space of sequences\nBut if the features f, remain local,the conditional sequence likelihood can be calculated exactly using dynamic programming\n\n\nTraining is slower, but CRFs avoid causal-competition biases\nThese (or a variant using a max margin criterion) are seen as the state-of-the-art these days â€¦ but in practice usually work much the same as MEMMs.\n\n2. Extracting relations from text\nCompany report: â€œInternational Business Machines Corporation (IBM or thecompany) was incorporated in the State of New Vork on June 16,1911,as the Computing-Tabulating-Recording Co.(C-T-R.)â€¦â€\nExtracted Complex Relation:\nCompany-Founding\nCompany IBM\nLocation New york\nDate June 16,1911\nOriginal-Name Computing-Tabulating-Recording Co.\n\n\nBut we will focus on the simpler task of extracting relation triples\nFounding-year(IBM,1911)\nFounding-location(IBM,New York)\nä»æ–‡æœ¬ä¸­æŠ½å–å‡ºå…³ç³»\n\n\n\n\n2.1 Extracting relation triples from text\n2.2 Why Relation Extraction?\nNERï¼šfind classifyâ€”â€”å…³ç³»æœ€ç»ˆä¹Ÿä¼šå˜æˆä¸€ä¸ªåˆ†ç±»é—®é¢˜\n\nCreate new structured knowledge graphs, useful for any app\n\nAugment current knowledge graphs\n\nAdding words to WordNet thesaurusï¼Œfacts to FreeBase or DBPedia\n\n\nSupport question answering\n\nThe grand daughter of which actor starred in the movieâ€E,T.â€?(acted-in ?x â€œE.T.â€)(is-a ?y actor)(granddaughter-of ?x?y)\n\n\nBut which relations should we extract?\n\n2.3 Automated Content Extraction (ACE)\n\nPhysical-Located PER-GPE\nHe was in Tennessee  \n\n\nPart-Whole-Subsidiary ORG-ORG\nXYZ, the parent company of ABC\n\n\nPerson-Social-Family   PER-PER\nJohnâ€™ s wife Yoko\n\n\nOrg-AFF-Founder   PER-ORG\nsteve Jobs , co-founder of Appleâ€¦\n\n\n\n2.4 UMLS: Unified Medical Language System\n134 entity types, 54 relations\n\n\nExtracting UMLS relations from a sentence\nDoppler echocardiography can be used to diagnose left anterior descending artery stenosis in patients with type 2 diabetes\nEchocardiography, Doppler DIAGNOSES Acquired stenosis\n\n\n\n2.5 Databases of Wikipedia Relations\n3. How to build relation extractors\nHand written patterns\nSupervised machine learning\nSemi supervised and unsupervised\nBootstrapping (using seeds)\nDistant supervision\nUnsupervised learning from the web\n\n\n\n3.1 Rules for extracting IS-A relation\nEarly intuition from Hearst (1992)\nâ€œAgar is a substance prepared from a mixture of red algaeï¼ˆçº¢è„‚ï¼‰,such as Gelidiumï¼ˆå‡èƒ¶ï¼‰, for laboratory orindustrial useâ€\n\n\nWhat does Gelidium mean?\nHow do you know?\n\nHearstâ€™s Patterns for extracting IS-A relations\n\nè¡¨ç¤ºaæ˜¯bçš„æ¨¡æ¿ \nâ€œY such as X((,X)*(, and | or)X)â€\nâ€œsuch Y as Xâ€\nâ€œx or other Yâ€\nâ€œX and other Yâ€\nâ€œY including xâ€\nâ€œY,especially Xâ€\n\n\n\n3.1.1 Extracting Richer Relations Using Rules\nIntuition: relations often hold between specific entities. \nlocated-in(ORGANIZATION,LOCATION)\nfounded (PERSONï¼ŒORGANIZATION)\ncures (DRUG, DISEASE)\n\n\nStart with Named Entity tags to help extract relation!\nåœ¨å·²ç»çŸ¥é“å‘½åå®ä½“çš„ç±»åˆ«æƒ…å†µä¸‹ï¼Œä¼šå¾ˆå®¹æ˜“çŸ¥é“ä»–ä»¬ä¹‹é—´çš„å…³ç³»\n\n\n\nä½†è¿™ç§æƒ…å†µä¹Ÿä¸ä¸€å®š\n\n\n\nWho holds what office in what organization?\nPERSON , POSITION of ORG\nGeorge Marshall , Secretary of State of the United States\n\n\nPERSON named|appointed|chose| etc PERSON Prep? POSITION\nTruman appointed Marshall Secretary of State\n\n\nPERSON [be]? named|appointed| etc ..) Prep? ORG POSITION\nGeorge Marshall was named US Secretary of State\n\n\n\n\n\n3.1.2 Summary: Hand-built patterns for relationsPlus:\n\nHuman patterns tend to be high-precision. \nCan be tailored to specific domains\n\nMinus\n\nHuman patterns are often low-recall\nA lot of work to think of all possible patterns!. Donâ€™t want to have to do this for every relation!. eâ€™d like better accuracy\n\n3.2 Supervised machine learning for relations\n\nChoose a set of relations weâ€™d like to extract\nChoose a set of relevant named entities\nFind and label data\nChoose a representative corpus\nLabel the named entities in the corpus\nHand-label the relations between these entities\nNLPæ ‡æ³¨ï¼Œæœ€ç»ˆå¯¼å‡ºcsvç­‰ç»“æ„åŒ–æ•°æ®\n\n\nBreak into training, development , and test\n\n\n\nStep\nFind all pairs of named entities (usually in same sentence)\n\nDecide if  entities are related\n\nå…ˆçœ‹æœ‰æ²¡æœ‰å…³ç³»ï¼Œå¦‚æœæ²¡æœ‰å…³ç³»ç›´æ¥è¿‡æ»¤æ‰\n\n\nIf yes,classify the relation\n\n\nWhy the extra step?\næœ‰æ²¡æœ‰å…³ç³»â€”â€”å±€éƒ¨ç‰¹å¾ï¼Œä»è€Œä½¿å¾—æŠŠç‰¹å¾è¿›è¡Œæ‰“åŒ…ï¼Œåœ¨è¿›è¡Œåˆ†ç±»\n\nFaster classification training by eliminating most pairs.\n\nCan use disjistï¼ˆä¸ç›¸å®¹ï¼‰ feature-sets appropriate for each task.\n\n\n\nå¯¹äºæ¯ä¸ªå¥å­è¿›è¡Œå®ä½“è¯†åˆ«åï¼ŒæŠ½å–æˆç›¸å…³çš„ä¸€æ¡æ•°æ®é›†å¦‚ä¸Š\n\n\n\n\n\né€šè¿‡å¥æ³•çš„ä¾èµ–å…³ç³»ï¼Œå¾—åˆ°å®ä½“ä¹‹é—´çš„ä¾å­˜å…³ç³»ï¼Œå¦‚ä¸Š\n\n3.3 Gazeteer and trigger word features for relation extraction\nTrigger list for family: kinship terms\nparent , wife, husband, grandparent, etc. [from WordNet]\n\n\nGazeteer:\n\nLists of useful geo or geopolitical words\nCountry name list\nOther sub-entities\n\n\n\n\nAmerican Airlines, a unit of AMR, immediately matched the move, spokesman Tim wagner said.\n\n\n\n3.4 Classifiers for supervised methods\nNow you can use any classifier you like\n\nMaxEnt\nNaive Bayes. \nSVM\n\n\nTrain it on the training set, tune on the dev set, test on the test set\n\n\n3.5 Summary: Supervised Relation ExtractionPlus:\n\nCan get high accuracies with enough hand-labeled training data,if test similar enough to training\n\nMinus:\n\nLabeling a large training set is expensive\n\nSupervised models are brittle,donâ€™t generalize well to different genres\n\n\n","categories":["nlp"]},{"title":"IR","url":"/2021/08/15/nlp%20learning/Chapter8_IR/","content":"IR\n\n1. HMM Exercise\nH M M : \\hat{g}=\\underset{y \\in Y}{\\operatorname{argmax}} P(x, y)\nTransition\n\n\n\\left.\\begin{array}{r}N\\rightarrow V \\\\ \\downarrow \\\\ c\\end{array}\\right\\} 9\\quad \\left.\\begin{array}{r}P\\rightarrow V \\\\ \\downarrow \\\\ a\\end{array}\\right\\} 9\n\\left.\\begin{array}{r}N-D \\\\ \\downarrow \\\\ a\\end{array}\\right\\} 1\nP(V \\mid N)=\\frac{9}{9+1}=\\frac{9}{10}\nP(D \\mid N)=0.1\nEmission\n\n\nP(a\\mid v)=0.5 \\quad P(a\\mid D)=1\nfor :\n\n\n\\begin{array}{r}N\\rightarrow ? \\\\ \\downarrow \\\\ a\\end{array}\n\\begin{aligned}\n?=& \\underset{i \\in\\{V, D\\}}{\\operatorname{argmax}} \\alpha P(i \\mid N) P(a \\mid i) \\\\\n=& \\operatorname{argmax}\\{(0.9 \\times 0.5) \\alpha, (0.1 \\times 1)\\alpha\\} \\\\\n=& V\n\\end{aligned}\nåˆ†æåŸå› ï¼šå› ä¸ºHMMåšäº†å±€éƒ¨å½’ä¸€åŒ–ï¼Œå¯¼è‡´HMMæ›´å®¹æ˜“è½¬ç§»åˆ°å…·æœ‰æ¯”è¾ƒå°‘è½¬ç§»çŠ¶æ€çš„çŠ¶æ€ã€‚E:/third\n\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°hmmçš„çŠ¶æ€ä¸å®¹æ˜“è¿›è¡Œè·³è½¬\n\n\n2. CRF vs. HMM\n\\begin{array}{l}\nH M M: P(\\vec{y}, \\vec{x})=P\\left(y_{1} \\mid \\operatorname{start} \\right)\\prod_{i=1}^{n-1} P\\left(y_{i-1} \\mid y_{i}\\right) \nP\\left(\\operatorname{end} \\mid y_{n}\\right) \\prod_{i=1}^{n} P\\left(x_{i} \\mid y_{i}\\right) \\\\\n\\log P(x, y)=\\log P(y_1 \\mid \\text { start })+\\sum_{i=1}^{n-1} \\log P\\left(y_{i-1} \\mid y_{i}\\right)\\\\\n+\\log P\\left(\\text { end } \\mid y_{n}\\right)+\\sum_{i=1}^{n} \\log P\\left(x_{i} \\mid y_{i}\\right) \\\\\n\\end{array}\nwe can easily get the equation as flowing:\n\n\n\\sum_{i=1}^{n} \\log P\\left(x_{i} \\mid y_{i}\\right)=\\sum_{s, t} \\log P(t \\mid s) \\cdot N_{s t}(x, y), \\quad\ns.t:\\text { s: tags},\\quad t=\\text { words }\nwhy?\n\nExample:\n\nâ€‹ : the dog ate the homework \n\n\n\n\\begin{array}{l}\nN_{D, \\text{the}}(x, y)=2 \\\\\nN_{N, \\text{dog}}(x, y)=1 \\\\\nN_{V, \\text{ate}}(x, y)=1 \\\\\nN_{N, {\\text {homework }}(x, y)=1} \\\\\nN_{s, t}(x, y)=0, \\quad\\text {(s,t) is other}\n\\text { combination }\n\\end{array}\n\\begin{array}{l}\n\\underset{i=1}{\\overset{n}\\sum}\\log P(x_i\\mid y_i)&=\\quad\\log \nP(\\text{the}\\mid\\text{D})+\\log P(\\text{dog}\\mid\\text{N})\\\\&+\\log P(\\text{ate}\\mid\\text{V})+\\log P(\\text{the}\\mid\\text{D})+\\log P(\\text{homework}\\mid\\text{N})\\\\\n&=\\quad \\log \nP(\\text{the}\\mid\\text{D})\\times 2+\\log P(\\text{dog}\\mid\\text{N})\\times 1+\\log P(\\text{ate}\\mid\\text{V})\\times 1\\\\&+\\log P(\\text{homework}\\mid\\text{N})\\times 1\\\\\n&=\\quad \\underset{s,t}{\\sum}\\log P(t\\mid s)\\cdot N(x,y)\n\\end{array}\nåŒç†ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹å¼å­çš„ç¬¬ä¸€ã€äºŒã€ä¸‰é¡¹åšå˜åŒ–ï¼š\n\n\n\\log P(y_1\\mid start)=\\underset{s}{\\sum}\\log P(t\\mid s)\\cdot N_{\\text{start,s}}(x,y)\n\\sum_{i=1}^{n-1} \\log P\\left(y_{i-1} \\mid y_{i}\\right)=\\underset{s,s'}{\\sum}\\log P(s'\\mid s)\\times N_{s,s'}(x,y)\n\\log P\\left(\\text { end } \\mid y_{n}\\right)=\\underset{s}{\\sum}log P(end\\mid s)\\times N_{s,end}(x,y)\næ‰€ä»¥ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹åŸå¼åšå˜æ¢ï¼š\n\n\n\\begin{array}{l}\n\\log P(x, y)&=&\\underset{s}{\\sum}\\log P(t\\mid s)\\cdot N_{\\text{start,s}}(x,y)+\\underset{s,s'}{\\sum}\\log P(s'\\mid s)\\times N_{s,s'}(x,y)\\\\&+&\\underset{s}{\\sum}log P(end\\mid s)\\times N_{s,end}(x,y)+\\underset{s,t}{\\sum}\\log P(t\\mid s)\\times N(x,y)\\\\\n&=& \\left[\\begin{array}{c}\n\\log p(t \\mid s) \\\\\n\\vdots \\\\\n\\log p(s \\mid \\text { start }) \\\\\n\\vdots \\\\\n\\log P\\left(s^{\\prime} \\mid s\\right) \\\\\n\\vdots \\\\\n\\log P(\\text { end } \\mid s)\\\\\n\\vdots\n\\end{array}\\right]^{t} \\cdot\\left[\\begin{array}{c}\nN_{s, t}(x, y) \\\\\n\\vdots \\\\\nN_{s t a r t,s}{(x, y)} \\\\\n\\vdots \\\\\nN_{s, s^{\\prime}}(x, y) \\\\\n\\vdots \\\\\nN_{s, \\text { end }}(x, y) \\\\\n\\vdots\n\\end{array}\\right]\\\\\n&=& w^t \\psi(x,y)\n\\end{array}\nå¯¹äºCRFè€Œè¨€â€‹æ˜¯å¯ä»¥å­¦ä¹ çš„å‚æ•°\né•¿åº¦ï¼štagswords(sL), tagsâ€‹â€‹ tages(s\\ +2s(start and end))\n\nè®­ç»ƒæ—¶ï¼Œæœ€å¤§åŒ–åéªŒæ¦‚ç‡\n\n\n\nw^*=\\underset{w}{\\operatorname{argmax}}P(\\vec{y}\\mid\\vec{x})=\\underset{w}{\\operatorname{argmax}}\\frac{P(\\vec{x},\\vec{y})}{\\underset{y'}{\\sum}P(x,y')}\nå–logåï¼š\n\n\nw^*=\\underset{w}{\\operatorname{argmax}}\\log P(x^n\\mid \\hat{y}^n)-\\sum_{y'}P(y'\\mid x^n)P(x^n,y')\næ ¹æ®æ¢¯åº¦ä¸Šå‡ï¼š\n\n\n\\theta\\rightarrow\\theta+\\eta\\nabla(\\theta)\n\\frac{\\partial \\theta(w)}{\\partial w_{s,t}}=N_{s,t}(x^n,y^n)-\\sum_{y'}P(y'\\mid x^n)N_{s,t}(x^n,y^n)3. CRFE:/third\n\nå‡è®¾\n\n\nP(\\boldsymbol{y}, \\boldsymbol{x})=f(\\boldsymbol{y}, \\boldsymbol{x})=h\\left(y_{1} , \\boldsymbol{x}\\right) +g\\left(y_{1}, y_{2}\\right)+h\\left(y_{2} , \\boldsymbol{x}\\right)+\\ldots \n+h\\left(y_{n} , \\boldsymbol{x}\\right)+g\\left(y_{n-1}, y_{n}\\right)\nå…¶å®å°±æ˜¯è¡¨ç¤ºæˆè¾¹çš„æ¡ä»¶æ¦‚ç‡ä»¥åŠçŠ¶æ€æ¡ä»¶æ¦‚ç‡\nåˆ™å¯ä»¥è®¡ç®—åéªŒæ¦‚ç‡ï¼š\n\n\nP(\\boldsymbol{y}|\\boldsymbol{x})=\\frac{1}{Z(x)}exp\\left(\\underset{i,k}{\\sum}\\lambda_k t_k(y_{i-1}, y_i,x,i)+\\underset{i,l}{\\sum}u_l t_l(y_{i-1}, y_i,x,i)\\right)\nZ(\\boldsymbol{x})=\\sum_\\boldsymbol{y'}exp\\left(\\underset{i,k}{\\sum}\\lambda_k t_k(y'_{i-1}, y'_i,x,i)+\\underset{i,l}{\\sum}u_l t_l(y'_{i-1}, y'_i,x,i)\\right)\nå‡è®¾æœ‰ä¸ªè½¬ç§»ç‰¹å¾ï¼Œä¸ªçŠ¶æ€ç‰¹å¾ï¼Œï¼Œè®°ï¼š\n\n\nf_{k}\\left(y_{i-1}, y_{i}, x, i\\right)=\\left\\{\\begin{array}{ll}\nt_{k}\\left(y_{i-1}, y_{i}, x, i\\right), & k=1,2, \\cdots, K_{1} \\\\\ns_{i}\\left(y_{i}, x, i\\right), & k=K_{1}+l ; l=1,2, \\cdots, K_{2}\n\\end{array}\\right.\nç„¶åå¯¹è½¬ç§»ä¸çŠ¶æ€ç‰¹å¾åœ¨å„ä¸ªä½ç½®æ±‚å’Œï¼š\n\n\nf_{k}(y, x)=\\sum_{i=1}^{n} f_{k}\\left(y_{i-1}, y_{i}, x, i\\right), \\quad k=1,2, \\cdots, K\nç”¨è¡¨ç¤ºç‰¹å¾çš„æƒå€¼ï¼š\n\n\nw_{k}=\\left\\{\\begin{array}{ll}\n\\lambda_{k}, & k=1,2, \\cdots, K_{1} \\\\\n\\mu_{l}, & k=K_{1}+l ; l=1,2, \\cdots, K_{2}\n\\end{array}\\right.\näºæ˜¯æ¡ä»¶éšæœºåœºå¯ä»¥ç”¨ä»¥ä¸‹å¼å­è¡¨ç¤ºï¼š\n\n\n\\begin{aligned}\nP(y \\mid x) &=\\frac{1}{Z(x)} \\exp \\sum_{k=1}^{K} w_{k} f_{k}(y, x) \\\\\nZ(x) &=\\sum_{yâ€˜} \\exp \\sum_{k=1}^{K} w_{k} f_{k}(yâ€™, x)\n\\end{aligned}\nä¸ºæƒå€¼å‘é‡ï¼š\n\n\nw=\\left(w_{1}, w_{2}, \\ldots, w_{K}\\right)^{\\mathrm{T}}\nä»¥è¡¨ç¤ºå…¨å±€ç‰¹å¾å‘é‡å³ï¼š\n\n\nF(y, x)=\\left(f_{1}(y, x), f_{2}(y, x), \\cdots, f_{K}(y, x)\\right)^{\\mathrm{T}}\nåˆ™æ¡ä»¶éšæœºåœºå¯ä»¥å†™æˆ ä¸  çš„å†…ç§¯çš„å½¢å¼:\n\n\nP_{w}(y \\mid x)=\\frac{\\exp (w \\cdot F(y, x))}{Z_{w}(x)}\nå…¶ä¸­\n\n\nZ_{w}(x)=\\sum_{y'} \\exp (w \\cdot F(y', x))3.1 Inference:\n\\mathbf{y}_{\\text {best }}=\\operatorname{argmax}_{\\mathbf{y}^{\\prime}} \\exp \\left(\\sum_{k=1}^{n} w^{\\top} f_{k}\\left(\\mathbf{x}, \\mathbf{y}^{\\prime}\\right)\\right)\nlf y consists of 5 variables with 30 values each, how expensive are these?Need to \nconstrain the form of our CRFs to make it tractableE:/third\nP(\\mathbf{y} \\mid \\mathbf{x}) \\propto \\prod_{k} \\exp \\left(\\phi_{k}(\\mathbf{x}, \\mathbf{y})\\right)\n\n\nP(\\mathbf{y} \\mid \\mathbf{x}) \\propto \\exp \\left(\\phi_{o}\\left(y_{1}\\right)\\right) \\prod_{i=2}^{n} \\exp \\left(\\phi_{t}\\left(y_{i-1}, y_{i}\\right)\\right) \\prod_{i=1}^{n} \\exp \\left(\\phi_{e}\\left(x_{i}, y_{i}\\right)\\right)E:/thirdE:/third\n\nå› ä¸ºæœ€å¥½ä¸è¦éšæ„ä¾èµ–ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ç»™å®ƒåŠ ä½ç½®ä¿¡æ¯E:/third\n\nNotation: omit  from the factor graph entirely (implicit)\n\nDonâ€™t include initial distribution, can bake into other factors\nSequential CRFs:\n\n\n\\begin{gathered}\nP(\\mathbf{y} \\mid \\mathbf{x})=\\frac{1}{Z} \\prod_{i=2}^{n} \\exp \\left(\\phi_{t}\\left(y_{i-1}, y_{i}\\right)\\right) \\prod_{i=1}^{n} \\exp \\left(\\phi_{e}\\left(y_{i}, i, \\mathbf{x}\\right)\\right) \\\\\nP(\\mathbf{y} \\mid \\mathbf{x}) \\propto \\exp w^{\\top}\\left[\\sum_{i=2}^{n} f_{t}\\left(y_{i-1}, y_{i}\\right)+\\sum_{i=1}^{n} f_{e}\\left(y_{i}, i, \\mathbf{x}\\right)\\right]\n\\end{gathered}3.2 Inference\n\n\\begin{aligned}\n& \\max _{y_{1}, \\ldots, y_{n}} e^{\\phi_{t}\\left(y_{n-1}, y_{n}\\right)} e^{\\phi_{e}\\left(y_{n}, n, \\mathbf{x}\\right)} \\cdots e^{\\phi_{e}\\left(y_{2}, 2, \\mathbf{x}\\right)} e^{\\phi_{t}\\left(y_{1}, y_{2}\\right)} e^{\\phi_{e}\\left(y_{1}, 1, \\mathbf{x}\\right)} \\\\\n=& \\max _{y_{2}, \\ldots, y_{n}} e^{\\phi_{t}\\left(y_{n-1}, y_{n}\\right)} e^{\\phi_{e}\\left(y_{n}, n, \\mathbf{x}\\right)} \\cdots e^{\\phi_{e}\\left(y_{2}, 2, \\mathbf{x}\\right)} \\max _{y_{1}} e^{\\phi_{t}\\left(y_{1}, y_{2}\\right)} \\underbrace{e^{\\phi_{e}\\left(y_{1}, 1, \\mathbf{x}\\right)}}\\\\\n=&\\max _{y_{3}, \\ldots, y_{n}} e^{\\phi_{t}\\left(y_{n-1}, y_{n}\\right)} e^{\\phi_{e}\\left(y_{n}, n, \\mathbf{x}\\right)} \\cdots \\max _{y_{2}} e^{\\phi_{t}\\left(y_{2}, y_{3}\\right)} \\underbrace{e^{\\phi_{e}\\left(y_{2}, 2, \\mathbf{x}\\right)} \\max _{y_{1}} e^{\\phi_{t}\\left(y_{1}, y_{2}\\right)} \\operatorname{score}_{1}\\left(y_{1}\\right)}\\\\\n=&\\max _{y_{3}, \\ldots, y_{n}} e^{\\phi_{t}\\left(y_{n-1}, y_{n}\\right)} e^{\\phi_{e}\\left(y_{n}, n, \\mathbf{x}\\right)} \\cdots \\max _{y_{2}} e^{\\phi_{t}\\left(y_{2}, y_{3}\\right)}score_2(y_2)\\\\\n=&\\max _{y_n}score_n(y_n)\n\\end{aligned}\nscore_i(y_i)=\\left\\{\\begin{array}{cc}\ne^{\\phi_{e}\\left(y_{i}, i, \\mathbf{x}\\right)},\\quad\\text{i=1}\\\\\ne^{\\phi_{e}\\left(y_{i}, i, \\mathbf{x}\\right)} \\max _{y_{i-1}} e^{\\phi_{t}\\left(y_{i-1}, y_{i}\\right)} \\operatorname{score}_{i-1}\\left(y_{1}\\right),\\quad\\text{i$\\neq$ 1}\n\\end{array}\\right.3.3 Training\nLogistic regression: \nMaximize $\\mathcal{L}\\left(\\mathbf{y}^{}, \\mathbf{x}\\right)=\\log P\\left(\\mathbf{y}^{} \\mid \\mathbf{x}\\right)$\nGradient is completely analogous to logistic regression:\n\n\n\\frac{\\partial}{\\partial w} \\mathcal{L}\\left(\\mathbf{y}^{*}, \\mathbf{x}\\right)=\\sum_{i=2}^{n} f_{t}\\left(y_{i-1}^{*}, y_{i}^{*}\\right)+\\sum_{i=1}^{n} f_{e}\\left(y_{i}^{*}, i, \\mathbf{x}\\right)\n\\text { intractable } \\quad-\\mathbb{E}_{\\mathbf{y}}\\left[\\sum_{i=2}^{n} f_{t}\\left(y_{i-1}, y_{i}\\right)+\\sum_{i=1}^{n} f_{e}\\left(y_{i}, i, \\mathbf{x}\\right)\\right]\nforward backward Algorithm\n\n\n\\frac{\\partial}{\\partial w} \\mathcal{L}\\left(\\mathbf{y}^{*}, \\mathbf{x}\\right)=\\sum_{i=1}^{n} f_{e}\\left(y_{i}^{*}, i, \\mathbf{x}\\right)-\\sum_{i=1}^{n} \\sum_{s} P\\left(y_{i}=s \\mid \\mathbf{x}\\right) f_{e}(s, i, \\mathbf{x})\næ‹Ÿç‰›é¡¿æ³•ï¼š\n\n\nP_{w}(y \\mid x)=\\frac{\\exp \\left(\\sum_{i=1}^{n} w_{i} f_{i}(x, y)\\right)}{\\sum_{y} \\exp \\left(\\sum_{i=1}^{n} w_{i} f_{i}(x, y)\\right)}\nå­¦ä¹ ä¼˜åŒ–ç›®æ ‡ï¼š\n\n\n\\min _{w \\in \\mathcal{R}^{n}} f(w)=\\sum_{x} \\tilde{P}(x) \\log \\sum_{y} \\exp \\left(\\sum_{i=1}^{n} w_{i} f_{i}(x, y)\\right)-\\sum_{x, y} \\tilde{P}(x, y) \\sum_{i=1}^{n} w_{i} f_{i}(x, y)\næ¢¯åº¦å‡½æ•°ï¼š\n\n\ng(w)=\\sum_{x, y} \\tilde{P}(x) P_{w}(y \\mid x) f(x, y)-E_{\\tilde{p}}(f)\nBFGSç®—æ³•ï¼š\nè¾“å…¥ï¼šç‰¹å¾å‡½æ•°;ç»éªŒåˆ†å¸ƒ\nè¾“å‡ºï¼šæœ€ä¼˜åŒ–å‚æ•°å€¼ï¼›æœ€ä¼˜åŒ–æ¨¡å‹\n(1) é€‰çš„åˆå§‹ç‚¹â€‹,å–â€‹ä¸ºæ­£å®šå¯¹ç§°çŸ©é˜µï¼Œç½®\n(2) è®¡ç®— â€‹ è‹¥ â€‹, å‰‡åœæ­¢è®¡ç®—: å¦åˆ™è½¬ (3)(3) æˆˆ â€‹ æ±‚å‡º â€‹(4) ä»¥ä¸ºæœç´¢: æ±‚ ä½¿å¾—ï¼šâ€‹\n\n\n\nf\\left(w^{(k)}+\\lambda_{k} p_{k}\\right)=\\min _{\\lambda \\geqslant 0} f\\left(w^{(k)}+\\lambda p_{k}\\right)â€‹      (5) ç½®â€‹\nâ€‹      (6) è®¡ç®—ï¼Œè‹¥ï¼Œåˆ™åœæ­¢è®¡ç®—ï¼›å¦åˆ™ï¼ŒæŒ‰ä¸‹å¼è®¡ç®—\n\nB_{k+1}=B_{k}+\\frac{y_{k} y_{k}^{\\mathrm{T}}}{y_{k}^{\\mathrm{T}} \\delta_{k}}-\\frac{B_{k} \\delta_{k} \\delta_{k}^{\\mathrm{T}} B_{k}}{\\delta_{k}^{\\mathrm{T}} B_{k} \\delta_{k}}â€‹      å…¶ä¸­ï¼Œ\n\ny_{k}=g_{k+1}-g_{k}, \\quad \\delta_{k}=w^{(k+1)}-w^{(k)}â€‹     (7) æŸ» , è½¬ (3).\n4. Information Retrieval4.1 Introduction\nInformation Retrieval (IR) is finding material (usually documents) of an unstructured nature (usually text) that satisfies an information need from within large collections (usually stored on computers)\n\n4.2 Term-document incidence matricesE:/third\n4.3 Incidence vectors\nSo we have a 0/1 vector for each term.\n\nTo answer query: take the vectors for Brutus, Caesar and Calpurnia (complemented)(åç ) â€‹â€‹â€‹ bitwise AND\n\n110100  AND 110111 AND 101111 = 100100E:/third\n\n\n4.4 Problem: Canâ€™t build the matrix\nConsider  million documents, each with about 1000 words.\nAvg 6 bytes/word including spaces/punctuation\n6GB of data in the documents.\n\n\nSay there are â€‹ distinct terms among these.\nâ€‹ matrix has half a trillion 0â€™s and 1â€™s.\nBut it has no more than one billion 1â€™s\nmatrix is extremely sparse\n\n\nWhatâ€™s a better representation?\nWe only record the 1 positions.\n\n\n\n4.5 Inverted index\nFor each term t , we must storkkkkke a list of all documents that contain t\nIdentify each doc by a docID , a document serial number\n\n\nCan we used fixed size arrays for this?E:/thirdE:/third\n\n4.5  Initial stages of text processing\nTokenization\nCut character sequence into word tokens\nDeal with â€œ Johnâ€™sâ€, a state of the art solution\n\n\n\n\nNormalization\nMap text and query term to same form\nYou want U.S.A. and USA to match\n\n\n\n\nStemming\nWe may wish different forms of a root to match\nauthorize authorization\n\n\n\n\nStop words\nWe may omit very common words (or not)\nthe, a, to, of\n\n\n\n\n\n4.5.1 Indexer steps: Token sequence\nSequence of (Modified token, Document ID) pairs.E:/third\n\n4.5.2 Indexer steps: Sort\nSort by terms\nAnd then docID\nCore indexing stepE:/third\n\n\n\n4.5.3 Indexer steps: Dictionary &amp; Postings\nMultiple term entries in a single document are merged.\nSplit into Dictionary and Postings\nDoc. frequency information is added.E:/third\n\n4.5.4 Where do we pay in storage? Pointers TermsE:/third\n4.6 Query processing with an inverted index4.6.1 Query processing: AND\nConsider processing the query:\nBrutus AND Caesar\nLocate Brutus in the Dictionary;\nRetrieve its postings.\n\n\nLocate Caesar in the Dictionary;\nRetrieve its postings.\n\n\nâ€œMergeâ€ the two postings (intersect the document sets):E:/third\n\n\n\n\n\nThe merge\n\nWalk through the two postings simultaneously, in time linear in the total number of postings entriesE:/third\n\nIf the list lengths are  and  , the merge takes  operations.E:/third\n\n\n4.7 The Boolean Retrieval Model &amp; Extended Boolean Models\nExercise : Adapt the merge for the\n\nBrutus AND NOT Caesar\nBrutus OR NOT Caesar\n\n\nCan we still run through the merge in time ? What can we achieve?\n\nWhat about an arbitrary Boolean formula? \n\n(Brutus OR Caesar) AND NOT (Antony OR Cleopatra)\n\n\nCan we always merge in â€œlinearâ€ time?\n\nLinear in N(N is the total posting size)\n\n\nCan we do better?\n\n4.8 Query optimization4.8.1 merge\nQuery: Brutus AND Calpurnia AND CaesarE:/third\n\nä»æœ€å°‘é¢‘æ•°çš„ä¸¤ä¸ªqueryå¼€å§‹åˆå¹¶\n\nProcess in order of increasing freq\n\nstart with smallest set, then keep cutting furtherE:/third\n\n\n\n4.8.2 More general optimization\ne.g., madding OR crowd ) AND ignoble OR strife\nGet doc. freq.â€™s for all terms.\nEstimate the size of each OR by the sum of its doc. freq.â€™s (conservative)\nProcess in increasing order of OR sizes.\n\n","categories":["nlp"]},{"title":"å¤ä¹ è¯¾","url":"/2021/08/15/nlp%20learning/review/","content":"å¤ä¹ è¯¾\n\nå¤ä¹ è¯¾å¤§ç±»åˆ«æŒ‰ç…§å¤ä¹ è¯¾é¡ºåºè€Œéä¸Šè¯¾é¡ºåºã€‚\n\nClassification\n\nbag of words representation\n\nNaive Bayes\n\nsmooth\n\n\nQA\n\nHistory\nparadigms of QA\nIR-Based QA\nKB-Based QA\nPattern Based\nParsing Based\n\n\n\n\nChatBot\n\nç”»æ¡†å›¾\n\n\nInformation Extraction\n\nNER\nSequence labeling\n\n\nHMM\n\nä¸‰ç§ç®—æ³•\nPOS tagging\n\n\n\n1. æ–‡æœ¬åˆ†ç±»\nä»bag of wordè¿™ç§åŸºäºè¯é¢‘çš„å†…å®¹å¼€å§‹ï¼Œç»Ÿè®¡æ–‡æ¡£ä¸­çš„æŸäº›è¯çš„è¯é¢‘å¯¹æ–‡æ¡£è¿›è¡Œåˆ†ç±»ã€‚\nç»Ÿè®¡æ–‡æ¡£çš„å•è¯ï¼Œå¹¶è·å¾—æœ‰å…³æ–‡æ¡£çš„å­—å…¸ã€‚ ç„¶åæˆ‘ä»¬å¯ä»¥ä»æ–‡æ¡£ä¸­è·å–æ¯ä¸ªå•è¯çš„é¢‘ç‡ã€‚ä¸€èˆ¬æˆ‘ä»¬åªé€‰å–æœ‰ç”¨çš„è¯æ¥ç»Ÿè®¡ã€‚\n\n\n\né‡‡ç”¨çš„æ–¹æ³•æ˜¯æœ´ç´ è´å¶æ–¯æ–¹æ³•ã€‚å¦‚ä¸‹æ˜¯æœ´ç´ è´å¶æ–¯çš„å…¬å¼ï¼š\n\n\n\næ ¹æ®ä¸Šé¢çš„å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æœ‰æŸäº›ç‰¹å¾çš„ç‰©å“è¿›è¡Œç±»åˆ«åˆ†ç±»ï¼Œå¦‚ä¸‹æ˜¯ä¸€ä¸ªæ°´æœåˆ†ç±»é—®é¢˜ã€‚\n\n\n\nå­˜åœ¨ç€æœ‰çš„ç‰¹å¾å¯èƒ½æ²¡æœ‰å€¼çš„æƒ…å†µï¼Œæ¯”å¦‚ä¸Šä¸€é¢˜é‡Œé¢Orangeé‡Œé¢å°±æ²¡æœ‰Longã€‚å¯ä»¥ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘çš„æ–¹å¼è§£å†³ã€‚\nè®­ç»ƒè¿‡ç¨‹ï¼Œé¦–å…ˆå»ºç«‹è¯å…¸ï¼Œç„¶åè®¡ç®—å…ˆéªŒï¼Œå³ç»Ÿè®¡æ‰€æœ‰æ–‡æ¡£ä¸­ï¼Œç±»åˆ«ä¸ºçš„æ–‡æ¡£é¢‘ç‡ã€‚ç„¶åè®¡ç®—ç±»æ¡ä»¶æ¦‚ç‡ï¼Œå³å…ˆç»Ÿè®¡æ–‡æ¡£çš„æ‰€æœ‰è¯æ•°ï¼Œç„¶åç»Ÿè®¡æ–‡æ¡£ä¸­çš„ä¸ªæ•°ã€‚\næµ‹è¯•è¿‡ç¨‹ä¸­\n\n\n\næ³¨æ„ï¼šå¦‚æœé¢˜ç›®è¯´è¦ç»Ÿè®¡unkè¯ï¼Œæ³¨æ„è¯è¡¨æ•°+1\n\n\n\\begin{aligned}\n\\hat{P}\\left(w_{u} \\mid c\\right) &=\\frac{\\operatorname{count}\\left(w_{u}, c\\right)+1}{\\left(\\sum_{w \\in V} \\operatorname{count}(w, c)\\right)+|V+1|} \\\\\n&=\\frac{1}{\\left(\\sum_{w \\in V} \\operatorname{count}(w, c)\\right)+|V+1|}\n\\end{aligned}\næ€»è€Œè¨€ä¹‹ï¼Œæ˜¯å¦éœ€è¦å¹³æ»‘ï¼Œéœ€è¦çœ‹é¢˜ç›®è¦æ±‚\nå°†ä¸Šè¿°åˆ†ç±»çš„æ–¹æ³•éƒ¨ç½²åˆ°è‡ªç„¶è¯­è¨€é¢†åŸŸï¼š\n\nè¦æ±‚ï¼šè®¡ç®—\n\n\n\n\\begin{gathered}\nF_{\\beta}=\\frac{\\left(\\beta^{2}+1\\right) P R}{\\beta^{2} P+R} \\\\\n\\mathrm{~F}_{1}=\\frac{2 P R}{P+R}\n\\end{gathered}2. QA\né—®ç­”ç³»ç»Ÿçš„å‘å±•å†å²ï¼š\n\n1961å¹´,BASEBALL\n2003å¹´ï¼ŒTAP Search\n2010å¹´å‰åï¼šWolfram Alphaï¼ŒSiriï¼ŒWatson\n2012,Googleçš„èœ‚é¸Ÿç®—æ³•\n2015RankBrain\n2019æ™ºèƒ½éŸ³ç®±\n\n\nQAçš„åˆ†ç±»ï¼š\n\nåŸºäºIRçš„æ–¹æ³•\n\nåŸºäºçŸ¥è¯†å›¾è°±çš„æ–¹æ³•\n\nåŸºäºæ··åˆçš„æ–¹æ³•\n\n\n\nè¦æ±‚ï¼šéœ€è¦éå¸¸ç†Ÿæ‚‰åœ°æŒæ¡å‡ ç±»æ–¹æ³•çš„è®¾è®¡æ¨¡å¼ä»¥åŠä¼˜ç¼ºç‚¹\næ¯”å¦‚ï¼ŒåŸºäºIRçš„QAéœ€è¦çŸ¥é“ä»£è¡¨å·¥ä½œæœ‰å“ªäº›ã€‚åŸºäºIRæµç¨‹è®¾è®¡çš„QAç³»ç»Ÿ,ä¸»è¦åˆ†æˆä¸‰æ­¥ï¼š\n\nç”¨çŸ¥è¯†å›¾è°±çš„QAå¯ä»¥è§£å†³çš„é—®é¢˜æ˜¯è¯­ä¹‰é¸¿æ²Ÿå’Œè¯æ³•é¸¿æ²Ÿã€‚åŸºäºçŸ¥è¯†å›¾è°±çš„è¯­ä¹‰è§£æçš„æ–¹æ³•åˆ†ä¸ºå‡ ç±»ï¼ŒåŸºäºçŸ¥è¯†å›¾è°±ç«¯åˆ°ç«¯çš„æ–¹æ³•åˆ†ä¸ºå‡ ç±»ã€‚å¦‚ä¸‹æ˜¯åŸºäºçŸ¥è¯†å›¾è°±çš„QAç³»ç»Ÿæ„å»ºæ–¹æ³•ï¼Œä¹Ÿæ˜¯Siriçš„æ„å»ºæ–¹æ³•ï¼š\n\nä¸‹é¢æ˜¯ä»‹ç»åŸºäºIRçš„QAç³»ç»Ÿçš„å…·ä½“çš„è®¾è®¡æµç¨‹ï¼ŒåŒ…å«äº†å¾ˆå¤šçš„IRçš„æ€æƒ³ ï¼š\néœ€è¦çŸ¥é“æ¯ä¸ªå¤§æ¡†æ¶é‡Œé¢æ˜¯ä»€ä¹ˆï¼Œæ¯ä¸ªå°çš„æ­¥éª¤æ˜¯ä»€ä¹ˆã€‚\n\nQuestion Processing:\n\néœ€è¦è¯¦ç»†äº†è§£æ¯ä¸ªå°çš„æ¡†å›¾é‡Œé¢æœ‰ä»€ä¹ˆå†…å®¹ï¼š\n23.2 Factoid Question Answering 819é¡µè¿›è¡Œäº†è®²è§£\nåŸºäºæ¨¡æ¿çš„QAä¹Ÿæ˜¯é‡è¦çš„ï¼Œæ¨¡æ¿çš„ç”Ÿæˆä»¥åŠå®ä¾‹åŒ–ï¼Œè®©å†™ä¸€ä¸ªæ¨¡æ¿ç”Ÿæˆçš„æ¶æ„åº”è¯¥ä¹Ÿæ˜¯å¯ä»¥å†™å‡ºæ¥çš„ï¼š\nåŒ…å«ä¸¤æ­¥ï¼š\nStep 1: Template generation linguistics processing\nStep 2: Template matching and instantiation NER\nè®©ä½ å†™ä¸€ä¸ªæ¨¡æ¿ç”Ÿæˆçš„æ¶æ„åº”è¯¥ä¹Ÿæ˜¯å¯ä»¥å†™å‡ºæ¥çš„ã€‚\n\nåŸºäºparsingçš„æ¶æ„å›¾ï¼Œä¸‹é¢çš„å›¾æ˜¯éå¸¸é‡è¦çš„ï¼Œå› ä¸ºåŒ…å«äº†å„ä¸ªæ­¥éª¤ï¼ŒåŒ…æ‹¬çŸ­è¯­æ˜ å°„ï¼Œèµ„æºæ˜ å°„ï¼Œè¯­ä¹‰ç»„åˆï¼ŒæŸ¥è¯¢ç”Ÿæˆã€‚\n\nä¼šå‡ºç°ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šè¯æ³•é¸¿æ²Ÿå’Œè¯­ä¹‰é¸¿æ²Ÿã€‚è¯æ³•é¸¿æ²Ÿæ˜¯æŒ‡æ–‡æœ¬åˆ°çŸ¥è¯†å›¾è°±ä¹‹é—´çš„æ˜ å°„éœ€è¦å®šä¹‰ï¼Œè¯­ä¹‰é¸¿æ²ŸæŒ‡çš„æ˜¯æŸ¥è¯¢æ—¶å€™çš„é—®é¢˜ï¼ˆè¿™é‡Œæ²¡è®²æ˜ç™½ï¼‰ã€‚æˆ‘ä»¬éœ€è¦æƒ³åˆ°æ€ä¹ˆå»è§£å†³è¿™äº›æ–¹æ³•ï¼Œä¸ç®¡æ˜¯ç”¨bertè¿˜æ˜¯æ€ä¹ˆçš„ã€‚\n\nå‡ºç°æ•ˆæœè¾ƒå·®çš„åŸå› ï¼šä¸€ä¸ªæ˜¯ç”±æ•°æ®å¼•èµ·çš„ï¼Œæ•°æ®é”™çš„ï¼Œå’Œæ•°æ®æ˜¯ä¸å®Œæ•´å’Œç¼ºå¤±çš„ã€‚æŸ¥è¯¢çš„è¯åŒ…æ‹¬äº†å¯¹æŸ¥è¯¢çš„é”™è¯¯ç†è§£ï¼Œè¿‡äºä¸¥æ ¼çš„æŸ¥è¯¢ï¼Œå¤±è´¥çš„æ’åºç®—æ³•ç­‰ã€‚\nåªéœ€è¦äº†è§£å³å¯\n\nä¸åŒç©ºé—´ä¸åŒä»»åŠ¡ï¼šæ¨ç†ï¼ŒæŸ¥è¯¢ï¼ŒåŠ é€Ÿã€‚\n\n3. ChatBotç›¸æ¯”è¾ƒQAå¢åŠ äº†ä¸¤ä¸ªæ¨¡å—ï¼Œå¯¹äºå¯¹è¯çš„ç®¡ç†ï¼Œä»¥åŠå¯¹è¯ç­–ç•¥çš„æ‰§è¡Œã€‚\nå¹³æ—¶çš„èŠå¤©æœºå™¨äººä¸»è¦æ˜¯ä¸¤ä¸ªçŠ¶æ€ï¼šä¸€ä¸ªæ˜¯åŸºäºé¢†åŸŸçš„ï¼Œå°é—­çš„ã€‚æ¯”å¦‚å¸®ä½ å»è®¢é…’åº—ï¼Œè®¢æœºç¥¨ä»€ä¹ˆçš„ã€‚è¿˜æœ‰ä¸€ä¸ªå°±æ˜¯å¼€æ”¾å¼çš„ã€‚å°é—­çš„æ˜¯åŸºäºè§„åˆ™æ¨¡æ¿ï¼Œç»Ÿè®¡ç»„ä»¶æˆ–è€…æ˜¯ä¸€äº›Deep Learningçš„æ–¹æ³•ã€‚\n\nè€ƒè¯•çš„æ—¶å€™ä¼šè®©ç”»æ¡†å›¾ï¼Œä½†æ˜¯æ³¨æ„ä¸è¦ç”»bertï¼Œç”»bertåé¢çš„ç»„ä»¶æ²¡æ³•è¯´ã€‚åƒä¸Šé¢çš„å°±æ–¹ä¾¿è¯´æ¯ä¸€ä¸ªç»„ä»¶æ˜¯å¹²ä»€ä¹ˆçš„ã€‚é¦–å…ˆæ˜¯å¯¹è¯­éŸ³çš„ç†è§£ï¼Œ çŠ¶æ€è¿½è¸ªï¼ˆéœ€è¦å¾ˆæ¸…æ¥šæ˜¯å¹²ä»€ä¹ˆçš„ï¼‰ï¼Œå¯¹è¯ç­–ç•¥çš„æ‰§è¡Œä¸å­¦ä¹ ï¼Œæœ€åæ˜¯è¿›è¡Œç”Ÿæˆã€‚åŒæ—¶è¿˜æœ‰ä¸€ä¸ªçŸ¥è¯†åº“ï¼ŒçŸ¥è¯†åº“çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ\n\n\nåœ¨è®¾è®¡ç³»ç»Ÿçš„æ—¶å€™ä»æ•´é—¨è¯¾çš„è§’åº¦å»æ€è€ƒï¼Œè¿™é—¨è¯¾ä¸»è¦ä¸¤ä¸ªéƒ¨åˆ†ï¼Œè‡ªç„¶è¯­è¨€çš„ç†è§£ï¼Œè‡ªç„¶è¯­è¨€çš„ç”Ÿæˆã€‚å‰é¢çš„æŠ€æœ¯åŒ…æ‹¬POSï¼ŒNER,ç­‰ã€‚\n4. ä¿¡æ¯çš„æŠ½å–æ‰¾åˆ°æ–‡æœ¬ï¼Œæ”¶é›†informationï¼Œè¿™äº›ä¿¡æ¯æ˜¯æœåŠ¡äºäººå’Œç®—æ³•çš„ã€‚\n\nä¸¤ä¸ªæ ¸å¿ƒä»»åŠ¡ï¼ŒNERçš„è¯†åˆ«å…³ç³»çš„æå–ã€‚è¿™ä¸ªPPTæ¯”è¾ƒè€äº†ã€‚\néœ€è¦å…³æ³¨ä¸€ä¸ªæ–°çš„æ–¹å‘ï¼šäº‹ä»¶æŠ½å–ã€‚é™¤äº†NERå’Œå…³ç³»æŠ½å–å¤–ï¼Œè¯´ä¸€ä¸ªä¿¡æ¯æŠ½å–å…¶ä»–çš„ä»»åŠ¡ã€‚æ¯”å¦‚å¤šæ¨¡æ€çŸ¥è¯†æŠ½å–ã€‚æœ€è¿‘çš„ä»»åŠ¡å°±æ˜¯åœ¨å…³æ³¨äº‹ä»¶æŠ½å–ï¼Œéœ€è¦äº†è§£æ¦‚å¿µ\nNERéœ€è¦è¯†åˆ«äººåï¼Œåœ°åï¼Œç»„ç»‡åä¹‹ç±»çš„ã€‚\n\n\næ ¸å¿ƒçš„æ€æƒ³è¿˜æ˜¯åŸæ¥çš„é‚£ä¸ªè®­ç»ƒæ¨¡å‹çš„æ€è·¯ï¼š\n\néœ€è¦ç»†åŒ–ï¼ŒçŸ¥é“æ€ä¹ˆæ ‡æ³¨ï¼Œæ€ä¹ˆè®­ç»ƒã€‚æ¯”å¦‚æ ‡å¿—ä½ï¼Œå¸¸è§çš„Featureï¼Œå¸¸è§çš„åˆ†ç±»å™¨ï¼Œå¯ä»¥ä½¿ç”¨æœ€ç®€å•çš„éšé©¬å°”ç§‘å¤«æ¨¡å‹ã€‚æ¯”å¦‚å‡ºç°ä¸€ä¸ªéšé©¬å°”ç§‘å¤«çš„é¢˜ç›®ã€‚ä¸‹é¢å¯èƒ½ä¼šæœ‰ä¸€ä¸ªNERçš„é¢˜ç›®ï¼Œå¦‚æœä¸ä¼šåšå¯ä»¥ç›´æ¥ç”¨éšé©¬å°”ç§‘å¤«ã€‚ä½†æ˜¯éœ€è¦å¼„æ¸…æ¥šçš„æ˜¯æ€ä¹ˆç”¨åˆ†ç±»å™¨å»åšã€‚ç›®æ ‡å‡½æ•°ï¼Œæ¯ä¸€æ­¥è¿‡ç¨‹ä¸ä½œç”¨æ˜¯ä»€ä¹ˆã€‚ä¸éœ€è¦éšé©¬å°”ç§‘å¤«çš„æ¨å¯¼è¿‡ç¨‹ï¼Œä½†æ˜¯éœ€è¦çŸ¥é“æ€ä¹ˆHMMæ˜¯æ€ä¹ˆè§£ç çš„ã€‚\n\n\n\nåšå…³ç³»çš„æŠ½å–ä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚æ„å»ºåˆç†çš„åˆ†ç±»å™¨å¹¶ä¸”æ„å»ºåˆç†çš„featureã€‚\n\n\næ•´ä¸ªè¯¾ç¨‹æœ‰ä¸‰ä¸ªåœ°æ–¹æ¶‰åŠåˆ°è®¡ç®—ï¼Œä¸€ä¸ªæ˜¯è´å¶æ–¯ï¼Œä¸€ä¸ªæ˜¯HMM å’Œç»´ç‰¹æ¯”ç®—æ³•æ¶‰åŠåˆ°ï¼Œå¹¶ä¸”è¿˜æœ‰ä¸€ä¸ªä½œä¸šã€‚TFIDFï¼Œéš”å£ç­çº§æ²¡æœ‰è®²ï¼ˆä½†æ˜¯çœ‹ä»–ä»¬çš„pptä¸Šé¢æ˜¯æœ‰çš„ï¼‰\n\n5. HMM\næ¨å¯¼éœ€è¦å®Œå…¨ç†Ÿç»ƒçš„æŒæ¡ï¼Œè¾“å…¥æ˜¯ä»€ä¹ˆè¾“å‡ºæ˜¯ä»€ä¹ˆ\n\n\n5.1 Maximun a posterior inference(MAP inference)\n\nHMMæœ‰ä¸¤ä¸ªç‹¬ç«‹æ€§å‡è®¾ï¼š\nè§‚æµ‹åºåˆ—ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ (A B ç‹¬ç«‹ æœ‰P(A, B) = P(A)P(B)ï¼Œæ‰€ä»¥è®¡ç®—è”åˆæ¦‚ç‡çš„æ—¶å€™æ‰èƒ½ç”¨å ä¹˜ )\nå½“å‰çŠ¶æ€ä»…ä¾èµ–äºå…ˆå‰çš„çŠ¶æ€\n\n\nNumber of states = K, Number of observations = M\nï¼šInitial probabilities over states (K*K matrix)\nï¼šTransition probabilities (K*M matrix)\n\nInput , Output â€‹ that corresponds to\n\n\n\nargmax_\\bold{y}P(\\bold{y}|\\bold{x},\\pi,A,B)=argmax_\\bold{y}P(\\bold{y},\\bold{x},\\pi,A,B)\n\\begin{array}{ll}\nP(\\bold{y},\\bold{x})\n&=P(y_1,\\ldots,y_n,x_1,\\ldots,x_n)\\\\\n&=P(\\bold{x}|\\bold{y})P(\\bold{y})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))\\\\\n&\\text{æ³¨é‡Šï¼šè¿™é‡Œç”¨äº†æ¡ä»¶ç‹¬ç«‹å‡è®¾ï¼Œä»¥åŠå¯è§ç¬¦å·çš„æ¦‚ç‡åªä¸å½“å‰çŠ¶æ€æœ‰å…³}\\\\ \n&\\times P(y_1)P(y_2|y_1)P(y_3|y_1,y_2)\\ldots P(y_n|y_1,\\ldots,y_{n-1})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))P(y_1)\\prod^n_{i=2}P(y_i|y_1,\\ldots,y_{i-1})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))P(y_1)\\prod^n_{i=2}P(y_i|y_{i-1})\\\\\n&\\text{æ³¨é‡Šï¼šè¿™é‡Œç”¨äº†éšé©¬å°”å¯å¤«ä¸€é˜¶å‡è®¾ï¼Œå³å½“å‰çŠ¶æ€çš„æ¦‚ç‡åªä¸ä¸Šä¸€ä¸ªçŠ¶æ€æœ‰å…³}\\\\\n&=P(y_1)\\prod^n_{i=2}P(y_i|y_{i-1})\\prod^n_{i=1}P(x_i|y_i)\n\\end{array}ä¸åŒæ¨¡å‹çš„æè¿°ï¼š\n\n5.2 DPæ¨å¯¼ï¼š\n\\begin{array}{ll}\n\\max_{y_1,\\ldots,y_n} P(\\bold{y},\\bold{x})\n&=\\max_{y_1,\\ldots,y_n}P(y_1,\\ldots,y_n,x_1,\\ldots,x_n)\\\\\n&=\\max_{y_1,\\ldots,y_n}P(y_1)\\prod^n_{i=2}P(y_i|y_{i-1})\\prod^n_{i=1}P(x_i|y_i)\\\\\n&=\\max_{y_1,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_2,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots P(y_3|y_2)P(x_3|y_3)\\max_{y_1}P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_2,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots P(y_3|y_2)P(x_3|y_3)\\max_{y_1}P(y_2|y_1)P(x_2|y_2)Score(y_1)\\\\\n&\\text{Initialize: } score_1(y_1)=P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_3,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots P(y_4|y_3)P(x_4|y_4) \\max_{y_2}(P(y_3|y_2)P(x_3|y_3)\\max_{y_1}P(y_2|y_1)P(x_2|y_2)Score(y_1))\\\\\n&=\\max_{y_3,\\ldots,y_n}P(y_n|y_{n-1})y(x_n|y_n)\\ldots P(y_4|y_3)P(x_4|y_4)\\max_{y_2}(P(y_3|y_2)P(x_3|y_3)Score(y_2))\\\\\n&\\text{Update: }score_2(y_2)=\\max_{y_1}P(y_2|y_1)P(x_2|y_2)Score(y_1)\\\\\n&=max_{y_n}score(y_n)\\\\\n\\end{array}\nscore(y_i)=\n\\left\\{\n\\begin{array}{cc}\nP(y_i)P(x_i|y_i),&\\text{i=1}\\\\\n\\max_{y_{i-1}}P(y_i|y_{i-1})P(x_i|y_i)Score(y_{i-1}),&\\text{i=2,$\\ldots$,n}\n\\end{array}\n\\right.\n\nä¸ç”¨åŠ¨æ€è§„åˆ’å‰ï¼Œç®—æ³•å¤æ‚åº¦ä¸ºï¼Œå³è¦éå†çš„è·¯å¾„æ•°é‡ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’åå˜ä¸ºâ€‹ï¼Œå³å¯¹äºæ¯æ¬¡è¿­ä»£åªéœ€è¦è®¡ç®—kä¸ªè”åˆæ¦‚ç‡ï¼Œæ¯ä¸ªè”åˆæ¦‚ç‡éœ€è¦è®¡ç®—kæ¬¡ä¹˜æ³•ï¼Œè€Œè¿­ä»£æ•°ä¸ºnæ¬¡ï¼Œæ‰€ä»¥æ—¶é—´å¤æ‚åº¦å¦‚ä¸Š\n\n5.3 Vitebri Algorithm\nâ€‹\nInitialization\nfor each hidden  â€‹â€‹â€‹\n\n\nRecursion\nfor t = 2 to n, for each :\n\nå³tæ—¶åˆ»éšè—çŠ¶æ€jçš„è”åˆæ¦‚ç‡ä¸ºä¸Šä¸€ä¸ªçŠ¶æ€è½¬ç§»çš„æœ€å¤§å€¼æ‰€æ¿€å‘å¯è§ç¬¦å·çš„æ¦‚ç‡\n\n\nâ€‹\næ‰¾åˆ°è·¯å¾„\n\n\n\n\nEnd\n\n\nâ€‹â€‹\nfor t=n-1 to 1(path back tracking)\n$w^(t)=\\psi_{w^(t+1)}(t+1)$\n\n\nend\n\n5.4 Supervised learning details\n can be estimated separately just by counting\n\ns denotes label, x denotes word, n denotes the number of total words\n\nInitial prob\n\n\n\\pi_s=\\frac{count(start\\rightarrow s)}{n}\nTransition prob\n\n\nA_{s',s}=\\frac{count(s\\rightarrow s')}{count(s)}\nEmission prob\n\n\nB_{s,x}=\\frac{count\\left(\n\\begin{array}{c}\ns\\\\\n\\downarrow\\\\\nx\n\\end{array}\n\\right)}{count(s)}5.5 tri-gram markov\n\\begin{array}{ll}\nP(\\bold{y},\\bold{x})\n&=P(y_1,\\ldots,y_n,x_1,\\ldots,x_n)\\\\\n&=P(\\bold{x}|\\bold{y})P(\\bold{y})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))\\\\\n&\\text{æ³¨é‡Šï¼šè¿™é‡Œç”¨äº†æ¡ä»¶ç‹¬ç«‹å‡è®¾ï¼Œä»¥åŠå¯è§ç¬¦å·çš„æ¦‚ç‡åªä¸å½“å‰çŠ¶æ€æœ‰å…³}\\\\ \n&\\times P(y_1)P(y_2|y_1)P(y_3|y_1,y_2)\\ldots P(y_n|y_1,\\ldots,y_{n-1})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))P(y_1)P(y_2|y_1)\\prod^n_{i=3}P(y_i|y_1,\\ldots,y_{i-1})\\\\\n&=(\\prod^n_{i=1}P(x_i|y_i))P(y_1)P(y_2|y_1)\\prod^n_{i=3}P(y_i|y_{i-2},y_{i-1})\\\\\n&\\text{æ³¨é‡Šï¼šè¿™é‡Œç”¨äº†éšé©¬å°”å¯å¤«äºŒé˜¶å‡è®¾ï¼Œå³å½“å‰çŠ¶æ€çš„æ¦‚ç‡åªä¸ä¸Šä¸€ä¸ªçŠ¶æ€æœ‰å…³}\\\\\n&=P(y_1)P(y_2|y_1)\\prod^n_{i=3}P(y_i|y_{i-2},y_{i-1})\\prod^n_{i=1}P(x_i|y_i)\n\\end{array}\n\\begin{array}{ll}\n\\max_{y_1,\\ldots,y_n} P(\\bold{y},\\bold{x})\n&=\\max_{y_1,\\ldots,y_n}P(y_1,\\ldots,y_n,x_1,\\ldots,x_n)\\\\\n&=\\max_{y_1,\\ldots,y_n}P(y_1)P(y_2|y_1)\\prod^n_{i=3}P(y_i|y_{i-2},y_{i-1})\\prod^n_{i=1}P(x_i|y_i)\\\\\n&=\\max_{y_1,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_3|y_1,y_2)P(x_3|y_3)P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_2,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_4|y_2,y_3)P(x_4|y_4)\\max_{y_1}P(y_3|y_1,y_2)P(x_3|y_3)P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_2,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_4|y_2,y_3)P(x_4|y_4)\\max_{y_1}P(y_3|y_1,y_2)P(x_3|y_3)Score(y_1,y_2)\\\\\n&\\text{Initialize: } score_1(y_1,y_2)=P(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1)\\\\\n&=\\max_{y_3,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_5|y_3, y_4)P(x_5|y_5) \\max_{y_2}P(y_4|y_2,y_3)P(x_4|y_4)\\max_{y_1}P(y_3|y_1,y_2)P(x_3|y_3)Score(y_1,y_2)\\\\\n&=\\max_{y_3,\\ldots,y_n}P(y_n|y_{n-2},y_{n-1})y(x_n|y_n)\\ldots P(y_5|y_3,y_4)P(x_5|y_5)\\max_{y_2}P(y_4|y_2,y_3)P(x_4|y_4)Score(y_2,y_3))\\\\\n&\\text{Update: }score(y_2,y_3)=\\max_{y_1}P(y_3|y_1,y_2)P(x_3|y_3)Score(y_1,y_2)\\\\\n&\\vdots\\\\\n    &=\\max_{y_{n-2},y_{n-1},y_n}P(y_n|y_{n-2},y_{n-1})P(x_n|y_n)\\max_{y_{n-3}}P(y_{n-1}|y_{n-3},y_{n-2})P(x_{n-1}|y_{n-1})Score(y_{y_{n-3}},y_{n-2})\\\\\n&\\text{Update: }score(y_{n-2},y_{n-1})=\\max_{y_{n-3}}P(y_{n-1}|y_{n-3},y_{n-2})P(x_{n-1}|y_{n-1})Score(y_{y_{n-3}},y_{n-2})\\\\\n&=\\max_{y_{n-2},y_{n-1},y_n}P(y_n|y_{n-2},y_{n-1})P(x_n|y_n)score(y_{n-2},y_{n-1})\\\\\n&=\\max_{y_{n-1},y_n}\\max_{y_{n-2}}P(y_n|y_{n-2},y_{n-1})P(x_n|y_n)score(y_{n-2},y_{n-1})\\\\\n&=\\max_{y_{n-1},y_{n}}score(y_{n-1},y_{n})\n\\end{array}\nscore(y_{i},y_{i+1})=\n\\left\\{\n\\begin{array}{cc}\nP(y_2|y_1)P(x_2|y_2)P(y_1)P(x_1|y_1),&\\text{i=1}\\\\\n\\max_{y_{i-1}}P(y_{i+1}|y_{i-1},y_{i})P(x_{i+1}|y_{i+1})score(y_{i-1},y_{i}),&\\text{i=2,$\\ldots$,n-1}\n\\end{array}\n\\right.5.6 HOMEWORK\n\nå…³é”®çš„ç‚¹\nä½œä¸šéœ€è¦éå¸¸ç†Ÿæ‚‰çš„æŒæ¡ã€‚\næœ´ç´ è´å¶æ–¯ï¼Œä»¥åŠå¹³æ»‘çš„æ–¹æ³•ã€‚\n\nNERä»¥åŠIEçš„è¿‡ç¨‹ç†Ÿæ‚‰æŒæ¡ã€‚\n\né‡åˆ°éš¾ç®—çš„åœ°æ–¹ï¼Œç›´æ¥ç”¨åˆ†æ•°å†™æˆä¹˜æ³•çš„å½¢å¼ä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œä¸éœ€è¦å±•å¼€æ¥ç®—ã€‚\nå¼€æ”¾é¢˜ï¼Œæœ‰ä¸¤ä¸ªé€‰æ‹©ï¼Œé€‰æ‹©å…¶ä¸­ä¸€ä¸ªå†™å°±è¡Œã€‚è®¾è®¡ä¸€ä¸ªQAï¼Œè®¾è®¡ä¸€ä¸ªIRï¼Œæˆ–è€…è®©ä½ è°ˆä¸€è°ˆBertçš„è¯­è¨€æ¨¡å‹çš„ç‰¹ç‚¹\næ‰€æœ‰çš„é¢˜ç›®éƒ½åº”è¯¥æ˜¯è‹±æ–‡ä½œç­”ã€‚\n\n","categories":["nlp"]},{"title":"Phrase queries and positional indexes","url":"/2021/08/15/nlp%20learning/Chapter9_tfidf/","content":"Phrase queries and positional indexes\n\nPhrase queries and positional indexes1. Phrase Queries\nå¦‚ä½•è§£å†³çŸ­è¯­ç´¢å¼•çš„ä¿¡æ¯æ£€ç´¢ï¼Ÿ\n\nThus the sentence I went to university at southeast of China is not a match.\n\nThe concept of phrase queries has proven easily understood by users; one of the few advanced search â€ ideas that works\n\n\nMany more queries are implicit phrase queries:\nnatural language processing\n\n\nFor this, it no longer suffices to store only\n\\&lt;term : docs &gt; entries\nå€’æ’æ— æ³•å®ç°\n\n\n\n1.1 Solution 1: Biword indexes\nIndex every consecutive pair of terms in the text as a phrase\n\nä¸¤ä¸¤ç»„åˆï¼Œè¿›è¡Œå­˜å‚¨\n\n\nFor example the text â€œFriends , Romans, Countrymenâ€ would generate the biwords\n\nfriends romans\nromans countrymen\n\n\nEach of these biwords is now a dictionary term\n\nTwo word phrase query processing is now immediate.\n\nè¿™ç§æ–¹æ³•å¯¹äºä¸¤ä¸ªå•è¯çš„ç»„åˆ\n\n\nå¯¹äºé•¿ç´¢å¼•ï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œä¸¤ä¸¤æ‹†åˆ†ï¼Œä»è€Œå½¢æˆå¤šä¸ªäºŒå…ƒè¯ç»„çš„åˆå–\n\nstandford university palo alto\nstandford unversity and university palo and palo alto\n\n\né™¤éæç«¯æƒ…å†µï¼Œä¼šé€ æˆFNï¼Œå¤§éƒ¨åˆ†æƒ…å†µå°±åˆé€‚çš„\nä½†æ˜¯è¿™ç§æ–¹æ³•ä¼šé€ æˆå¤§é‡çš„å­˜å‚¨å¼€é”€\n\n1.2 Solution 2: Positional Indexes\nIn the postings, store, for each term the position(s) in which tokens of it appear:\n&lt;term , number of docs containing termdoc1: position1, position2 â€¦doc2: position1, position2 â€¦etc.&gt;\nå­˜å‚¨äº†æ–‡æ¡£çš„ä½ç½®\n\n\nPositional Index Example\nWhich of docs 1,2,4,5 could contain to be or not to be\n\n&lt;be :993427;\n1: 7, 18, 33, 72, 86,231;\n2: 3, 149ï¼›\n4: 17, 191, 291, 430,434;\n5: 363, 367,...&gt;\næˆ‘ä»¬å¯ä»¥å‘ç°4å’Œ5æœ‰å¯èƒ½æ˜¯å­˜åœ¨è¿™å¥è¯çš„ï¼Œå› ä¸ºä»–ä»¬çš„å·®åˆ†åºåˆ—å«æœ‰4è¿™ä¸€é¡¹\nä¸€èˆ¬è€Œè¨€ï¼Œä¸¤ä¸ªè¯çš„ä¿¡æ¯éƒ½æ˜¯å­˜åœ¨çš„ï¼Œé‚£ä¹ˆè¿™ç§æƒ…å†µå¦‚ä½•å¤„ç†ï¼Ÿ\nto:\n2:1,17,74,222,551;  4:8,16,190,429,433;     7:13,23,191â€¦\n\n\nbe:\n1:17,19 ;    4:17,191,291,430,434; 5:14,19,101â€¦\n\n\nç®—æ³•æ€è·¯ï¼Œåˆ©ç”¨ä¸¤çº§å€’æ’ç´¢å¼•ï¼Œå…ˆä»1å¼€å§‹ï¼Œç„¶åçœ‹toæ²¡æœ‰1,æ‰€ä»¥åˆ é™¤1ï¼Œå†çœ‹2ï¼Œå‘ç°beï¼Œæ²¡æœ‰2ï¼Œæ‰€ä»¥åˆ é™¤2ï¼Œè¿™æ ·å°±ä¸€èµ·æœç´¢åˆ°4ï¼›\nä»4é‡Œæˆ‘ä»¬é€šè¿‡to beåªå·®1çš„å…³ç³»ï¼Œå¯ä»¥å¾—åˆ°ä¸€å †å€™é€‰\n4:8,16,190,429,433;  \n4:17,191,291,430,434; \n\n\nç´§æ¥ç€å†é€šè¿‡to be or not to beå‰©ä½™çš„ä½ç½®å…³ç³»ç­›é€‰åˆ°å‡ ä¸ª\n4:429,433;\n4:430,434;\n\n\nä¼šå æ®2-4å€çš„å­˜å‚¨å¼€é”€ï¼šA positional index is 2-4 as large as a  nonpositional index\n\nPositional index size 35 50% of volume of original text\n\nCaveat: all of this holds for â€œEnglish likeâ€ languages\n\n\n\n2. Ranked Retrieval2.1 Problem with Boolean search:\nThus far, our queries have all been Boolean.\nDocuments either match or donâ€™t.\nå¯¹äºå¸ƒå°”å‹æ’åºä¼šè¿‡äºç»å¯¹\n\n\nGood for expert users with precise understanding of their needs and the collection.\n\nAlso good for applications: Applications can easily consume 1000sof results\nå¥½å¤„ï¼Œå¯¹äºä¸“å®¶å¯ä»¥å†™å¾ˆå¤šç²¾å‡†çš„æŸ¥è¯¢ï¼ŒæŸ¥åˆ°å°±æœ‰ï¼ŒæŸ¥ä¸åˆ°å°±ä¸€å®šæœ‰\nå°é—­ä¸–ç•Œï¼šæœ‰åˆ™ä¸€å®šèƒ½æŸ¥åˆ°ï¼›å¼€æ”¾ä¸–ç•Œï¼šæŸ¥ä¸åˆ°å¯èƒ½æ˜¯ç”±äºçŸ¥è¯†åº“çš„ç¼ºå¤±\n\n\nNot good for the majority of users.\n\nMost users incapable of writing Boolean queries (or they are,but they think itâ€™s too much work).\næ™®é€šäººæ— æ³•ä½¿ç”¨å¸ƒå°”æŸ¥è¯¢\n\n\nMost users donâ€™t want to wade through 1000s of results.\nThis is particularly true of web search.\n\n\nå¦‚ä½•è§£å†³è¿™ç§è¦ä¹ˆå¾ˆå¤šç­”æ¡ˆï¼Œè¦ä¹ˆæ‰¾ä¸åˆ°ç­”æ¡ˆè¿™ç§æƒ…å†µ\n\n\n\n\nFeast or Famine : Not A Problem In Ranked Retrieval\n\nWhen a system produces a ranked result set, large result sets are not an issue\n\nIndeed, the size of the result set is not an issue\nWe just show the top k ( â‰ˆ 10) results\nWe donâ€™t overwhelm the user\nPremise: the ranking algorithm works\n\n\n\n2.2 Scoring as The Basis Of Ranked Retrieval\nWe wish to return in order the documents most likely to beuseful to the searcher\n\nHow can we rank order the documents in the collection withrespect to a query\n\nAssign a score say in [0, 1] to each document\n\nThis score measures how well document and query â€œmatchâ€œ\n\nLetâ€™s start with a one term query\n\nIf the query term does not occur in the document: scoreshould be 0\n\né¦–å…ˆdocumentä¸åŒ…å«å…³é”®å­—çš„è‚¯å®šscore=0ï¼Œ\n\n\nThe more frequent the query term in the document, thehigher the score (should be ) reallyï¼Ÿ\n\nä¸åŒdocumentå«æœ‰çš„termé¢‘æ¬¡ä¸ä¸€æ ·ï¼Œå¯¹äºå•ä¸ªè¯å‡ºç°è¶Šå¤šè¶Šç›¸å…³ï¼Œä½†æ˜¯å¯¹äºå¤šä¸ªè¯å°±ä¸ä¸€å®š\n\n\n\n3.3 Scoring with the Jaccard Coefficient\nA commonly used measure of overlap of two sets A and B isthe Jaccard coefficient\n\n\n\\begin{array}{ll}\njaccard (A,B) = |A\\cap B | / |A\\cup B| \\\\\njaccard (A,A) = 1\\\\                                   \njaccard (A,B) = 0\\text{ if }A\\cap B = 0\\\\\n\\end{array}\nA and B donâ€™t have to be the same size.\n\nAlways assigns a number between 0 and 1.\n\nWhat is the query document match score that the Jaccard coefficient computes for each of the two documents belowï¼Ÿ\n\nQuery : ides of march\nDocument 1: caesar died in march\nJ(Q,D1)=1/6\n\n\nDocument 2: the long march\nJ(Q,D2)=1/5\n\n\n\n\n\n3.3.1 Issues With Jaccard For Scoring\nIt doesnâ€™t consider term frequency (how many times a termoccurs in a document)\n\nRare terms in a collection are more informative than frequentterms\nå‡ºç°æ¬¡æ•°è¶Šå°‘ä¿¡æ¯ç†µè¶Šå¤§\n\n\nJaccard doesnâ€™t consider this information\n\n\nWe need a more sophisticated way of normalizing for length\n\nWe can use \n\n\n\n3.4 Term Frequency Weighting3.4.1 Recall: Term-document Incidence Matrix\n\nEach document is represented by a binary vector\n\nConsider the number of occurrences of a term in a document:\n\nEach document is a count vector in :a column below\n\n\n\n\n3.4.2 Term Frequency â€‹â€‹â€‹\nThe term frequency â€‹â€‹â€‹ of term â€‹â€‹â€‹ in document â€‹â€‹â€‹ is defined as the number of times that â€‹â€‹â€‹ occurs in â€‹â€‹â€‹.\nè¯tåœ¨æ–‡ç« då‡ºç°çš„æ¬¡æ•°\n\n\nWe want to use tf when computing query-document match scores. But now?\nå‡ºç°9æ¬¡å’Œå‡ºç°10æ¬¡å…¶å®å¹¶ä¸æ˜¯å·®å¾ˆå¤šï¼Œå…¶å®å‡ºç°æ¬¡æ•°ä¸æŸ¥è¯¢å¹¶ä¸çº¿æ€§ç›¸å…³\n\n\n\n3.4.3 Log-frequency Weighting\nThe log frequency weight of term t in d is\n\n\nw_{t, d}=\\left\\{\\begin{array}{cc}\n1+\\log _{10} \\mathrm{tf}_{t, d}, & \\text { if } \\mathrm{tf}_{t, d}>\\mathrm{O} \\\\\n\\mathrm{O}, & \\text { otherwise }\n\\end{array}\\right.\nåŒºåˆ†å‡ºç°ä¸€æ¬¡å’Œå‡ºç°é›¶æ¬¡\nScore for a document-query pair: sum over terms t in both q and d:\nè®¡ç®—quieryå’Œdocumenté‡Œå…±åŒå‡ºç°çš„è¯çš„åˆ†æ•°ä¹‹å’Œ\n\n\n\n\n\\text{score}=\\sum_{t \\in q \\cap d}\\left(1+\\log \\mathrm{tf}_{t, d}\\right)\nThe score is 0 if none of the query terms is present in the document.\n\n3.4.4 (Inverse) Document Frequency WeightingDocument Frequency\nRare terms are more informative than frequent terms\nRecall stop words\n\n\nå¯¹äºä¿¡æ¯é‡æ¯”è¾ƒé«˜çš„è¯æˆ‘ä»¬å°†ä¼šç»™äºˆæ›´é«˜çš„æƒé‡\n\n3.4.5 idf Weight\nä»æ‰€æœ‰è¯­æ–™é‡Œè¿›è¡Œæœç´¢ï¼Œdfè¶Šé«˜ï¼Œè¿™ä¸ªæœ¯è¯­å«æœ‰çš„ä¿¡æ¯è¶Šä½\n\nâ€‹â€‹ is the document frequency of â€‹â€‹ : the number of documents that contain â€‹â€‹\n\nâ€‹â€‹ is an inverse measure of the informativeness of â€‹â€‹\nâ€‹\n\n\nä¸€ä¸ªè¯åœ¨æ‰€æœ‰æ–‡æ¡£å‡ºç°çš„çš„é¢‘ç‡\nWe define the idf (inverse document frequency) of  by\nWe use  instead of  to â€œdampenâ€œ(æŠ‘åˆ¶) the effect of idf.\n\n\n\n\n\\text{Idf}_{t}=\\log _{10}\\left(N / \\mathrm{df}_{t}\\right)\næ˜¯æ–‡æ¡£æ•°ï¼Œæ˜¯tå‡ºç°çš„æ–‡æ¡£æ•°\nWill turn out the base of the log is immaterialä¸é‡è¦\n\n\n3.4.6 Effect of idf on Ranking\nQuestion: Does idf have an effect on ranking for one-term queries, like\n\niPhone\n\n\nidf has no effect on ranking one term queries\n\nidf affects the ranking of documents for queries with at least two terms\nå¦‚æœquieryåªåŒ…å«ä¸€ä¸ªå•è¯ï¼Œé‚£ä¹ˆidfå¯¹å…¶æ²¡æœ‰å½±å“ï¼›å¦‚æœåŒ…å«å¤šä¸ªå•è¯ï¼Œåˆ™æœ‰å½±å“\ntfè¶Šå¤§ä¸å½“å‰documentè¶Šç›¸å…³ï¼Œtermçš„ä¿¡æ¯é‡\n\n\nidfä½¿å¾—å¤šä¸ªè¯çš„æœç´¢çš„TFè®¡ç®—æœ‰æƒé‡ï¼Œç›¸å½“äºå¯¹TFè¿›è¡Œäº†åŠ æƒæ±‚å’Œ\n\n3.4.7 Collection vs. Document Frequency\ncollection frequency ç›¸å½“äºæŠŠtermåœ¨æ‰€æœ‰è¯­æ–™å‡ºç°çš„æ¬¡æ•°è¿›è¡Œäº†æ±‚å’Œ\n\n\n\nidfä¸ºä½•è¦å’Œæ–‡æ¡£æœ‰å…³ï¼Ÿ\nthe åœ¨100ä¸ªæ–‡æ¡£æœ‰å…³ï¼Œé‚£ä¹ˆç›¸å½“äºä¿¡æ¯é‡ä¸º0\nä¸œå—å¤§å­¦åœ¨å…¶ä¸­ä¸€ç¯‡æ–‡æ¡£çš„å‡ºç°100æ¬¡ï¼Œå…¶å®ä¿¡æ¯é‡å¾ˆå¤§\næ‰€ä»¥æˆ‘ä»¬ä¸èƒ½é‡‡ç”¨collection feqï¼Œè¦é‡‡ç”¨doc feq\n\n\n\n3.4.8 tf-idf Weighting\nThe tf-idf weight of a term is the product of its tf weight and its idf weight.\n\n\n\\mathrm{w}_{t, d}=\\left(1+\\log \\mathrm{tf}_{t, d}\\right) \\times \\log _{10}\\left(N / \\mathrm{df}_{t}\\right)\nBest known weighting scheme in information retrieval\nNote: the â€œ-â€œ in tf-idf is a hyphen, not a minus sign!\nAlternative names: tf.idf, \n\n\nIncreases with the number of occurrences within a document\nIncreases with the rarity of the term in the collection\n\nè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥æŠŠåŸæ¥çš„å¸ƒå°”çŸ©é˜µæ¢æˆtf-idfå€¼\n\n\n3.4.9 Final Ranking of Documents for a Query\n\\operatorname{Score}(q, d)=\\sum_{t \\in q \\cap d} \\operatorname{tf} . \\mathrm{idf}_{t, d}Binary â†’ count â†’ weight matrix\n\nEach document is now represented by a real-valued vector of tf-idf weights \n\n3.5 The Vector Space Model (VSM)3.5.1 Documents As Vectors\nNow we have a |V|-dimensional vector space\nTerms are axes of the space\nDocuments are points or vectors in this space\nVery high-dimensional: tens of millions of dimensions when you apply this to a web search engine\nThese are very sparse vectors â€“ most entries are zero\nå‘é‡è¡¨ç¤ºè¿‡äºç¨€ç–ï¼Œç»´åº¦è¿‡å¤§\n\n3.5.2 Queries As Vectors\nKey idea 1: Do the same for queries: represent them as vectors in the space\nidfå’Œdocumentè®¡ç®—æ–¹å¼ç›¸åŒ,tfå¯ä»¥ç†è§£ä¸ºæŠŠquieryå½“ä½œä¸€ä¸ªdocumentç„¶åå»è®¡ç®—ä»–çš„tf\n\n\nKey idea 2: Rank documents according to their proximityï¼ˆ(æ—¶é—´æˆ–ç©ºé—´)é‚»è¿‘ï¼‰ to the query in this space\nproximity = similarity of vectors\nproximity â‰ˆ inverse of distance\nè·ç¦»çš„å€’æ•°å’Œç›¸ä¼¼æ€§æœ‰åŒºåˆ«\n\n\n\n3.5.3 Formalizing Vector Space Proximity\nEuclidean distance is a bad idea, because Euclidean distance is large for vectors of different lengths.\n\nThe Euclidean distance between  and  is large even though the distribution of terms in the query  and the distribution of terms in the document â€‹â€‹ are very similar.\n\nç®€è¨€ä¹‹å°±æ˜¯ç›¸ä¼¼åº¦åº”è¯¥æ›´è€ƒè™‘ç‰¹å¾çš„åˆ†å¸ƒè€Œä¸æ˜¯è€ƒè™‘å®å€¼ï¼Œå› ä¸ºæ–‡æ¡£çš„é•¿åº¦ä¸€å®šæ˜¯æ›´é•¿çš„ï¼Œå¯èƒ½ä¼šé€ æˆæ¯ä¸ªç»´åº¦ä¸Šçš„å€¼éƒ½æ¯”è¾ƒå¤§ã€‚\n\n\n\n\n3.5.4 Use Angle Instead Of Distance\nThe Euclidean distance between the two documents can be quite large\nThe angle between the two documents is 0, corresponding to maximal similarity.\nKey idea: Rank documents according to angle with query.\n\n3.5.5 From Angles To Cosines\nThe following two notions are equivalent.\nRank documents in decreasing order of the angle between query and document\nRank documents in increasing order of cosine(query,document)\n\n\nCosine is a monotonically decreasing function for the interval â€‹\n\n3.5.6 computing cosines\nA vector can be (length-) normalized by dividing each of its components by its length - for this we use the â€‹ norm:\n\n\n\\|\\vec{x}\\|_{2}=\\sqrt{\\sum_{i} x_{i}^{2}}\nDividing a vector by its  norm makes it a unit (length) vector (on surface of unit hypersphere)\nEffect on the two documents â€‹ and â€‹ ( â€‹ appended to itself) from earlier slide: they have identical vectors after length normalization.\nLong and short documents now have comparable weights\n\n\n\n\n\n is the tf-idf weight of term  in the query  is the tf-idf weight of term  in the document  is the cosine similarity of  and  or, equivalently, the cosine of the angle between  and .\n\nFor length-normalized vectors, cosine similarity is simply the dot product (or scalar product):\n\n\n\n\\cos (\\vec{q}, \\vec{d})=\\vec{q} \\cdot \\vec{d}=\\sum_{i=1}^{|V|} q_{i} d_{i}\nfor â€‹ length-normalized.\nCosine Similarity Illustrated\n\n\n3.5.7 Cosine similarity amongst 3 documents\nHow similar are the novels â€œSaS: Sense and SensibilityPaP: Pride and PrejudiceWH: Wuthering Heightsâ€?\nTerm frequencies (counts)\n\n\n\nNote: To simplify this example, we donâ€™t do idf weighting.\n\n\n3.6 Calculating if-idf Cosine Scores in an IR System3.6.1 tf-idf Weighting Has Many Variants\n\nMany search engines allow for different weightings for queries vs. documents\nSMART Notation: denotes the combination in use in an engine, with the notation ddd.qqq using the acronyms from the previous table\nA very standard weighting scheme is: lnc.ltc\nDocument : logarithmic tf (l as first character), no idf and cosine normalization\nQuery : logarithmic tf (l in leftmost column), idf (t in second column), cosine normalization â€¦\n\n3.6.2 tf-idf example: lnc.ltc\nDocument: car insurance auto insurance\nQuery: best car insurance\n\n\n\nExercise: what is N, the number of docs?\n\n\nN=10^{2.3}\\times 5000=99763\n\\begin{aligned}\n&\\text { Doc length }=\\sqrt{1^{2}+0^{2}+1^{2}+1.3^{2}} \\approx 1.92 \\\\\n&\\text { Score }=0+0+0.27+0.53=0.8\n\\end{aligned}Computing cosine scores\n4. Evaluating Search Engines\nAssume 10 rel docs in collection\n\n\n\nRï¼š1/10ï¼Œ1/10ï¼Œ1/10ï¼Œ1/5ï¼Œ3/10ï¼Œ3/10ï¼Œ2/5ï¼Œ2/5ï¼Œ2/5ï¼Œ2/5\nPï¼š1      ï¼Œ0.5ï¼Œ   0.33ï¼Œ0.5ï¼Œ0.6   ï¼Œ 0.5ï¼Œ  4/7ï¼Œ0.5ï¼Œ4/9ï¼Œ2/5  \n\n\n4.1 Two Current Evaluation Measuresâ€¦\nMean average precision (MAP)\nAP: Average of the precision value obtained for the top k documents, each time a relevant doc is retrieved\nAvoids interpolation, use of fixed recall levels\nDoes weight most accuracy of top returned results\nMAP for set of queries is arithmetic average of APs\nMacro-averaging: each query counts equally\nç®€è¨€ä¹‹å°±æ˜¯å¯¹äºä¸€ä¸ªé—®ç­”é›†åˆï¼Œç®—ä»–ä»¬çš„å¹³å‡æ­£ç¡®ç‡\n\n\nR-precision\nIf have known (though perhaps incomplete) set of relevant documents of size Rel, then calculate precision of top Rel docs returned\nå¦‚æœå·²çŸ¥ï¼ˆå°½ç®¡å¯èƒ½ä¸å®Œæ•´ï¼‰ä¸€ç»„å¤§å°ä¸ºRelçš„ç›¸å…³æ–‡æ¡£ï¼Œåˆ™è®¡ç®—è¿”å›çš„top Relæ–‡æ¡£çš„ç²¾åº¦\n\n\nPerfect system could score 1.0.\n\n\n\n","categories":["nlp"]},{"title":"Gray-Level Grouping","url":"/2021/08/15/Image%20processing/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1/absolute%20discounting%20back-off%E7%AE%97%E6%B3%95/","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\n1. Abstract\næœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å½©è‰²å›¾åƒç›´æ–¹å›¾å‡è¡¡æ–¹æ³•ï¼šè¯¥æ–¹æ³•åˆ©ç”¨é¢œè‰²åˆ†é‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¹¶å€Ÿç”¨è¯­è¨€ç»Ÿè®¡å·¥ç¨‹ä¸­çš„å¤šçº§å¹³æ»‘æŠ€æœ¯è¿›è¡Œå›¾åƒå¢å¼ºã€‚ å¤šçº§å¹³æ»‘æŠ€æœ¯æ—¨åœ¨æœ‰æ•ˆåœ°å¤„ç†ä¸å¯è§é¢œè‰²å€¼çš„é—®é¢˜ï¼Œå…¶åˆ©ç”¨ä¸€ç§å•ç‹¬è€ƒè™‘æˆ–è€…ç»¼åˆè€ƒè™‘çš„æ–¹æ³•è§£å†³ã€‚æœ€ç»ˆå°†è¿™é¡¹æŠ€æœ¯åº”ç”¨äº å›¾ç‰‡çš„HSI é¢œè‰²ç©ºé—´ï¼Œæ­¤å¤„å°†å…¶åº”ç”¨äº HSI é¢œè‰²ç©ºé—´ä»¥è·å¾—å¼ºåº¦æ¦‚ç‡å’Œç»™å®šå¼ºåº¦çš„é¥±å’Œæ¦‚ç‡ï¼Œè€Œè‰²è°ƒä¿æŒä¸å˜ã€‚\næ­¤å¤–ï¼Œä¸ºæ¶ˆé™¤è‰²åŸŸé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ï¼Œåœ¨åŸºäºä¿æŒè‰²è°ƒä¸å˜çš„æƒ…å†µä¸‹ï¼Œå¯¹éçº¿æ€§å˜æ¢çš„æŠ€æœ¯è¿›è¡Œäº†æ‰©å±•çš„æ–¹æ³•ã€‚ è¿™æ˜¯è®ºæ–‡ä¸­æå‡ºçš„ç¬¬äºŒç§æ–¹æ³•ã€‚ \næ¥ç€ï¼Œæœ¬æ–‡å°†ä»¥ä¸Šä¸¤ç§å‡è¡¡å›¾åƒæ–¹æ³•ä¸å…¶ä»–ç†ŸçŸ¥çš„æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚ ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ ¹æ®å¤„ç†åå›¾åƒçš„è§†è§‰å¸å¼•åŠ›å’Œå®¢è§‚å“è´¨å› æ•°æ¥åˆ¤æ–­çš„å›¾åƒå‡è¡¡è´¨é‡è¯„ä»·ç®—æ³•ï¼Œä¾‹å¦‚ï¼šå°†æ‰€å¾—é¢œè‰²ç›´æ–¹å›¾ä¸å¤šå…ƒå‡åŒ€æ¦‚ç‡å¯†åº¦å‡½æ•°ä¹‹é—´çš„ç†µå’Œ Kullback-Leibler æ•£åº¦ä¼°è®¡ç®—æ³•ã€‚\n\n2. Introduction\nå›¾åƒå¢å¼ºæ—¨åœ¨ä»äººç±»è§†è§‰çš„è§’åº¦æ”¹è¿›å›¾åƒã€‚ é€šè¿‡å¢åŠ å›¾åƒåŠ¨æ€èŒƒå›´çš„æ–¹å¼ï¼Œé”åŒ–å›¾åƒçš„è¾¹ç¼˜ã€è¾¹ç•Œå’Œå¯¹æ¯”åº¦ç­‰å›¾åƒç‰¹å¾ï¼Œè€Œä¸æ”¹å˜å›¾åƒä¸­å›ºæœ‰ä¿¡æ¯å†…å®¹ ã€‚ ä¸ºæ­¤ï¼Œå¼€å‘äº†å¤šç§æŠ€æœ¯ã€‚ å…¶ä¸­åŒ…æ‹¬å¯¹æ¯”åº¦å¤„ç†ã€é™å™ªã€è¾¹ç¼˜é”åŒ–å’Œé”åŒ–ã€è¿‡æ»¤ã€ä¼ªç€è‰²ã€å›¾åƒæ’å€¼å’Œæ”¾å¤§ã€‚\nå¯¹æ¯”åº¦æ“çºµæŠ€æœ¯å¯ä»¥åˆ†ä¸ºå…¨å±€æˆ–è‡ªé€‚åº”ã€‚ å…¨å±€æŠ€æœ¯å¯¹æ‰€æœ‰å›¾åƒåƒç´ åº”ç”¨å˜æ¢ï¼Œè€Œè‡ªé€‚åº”æŠ€æœ¯ä½¿ç”¨éšå±€éƒ¨å›¾åƒç‰¹å¾è‡ªé€‚åº”å˜åŒ–çš„è¾“å…¥-è¾“å‡ºå˜æ¢ã€‚ æ›´å¸¸è§çš„å…¨å±€æŠ€æœ¯æ¯”å¦‚çº¿æ€§å¯¹æ¯”åº¦æ‹‰ä¼¸ã€ç›´æ–¹å›¾å‡è¡¡å’Œå¤šé€šé“è¿‡æ»¤ã€‚ æœ€å¸¸è§çš„è‡ªé€‚åº”æŠ€æœ¯æ˜¯è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ– (AHE) å’Œå¯¹æ¯”åº¦é™åˆ¶è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ– (CLAHE) [2,3]ã€‚  AHE å°†ä¸åŒçš„ç°åº¦å˜æ¢å±€éƒ¨åº”ç”¨äºæ¯ä¸ªå°å›¾åƒåŒºåŸŸï¼Œå› æ­¤éœ€è¦ç¡®å®šåŒºåŸŸå¤§å°ã€‚  CLAHE é€šè¿‡é™åˆ¶å±€éƒ¨å¯¹æ¯”åº¦å¢ç›Šæ¥æ”¹è¿›åˆšåˆšæè¿°çš„æŠ€æœ¯ã€‚ å·²ç¡®å®šåä¸€ç§æ–¹æ³•çš„ä¸¤ä¸ªç¼ºç‚¹ï¼Œå³å¯¹å›¾åƒå¹³æ»‘åŒºåŸŸä¸­äº§ç”Ÿä¸å¯é¿å…çš„å™ªå£°å¢å¼ºå’Œå¯¹æ¯”åº¦å¢ç›Šã€‚\næœ¬æ–‡ä¸»è¦ä½¿ç”¨å…¨å±€çš„æ–¹æ³•å¯¹å›¾åƒè¿›è¡Œå¢å¼ºå¤„ç†ã€‚æ›´å‡†ç¡®æ¥è¯´ï¼Œä¸ºäº†å…±åŒå‡è¡¡HSIè‰²å½©ç©ºé—´çš„é¥±å’Œåº¦ä»¥åŠå¼ºåº¦ä¸¤ä¸ªåˆ†é‡ï¼Œæœ¬æ–‡åˆ©ç”¨ä»ç»Ÿè®¡è¯­è¨€å»ºæ¨¡ä¸­å€Ÿç”¨çš„ä¸€å…ƒå’ŒäºŒå…ƒæ¦‚ç‡çš„æ¦‚å¿µä»¥åŠæ¦‚ç‡å¹³æ»‘å‡è¡¡åŒ–å½©è‰²ç›´æ–¹å›¾ã€‚ç›´æ–¹å›¾å‡è¡¡åŒ–æ–¹æ³•éƒ¨åˆ†å»ºç«‹åœ¨Pitas and Kinikliså»ºè®®çš„åŸºç¡€ä¸Šï¼Œä½†å®ƒé€šè¿‡å¹³æ»‘å¿…è¦çš„æ¦‚ç‡è¿›è¡Œæ‰©å±•ï¼Œä»¥æŠµæ¶ˆçœ‹ä¸è§çš„é¢œè‰²åˆ†é‡ç»„åˆçš„å½±å“ï¼Œè¿™æºäºé¢œè‰²ç©ºé—´çš„ç»´åº¦å’Œå›¾åƒä¸­å­˜åœ¨çš„é¢œè‰²æ•°é‡é€šå¸¸æœ‰é™ã€‚ æ­¤å¤–ï¼Œå¼€å‘äº†ç¬¬äºŒç§æ–¹æ³•ï¼Œä»¥é€šè¿‡åˆ©ç”¨ Naik å’Œ Murthy [6] ä¸­æå‡ºçš„è½¬æ¢ï¼Œæ¥æ¶ˆé™¤è‰²åŸŸé—®é¢˜ã€‚ å°†æ‰€æå‡ºæ–¹æ³•çš„æ€§èƒ½ä¸ Pitas å’Œ Kiniklis [5,7] æå‡ºçš„æ–¹æ³•ä»¥åŠæ¯ä¸ªé¢œè‰²åˆ†é‡çš„å•ç‹¬å‡è¡¡è¿›è¡Œæ¯”è¾ƒã€‚ æ¯”è¾ƒä¸ä»…ä½¿ç”¨ä¸»è§‚åº¦é‡ï¼ˆå³å‡è¡¡å›¾åƒåœ¨è§†è§‰ä¸Šçš„å¸å¼•åŠ›å¦‚ä½•ï¼‰ï¼Œè¿˜ä½¿ç”¨å®¢è§‚çš„å“è´¨å› æ•°ï¼Œä¾‹å¦‚æ‰€å¾—é¢œè‰²ç›´æ–¹å›¾ä¸ç›¸åº”çš„å¤šå…ƒå‡åŒ€æ¦‚ç‡å¯†åº¦ä¹‹é—´çš„ç†µå’Œ Kullback-Leibler æ•£åº¦ åŠŸèƒ½ã€‚\nè®ºæ–‡çš„å¤§çº²å¦‚ä¸‹ã€‚ åœ¨ç¬¬ 2 èŠ‚ä¸­ï¼Œç®€è¦ä»‹ç»äº†å½©è‰²å›¾åƒç›´æ–¹å›¾å‡è¡¡æ–¹æ³•ã€‚ åœ¨ç¬¬ 3 èŠ‚ä¸­ï¼Œæè¿°äº†æœ¬æ–‡æå‡ºçš„åŸºçº¿ç›´æ–¹å›¾å‡è¡¡æ–¹æ³•å’Œæ–°ç®—æ³•ã€‚ å®éªŒç»“æœåœ¨ç¬¬ 4 èŠ‚ä¸­å±•ç¤ºï¼Œæœ€ååœ¨ç¬¬ 5 èŠ‚ä¸­å¾—å‡ºç»“è®ºã€‚ RGB å’Œ HSI é¢œè‰²ç©ºé—´çš„ç®€è¦æè¿°åœ¨é™„å½• A ä¸­ç»™å‡ºã€‚\n\n3. Algorithmsé¢œè‰²ç©ºé—´ä»‹ç»\nHSV\n\n\n\nRGBè½¬åŒ–åˆ°HSVçš„ç®—æ³•:max=max(R,G,B);min=min(R,G,B);V=max(R,G,B);S=(max-min)/maxif(R = max) H =(G-B)/(max-min) 60;if(G = max) H = 120+(B-R)/(max-min) 60;if(B = max) H = 240 +(R-G)/(max-min) 60;if(H &lt; 0) H = H+ 360;\n\nHSV(hue,saturation,value)é¢œè‰²ç©ºé—´çš„æ¨¡å‹å¯¹åº”äºåœ†æŸ±åæ ‡ç³»ä¸­çš„ä¸€ä¸ªåœ†é”¥å½¢å­é›†ï¼Œåœ†é”¥çš„é¡¶é¢å¯¹åº”äºV=1. å®ƒåŒ…å«RGBæ¨¡å‹ä¸­çš„R=1ï¼ŒG=1ï¼ŒB=1 ä¸‰ä¸ªé¢ï¼Œæ‰€ä»£è¡¨çš„é¢œè‰²è¾ƒäº®ã€‚è‰²å½©Hç”±ç»•Vè½´çš„æ—‹è½¬è§’ç»™å®šã€‚çº¢è‰²å¯¹åº”äº è§’åº¦0Â° ï¼Œç»¿è‰²å¯¹åº”äºè§’åº¦120Â°ï¼Œè“è‰²å¯¹åº”äºè§’åº¦240Â°ã€‚åœ¨HSVé¢œè‰²æ¨¡å‹ä¸­ï¼Œæ¯ä¸€ç§é¢œè‰²å’Œå®ƒçš„è¡¥è‰²ç›¸å·®180Â° ã€‚ é¥±å’Œåº¦Så–å€¼ä»0åˆ°1ï¼Œæ‰€ä»¥åœ†é”¥é¡¶é¢çš„åŠå¾„ä¸ºï¼‘ã€‚HSVé¢œè‰²æ¨¡å‹æ‰€ä»£è¡¨çš„é¢œè‰²åŸŸæ˜¯CIEè‰²åº¦å›¾çš„ä¸€ä¸ªå­é›†ï¼Œè¿™ä¸ª æ¨¡å‹ä¸­é¥±å’Œåº¦ä¸ºç™¾åˆ†ä¹‹ç™¾çš„é¢œè‰²ï¼Œå…¶çº¯åº¦ä¸€èˆ¬å°äºç™¾åˆ†ä¹‹ç™¾ã€‚åœ¨åœ†é”¥çš„é¡¶ç‚¹(å³åŸç‚¹)å¤„ï¼ŒV=0,Hå’ŒSæ— å®šä¹‰ï¼Œ ä»£è¡¨é»‘è‰²ã€‚åœ†é”¥çš„é¡¶é¢ä¸­å¿ƒå¤„S=0ï¼ŒV=1,Hæ— å®šä¹‰ï¼Œä»£è¡¨ç™½è‰²ã€‚ä»è¯¥ç‚¹åˆ°åŸç‚¹ä»£è¡¨äº®åº¦æ¸æš—çš„ç°è‰²ï¼Œå³å…·æœ‰ä¸åŒ ç°åº¦çš„ç°è‰²ã€‚å¯¹äºè¿™äº›ç‚¹ï¼ŒS=0,Hçš„å€¼æ— å®šä¹‰ã€‚å¯ä»¥è¯´ï¼ŒHSVæ¨¡å‹ä¸­çš„Vè½´å¯¹åº”äºRGBé¢œè‰²ç©ºé—´ä¸­çš„ä¸»å¯¹è§’çº¿ã€‚ åœ¨åœ†é”¥é¡¶é¢çš„åœ†å‘¨ä¸Šçš„é¢œè‰²ï¼ŒV=1ï¼ŒS=1,è¿™ç§é¢œè‰²æ˜¯çº¯è‰²ã€‚HSVæ¨¡å‹å¯¹åº”äºç”»å®¶é…è‰²çš„æ–¹æ³•ã€‚ç”»å®¶ç”¨æ”¹å˜è‰²æµ“å’Œ è‰²æ·±çš„æ–¹æ³•ä»æŸç§çº¯è‰²è·å¾—ä¸åŒè‰²è°ƒçš„é¢œè‰²ï¼Œåœ¨ä¸€ç§çº¯è‰²ä¸­åŠ å…¥ç™½è‰²ä»¥æ”¹å˜è‰²æµ“ï¼ŒåŠ å…¥é»‘è‰²ä»¥æ”¹å˜è‰²æ·±ï¼ŒåŒæ—¶ åŠ å…¥ä¸åŒæ¯”ä¾‹çš„ç™½è‰²ï¼Œé»‘è‰²å³å¯è·å¾—å„ç§ä¸åŒçš„è‰²è°ƒã€‚\n\n\nHSI\nHSIè‰²å½©ç©ºé—´æ˜¯ä»äººçš„è§†è§‰ç³»ç»Ÿå‡ºå‘ï¼Œç”¨è‰²è°ƒ(Hue)ã€è‰²é¥±å’Œåº¦(Saturationæˆ–Chroma)å’Œäº®åº¦ (Intensityæˆ–Brightness)æ¥æè¿°è‰²å½©ã€‚HSIè‰²å½©ç©ºé—´å¯ä»¥ç”¨ä¸€ä¸ªåœ†é”¥ç©ºé—´æ¨¡å‹æ¥æè¿°ã€‚ç”¨è¿™ç§ æè¿°HISè‰²å½©ç©ºé—´çš„åœ†é”¥æ¨¡å‹ç›¸å½“å¤æ‚ï¼Œä½†ç¡®èƒ½æŠŠè‰²è°ƒã€äº®åº¦å’Œè‰²é¥±å’Œåº¦çš„å˜åŒ–æƒ…å½¢è¡¨ç°å¾—å¾ˆæ¸…æ¥šã€‚\né€šå¸¸æŠŠè‰²è°ƒå’Œé¥±å’Œåº¦é€šç§°ä¸ºè‰²åº¦ï¼Œç”¨æ¥è¡¨ç¤ºé¢œè‰²çš„ç±»åˆ«ä¸æ·±æµ…ç¨‹åº¦ã€‚ç”±äºäººçš„è§†è§‰å¯¹äº®åº¦çš„æ•æ„Ÿ ç¨‹åº¦è¿œå¼ºäºå¯¹é¢œè‰²æµ“æ·¡çš„æ•æ„Ÿç¨‹åº¦ï¼Œä¸ºäº†ä¾¿äºè‰²å½©å¤„ç†å’Œè¯†åˆ«ï¼Œäººçš„è§†è§‰ç³»ç»Ÿç»å¸¸é‡‡ç”¨HSIè‰²å½©ç©ºé—´ï¼Œ å®ƒæ¯”RGBè‰²å½©ç©ºé—´æ›´ç¬¦åˆäººçš„è§†è§‰ç‰¹æ€§ã€‚åœ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä¸­å¤§é‡ç®—æ³•éƒ½å¯åœ¨HSIè‰²å½©ç©ºé—´ä¸­ æ–¹ä¾¿åœ°ä½¿ç”¨ï¼Œå®ƒä»¬å¯ä»¥åˆ†å¼€å¤„ç†è€Œä¸”æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚å› æ­¤ï¼Œåœ¨HSIè‰²å½©ç©ºé—´å¯ä»¥å¤§å¤§ç®€åŒ–å›¾åƒåˆ†æ å’Œå¤„ç†çš„å·¥ä½œé‡ã€‚HSIè‰²å½©ç©ºé—´å’ŒRGBè‰²å½©ç©ºé—´åªæ˜¯åŒä¸€ç‰©ç†é‡çš„ä¸åŒè¡¨ç¤ºæ³•ï¼Œå› è€Œå®ƒä»¬ä¹‹é—´å­˜åœ¨ç€ è½¬æ¢å…³ç³»ã€‚\nHSI è‰²å½©æ¨¡å‹æ˜¯ä»äººçš„è§†è§‰ç³»ç»Ÿå‡ºå‘ï¼Œç”¨ H ä»£è¡¨è‰²ç›¸ (Hue)ã€S ä»£è¡¨é¥±å’Œåº¦ (Saturation) å’Œ I ä»£è¡¨äº®åº¦ (Intensity) æ¥æè¿°è‰²å½©ã€‚é¥±å’Œåº¦ä¸é¢œè‰²çš„ç™½å…‰å…‰é‡åˆšå¥½æˆåæ¯”ï¼Œå®ƒå¯ä»¥è¯´æ˜¯ä¸€ä¸ªé¢œè‰²é²œæ˜ä¸å¦çš„æŒ‡æ ‡ã€‚å› æ­¤å¦‚æœæˆ‘ä»¬åœ¨æ˜¾ç¤ºå™¨ä¸Šä½¿ç”¨ HIS æ¨¡å‹æ¥å¤„ç†å›¾åƒï¼Œå°†èƒ½å¾—åˆ°è¾ƒä¸ºé€¼çœŸçš„æ•ˆæœã€‚ \nè‰²ç›¸ (Hue)ï¼šæŒ‡ç‰©ä½“ä¼ å¯¼æˆ–åå°„çš„æ³¢é•¿ã€‚æ›´å¸¸è§çš„æ˜¯ä»¥é¢œè‰²å¦‚çº¢è‰²ï¼Œæ©˜è‰²æˆ–ç»¿è‰²æ¥è¾¨è¯†ï¼Œå– 0 åˆ° 360 åº¦çš„æ•°å€¼æ¥è¡¡é‡ã€‚ \né¥±å’Œåº¦ (Saturation)ï¼šåˆç§°è‰²åº¦ï¼Œæ˜¯æŒ‡è‰²å½©çš„å¼ºåº¦æˆ–çº¯åº¦ã€‚é¥±å’Œåº¦ä»£è¡¨ç°è‰²ä¸è‰²è°ƒçš„æ¯”ä¾‹ï¼Œå¹¶ä»¥ 0% (ç°è‰²) åˆ° 100% (å®Œå…¨é¥±å’Œ) æ¥è¡¡é‡ã€‚ \näº®åº¦ (Intensity)ï¼šæ˜¯æŒ‡é¢œè‰²çš„ç›¸å¯¹æ˜æš—åº¦ï¼Œé€šå¸¸ä»¥ 0% (é»‘è‰²) åˆ° 100% (ç™½è‰²) çš„ç™¾åˆ†æ¯”æ¥è¡¡é‡ã€‚\n\n\n\n3.1 Separate equalization of the three color componentsâ€”Method I\nâ€‹ï¼šä»¥æ¯ä¸ªåƒç´ çš„ç°åº¦å€¼ä½œä¸ºéšæœºå˜é‡\nï¼šç°åº¦å–å€¼èŒƒå›´ï¼Œæœ¬æ–‡ä¸º256\n\n\n\\begin{equation}\nf_{\\mathbf{x}}\\left(x_{k}\\right)=P\\left\\{\\mathbf{x}=x_{k}\\right\\}=\\frac{N\\left(x_{k}\\right)}{\\sum_{m=0}^{L-1} N\\left(x_{m}\\right)} \\quad \\forall k=0,1, \\ldots, L-1\n\\end{equation}\ny_{k}=F_{\\mathbf{x}}\\left(x_{k}\\right)=P\\left\\{\\mathbf{x} \\leqslant x_{k}\\right\\}=\\sum_{m=0}^{k} f\\left(x_{m}\\right) \\quad \\forall k=0,1, \\ldots, L-1\n(1)ä¸ºæ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œï¼ˆ2ï¼‰ä¸ºåˆ†å¸ƒå‡½æ•°\n\n3.2. 3-D Equalization in the RGB spaceâ€”Method II\nâ€‹â€‹ï¼šåŸæ¥çš„åƒç´ ç‚¹éšæœºå˜é‡\nâ€‹â€‹ï¼šç»è¿‡ï¼ˆ4ï¼‰å¼å˜æ¢åçš„åƒç´ ç‚¹\n\n\n\\begin{aligned}\ny_{\\mathrm{R}_{k} \\mathrm{G}_{s} \\mathrm{~B}_{t}} &=F_{\\mathbf{x}_{\\mathrm{R}} \\mathrm{x}_{\\mathrm{G}} \\mathbf{x}_{\\mathrm{B}}}\\left(x_{\\mathrm{R}_{k}}, x_{\\mathrm{G}_{\\mathrm{s}}}, x_{\\mathrm{B}_{t}}\\right)=P\\left\\{\\mathbf{x}_{\\mathrm{R}} \\leqslant x_{\\mathrm{R}_{k}}, \\mathbf{x}_{\\mathrm{G}} \\leqslant x_{\\mathrm{G}_{\\mathrm{s}}}, \\mathbf{x}_{\\mathrm{B}} \\leqslant x_{\\mathrm{B}_{t}}\\right\\} \\\\\n&=\\sum_{i=0}^{k} \\sum_{j=0}^{s} \\sum_{m=0}^{t} f\\left(x_{\\mathrm{R}_{i}}, x_{\\mathrm{G}_{j}}, x_{\\mathrm{B}_{m}}\\right) \\quad \\forall k, s, t=0,1, \\ldots, L-1\n\\end{aligned}\n\\begin{aligned}\ny_{\\mathrm{R}_{k^{\\prime}} \\mathrm{G}_{j} \\mathrm{~B}^{\\prime}} &=\\sum_{i=0}^{k^{\\prime}} \\sum_{j=0}^{s^{\\prime}} \\sum_{m=0}^{t^{\\prime}} \\frac{1}{L^{3}} \\\\\n&=\\frac{\\left(k^{\\prime}+1\\right)\\left(s^{\\prime}+1\\right)\\left(t^{\\prime}+1\\right)}{L^{3}} \\forall k^{\\prime}, s^{\\prime}, t^{\\prime}=0,1, \\ldots, L-1,\n\\end{aligned}\nå…·ä½“è€Œè¨€ï¼Œå¯¹äºæ¯ä¸€ä¸ªåƒç´  å˜æ¢åä¸º ï¼Œåº”æ»¡è¶³ï¼Œä¸”å°½å¯èƒ½å°ã€‚\n\n3.3. Equalization of the intensity component in the HSI spaceâ€” Method III\nâ€‹â€‹ï¼šå¯¹åº”æ¯ä¸€ä¸ªåƒç´ çš„éšæœºå˜é‡ï¼Œå¼ï¼ˆ5ï¼‰ä¸ºå…¶æ¦‚ç‡å¯†åº¦å‡½æ•°\n\n\nf_{\\mathrm{x}_{\\mathrm{I}}}\\left(x_{\\mathrm{I}_{k}}\\right)= \\begin{cases}12 \\times x_{\\mathrm{I}_{k}}^{2} & \\text { for } 0 \\leqslant x_{\\mathrm{I}_{k}} \\leqslant 0.5 \\\\ 12 \\times\\left(1-x_{\\mathrm{I}_{k}}\\right)^{2} & \\text { for } 0.5 \\leqslant x_{\\mathrm{I}_{k}} \\leqslant 1\\end{cases}3.4. 2-D Equalization for intensity and saturation in the HSI space â€” Method IV\nâ€‹ï¼šå¯¹åº”æ¯ä¸€ä¸ªåƒç´ çš„éšæœºå˜é‡\n\nâ€‹ï¼šå–äº®åº¦å’Œé¥±å’Œåº¦ä½œä¸ºç ”ç©¶å¯¹è±¡çš„éšæœºå˜é‡\n\nâ€‹ï¼šè”åˆåˆ†å¸ƒå‡½æ•°\nå¯¹äºç»™å®šnä¸ªä»»æ„çš„éšæœºå˜é‡ï¼Œçš„å½¢å¼ä¸º\n\n\n\n\\mathbf{y}_{1}=F\\left(\\mathbf{x}_{1}\\right), \\quad \\mathbf{y}_{2}=F\\left(\\mathbf{x}_{2} \\mid \\mathbf{x}_{1}\\right), \\ldots, \\mathbf{y}_{n}=F\\left(\\mathbf{x}_{n} \\mid \\mathbf{x}_{n-1}, \\ldots, \\mathbf{x}_{1}\\right)\nå…¶å‡è¡¡åçš„åƒç´ ä¸ºâ€‹ï¼šå…¶ä¸­â€‹ï¼Œ \n\n\ny_{\\mathrm{I}_{k}}=F\\left(x_{\\mathrm{I}_{k}}\\right)=P\\left\\{\\mathbf{x}_{\\mathrm{I}} \\leqslant x_{\\mathrm{I}_{k}}\\right\\}=\\sum_{m=0}^{k} f\\left(x_{\\mathrm{I}_{m}}\\right)=\\sum_{m=0}^{k} P\\left(\\mathbf{x}_{\\mathrm{I}}=x_{\\mathrm{I}_{m}}\\right)\ny_{\\mathrm{S}_{t}}=F\\left(x_{\\mathrm{S}_{t}} \\mid x_{\\mathrm{I}_{k}}\\right)=\\sum_{m=0}^{t} f\\left(x_{\\mathrm{S}_{m}} \\mid x_{\\mathrm{I}_{k}}\\right)=\\sum_{m=0}^{t} \\frac{P\\left(\\mathbf{x}_{\\mathrm{I}}=x_{\\mathrm{I}_{k}}, \\mathbf{x}_{\\mathrm{S}}=x_{\\mathrm{S}_{m}}\\right)}{P\\left(\\mathbf{x}_{\\mathrm{I}}=x_{\\mathrm{I}_{k}}\\right)}â€‹        å…¶å®å°±æ˜¯äº®åº¦çš„åˆ†å¸ƒå‡½æ•°ï¼Œä»¥åŠç»™å®šäº®åº¦ï¼Œé¥±å’Œåº¦çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒå‡½æ•°\n\nä½†ä½œè€…å‘ç°ç”±äºäºŒç»´éšæœºå˜é‡åˆ†å¸ƒçš„ç¨€ç–æ€§ï¼ˆL*Mç§å¯èƒ½ï¼‰ï¼Œæ‰€ä»¥éœ€è¦å¯¹åŸæ¥çš„æ¦‚ç‡å¯†åº¦è¿›è¡Œå¹³æ»‘å¤„ç†\n\n\n\nP\\left(\\mathbf{x}_{\\mathrm{I}}=x_{\\mathrm{I}_{k}}\\right)=P\\left(x_{\\mathrm{I}_{k}}\\right)= \\begin{cases}\\frac{N\\left(x_{1 /}\\right)-b_{1}}{N} & \\text { if } N\\left(x_{\\mathrm{I}_{k}}\\right)>0 \\\\ b_{\\mathrm{I}} \\frac{L-n_{0}}{N} \\frac{1}{\\sum_{L: N\\left(\\mathrm{x}_{i}\\right)=0}^{1} 1} & \\text { if } N\\left(x_{\\mathrm{I}_{k}}\\right)=0\\end{cases}\nP\\left(\\mathbf{x}_{\\mathrm{S}}=x_{\\mathrm{S}_{t}} \\mid \\mathbf{x}_{\\mathrm{I}}=x_{\\mathrm{I}_{k}}\\right)=P\\left(x_{\\mathrm{S}_{t}} \\mid x_{\\mathrm{I}_{k}}\\right)\næ˜¯ç°åº¦å’Œé¥±å’Œåº¦çš„å¯å–çš„æ•°å€¼ä¸ªæ•°\næ˜¯å›¾ç‰‡åƒç´ æ€»æ•°\nå¯¹äºæŒ‡å®šé¢œè‰²çš„åƒç´ ä¸ªæ•°\nä¸ºå›¾ç‰‡ä¸­ä¸ºå‡ºç°äº®åº¦å€¼å¾—ä¸ªæ•°\næ˜¯ç»™å®šäº®åº¦ä¸‹ï¼Œæœªå‡ºç°é¥±å’Œåº¦å€¼å¾—ä¸ªæ•°ï¼Œ\nï¼šæŸç§ï¼ˆäº®åº¦ï¼Œé¥±å’Œåº¦ï¼‰å‡ºç°çš„æ¬¡æ•°\n\nâ€‹\n\n3.5. 2-D Equalization in Intensity-saturation components of the HSI space with gamut eliminationâ€”Method V\nåˆ©ç”¨éçº¿æ€§å˜æ¢çš„æ–¹æ³•è§£å†³è‰²åŸŸé—®é¢˜\n\n\nf_{m, n}(x)= \\begin{cases}\\delta_{1}+\\left(m-\\delta_{1}\\right)\\left(\\frac{x-\\delta_{1}}{m-\\delta_{1}}\\right)^{n}, & \\delta_{1} \\leqslant x \\leqslant m \\\\ \\delta_{2}-\\left(\\delta_{2}-m\\right)\\left(\\frac{\\delta_{2}-x}{\\delta_{2}-m}\\right)^{n}, & m \\leqslant x \\leqslant \\delta_{2}\\end{cases}\nï¼šä¸ºä¸¤ä¸ªå¸¸æ•°ã€‚åœ¨æ ‡å‡†çš„S-type å¯¹æ¯”åº¦å¢å¼ºé‡Œï¼Œ.â€‹\n\nâ€‹ï¼šæ˜¯åƒç´ å¼ºåº¦å€¼å½’ä¸€çš„ç»“æœ\n\nâ€‹ï¼Œå…¶ä¸­ï¼š\n\nå½“â€‹è¯´æ˜åƒç´ å€¼å¯èƒ½è¶…è¿‡äº†è‰²åŸŸèŒƒå›´ï¼Œé¢œè‰²å‘é‡åˆ™ä¼šè½¬æ¢åˆ°CMYç©ºé—´\n\nx_{\\mathrm{C}}=1-x_{\\mathrm{R}}, \\quad x_{\\mathrm{M}}=1-x_{\\mathrm{G}},  \\quad x_{\\mathrm{Y}}=1-x_{\\mathrm{B}}\nç„¶åï¼Œæ¯ä¸ªåƒç´ å€¼é€šè¿‡è¿›è¡Œç¼©æ”¾ï¼Œå†å°†åƒç´ å€¼è½¬åŒ–ä¼šRGBç©ºé—´\n\n\n\n\nResults\nåŒæ—¶åˆ©ç”¨ä¸»è§‚çš„æ–¹å¼ä»¥åŠå®¢è§‚çš„æ–¹å¼\nä¸»è§‚æ–¹å¼ï¼šè§†è§‰å¸å¼•åŠ›å’Œä¸å¿…è¦çš„é¢œè‰²å¤±çœŸ\nå®¢è§‚æ–¹å¼ï¼šäº¤å‰ç†µä»¥åŠKLæ•£ç‚¹\n\n\nç†µä»£è¡¨ä¸€ä¸ªéšæœºå˜é‡çš„ä¸ç¡®å®šç¨‹åº¦ï¼Œå› ä¸ºç†µè¶Šå¤§ä»£è¡¨éšæœºå˜é‡çš„åˆ†å¸ƒè¶Šå‡åŒ€ï¼Œæ‰€ä»¥æœ¬æ–‡æœ€å¤§åŒ–äº¤å‰ä¸Š\n\n\n\\begin{aligned}\nH\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots, \\mathbf{x}_{n}\\right)=&-\\sum_{x_{1}} \\sum_{x_{2}} \\cdots \\sum_{x_{n}} P\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right) \\\\\n& \\times \\log _{2} P\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)\n\\end{aligned}\nKLæ•£åº¦ç”¨äºè¡¡é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„å·®åˆ«ï¼Œåœ¨æœ¬æ–‡å®éªŒä¸­KLæ•£åº¦ç”¨äºè¡¡é‡åŸå§‹ç›´æ–¹å›¾å’Œå‡è¡¡åçš„ç›´æ–¹å›¾ä¸å‡åŒ€åˆ†å¸ƒçš„ç›¸ä¼¼åº¦ã€‚\n\n\n\\begin{aligned}\n&D\\left(f\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right) \\| g\\left(x_{u}, y_{u}, \\ldots, z_{u}\\right)\\right) \\\\\n&\\quad=\\sum_{x_{1}} \\sum_{x_{2}} \\cdots \\sum_{x_{n}} P\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right) \\\\\n&\\quad \\times \\log _{2}\\left(\\frac{P\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)}{g\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)}\\right)\n\\end{aligned}\nä¸ºn-dimå‡åŒ€åˆ†å¸ƒ\n\n\n\n\n\n\n\n\n\n","categories":["ImageProcessing"]},{"title":"Motion & Tracking","url":"/2021/08/15/cv/8.%20Motion%20&%20Tracking/","content":"Motion &amp; Tracking\n\n1. Recall: Histograms of oriented gradients (HOG)\nPartition image into blocks and compute histogram of gradient orientations in each block\n\n\n\nå¯¹å…‰ç…§ä¸æ•æ„Ÿï¼Œä¸€å®šç¨‹åº¦ä¸Šå¯ä»¥å®¹å¿ä¸€äº›å˜åŒ–\n\n1.1 Pedestrian detection with HOG\nTrain a pedestrian template using a linear support vector machine\n\n\n\nAt test time, convolve feature map with template(SVM)\nFind local maxima of response\nFor multi-scale detection, repeat over multiple levels of a HOG pyramid\n\n\n1.2 Window-based detection: strengths\nSliding window detection and global appearance descriptors: Simple detection \nprotocol to implement\nGood feature choices critical\nPast successes for certain classes\n\n\n\n1.3 High computational complexity\nFor example: 250,000 locations x 30 orientations x 4 scales = 30,000,000 evaluations!\nIf training binary detectors independently, means cost increases linearly with number of classes\n\nå¯¹äºä¸€äº›æ–¹å½¢çš„æ¡†ä¸èƒ½æœ‰é’ˆå¯¹è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå› ä¸ºç‰©ä½“ä¸ä¸€å®šéƒ½æ˜¯å‘ˆçŸ©å½¢åˆ†å¸ƒçš„\n\nNon-rigid, deformableï¼ˆéåˆšæ€§çš„ã€å¯å˜å½¢çš„ç‰©ä½“ï¼‰ objects not captured well with representations assuming a fixed 2d structure; or must assume fixed viewpoint\n\nå¯¹éåˆšæ€§å½¢å˜ä¸å…·æœ‰é²æ£’æ€§\n\n\n\n\n\nIf considering windows in isolation, context is lostã€\nä¸¢å¤±ä¸Šä¸‹æ–‡ä¿¡æ¯\n\n\n\n\n\nIn practice, often entails large, cropped training set (expensive)\nRequiring good match to a global appearance description can lead to sensitivity to partial occlusions\néœ€è¦æ ‡è®°\n\n\n\n\n2. Discriminative part-based models\nSingle rigid template usually not enough to represent a category\nMany objects (e.g. humans) are articulated(é“°æ¥å¼), or have parts that can vary in configuration(ç»“æ„)\n\n\n\n\n\nMany object categories look very different from different viewpoints, or from instance to instance\nä¸åŒè§†è§’å¸¦æ¥çš„å˜åŒ–\n\n\n\n\n2.1 Solution\nå…ˆç”¨å…¨å±€åšå“åº”ï¼Œå†ç”¨å±€éƒ¨ç®—å­åšç›¸åº”\nä¸ç®¡æ˜¯å“ªä¸ªéƒ¨åˆ†å­˜åœ¨ï¼Œéƒ½å¯ä»¥åˆ¤å®šä¸ºç›®æ ‡æ£€æµ‹æˆåŠŸ\n\n\n\n\nè™½ç„¶ç©ºé—´ç»„åˆå‘ç”Ÿå˜åŒ–ï¼Œä½†æ˜¯éƒ¨ä»¶ä»èƒ½æ£€æµ‹å‡ºæ¥\n\n3. Object proposals3.1 Main idea:\nLearn to generate category-independent regions/boxes that have object-like properties.\nLet object detector search over â€œproposalsâ€, not exhaustive sliding windows\næ‰¾æœ‰ç›®æ ‡çš„çª—å£\n\n\n\n\n\nå¤šå°ºåº¦æ˜¾è‘—æ€§\näººçœ¼åœ¨è§‚æµ‹ç‰©ä½“æ—¶ï¼Œä¼šæœ‰å…³æ³¨ç‚¹\n\n\n\n\n\né¢œè‰²å¯¹æ¯”åº¦\nä¸€èˆ¬ç‰©ä½“æ£€æµ‹å‘¨å›´ç¯å¢ƒçš„é¢œè‰²å­˜åœ¨æ˜æ˜¾çš„å˜åŒ–\n\n\n\n\n\nè¾¹ç¼˜å¯†åº¦ï¼Œä¸€èˆ¬æ¥è¯´ä¸€ä¸ªç‰©ä½“çš„è¾¹ç¼˜æ˜¯é—­åˆçš„\n\n\n\nè¶…åƒç´ è·¨è¶Šæ€§ï¼šæŠŠç›¸ä¼¼çš„åƒç´ ç‚¹èšç±»åœ¨ä¸€èµ·å«è¶…åƒç´ ï¼Œä¸€ä¸ªè¶…åƒç´ ä¸åº”è¯¥å±äºä¸¤ä¸ªç±»ã€‚ä¸€ä¸ªæ¡†ä¸å¯èƒ½è·¨è¶Šè¶…åƒç´ ï¼Œå¦åˆ™æ¡†å†…æ— ç›®æ ‡\n\n\n\n\nåªéœ€è¦1000ä¸ªçª—å£ï¼Œå°±èƒ½æŠŠç›®æ ‡æ¡†å‡ºæ¥\n\n3.2 Summary\nObject recognition as classification task\nBoosting (face detection ex)\nSupport vector machines and HOG (person detection ex)\nSliding window search paradigm\nPros and cons\nSpeed up with attentional cascade\nDiscriminative part-based models, object proposals\n\n\n\n\n\n4. Motion and Tracking4.1 From images to videos\nA video is a sequence of frames captured over time\nNow our image data is a function of space (ğ‘¥,ğ‘¦)and time (ğ‘¡)\n\n\n4.2 Motion is a powerful perceptual cue\nSometimes, it is the only cue\næ¯ä¸€å¸§å›¾ç‰‡å…·æœ‰å¼ºç›¸å…³æ€§ï¼Œè¿åŠ¨å¯ä»¥å¸¦æ¥ä¸°å¯Œçš„ä¿¡æ¯\nä¸‹å›¾åœ¨è¿åŠ¨æ—¶å¯ä»¥çœ‹åˆ°ä¸¤ä¸ªåœ†\n\n\n\n\n\nEven â€œimpoverishedâ€ motion data can evoke a strong percept\nä¸‹å›¾å¯ä»¥çœ‹å‡ºä¸€ä¸ªè¿åŠ¨çš„äºº\n\n\n\n\n4.3 Uses of motion in computer vision\n3D shape reconstruction\nå¤šè§’åº¦æ‹æ‘„\n\n\nObject segmentation\nLearning and tracking of dynamical models\nç›®æ ‡è¿½è¸ª\n\n\nEvent and activity recognition\n\n4.4 Motion field\nmotion field is the projection of the 3D scene motion into the image\nè¿åŠ¨åœºæ˜¯3Dåœºæ™¯è¿åŠ¨åˆ°å›¾åƒä¸­çš„æŠ•å½±\n\n\n\n\n\n4.5 Motion estimation: Optical flow\nDefinition: optical flow is the apparent motion of brightness patterns in the image\n\næ˜æ˜¾äº®åº¦æ¨¡å¼çš„è¿åŠ¨\nå…‰æµï¼ˆoptical flowï¼‰æ˜¯ç©ºé—´è¿åŠ¨ç‰©ä½“åœ¨è§‚å¯Ÿæˆåƒå¹³é¢ä¸Šçš„åƒç´ è¿åŠ¨çš„ç¬æ—¶é€Ÿåº¦ã€‚\n\n\nIdeally, optical flow would be the same as the motion field\n\nHave to be careful: apparent motion can be caused by lighting changes without any actual motion\nThink of a uniform rotating sphere under fixed lighting vs. a stationary sphere under moving illumination\nä¸€ç§æ˜¯å‡åŒ€å…‰ç…§å¯¹é€‰è£…çƒä½“çš„å½±å“\nä¸€ç§æ˜¯å…‰ç…§å˜åŒ–ï¼Œä½†æ˜¯ç‰©ä½“ä¸åŠ¨\n\n\nGOAL:Recover image motion at each pixel from optical flow\n\n4.6 Estimating optical flow\n\næ—¶é—´å¾ˆå°ï¼Œä½ç§»çŸ¢é‡è¿‘ä¼¼äºé€Ÿåº¦çŸ¢é‡\n\nGiven two subsequent frames, estimate the apparent motion field u(x,y), v(x,y) between them\n\nu,våˆ†åˆ«æ˜¯æ¨ªå‘é€Ÿåº¦å’Œçºµå‘é€Ÿåº¦\n\n\n\n\n\nKey assumptions\nBrightness constancy: projection of the same point looks the same in every frame\näº®åº¦æ’å®šä¸å˜ã€‚ç›¸åŒçš„æŠ•å½±ç‚¹åœ¨ä¸åŒå¸§é—´è¿åŠ¨æ—¶ï¼Œå…¶äº®åº¦ä¸ä¼šå‘ç”Ÿæ”¹å˜ã€‚\n\n\nSmall motion:points do not move very far\næ—¶é—´è¿ç»­æˆ–è¿åŠ¨æ˜¯â€œå°è¿åŠ¨â€ã€‚å³æ—¶é—´çš„å˜åŒ–ä¸ä¼šå¼•èµ·ç›®æ ‡ä½ç½®çš„å‰§çƒˆå˜åŒ–ï¼Œç›¸é‚»å¸§ä¹‹é—´ä½ç§»è¦æ¯”è¾ƒå°ã€‚\n\n\nSpatial coherence:points move like their neighbors\nç©ºé—´ç›¸å…³æ€§ï¼šç›¸é‚»çš„ç‚¹ç›¸ä¼¼\n\n\n\n\n\n4.6.1 Key Assumptions: small motions\n\nç›¸é‚»å¸§ï¼ŒæŸä¸ªåŒºåŸŸçš„åƒç´ æ˜¯é€æ¸å˜åŒ–çš„\n\n4.6.2 Key Assumptions: spatial coherence\n\nç©ºé—´ä¸Šçš„ä¸€è‡´æ€§ï¼Œåœ¨å°é¢†åŸŸä¸Šè¿åŠ¨è¶‹åŠ¿æ˜¯ç›¸ä¼¼çš„\n\n4.6.3 Key Assumptions: brightness Constancy\n4.7 The brightness constancy constraint\näº®åº¦æ’å®š\n\n\nI(x, y, t-1)=I(x+u(x, y), y+v(x, y), t)\n\nBrightness Constancy Equation:\nI(x, y, t-1)=I(x+u(x, y), y+v(x, y), t)\nLinearizing the right side using Taylor expansion:\n\n\n\\begin{aligned}\n&\\quad I(x+u, y+v, t) \\approx I(x, y, t-1)+I_{x}u(x, y)+I_{y} v(x, y)+I_{t} \\\\ \\\\\n&\\quad I(x+u, y+v, t)-I(x, y, t-1)=I_{x} \\cdot u(x, y)+I_{y} \\cdot v(x, y)+I_{t} \\\\ \\\\\n&\\text { Hence, } \\quad I_{x} \\cdot u+I_{y} \\cdot v+I_{t} \\approx 0 \\rightarrow \\nabla I \\cdot[u ,v]^{T}+I_{t}=0\n\\end{aligned}\ntæ–¹å‘æ±‚å¯¼å³ä¸ºï¼š\n\n\nF_t=\\left[\\begin{array}{cc}\n1 & 1\\\\\n1 & 1\n\\end{array}\\right]ï¼Œ\\ \nF_{t-1}=\\left[\\begin{array}{cc}\n-1 & -1\\\\\n-1 & -1\n\\end{array}\\right]\nCan we use this equation to recover image motion (u,v) at each pixel?\n\n\n\\nabla I \\cdot[u, v]^{T}+I_{t}=0\nå¢é‡å’Œæ¢¯åº¦æ–¹å‘å‚ç›´çš„è¯ï¼Œå¢é‡å°±æ— å½±å“\n\n\n\\nabla I \\cdot[u, v]^{T}=0,\\text{for any u, v, if }\\nabla I \\perp [u,v]\nHow many equations and unknowns per pixel?\n\nOne equation (this is a scalar equation!), two unknowns (u,v)\næ— æ³•æ±‚è§£å‚æ•°\n\n\nThe component of the flow perpendicularï¼ˆå‚ç›´ï¼‰ to the gradient (i.e., parallel to the edge) cannot be measured\n\n\n\n\nä¼šæœ‰å¤šä¸ªè§£ï¼Œä¸å®é™…è¿åŠ¨å°±ä¼šä¸ä¸€è‡´\n\n4.8 The aperture problem\nå­”å¾„é—®é¢˜æŒ‡åœ¨è¿åŠ¨ä¼°è®¡ï¼ˆMotion Estimationï¼‰ä¸­æ— æ³•é€šè¿‡å•ä¸ªç®—å­ã€è®¡ç®—æŸä¸ªåƒç´ å€¼å˜åŒ–çš„æ“ä½œï¼Œä¾‹å¦‚ï¼šæ¢¯åº¦ã€‘å‡†ç¡®æ— è¯¯åœ°è¯„ä¼°ç‰©ä½“çš„è¿è¡Œè½¨è¿¹ã€‚åŸå› æ˜¯æ¯ä¸€ä¸ªç®—å­åªèƒ½å¤„ç†å®ƒæ‰€è´Ÿè´£å±€éƒ¨åŒºåŸŸçš„åƒç´ å€¼å˜åŒ–ï¼Œç„¶è€ŒåŒä¸€ç§åƒç´ å€¼å˜åŒ–å¯èƒ½æ˜¯ç”±ç‰©ä½“çš„å¤šç§è¿è¡Œè½¨è¿¹å¯¼è‡´ã€‚\n\n\n\nåœ¨å°å­”é‡Œçœ‹æ˜¯å¹³è¡Œè¿åŠ¨ï¼Œä½†å®é™…ä¸‰ç»´è¿åŠ¨å´ä¸æ˜¯\n\n\n\nä¸‰ç»´æ˜¯æ—‹è½¬ï¼Œä½†æ˜¯äºŒç»´çœ‹èµ·æ¥æ˜¯å‘ä¸Šèµ°\né€™å°±æ˜¯ã€Œå€åŸŸ(local)ã€ å’Œã€Œ å…¨åŸŸ (global)ã€ è¦–è¦ºè™•ç†çš„å·®åˆ¥ã€‚æˆ‘å€‘çš„è¦–è¦ºç³»çµ±å€åŸŸä¸Š (locally) å¯ä»¥æœ‰å­”å¾‘å•é¡Œçš„éŒ¯è¦ºï¼Œä½†æ˜¯ç•¶æˆ‘å€‘è§€å¯Ÿçš„ç¯„åœæ˜¯å…¨åŸŸ (globally)çš„æ™‚å€™ï¼Œå»åˆåˆ†æçš„å‡ºä¾†ä¸‰å¼µç´™æ¢ä¸åŒçš„ç§»å‹•æ–¹å‘ã€‚\n\n4.9 Solving the ambiguity\nHow to get more equations for a pixel?\nSpatial coherence constraint:\nAssume the pixelâ€™s neighbors have the same (u,v)\nIf we use a 5x5 window, that gives us 25 equations per pixel\n\n\n\n\n\\begin{gathered}\n0=I_{t}\\left(\\mathrm{p}_{\\mathrm{i}}\\right)+\\nabla I\\left(\\mathrm{p}_{\\mathrm{i}}\\right) \\cdot\\left[\\begin{array}{ll}\nu & v\n\\end{array}\\right] \\\\ \\\\\n{\\left[\\begin{array}{cc}\nI_{x}\\left(\\mathrm{p}_{1}\\right) & I_{y}\\left(\\mathrm{p}_{1}\\right) \\\\\nI_{x}\\left(\\mathrm{p}_{2}\\right) & I_{y}\\left(\\mathrm{p}_{2}\\right) \\\\\n\\vdots & \\vdots \\\\\nI_{x}\\left(\\mathrm{p}_{25}\\right) & I_{y}\\left(\\mathrm{p}_{25}\\right)\n\n\\end{array}\\right]\\left[\\begin{array}{l}\nu \\\\\nv\n\\end{array}\\right]=-\\left[\\begin{array}{c}\nI_{t}\\left(\\mathrm{p}_{1}\\right) \\\\\nI_{t}\\left(\\mathrm{p}_{2}\\right) \\\\\n\\vdots \\\\\nI_{t}\\left(\\mathrm{p}_{25}\\right)\n\\end{array}\\right]}\n\\end{gathered}\nOverconstrained linear system\n\n\n\\left[\\begin{array}{cc}\nI_{x}\\left(\\mathrm{p}_{1}\\right) & I_{y}\\left(\\mathrm{p}_{1}\\right) \\\\\nI_{x}\\left(\\mathrm{p}_{2}\\right) & I_{y}\\left(\\mathrm{p}_{2}\\right) \\\\\n\\vdots & \\vdots \\\\\nI_{x}\\left(\\mathrm{p}_{25}\\right) & I_{y}\\left(\\mathrm{p}_{25}\\right)\n\\end{array}\\right]\\left[\\begin{array}{l}\nu \\\\\nv\n\\end{array}\\right]=-\\left[\\begin{array}{c}\nI_{t}\\left(\\mathrm{p}_{1}\\right) \\\\\nI_{t}\\left(\\mathrm{p}_{2}\\right) \\\\\n\\vdots \\\\\nI_{t}\\left(\\mathrm{p}_{25}\\right)\n\\end{array}\\right] \\quad \\begin{array}{cc}\nA & d=b \\\\\n25 \\times 2 & 2 \\times 1\n\\end{array}\nLeast squares solution for $d$ given by $\\left(A^{T} A\\right) d=A^{T} b$\n\n\n\\begin{gathered}\n{\\left[\\begin{array}{cc}\n\\sum I_{x} I_{x} & \\sum I_{x} I_{y} \\\\\n\\sum I_{x} I_{y} & \\sum I_{y} I_{y}\n\\end{array}\\right]\\left[\\begin{array}{l}\nu \\\\\nv\n\\end{array}\\right]=-\\left[\\begin{array}{c}\n\\sum I_{x} I_{t} \\\\\n\\sum I_{y} I_{t}\n\\end{array}\\right]} \\\\\nA^{T} A\n\\end{gathered}\nThe summations are over all pixels in the $\\mathrm{K} \\times \\mathrm{K}$ window\n\nOptimal $(u, v)$ satisfies Lucas-Kanade equation\n\n\n\n\\begin{gathered}\n{\\left[\\begin{array}{cc}\n\\sum I_{x} I_{x} & \\sum I_{x} I_{y} \\\\\n\\sum I_{x} I_{y} & \\sum I_{y} I_{y}\n\\end{array}\\right]\\left[\\begin{array}{l}\nu \\\\\nv\n\\end{array}\\right]=-\\left[\\begin{array}{c}\n\\sum I_{x} I_{t} \\\\\n\\sum I_{y} I_{t}\n\\end{array}\\right]} \\\\\nA^{T} A\n\\end{gathered}\nWhen is this solvable? I.e., what are good points to track?\n$A^TA$â€‹ should be invertible\nä¸ä¸€å®šå¯é€†\n\n\n$A^TA$â€‹â€‹ should not be too small due to noise \neigenvalues $\\lambda_{1}$ and $\\lambda_{2}$ of $A^{\\top} A$â€‹ should not be too small\nå¦‚æœ$A^TA$å€¼å¾ˆå°ï¼Œå¦‚æœæœ‰å™ªéŸ³ï¼Œå°±ä¼šé€ æˆå¾ˆå¤§çš„æ‰°åŠ¨ï¼Œæ‰€ä»¥ç‰¹å¾å€¼ä¸èƒ½å¤ªå°\n\n\n$A^TA$â€‹ should be well-conditioned\n$\\lambda_{1} / \\lambda_{2}$â€‹ should not be too large $\\left(\\lambda_{1}=\\right.$â€‹ larger eigenvalue $)$â€‹â€‹\n\n\n\n\nDoes this remind you of anything?\nCriteria for Harris corner detector\n\n\n\n4.10 Recall: second moment matrix\nEstimation of optical flow is well-conditioned precisely for regions with high â€œcornernessâ€:\n\n\n4.10.1 Low texture region\n\nå¯¹äºå¹³æ»‘åŒºåŸŸå’Œè¾¹ç¼˜éƒ½ä¸å¥½æ£€æµ‹å…‰æµä¼°è®¡\nè§’ç‚¹ä¼šè¾ƒä¸ºå®¹æ˜“æ£€æµ‹ï¼Œå› ä¸ºä»–çš„æ¢¯åº¦åœ¨å„ä¸ªæ–¹å‘éƒ½æœ‰å˜åŒ–\n\n\n\n4.10.2 The aperture problem resolved\n\n\nç”¨æ‰¾äº¤ç‚¹çš„æ–¹å¼ï¼Œæ¥è¿›è¡Œçº¦æŸ\n\n4.11 Errors in Lucas-Kanade\nThe motion is large (larger than a pixel)\nA point does not move like its neighbors\næŸ”æ€§ç‰©ä½“çš„å˜åŒ–\n\n\nBrightness constancy does not hold\n\nRevisiting the small motion assumption\n\nIs this motion small enough?\nProbably notâ€”itâ€™s much larger than one pixel\nHow might we solve this problem?\n\n\næ„æ€æ˜¯å¯¹äºä¸€äº›æ¯”è¾ƒå¤§çš„è¿åŠ¨æ€ä¹ˆè¿›è¡Œæµ‹é‡ï¼Ÿ\n\n4.12 Reduce the resolution!\n\nåˆ©ç”¨ä¸‹é‡‡æ ·ï¼Œé‚£ä¹ˆåŸæ¥åç§»ä¸¤ä¸ªåƒç´ çš„è¿åŠ¨ï¼Œå°±ä¼šå˜æˆåç§»ä¸€ä¸ªåƒç´ ï¼Œä»è€Œæé«˜é²æ£’æ€§\n\n4.13 Coarse-to-fine optical flow estimation\n\nå…ˆå°†å›¾ç‰‡è¿›è¡Œä¸‹é‡‡æ ·\n\n\n\nç„¶åä»æœ€ä½åˆ†è¾¨ç‡çš„å›¾ç‰‡å¼€å§‹è¿›è¡Œå…‰æµä¼°è®¡ï¼Œç„¶ååœ¨è¿›è¡Œä¸Šé‡‡æ ·\nå¯¹äºä½åˆ†è¾¨ç‡æ±‚å¾—çš„u,vå°†ä½œä¸ºä¸‹ä¸€å±‚çš„åˆå§‹å€¼\n\n\n\n\n4.14 A point does not move like its neighbors\nMotion segmentation\n\n\n\nå…ˆåˆ†å—ï¼Œå†ç”¨èšç±»çš„æ–¹æ³•ï¼Œæ‰¾çœŸæ­£çš„æ–¹å‘ï¼ŒæŠŠå›¾åƒåˆ†ä¸ºä¸åŒçš„å±‚ï¼Œä½œä¸ºæ•´ä½“ç›®æ ‡çš„è€ƒè™‘\nBrightness constancy does not hold\nFeature matching\n\n\nå…ˆæ£€æµ‹å…³é”®ç‚¹ï¼Œå°±å¯ä»¥è¿½è¸ªå…³é”®ç‚¹çš„è½¨è¿¹\n\n5. Feature Tracking\n\n\né€šè¿‡æ‰¾åˆ°å›¾åƒçš„å…³é”®ç‚¹ï¼Œç„¶åæœ€ç»ˆå›¾åƒå…³é”®ç‚¹ï¼Œä»è€Œå½¢æˆç‰¹å¾è¿½è¸ª\n\n5.1 Single object tracking\n\nå¯ä»¥æœ‰æ•ˆçš„è§£å†³é®æŒ¡é—®é¢˜\n\n5.2 Multiple object tracking\n\nå¯èƒ½é‡åˆ°çš„é—®é¢˜\nå®ä½“é‡å \nå®ä½“åˆ†å¼€ï¼ˆidä¸èƒ½ææ··ï¼‰\n\n\n\n5.3 Tracking with a fixed camera\n\nå› ä¸ºç”¨å›ºå®šçš„ç›¸æœºæ‹æ‘„ï¼Œå½“äººè¿åŠ¨æ—¶ä¼šå¯¼è‡´å°ºåº¦ä¼šå‘ç”Ÿå˜åŒ–\n\n5.4 Tracking with a moving camera\n\nè¿åŠ¨çš„ç›¸æœºèƒŒæ™¯å‘ç”Ÿå˜åŒ–\n\n5.5 Tracking with multiple cameras\n\nè§’åº¦å˜åŒ–\n\n5.6 Challenges in Feature tracking\nFigure out which features can be tracked\nEfficiently track across frames\n\n\nSome points may change appearance over time\ne.g., due to rotation, moving into shadows, etc.\n\n\nDrift: small errors can accumulate as appearance model is updated\nä¸¤å¸§æœ‰å°çš„è¯¯å·®ï¼Œå°çš„è¯¯å·®ç´¯ç§¯æˆå¤§çš„è¯¯å·®\n\n\nPoints may appear or disappear.\nç‰¹å¾ç‚¹æ¶ˆå¤±ä¸å‡ºç°\n\n\n\n5.7 What are good features to track?\nIntuitively, we want to avoid smooth regions and edges. But is there a more is principled way to define good features?\nç¨³å®šå¥½è®¡ç®—\nKey idea: â€œgoodâ€ features to track are the ones whose motion can be estimated reliably\nWhat kinds of image regions can we detect easily and consistently?\n\n5.8 Motion estimation techniques\nOptical flow\nRecover image motion at each pixel from spatio-temporal image brightness variations (optical flow)\n\n\nFeature-tracking\n\nExtract visual features (corners, textured areas) and â€œtrackâ€ them over multiple frames\n\n\nç‰¹å¾è·Ÿè¸ªï¼šå¯ä»¥ç”¨å…‰æµç®—æ³•æ¥å¸®åŠ©æœ€ç»ˆè·Ÿè¸ª\n\n\n5.9 Optical flow can help track features\nOnce we have the features we want to track, lucas-kanadeor other optical flow algorithsmcan help track those features\n\n\n\n6. Shi-Tomasifeature tracker6.1 Simple KLT tracker\nFind a good point to track (harriscorner)\nFor each Harris corner compute motion (translation or affine) between consecutive frames.\nLink motion vectors in successive frames to get a track for each Harris point\nIntroduce new Harris points by applying Harris detector at every m (10 or 15) frames\næ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„å¥½çš„ç‰¹å¾ç‚¹\n\n\nTrack new and old Harris points using steps 1â€3\n\n6.2 Recall: Challenges in Feature tracking\nFigure out which features can be tracked\nSome points may change appearance over time\nDrift: small errors can accumulate as appearance model is updated\næ‰€ä»¥è¦æ‰¾ä¸€äº›æ¯”è¾ƒç¨³å®šçš„ç‰¹å¾ç‚¹ä½œä¸ºæœ€ç»ˆå¯¹è±¡\n\n\nPoints may appear or disappear.\n\nNeed to be able to add/delete tracked points\n\n\nCheck consistency of tracks by affine registration to the first observed instance of the feature\n\nAffine model is more accurate for larger displacements\n\n6.3 2D transformations\nå¯å‚è€ƒé˜…è¯» 2D transformation review\n\n\n6.3.1 Translation\nLet the initial feature be located by (x, y).\n\nIn the next frame, it has translated to (xâ€™, yâ€™).\n\nWe can write the transformation as:\n\n\n\n\\begin{array}{ll}\nx'=x+b_1\\\\\ny'=y+b_2\n\\end{array}\nWe can write this as a matrix transformation using homogeneous coordinates:\n\n\n\n\\left[\\begin{array}{l}\nx^{\\prime} \\\\\ny^{\\prime}\n\\end{array}\\right]=\\left[\\begin{array}{lll}\n1 & 0 & b_{1} \\\\\n0 & 1 & b_{2}\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny \\\\\n1\n\\end{array}\\right]\nNotation:\n\n\nW(\\boldsymbol{x} ; \\boldsymbol{p})=\\left[\\begin{array}{lll}\n1 & 0 & b_{1} \\\\\n0 & 1 & b_{2}\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny \\\\\n1\n\\end{array}\\right]\nThere are only two parameters:\n\n\n\\boldsymbol{p}=\\left[\\begin{array}{l}\nb_{1} \\\\\nb_{2}\n\\end{array}\\right]\nThe derivative of the transformation w.r.t. $\\mathbf{p}$ :\n\n\n\\frac{\\partial W}{\\partial \\boldsymbol{p}}(\\boldsymbol{x} ; \\boldsymbol{p})=\\left[\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right]\nThis is called the Jacobian.\n\n6.3.2 Similarity motion\nRigid motion includes scaling + translation.\nWe can write the transformations as:\n\n\n\\begin{array}{ll}\nx'=ax+b_1\\\\\ny'=ay+b_2\n\\end{array}\nW(\\boldsymbol{x} ; \\boldsymbol{p})=\\left[\\begin{array}{lll}a & 0 & b_{1} \\\\ 0 & a & b_{2}\\end{array}\\right]\\left[\\begin{array}{l}x \\\\ y \\\\ 1\\end{array}\\right]\n\\boldsymbol{p}=\\left[\\begin{array}{lll}a & \\mathrm{~b}_{1} & \\mathrm{~b}_{2}\\end{array}\\right]^{T}\n\\frac{\\partial W}{\\partial p}(\\boldsymbol{x} ; \\boldsymbol{p})=\\left[\\begin{array}{lll}x & 1 & 0 \\\\ y & 0 & 1\\end{array}\\right]6.3.3 Affine motion\nAffine motion includes scaling + rotation + translation.\n\n\n\\begin{aligned}\n&W(\\boldsymbol{x} ; \\boldsymbol{p})=\\left[\\begin{array}{lll}\na_{1} & a_{2} & b_{1} \\\\\na_{3} & a_{4} & b_{2}\n\\end{array}\\right]\\left[\\begin{array}{l}\nx \\\\\ny \\\\\n1\n\\end{array}\\right] \\\\ \\\\\n&\\boldsymbol{p}=\\left[\\begin{array}{llll}\na_{1} & \\mathrm{a}_{2} & \\mathrm{~b}_{1} & a_{3} & a_{4} & b_{2}\n\\end{array}\\right]^{T} \\\\ \\\\\n&\\frac{\\partial W}{\\partial p}(\\boldsymbol{x} ; \\boldsymbol{p})=\\left[\\begin{array}{llllll}\nx & y & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & x & y & 1\n\\end{array}\\right]\n\\end{aligned}6.4 Iterative KLT tracker\nGiven a video sequence, find all the features and track them across the video.\nFirst, use Harris corner detection to find features and their location $\\boldsymbol{x}$. For each feature at location $\\boldsymbol{x}=\\left[\\begin{array}{ll}x &amp; y\\end{array}\\right]^{T}$â€‹\nChoose a descriptor create an initial template for that feature: $T(\\boldsymbol{x})$â€‹.\næ³¨æ„åˆå§‹å¸§æ•°ä¼šå¯¹æ¯ä¸ªç‰¹å¾è®¡ç®—ä¸€ä¸ªæè¿°ç¬¦æ¨¡æ¿ï¼Œç”¨äºæ¯”è¾ƒå¾€åç‰¹å¾æè¿°ç¬¦å’Œè¯¥æ¨¡æ¿çš„å·®è·\nOur aim is to find the $\\boldsymbol{p}$ that minimizes the difference between the template $T(\\boldsymbol{x})$ and the description of the new location of $\\boldsymbol{x}$â€‹â€‹â€‹ after undergoing the transformation.\nåœ¨ç‰¹å¾å¯¹åº”çš„è¿™æ ·ä¸€ä¸ªå°åŒºåŸŸï¼Œè¿›è¡Œæœ€å°åŒ–å˜åŒ–å‰åæè¿°ç¬¦ä¹‹é—´çš„å·®å€¼\n\n\n\n\n\\sum_{x}[I(W(\\boldsymbol{x} ; \\boldsymbol{p}))-T(x)]^{2}\nFor all the features $x$ in the image $I$,\n\n$I(W(\\boldsymbol{x} ; \\boldsymbol{p}))$ is the estimate of where the features move to in the next frame after the transformation defined by $W(\\boldsymbol{x} ; \\boldsymbol{p})$. Recall that $\\boldsymbol{p}$â€‹ is our vector of parameters.\nSum is over an image patch around $\\boldsymbol{x}$â€‹.\n\n\nWe will instead break down $\\boldsymbol{p}=\\boldsymbol{p}_{\\mathbf{0}}+\\Delta \\boldsymbol{p}$\n\nLarge $+$ small $/$ residual motion\nWhere $\\boldsymbol{p}_{\\mathbf{0}}$ is going to be fixed and we will solve for $\\Delta \\boldsymbol{p}$, which is a small value.\nWe can initialize $\\boldsymbol{p}_{\\mathbf{0}}$ with our best guess of what the motion is and initialize $\\Delta \\boldsymbol{p}$â€‹â€‹ as zero.\n\n\n\n\n\\begin{aligned}\n& \\sum_{x}\\left[I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}+\\Delta \\boldsymbol{p}\\right)\\right)-T(x)\\right]^{2} \\\\\n\\approx & \\sum_{x}\\left[I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)\\right)+\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}} \\Delta \\boldsymbol{p}-T(x)\\right]^{2}\n\\end{aligned}\nItâ€™s a good thing we have already calculated what $\\frac{\\partial W}{\\partial p}$ would look like for affine, translations and other transformations!\n\nSo our aim is to find the $\\Delta \\boldsymbol{p}$ that minimizes the following:\n\nJ=\\underset{\\Delta p}{\\operatorname{argmin}} \\sum_{x}\\left[I\\left(W\\left(x ; p_{0}\\right)\\right)+\\nabla I \\frac{\\partial W}{\\partial p} \\Delta p-T(x)\\right]^{2}\nWhere $\\nabla I=\\left[\\begin{array}{ll}I_{x} &amp; I_{y}\\end{array}\\right]$\n\nDifferentiate wrt $\\Delta \\boldsymbol{p}$â€‹ and setting it to zero:\n\n\n\n\\frac{\\partial J}{\\partial \\Delta p}=2\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial p}\\right]^{T}\\left[I\\left(W\\left(x ; p_{0}\\right)\\right)+\\nabla I \\frac{\\partial W}{\\partial p} \\Delta p-T(x)\\right]\n\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial p}\\right]^{T}\\left[I\\left(W\\left(x ; p_{0}\\right)\\right)+\\nabla I \\frac{\\partial W}{\\partial p} \\Delta p-T(x)\\right]=0\nSolving for $\\Delta \\boldsymbol{p}$ in:\n\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^{T}\\left[I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)\\right)+\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}} \\Delta \\boldsymbol{p}-T(x)\\right]=0\nwe get:\n\n\n\\sum_{x}\\left[\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^{T}I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)\\right)+\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^T\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}} \\Delta \\boldsymbol{p}-\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^TT(x)\\right]=0\n\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^{T}I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)\\right)+\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^T\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}} \\Delta \\boldsymbol{p}-\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^TT(x)=0\n\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^T\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}} \\Delta \\boldsymbol{p}=\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^T\\left[T(x)-I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)\\right)\\right]\n\\left(\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^T\\nabla I \\frac{\\partial W}{\\partial\\boldsymbol{p}}\\right)  \\Delta \\boldsymbol{p}=\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^T\\left[T(x)-I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)\\right)\\right]\n\\Delta \\boldsymbol{p}=H^{-1} \\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^{T}\\left[T(x)-I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)\\right)\\right]\nwhere $H=\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial p}\\right]^{T}\\left[\\nabla I \\frac{\\partial W}{\\partial p}\\right]$\n\n\nH=\\sum_{x}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]^{T}\\left[\\nabla I \\frac{\\partial W}{\\partial \\boldsymbol{p}}\\right]\nH matrix for translation transformations\n\nRecall that\n\n$\\nabla I=\\left[\\begin{array}{ll}I_{x} &amp; I_{y}\\end{array}\\right]$ and\nfor translation motion, $\\frac{\\partial W}{\\partial p}(\\boldsymbol{x} ; \\boldsymbol{p})=\\left[\\begin{array}{ll}1 &amp; 0 \\ 0 &amp; 1\\end{array}\\right]$Therefore,\n\n\n\\begin{aligned}\nH&=\\sum_{x}\\left[\n\\left[\\begin{array}{ll}\nI_{x} & I_{y}\n\\end{array}\\right]\n\\left[\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right]\\right]^{T}\\left[\\begin{array}{ll}\nI_{x} & I_{y}\n\\end{array}\\right]\\left[\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right] \\\\\n&={\\sum_{x}\\left[\\begin{array}{ll}\nI_{x}^{2} & I_{x} I_{y} \\\\\nI_{x} I_{y} & I_{y}^{2}\n\\end{array}\\right]} \\begin{array}{l}\n\\text { That's the Harris corner } \\\\\n\\text { detector we learnt in } \\\\\n\\text { class!!! }\n\\end{array}\n\\end{aligned}\nH matrix for affine transformations\n\n\n\\begin{aligned}\nH&=\\sum_{x}\\left[\n\\left[\\begin{array}{ll}\nI_{x} & I_{y}\n\\end{array}\\right]\n\\left[\\begin{array}{llllll}\nx & y & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & x & y & 1\n\\end{array}\\right]\\right]^{T}\\left[\\begin{array}{ll}\nI_{x} & I_{y}\n\\end{array}\\right]\n\\left[\\begin{array}{llllll}\nx & y & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & x & y & 1\n\\end{array}\\right] \\\\\n&={\\sum_{x}\\left[\\begin{array}{llllll}\nx & y & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & x & y & 1\n\\end{array}\\right]^T\\left[\\begin{array}{ll}\nI_{x}^{2} & I_{x} I_{y} \\\\\nI_{x} I_{y} & I_{y}^{2}\n\\end{array}\\right]}\\left[\\begin{array}{llllll}\nx & y & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & x & y & 1\n\\end{array}\\right]\\\\\n&=\\sum_{\\mathbf{x}}\\left[\\begin{array}{cccccc}\nI_{x}^{2} & I_{x} I_{y} & x I_{x}^{2} & y I_{x} I_{y} & x I_{x} I_{y} & y I_{x} I_{y} \\\\\nI_{x} I_{y} & I_{y}^{2} & x I_{x} I_{y} & y I_{y}^{2} & x I_{y}^{2} & y I_{y}^{2} \\\\\nx I_{x}^{2} & y I_{x} I_{y} & x^{2} I_{x}^{2} & y^{2} I_{x} I_{y} & x y I_{x} I_{y} & y^{2} I_{x} I_{y} \\\\\ny I_{x} I_{y} & y I_{y}^{2} & x y I_{x} I_{y} & y^{2} I_{y}^{2} & x y I_{y}^{2} & y^{2} I_{y}^{2} \\\\\nx I_{x} I_{y} & x I_{y}^{2} & x^{2} I_{x} I_{y} & x y I_{y}^{2} & x^{2} I_{y}^{2} & x y I_{y}^{2} \\\\\ny I_{x} I_{y} & y I_{y}^{2} & x y I_{x} I_{y} & y^{2} I_{y}^{2} & x y I_{y}^{2} & y^{2} I_{y}^{2}\n\\end{array}\\right]\n\\end{aligned}6.5 Overall KLT tracker algorithm\nGiven the features from Harris detector:\nè¿™é‡Œåº”è¯¥æŒ‡çš„æ˜¯å¾—åˆ°ç‰¹å¾çš„åæ ‡ä¿¡æ¯ä»¥åŠç‰¹å¾ä¿¡æ¯\nå¯¹äºè¿½è¸ªè€Œè¨€å¯ä»¥ç›´æ¥ç”¨å…‰æµæ³•æœ€ç»ˆç‰¹å¾ï¼Œä½†å…‰æµæ³•æ˜¯æœ‰è¯¯å·®çš„\nå› ä¸ºå­˜åœ¨å™ªå£°ï¼Œæ‰€ä»¥éœ€è¦å»æ¯”è¾ƒ10å¸§å‰åçš„ç‰¹å¾å˜åŒ–ï¼Œä¸€èˆ¬æ¥è®²ç»è¿‡2Då˜æ¢åä»èƒ½æ‰¾åˆ°ç‰¹å¾\nå­˜åœ¨ä¸€ç§æƒ…å†µï¼Œä¹Ÿå°±æ˜¯è¯¥ç‰¹å¾å·²ç»æ¶ˆå¤±ï¼Œåˆ™æ­¤æ—¶ä¸€å®šæ‰¾ä¸åˆ°ä¸€ç§åˆé€‚å°è¿åŠ¨ï¼Œä½¿å¾—ç‰¹å¾è¿›è¡Œæœ‰æ•ˆçš„å˜æ¢\n\n\n\n\nInitialize $\\boldsymbol{p}_{\\mathbf{0}}$ and $\\Delta \\boldsymbol{p}$.\nCompute the initial templates $T(x)$ for each feature.\nTransform the features in the image $I$ with $W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)$.\nMeasure the error: $I\\left(W\\left(\\boldsymbol{x} ; \\boldsymbol{p}_{\\mathbf{0}}\\right)\\right)-T(x)$.\nCompute the image gradients $\\nabla I=\\left[\\begin{array}{ll}I_{x} &amp; I_{y}\\end{array}\\right]$.\nEvaluate the Jacobian $\\frac{\\partial W}{\\partial p}$.\nCompute steepest descent $\\nabla I \\frac{\\partial W}{\\partial p}$.\nCompute Inverse Hessian $H^{-1}$\nCalculate the change in parameters $\\Delta \\boldsymbol{p}$\nUpdate parameters $\\boldsymbol{p}_{\\mathbf{0}}=\\boldsymbol{p}_{\\mathbf{0}}+\\Delta \\boldsymbol{p}$\nRepeat 2 to 10 until $\\Delta \\boldsymbol{p}$ is small.\n\n\n$\\Delta \\boldsymbol{p}$å¦‚æœä¸€ç›´å¾ˆå¤§ï¼Œåˆ™æŠŠè¯¥ç‰¹å¾åˆ å»\n\næ€»çš„æ¥è¯´ï¼Œè¯¥ç®—æ³•æ˜¯ä¸ºäº†æŒç»­ç›‘è§†ç‰¹å¾çš„ä¸€ä¸ªç®—æ³•ï¼Œæ¯éš”10å¸§å·¦å³è¿›è¡Œä¾æ¬¡è¿ç®—ï¼Œå½“è¯¥è¿ç®—æŒ‡çš„æ˜¯åœ¨ç»™å®šä¸¤å¼ å›¾ç‰‡ï¼Œç»™å®šäº†ä¸€å¼€å§‹è®¡ç®—çš„ç‰¹å¾æ¨¡æ¿ï¼Œç„¶åæ¯éš”10fpåšä¸€æ¬¡åˆ¤åˆ«ï¼Œä»å½“å‰å¸§çš„å‰ç¬¬åå¸§çš„æŸä¸€ä¸ªç‰¹å¾ç‚¹è¿›è¡Œ2Då˜æ¢åˆ°å½“å‰å¸§å°±å¯ä»¥å¾—åˆ°å½“å‰å¸§çš„å°åŒºåŸŸæè¿°ç¬¦ï¼Œé€šè¿‡æœ€å°åŒ–ä¸¤è€…çš„rmsï¼Œæ‰¾åˆ°ç¬¦åˆçš„å°$\\Delta p$è¯´æ˜è¯¥ç‰¹å¾å®Œå¥½ï¼Œå¦åˆ™è¯¥ç‰¹å¾å¯èƒ½å·²ç»æ¶ˆå¤±ï¼Œåˆ™ä¸å†å¯¹è¯¥ç‰¹å¾è¿›è¡Œè¿½è¸ª\n\n\n","categories":["CV"]},{"title":"Chatbots","url":"/2021/08/15/nlp%20learning/Chapter12_Chatbots/","content":"Chatbots\n\n1. What is Chatbots /Dialogue1.1 Two kind of conversational agents(Task-based) Dialogue Agents(Close domain)\n\nPersonal assistant, help users achieve a certain task in vertical domains, e.g., education and medical\n\nCombination of rules and statistical components\n\nFrames with slots and values: a set of slots, to be filled with information of a given type. Each associated with a question to the user.\n\n\nChatbots (Open domain)\n\nNo specific goal, focus on humanlike conversations\n\nFor fun, or even for therapy\n\nRule-based: Pattern-action rules (ELIZA) + A mental model (PARRY): The first system to pass the Turing Test!\n\nCorpus-based: Information Retrieval (XiaoIce) or Neural encoder-decoder (variants of E2E seq2seq model) (BlenderBot)\n\n\n\n2. Properties of Human Conversation2.1 propertites\n\nTurns\n\nWe call each contribution a â€œturnâ€\n\n\nInterruptions and Barge-in:Allowing the user to interrupt\n\nEnd-pointing\n\nThe task for a speech system of deciding whether the user hasstopped talking.\n\n\n\n\nEach turn (utterance in a dialogue is a kind of action\n\nConstatives: committing the speaker to somethingâ€™s being the case\n\nä½¿è¯´è¯è€…ç¡®ä¿¡æŸäº‹æ˜¯çœŸå®çš„\nanswering , claiming , confirming , denying , disagreeing , stating \n\n\nDirectives: attempts by the speaker to get the addressee to do\næ¼”è®²è€…è¯•å›¾è®©æ”¶ä»¶äººè¿™æ ·åš\nadvising , asking , forbidding , inviting , ordering , requesting\n\n\nCommissives: committing the speaker to some future course of action\nè®©æ¼”è®²è€…å¯¹æœªæ¥çš„è¡ŒåŠ¨åšå‡ºæ‰¿è¯º\npromising, planning, vowing, betting, opposing\n\n\nAcknowledgments: express the speakerâ€™s attitude regarding the hearerwith respect to some social action \nè¡¨è¾¾è¯´è¯äººå¯¹å¬è¯äººå…³äºæŸäº›ç¤¾ä¼šè¡Œä¸ºçš„æ€åº¦\napologizing , greeting , thanking , accepting an acknowledgment \n\n\n\n2.1 Grounding\nParticipants in conversation or any joint activity need to establish common ground.\nå¯¹è¯åº”è¯¥å»ºç«‹äºå¯¹äº‹å®çš„ä¸€è‡´ç†è§£ä¸Š\n\n\nPrinciple of closure . Agents performing an action require evidence, sufficient forcurrent purposes, that they have succeeded in performing it \n\nå°é—­åŸåˆ™ã€‚æ‰§è¡ŒæŸé¡¹æ“ä½œçš„ä»£ç†éœ€è¦è¶³å¤Ÿçš„è¯æ®ï¼Œè¯æ˜ä»–ä»¬å·²æˆåŠŸæ‰§è¡Œè¯¥æ“ä½œ\n\n\nSpeech is an action too! So speakers need to ground each otherâ€™s utterances.\n\nè¯­è¨€ä¹Ÿæ˜¯è¡ŒåŠ¨ï¼å› æ­¤ï¼Œæ¼”è®²è€…éœ€è¦è®©å¯¹æ–¹çš„è¯è¯­æœ‰æ ¹æ®ã€‚\nGrounding : acknowledging that the hearer has understood æ‰¿è®¤å¬è€…å·²ç»ç†è§£\n\n\n\n2.1.1 Grounding: Establishing Common Ground\n\né€šè¿‡ä¸€äº›ç‰¹æ®Šçš„è¿è´¯è¯å¯ä»¥ç¼“è§£å°´å°¬ã€‚\n\n\n2.2 Conversations have structure\nLocal structure between adjacent speech acts, from the field of conversational analysis ä»ä¼šè¯åˆ†æçš„è§’åº¦çœ‹ç›¸é‚»è¨€è¯­è¡Œä¸ºä¹‹é—´çš„å±€éƒ¨ç»“æ„\n\nCalled adjacency pairs: \n\nQUESTION â€¦ A NSWER\nPROPOSAL â€¦ A CCEPTANCE /R EJECTION\nCOMPLIMENTS (â€œNice jacket!â€)â€¦ DOWNPLAYER (â€œOh, this old thIng?â€)\n\n\n\n2.3 Another kind of structure: Subdialogues\nCorrection subdialogue å­å¯¹è¯çš„æ­£ç¡®æ€§\n\nè¦ä¿è¯å¯ä»¥ä»»æ„æ’å…¥å­å¯¹è¯ï¼Œä¸”å­å¯¹è¯çš„ç»“æœæ˜¯å¯¹çš„ï¼Œå¹¶ä¸”å¯èƒ½å½±å“åˆ°åŸæ¥çš„å¯¹è¯\nAgent : OK. Thereâ€™s #two non stops# ç›´è¾¾ç«™\nClient: #Act actually#, what day of the week is the 15th?\nAgent : Itâ€™s a Friday\nClient: Uh hmm. I would consider staying there an extra day til Sunday. \nAgent : OKâ€¦OK. On Sunday I have â€¦\n\n\nClarification Subdialogues\n\nUser : What do you have going to UNKNOWN WORD on the 5th?\nSystem: Letâ€™s see, going where on the 5th\nUser: Going to Hong Kong. æ¾„æ¸…å»å“ªé‡Œ\nSystem : OK, here are some flightsâ€¦\n\n\nPresequences å¯èƒ½åœ¨æ­£å¼å¼€å§‹å¯¹è¯æœ‰ä¸ªå¼€åœº\n\nUser : Can you make train\nSystem : Yes I can\nUser : Great, Iâ€™d like to reserve a seat on the 4pm train to New York.\n\n\n\n2.4 Conversational Initiative\nå¯¹è¯çš„ä¸»åŠ¨æƒ\n\nSome conversations are controlled by one person æœ‰äº›å¯¹è¯ç”±ä¸€ä¸ªäººæ§åˆ¶\n\nA reporter interviewing a chef asks questions, and the chef responds.ä¸€ä½é‡‡è®¿å¨å¸ˆçš„è®°è€…é—®äº†ä¸€äº›é—®é¢˜ï¼Œå¨å¸ˆå›ç­”ã€‚\nThis reporter has the conversational initiative This reporter has the conversational initiative\n\n\nMost human conversations have mixed initiative : å¤§å¤šæ•°äººé™…å¯¹è¯éƒ½æœ‰æ··åˆçš„ä¸»åŠ¨æ€§ï¼š\nI lead, then you lead, then I lead.\n\n\nMixed initiative is very hard for NLP systems, which often default to simpler styles that can be frustrating for humans: æ··åˆä¸»åŠ¨å¯¹NLPéå¸¸å›°éš¾ï¼Œå› ä¸ºNLPç»å¸¸é»˜è®¤é‡‡ç”¨æ›´ç®€å•çš„æ¨¡å¼\nUser initiative (user asks or commands, system\nSystem initiative (system asks user questions to fill out a form, user canâ€™t change the direction)\n\n\n\n2.5 Even harder problems: Inference\næ¨ç†\nAgent: And, what day in May did you want to travel?\n\nClient : OK, uh, I need to be there for a meeting thatâ€™s from the 12th to the 15th.\n\n\n3. Rule based Chatbots3.1 Eliza pattern/transform rules\nå¤§æ¦‚æ€æƒ³å°±æ˜¯æå–å…³é”®è¯ï¼Œç„¶åæ ¹æ®åº“é‡Œå…³é”®è¯å¯¹åº”çš„ç­”æ¡ˆè¿›è¡Œæ’åº\n\ns/. Iâ€™M ( depressed|sad ) ./I AM SORRY TO HEAR YOU ARE 1/\n\ns/. I AM ( depressed|sad ) ./WHY DO YOU THINK YOU ARE 1/\n\ns/. all ./IN WHAT WAY?/\n\ns/. always ./CAN YOU THINK OF A SPECIFIC EXAMPLE?/\n\n\n\n0 means *\nThe 3 is the constituent # in pattern\n\nexample\n\nYou hate me\nWHAT MAKES YOU THINK I HATE YOU\n\n\n\n\nUser: I know everybody laughed at me\nâ€œIâ€ is very general:\n\nI: (I *)â€”&gt; (YOU SAY YOU)\nELIZA: YOU SAY YOU KNOW EVERYBODY LAUGHED AT YOU\n\n\nâ€œEverybodyâ€ is more specific and interesting\n\nEverybody: (Everybody *)â€”&gt; (WHO IN PARTICULAR ARE YOU THINKING\nELIZA: WHO IN PARTICULAR ARE YOU THINKING OF?\n\n\nImplementation: keywords stored with their rank\nEverybody 5 (list of transformation rules\nI                   0 (list of transformation rules\n\n\n\n\n3.1.1 Memory\nå¦‚ä½•å¯¹å¯¹è¯è¿›è¡Œå­˜å‚¨-&gt;ç”¨äºè¿›è¡Œåç»­ç­”æ¡ˆæå–ï¼Œä¸‹é¢ä¸¾çš„æ˜¯æå–MYå…³é”®è¯ï¼Œéšæœºé€‰æ‹©ä¸€ç§å˜æ¢è¿›è¡Œå­˜å‚¨ã€‚\n\n\n\nWhenever â€œMYâ€ is highest keyword å¯¹ä¸€äº›è¯­å¥è¿›è¡Œå­˜å‚¨\nRandomly select a transform on the MEMORY list\nApply to sentence \nStore on a (first in first out) queue\n\n\nLater, if no keyword matches a sentence å¦‚æœæ²¡æœ‰å…³é”®è¯åŒ¹é…ï¼Œå°±è¿”å›é˜Ÿé¦–\nReturn the top of the MEMORY queue instead\n\n\n\n3.1.2 Ethical implications: Anthropomorphism and Privacy\nå¤§è‡´æ˜¯ä¸€äº›äººæ²‰è¿·äºå’ŒèŠå¤©æœºå™¨äººè°ˆè¯ï¼Œè¿˜è¦æ±‚ä»–ä»¬çš„å¯¹è¯å…·æœ‰éšç§æ€§\n\n3.2 PARRY: A computational model of schizophrenia\nAnother chatbot with a clinical psychology focus\nUsed to study schizophrenia ç²¾ç¥åˆ†è£‚ç—‡\n\nSame pattern response structure as Eliza\n\nBut a much richer:\ncontrol structure æ§åˆ¶ç»“æ„\nlanguage understanding capabilities è¯­è¨€ç†è§£èƒ½åŠ›\nmodel of mental state. å¿ƒç†çŠ¶æ€æ¨¡å‹ã€‚\nvariables modeling levels of Anger, Fear, Mistrust\næ¨¡æ‹Ÿæ„¤æ€’ã€ææƒ§ã€ä¸ä¿¡ä»»ç¨‹åº¦çš„å˜é‡\n\n\n\n\n\n3.2.1 model of mental state å¿ƒç†çŠ¶æ€æ¨¡å‹\nAffect variables\nFear (0 20)           Anger (0 20)         Mistrust (0 15)\n\nStart with all variables low\n\nAfter each user turn\nEach user statement can change Fear and Anger\nE.g., Insults increases Anger, Flattery decreases Anger\nMentions of his delusions increase Fear\n\n\n\n\n\n3.2.2 Parryâ€™s responses depend on mental state\n4. Corpus based Chatbots\nDialogue as a Markov Decision Process (MDP)\nGiven state ğ’”, select action ğ’‚ according to (hierarchical) policy ğ… \nç»™å®šçŠ¶æ€ğ’”, é€‰æ‹©åŠ¨ä½œğ’‚ æ ¹æ®ï¼ˆåˆ†çº§ï¼‰æ”¿ç­–ğ…\n\n\nReceive reward ğ’“, observe new state s sâ€²\nè§‚å¯Ÿæ–°çš„çŠ¶æ€ï¼Œæ”¶åˆ°å“åº”å¥–åŠ±r\n\n\nContinue the cycle until the episode terminates.\nç»§ç»­å¾ªç¯ç›´åˆ°å¯¹è¯æƒ…èŠ‚ç»“æŸ\n\n\n\n\nGoal of dialogue learning: find optimal ğ… to maximize expected rewards\n\nå¯¹è¯å­¦ä¹ çš„ç›®æ ‡ï¼šæ‰¾åˆ°æœ€ä½³ğ… æœ€å¤§åŒ–é¢„æœŸå›æŠ¥\n\n\nA unified view: dialogue as optimal decision making Dialogue\n\n\n\n4.1 Two architectures for corpus based chabots\nResponse by retrieval  æ£€ç´¢å“åº”\nUse information retrieval to grab a response (that is appropriate to the context) from some corpus ä½¿ç”¨ä¿¡æ¯æ£€ç´¢ä»ä¸€äº›è¯­æ–™åº“ä¸­è·å–å“åº”ï¼ˆé€‚åˆä¸Šä¸‹æ–‡ï¼‰\n\n\nResponse by generation ç”Ÿæˆå“åº”\n\nUse a language model or encoder decoder to generate the response given the dialogue context  åœ¨ç»™å®šå¯¹è¯ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨è¯­è¨€æ¨¡å‹æˆ–ç¼–ç å™¨-è§£ç å™¨ç”Ÿæˆå“åº”\n\n\nModern corpus based chatbots are very data-intensive \n\nç°ä»£åŸºäºè¯­æ–™åº“çš„èŠå¤©æœºå™¨äººéå¸¸æ•°æ®å¯†é›†\n\n\nThey commonly require hundreds of millions or billions of words\n\n\n\n4.2 Response by retrieval: classic IR method\nGiven a user turn  , and a training corpus  of conversation\nFind in  the turn  that is most similar ( tf idf cosine) to q\nSay r\n\n\n\\operatorname{response}(q, C)=\\underset{r \\in C}{\\operatorname{argmax}} \\frac{q \\cdot r}{|q||r|}\næ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œåªæ˜¯æ¢äº†è®¡ç®—ç›¸ä¼¼åº¦çš„æ–¹æ³•ï¼š\n\n\n\\begin{aligned}\nh_{q} &=\\operatorname{BERT}_{Q}(\\mathrm{q})[\\mathrm{CLS}] \\\\\nh_{r} &=\\operatorname{BERT}_{R}(\\mathrm{r})[\\mathrm{CLS}] \\\\\n\\operatorname{response}(q, C) &=\\underset{r \\in C}{\\operatorname{argmax}} h_{q} \\cdot h_{r}\n\\end{aligned}4.2.1 Response by retrieving and refining knowledge\nCan generate responses from informative text rather than dialogue?\nåˆ©ç”¨IRè¿›è¡Œä¿¡æ¯æ£€ç´¢å¾—åˆ°ç­”æ¡ˆ\nTo respond to turns like â€œTell me something about Beijingâ€\nXiaoIce collects sentences from public lectures and news articles.\nAnd searches them using IR based on query expansion from userâ€™s turn\n\n\nAugment encoder decoder model\nå¢å¼ºç¼–ç è§£ç æ¨¡å‹\nuse IR to retrieve passages from Wikipedia\nconcatenate each Wikipedia sentence to the dialogue context with a separator token. ä½¿ç”¨åˆ†éš”ç¬¦æ ‡è®°å°†æ¯ä¸ªWikipediaå¥å­è¿æ¥åˆ°å¯¹è¯ä¸Šä¸‹æ–‡ã€‚\nGive as encoder context to the encoder decoder model, which learns to incorporate text into its response ä¸ºç¼–ç å™¨-è§£ç å™¨æ¨¡å‹æä¾›ç¼–ç å™¨ä¸Šä¸‹æ–‡ï¼Œè¯¥æ¨¡å‹å­¦ä¹ å°†æ–‡æœ¬åˆå¹¶åˆ°å…¶å“åº”ä¸­\n\n\n\n\n\n4.3 Response by generation\nThink of response production as an encoder-decoder task\nGenerate each token  of the response by conditioning on the encoding of the entire query  and the response so far â€‹\nç”Ÿæˆæ¯ä¸ªtokenæ˜¯åŸºäºæ•´ä¸ªæŸ¥è¯¢çš„ç¼–ç qï¼Œä»¥åŠè¿‡å»çš„çš„token\n\n\n\n\n\\hat{r}_{t}=\\operatorname{argmax}_{\\mathrm{w} \\in \\mathrm{V}} P\\left(w \\mid q, r_{1} \\ldots r_{t-1}\\right)\n\n\nAlternative approach: fine tune a large language model on conversational data\n\nThe Chirpy Cardinal system (Paranjape et al., 2020):\n\nfine tunes GPT 2\non the E MPATHETIC D IALOGUES dataset ( Rashkin et al., 2019)\n\n\nOngoin research problems: Neural chatbots can get repetitive, bland, and inconsistent ç¥ç»èŠå¤©æœºå™¨äººä¼šå˜å¾—é‡å¤ã€ä¹å‘³å’Œä¸ä¸€è‡´\n\n\n\n4.4 Challenge: The blandness problem\n\nå›ç­”è¿‡äºæ— è¶£\n\nBlandness problem: cause and remedies åŸå› å’Œæ”¹å–„\n\nCommon MLE objective (maximum likelihood) éƒ½ä½¿ç”¨æœ€å¤§ä¼¼ç„¶å‡½æ•°è¿›è¡Œä¼˜åŒ–\n\n\n\nåˆ©ç”¨äº’ä¿¡æ¯æ”¹å–„ Mutual information objective:\nåŒæ—¶ä¼˜åŒ–åŒæ–¹çš„æ¡ä»¶æ¦‚ç‡ï¼Œä½¿å¾—ç­”æ¡ˆå’Œé—®é¢˜æ›´ç›¸å…³\n\n\n\n\nMutual Information for Neural Network Generation\nMutual information objective:\n\n\n\n\n\nå¸Œæœ›Targeèƒ½ç”ŸæˆSourceçš„æ¦‚ç‡åº”è¯¥æœ€å°ï¼Œä»è€Œå¢åŠ çº¦æŸ\n\nSample outputs\n\n\n\n4.5 Challenge: The consistency problem\nå³å‰åä¸ä¸€è‡´é—®é¢˜\n\nE2E systems often exhibit poor response consistency :\n\n\n\n\nConversational data:\nåŸå› å‡ºåœ¨æ•°æ®é›†æœ¬èº«å°±ä¸æ˜¯1å¯¹1å…³ç³»\n\n\n\n\n\n\nè§£å†³æ–¹æ³•ï¼Œå°†æ¯ä¸ªé—®ç­”ç¼–ç åŠ å…¥ä¸ªäººåŒ–ä¿¡æ¯ï¼Œä½¿å¾—ç­”æ¡ˆå”¯ä¸€ï¼Œå‡å°‘æ­§ä¹‰æ€§ã€‚\n\n\n4.5.1 Personal modeling as multi-task learning\n\nImproving personalization with multiple losses\n\n\n\nä¼˜åŒ–ï¼Œä½¿äººç‰©è§’è‰²å¯ä»¥â€œé¢„æµ‹â€è‡ªå·±çš„ååº”\nåšæ³•å¦‚å›¾å„è‡ªç»è¿‡ä¸€ä¸ªéšè—å±‚ï¼Œç„¶åæœ€åcatåå†ç»è¿‡ä¸€ä¸ªéšè—å±‚ä½œä¸ºæœ€åè¾“å‡ºï¼Œä¼˜åŒ–å››éƒ¨åˆ†çš„æŸå¤±ï¼Œå¢åŠ å¯¹èº«ä»½çš„çº¦æŸ\n\n4.6 Challenge: Long conversational context\nå¯¹é•¿å¯¹è¯æ— è®°å¿†æ€§\n\nIt can be challenging for LSTM/GRU to encode very long context (i.e. more than 200 words: Khandelwal + 18\n\nHierarchical Encoder Decoder (HRED) Serban + 16\n\nEncodes: utterance (word by word) + conversation (turn by turn) ç¼–ç ï¼šè¯è¯­ï¼ˆé€å­—ï¼‰+å¯¹è¯ï¼ˆé€å¥ï¼‰å°±æ˜¯æ—¢è¦æŠŠå½“å‰çš„è¯è¯­ç¼–ç ï¼Œä¹Ÿè¦æŠŠå†å²æ‰€æœ‰è¯­æ–™è¿›è¡Œç¼–ç \n\n\n\n\n\nHierarchical Latent Variable Encoder Decoder (VHRED) Serban+ 17\nAdds a latent variable to the decoder å‘è§£ç å™¨æ·»åŠ ä¸€ä¸ªæ½œåœ¨å˜é‡\nTrained by maximizing variational lower bound on the log likelihood Related\né€šè¿‡æœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶ç›¸å…³å‡½æ•°çš„å˜åˆ†ä¸‹ç•Œè¿›è¡Œè®­ç»ƒ\n\n\n\n\n\n\n5. Hybrid Architectures\nChirpy Cardinal (Paranjape et al., 2020) response generation from a series of different generators\nGPT 2 finetuned on EmpatheticDialogues\nGPT 2 finetuned to paraphrase content è§£æå†…å®¹ from Wikipedia  \nRule based movie or music generators that produce scripted conversation about a movie or a musician åŸºäºè§„åˆ™çš„ç”µå½±æˆ–éŸ³ä¹ç”Ÿæˆå™¨ï¼Œç”¨äºç”Ÿæˆæœ‰å…³ç”µå½±æˆ–éŸ³ä¹å®¶çš„è„šæœ¬å¼å¯¹è¯\nasking the userâ€™s opinion about a movie,\ngiving a fun fact,\nasking the user their opinion on an actor in the movie.\n\n\n\n6. The Frame based (â€œGUSâ€) Dialogue Architecture åŸºäºæ¡†æ¶çš„ï¼ˆâ€œGUSâ€ï¼‰å¯¹è¯æ¶æ„\nSometimes called â€œ task based dialogue agentsâ€\n\nSystems that have the goal of helping a user solve a task like making a travel reservation or buying a product æ—¨åœ¨å¸®åŠ©ç”¨æˆ·è§£å†³æ—…è¡Œé¢„è®¢æˆ–è´­ä¹°äº§å“ç­‰ä»»åŠ¡çš„ç³»ç»Ÿ\n\n\nArchitecture:\n\nFirst proposed in the GUS system of 1977\nA knowledge structure representing user intentions è¡¨ç¤ºç”¨æˆ·æ„å›¾çš„çŸ¥è¯†ç»“æ„\nOne or more frames (each consisting of slots with values ä¸€ä¸ªæˆ–å¤šä¸ªå¸§ï¼ˆæ¯ä¸ªå¸§ç”±å¸¦å€¼çš„æ’æ§½ç»„æˆï¼‰\n\n\n\n6.1 The Frame\nA set of slots , to be filled with information of a given type\nä¸€ç»„æ’æ§½ï¼Œç”¨äºå¡«å……ç»™å®šç±»å‹çš„ä¿¡æ¯\n\n\nEach associated with a question to the user\næ¯ä¸ªéƒ½ä¸ç”¨æˆ·çš„ä¸€ä¸ªé—®é¢˜ç›¸å…³è”\n\n\nSometimes called a domain ontology\næœ‰æ—¶ç§°ä¸ºé¢†åŸŸæœ¬ä½“\n\n\n\n\n6.2 Control structure for GUS frame architecture\nSystem asks questions of user, filling any slots that user specifies\n\nUser might fill many slots at a time:\n\nI want a flight from San Francisco to Denver one way leaving after five p.m . on Tuesday\n\n\nWhen frame is filled, do database query\n\n\n6.3 GUS slots have condition action rules attached\nGUSæ’æ§½é™„å¸¦äº†æ¡ä»¶æ“ä½œè§„åˆ™\n\nSome rules attached to the DESTINATION slot for the plane booking frame\n\né£æœºé¢„è®¢æ¡†æ¶ä¸­çš„ç›®çš„åœ°æ—¶æ®µé™„åŠ çš„ä¸€äº›è§„åˆ™\n\n\nOnce the user has specified the destination\nä¸€æ—¦ç”¨æˆ·æŒ‡å®šäº†ç›®çš„åœ°\nEnter that city as the default StayLocation for the hotel booking frame.\nè¾“å…¥è¯¥åŸå¸‚ä½œä¸ºé…’åº—é¢„è®¢æ¡†æ¶çš„é»˜è®¤ä½ç½®ã€‚\n\n\nOnce the user has specified DESTINATION DAY for a short trip\n\nä¸€æ—¦ç”¨æˆ·æŒ‡å®šäº†çŸ­é€”æ—…è¡Œçš„ç›®çš„åœ°æ—¥æœŸ\nAutomatically copy as ARRIVAL DAY. è‡ªåŠ¨å¤åˆ¶ä¸ºåˆ°è¾¾æ—¥æœŸ\n\n\nFrames like:\n\nCar or hotel reservations\nGeneral route information\nWhich airlines fly from Boston to San Francisco? ,\n\n\nInformation about airfare practices\nDo I have to stay a specific number of days to get a decent airfare?.\n\n\nFrame detection:\nSystem must detect which slot of which frame user is filling\nç³»ç»Ÿå¿…é¡»æ£€æµ‹ç”¨æˆ·æ­£åœ¨å¡«å……å“ªä¸ªå¸§çš„å“ªä¸ªæ’æ§½\nAnd switch dialogue control to that frame.\nå¹¶å°†å¯¹è¯æ§åˆ¶åˆ‡æ¢åˆ°è¯¥å¸§ã€‚\n\n\n\n6.3.1 GUS: Natural Language Understanding for filling dialog slots\nDomain classification  é¢†åŸŸåˆ†ç±»\n\nAsking weather? Booking a flight? Programming alarm clock?\n\n\nIntent Determination  æ„å›¾ç¡®å®š\n\nFind a Movie, Show Flight, Remove Calendar Appt\n\n\nSlot Filling  æ’æ§½å¡«å……\n\nExtract the actual slots and fillers æå–å®é™…æ’æ§½å’Œå¡«å……å™¨\n\n\n\n\n\n6.4.2 How to fill slots-&gt;Rule based Slot filling\nWrite regular expressions or grammar rules\nWake me (up) | set (the|an ) alarm | get me up\n\nDo text normalization\n\nA template is a pre-built response string æ¨¡æ¿æ˜¯é¢„æ„å»ºçš„å“åº”å­—ç¬¦ä¸²\n\nTemplates can be fixed \n\nâ€œHello, how can I help you?â€\n\n\nOr have variables\nâ€œWhat time do you want to leave CITY ORIG?â€\nâ€œWill you return to CITY ORIG from CITY DEST?â€\n\n\n\n6.5 A more sophisticated å¤æ‚çš„ version of the frame based architecture6.5.1 A Multi-turn Task oriented Dialogue state Architecture\n6.5.2 Components in a dialogue state architecture\nå¯¹è¯çŠ¶æ€ä½“ç³»ç»“æ„ä¸­çš„ç»„ä»¶\nLU:extracts slot fillers from the userâ€™s utterance using machine learning\nLUï¼šä½¿ç”¨æœºå™¨å­¦ä¹ ä»ç”¨æˆ·çš„è¯è¯­ä¸­æå–æ§½å¡«å……\n\n\nDialogue state tracker:maintains the current state of the dialogue (userâ€™s most recent dialogue act, set of slot filler constraints from user has expressed so far).\nå¯¹è¯çŠ¶æ€è·Ÿè¸ªå™¨ï¼šç»´æŠ¤å¯¹è¯çš„å½“å‰çŠ¶æ€ï¼ˆç”¨æˆ·æœ€è¿‘çš„å¯¹è¯è¡Œä¸ºï¼Œç”¨æˆ·è¿„ä»Šä¸ºæ­¢è¡¨è¾¾çš„ä¸€ç»„æ’æ§½å¡«å……çº¦æŸï¼‰ã€‚\n\n\nDialogue policy: decides what the system should do or say next\nå¯¹è¯æ”¿ç­–ï¼šå†³å®šç³»ç»Ÿä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆæˆ–è¯´ä»€ä¹ˆ\nGUS policy: ask questions until the frame was full then report back the results of some database query\nGUSç­–ç•¥ï¼šè¯¢é—®é—®é¢˜ï¼Œç›´åˆ°æ¡†æ¶å·²æ»¡ï¼Œç„¶åæŠ¥å‘Šä¸€äº›æ•°æ®åº“æŸ¥è¯¢çš„ç»“æœ\n\n\nMore sophisticated: know when to answer questions, when to ask a clarification question, when to make a suggestion,etc\næ›´å¤æ‚ï¼šçŸ¥é“ä½•æ—¶å›ç­”é—®é¢˜ã€ä½•æ—¶æå‡ºæ¾„æ¸…é—®é¢˜ã€ä½•æ—¶æå‡ºå»ºè®®ç­‰\n\n\n\n\nNLG: produce more natural, less templated utterances\n\n6.6 Dialogue Acts\nCombine the ideas of speech acts and grounding into a single representation\nå°†è¨€è¯­è¡Œä¸ºå’ŒåŸºç¡€çš„æ€æƒ³ç»“åˆæˆä¸€ä¸ªå•ä¸€çš„è¡¨è¾¾\n\n\n\n\n\n6.7 How to fill slots - Machine learning Slot filling\nMachine learning classifiers to map words to semantic frame fillers\næœºå™¨å­¦ä¹ åˆ†ç±»å™¨å°†å•è¯æ˜ å°„åˆ°è¯­ä¹‰æ¡†æ¶å¡«å……è¯\n\n\nGiven a set of labeled sentences\nInput:\nI want to fly to San Francisco on Monday pleaseâ€\n\n\nOutput: \nDestination: SF\nDepart-time: Monday\n\n\n\n\nBuild a classifier to map from one to the other Requirements: Lots of labeled data\næ„å»ºä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå°†ä¸€ä¸ªéœ€æ±‚æ˜ å°„åˆ°å¦ä¸€ä¸ªéœ€æ±‚ï¼šå¤§é‡æ ‡è®°æ•°æ®\n\n\n\n6.7.1 Slot filling as sequence labeling: BIO tagging\nThe BIO tagging paradigm\n\nIdea: Train a classifier to label each input word with a tag that tells us what slot (if any) it fills\n\næƒ³æ³•ï¼šè®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨ï¼Œç”¨ä¸€ä¸ªæ ‡ç­¾æ ‡è®°æ¯ä¸ªè¾“å…¥å•è¯ï¼Œå‘Šè¯‰æˆ‘ä»¬å®ƒå¡«å……äº†ä»€ä¹ˆæ§½ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰\n\n\n\n\n\nWe create a B and I tag for each slot type \nAnd convert the training data to this format\n\nSlot filling using contextual embeddings\n\nOnce we have the BIO tag of the sentence\n\n\nWe can extract the filler string for each slot\næˆ‘ä»¬å¯ä»¥æå–æ¯ä¸ªæ’æ§½çš„å¡«å……å­—ç¬¦ä¸²\n\n\nAnd then normalize it to the correct form in the ontology\nç„¶åå°†å…¶è§„èŒƒåŒ–ä¸ºæœ¬ä½“ä¸­çš„æ­£ç¡®å½¢å¼\n\n\nLike â€œSFOâ€ for San Francisco\nUsing homonym dictionaries (SF=SFO=San Francisco)\nä½¿ç”¨åŒåè¯å…¸ï¼ˆSF=SFO=San Francisco\n\n\n\n6.8 The task of dialogue state tracking\nå¯ä»¥ç®€å•ç†è§£ä¸ºä¸€ç›´ä¿ç•™åŸæ¥çš„slotç›´åˆ°æ»¡\n\n\n\n\nDialogue act interpretation algorithm: å¯¹è¯è¡Œä¸ºè§£é‡Šç®—æ³•ï¼š\n1 of N supervised classification to choose inform Nä¸ªç›‘ç£åˆ†ç±»ä¸­çš„1ä¸ªé€‰æ‹©ä¿¡æ¯\nBased on encodings of current sentence + prior dialogue acts åŸºäºå½“å‰å¥å­çš„ç¼–ç +å…ˆå‰çš„å¯¹è¯è¡Œä¸º\n\n\nSimple dialogue state tracker: ç®€å•å¯¹è¯çŠ¶æ€è·Ÿè¸ªå™¨ï¼š\nRun a slot filler after each sentence åœ¨æ¯ä¸ªå¥å­åè¿è¡Œæ’æ§½å¡«å……ç¨‹åº\n\n\n\nAn special case of dialogue act detection:Detecting Correction Acts\n\nIf system misrecognizes an utterance\nUser might make a correction\nRepeat themselves\nRephrasing é‡æ–°æªè¾\nSaying â€œnoâ€ to a confirmation question\n\n\n\nFeatures for detecting corrections in spoken dialogue\n\n6.9 Dialogue Policy\nAt turn  predict action  to take, given entire history:\n\n\n\\hat{A}_{i}=\\underset{A_{i} \\in A}{\\operatorname{argmax}} P\\left(A_{i} \\mid\\left(A_{1}, U_{1}, \\ldots, A_{i-1}, U_{i-1}\\right)\\right.\nSimplify by just conditioning on the current dialogue state (filled frame slots) and the last turn by system and user: åªéœ€è°ƒèŠ‚å½“å‰å¯¹è¯çŠ¶æ€ï¼ˆå¡«å……çš„å¸§æ§½ï¼‰å’Œæœ€åä¸€åœˆä»¥åŠç³»ç»Ÿå’Œç”¨æˆ·çš„åœˆæ•°å³å¯ç®€åŒ–\n\n\n\\hat{A}_{i}=\\underset{A_{i} \\in A}{\\operatorname{argmax}} P\\left(A_{i} \\mid \\text { Frame }_{i-1}, A_{i-1}, U_{i-1}\\right)6.9.1 Policy example: Confirmation and Rejection\nDialogue systems make errors\nSo they to make sure they have understood user\nTwo important mechanisms:\nconfirming understandings with the user\nrejecting utterances è¯è¯­ that the system is likely to have misunderstood.\n\n\n\n6.9.2 ConfirmationExplicit confirmation strategy\n\nImplicit confirmation strategy\n\nConfirmation strategy tradeoffs\n\nExplicit confirmation makes it easier for users to correct the systemâ€™s misrecognitions since a user can just answer â€œnoâ€ to the confirmation question.\nBut explicit confirmation is also awkward and increases the length of the conversation ( Danieli and Gerbino 1995, Walker et al. 1998).\n\n6.9.3 Rejection\nProgressive prompting for rejection\nDonâ€™t just repeat the question â€œWhen would you like to leave?â€ Give user guidance about what they can say:\n\n\nUsing confidence to decide whether to confirm:\nASR or NLU systems can assign a confidence value indicating how likely they are that they understood the user.\nAcoustic log-likelihood of the utterance å£°éŸ³çš„å¯¹æ•°ä¼¼ç„¶æ€§\nProsodic features éŸµå¾‹ç‰¹å¾\nRatio of score of best to second-best interpretation æœ€ä½³å£è¯‘å¾—åˆ†ä¸æ¬¡ä¼˜å£è¯‘å¾—åˆ†ä¹‹æ¯”\n\n\nSystems could use set confidence thresholds:\n\n\n\\begin{array}{lll}\n","categories":["nlp"]},{"title":"é¢˜ç›®","url":"/2021/08/15/knowledge%20engineering/%E9%A2%98%E7%9B%AE/","content":"é¢˜ç›®\n1. XML RdfAuthoring guidelines:\n\nAll elements must have an end tag. æ ‡ç­¾æœ‰å¤´æœ‰å°¾\nAll elements must be cleanly nested (overlapping elements are not allowed). æ‰€æœ‰å…ƒç´ å¿…é¡»ä¸èƒ½é‡å¤\nAll attribute values must be enclosed in quotation marks. \nEach document must have a unique first element, the root node.\nå¤§å°å†™æ•æ„Ÿ\n\n&lt;book&gt;\t&lt;title&gt;Knowledge Graph&lt;/Title&gt; &lt;!--å°¾æ ‡ç­¾æœ‰è¯¯--&gt;\t&lt;author&gt;\t\t&lt;firstName&gt;Guilin&lt;/firstName&gt;\t\t&lt;lastName&gt;Qi&lt;/lastName&gt;\t\t&lt;email&gt;gqi@seu.edu.cn&lt;/email&gt;\t\tThis is some text inside an XML element.\t&lt;/author&gt;\t&lt;author&gt;\t\t&lt;firstName&gt;Tianxing&lt;lastName&gt;\t\t&lt;/firstName&gt;Wu&lt;/lastName&gt; &lt;!--åµŒå¥—å‡ºé”™--&gt;\t&lt;email&gt;tianxingwu@seu.edu.cn&lt;/email&gt;&lt;/author&gt;&lt;!--ç¼ºå°‘&lt;/book&gt;--&gt;\n&lt;!--Typed Literals:--&gt;â€œBeantownâ€^^xsd:stringâ€œThe Bay Stateâ€ ^^xsd:string&lt;!--Plain literal and literals with language tags:--&gt;â€œFranceâ€ â€œFranceâ€@en â€œFranceâ€@frâ€œæ³•å›½â€@zh â€œFrankreichâ€@de&lt;!--Equalities for Literals:--&gt; â€œ001â€^^xsd:integer = â€œ1â€^^xsd:integer â€œ123.0â€^^xsd:decimal = â€œ00123â€^^xsd:integer (based on datatype hierarchy)&lt;!--ä¸Šé¢è¿™ä¸¤ç§å½¢å¼ç­‰ä»·ï¼Œå› ä¸ºintegeræ˜¯decimalçš„çˆ¶èŠ‚ç‚¹--&gt;\n\nNaming conflicts exist in different XML documents\n\nXML document_1&lt;table&gt;&lt;tr&gt;\t&lt;td&gt;Apples&lt;/td&gt;    &lt;td&gt;Bananas&lt;/td&gt;&lt;/ tr&gt;&lt;/table&gt;\n\nSolution \n\nXML document_1&lt;h:table&gt;\t&lt;h:tr&gt;\t\t&lt;h:td&gt;Apples&lt;/h:td&gt;        &lt;h:td&gt;Bananas&lt;/h:td&gt;    &lt;/h:tr&gt;&lt;/h:table&gt;\n\n2.Naming conflicts exist in different XML documents\n\nXML document_2&lt;table&gt;\t&lt;name&gt;African Coffee Table&lt;/name&gt;    &lt;width&gt;8G&lt; /width&gt;&lt;length&gt;120&lt;/length&gt;&lt; /table&gt;\n\nanswer\n\nXML document_2&lt; f:table&gt;\t&lt;f:name &gt;African Coffee lable&lt;/f:name&gt;    &lt;f:width&gt;80&lt;/f:width&gt;\t&lt;f:length&gt;120&lt;/f:length&gt;&lt;/f:table&gt;\n\n\nDoes the datatype â€œå¾·å›½â€ equals to â€œå¾·å›½â€ @ zh ?\nAnswerï¼šä¸ç›¸åŒï¼Œå› ä¸ºä»–ä»¬ä½äºçš„å±‚æ¬¡ç»“æ„ä¸åŒ\n\n\n\n\n\nURI è‹±æ–‡å­—ç¬¦   IRIä»»ä½•ç¼–ç \n\nEqualities for Literals:â€œ0013^^xsd:integer =â€œ13â€^^xsd:integerâ€œ123.0^^xsd:decimal= â€œ00123â€1^^xsd:integer (based on data type hierarchy)\nExercise\nDoes the datatypeâ€œå¾·å›½â€equals toâ€œå¾·å›½â€@ zh ?\n\nä¸ä¸€æ ·\n\nRDFè¡¨ç¤ºNå…ƒå…³ç³»\n\nç”¨ä¸€ä¸ªèŠ‚ç‚¹ä¸­ä»‹\n\n\n\nåˆ©ç”¨ä¸€ä¸ªç©ºèŠ‚ç‚¹\n\n\n\n@prefix sw: &lt;http://www.semanticweb.org/ontology-9/&gt;sw:John sw:is_a sw:professors;\t\tsw:has_id sw:987654321;\t\tsw:has_name sw:John Doe.\n\n\n\n\n\n\n\nRepresent the following sentence graphically by means of the blank node:Wikipedia said that Tolkien wrote Lord of the Rings.\n\n\n\nPlease represent the following sentences graphically by means of blank nodes.Jonathon says cherries taste sweet.1æœˆ14æ—¥ï¼Œå›½å®¶è¯ç›‘å±€å®£å¸ƒé…šé…ç‰‡åœæ­¢ç”Ÿäº§\n\n\n\nGivenï¼š\n\nex:happilyMarriedWith rdfs:subPropertyOf ex:isMarriedTo . ex:isMarriedTo rdfs:domain ex:Person . ex:isMarriedTo rdfs:range ex:Person . ex:pascal ex:happilyMarriedWith ex:lisa .\n\nå¯æ¨å‡ºï¼š\n\nex:pascal ex:isMarriedTo ex:lisa . ex:pascal rdf:type ex:Person . ex:lisa rdf:type ex:Person .\n\nWhat can be inferred from the following triples using RDFS semantics?\n\nex:Postgraduate_student rdfs:subClassOf ex:Student ex:Professor rdfs:subClassOf ex:Academic_staff ex:Supervise rdfs:domain ex:Professor ex:Supervise rdfs:range ex:Postgraduate_student ex:John ex:Supervise ex:Mary\nex:John rdf:type ex:Professor ex:Mary rdf:type ex:Postgraduate_student ex:John rdf:type ex:Academic_staffex:Mary rdf:type ex:Studentt\n\nWhat can be inferred from the following triples using RDFS semantics?\n\nex:Undergraduate_student rdfs:subClassOf ex:Student .ex:Postgraduate_student rdfs:subClassOf ex:Student .ex:Professor rdfs:subClassOf ex: Academic_staff .ex:Academic_staff rdfs:subClassOf ex:University_staff .ex:Teach rdfs:domain ex:Academic_staff .ex:Teach rdfs:range ex:Student .ex:Supervise rdfs:domain ex:Professor .ex:Supervise rdfs:range ex:Postgraduate_student .ex:John ex:Supervise ex:Mary .\nex:Professor rdfs:subClassOf ex: University_staff .ex:John rdf:type ex:Professor .ex:Mary rdf:type ex:Postgraudate_student .ex:John rdf:type ex:Academic_staff .ex:John rdf:type ex:University_staff .ex:Mary rdf:type ex:Student .\n\nsw:John sw:is_a sw:professors . sw:John sw:has_name â€œJohn Doeâ€ . sw:John sw:has_id â€œ987654321â€ .\nsw:John sw:is_a sw:professors ; \t\tsw:has_name â€œJohn Doeâ€ ; \t\tsw:has_id â€œ987654321â€ .\n\nUse a RDF graph to represent the sentence â€œJohn is working in a company located in Sydneyâ€ (bland node can be considered).\n\n\n\nDoes the datatype â€œ3.14â€^^xsd:string equal to â€œ+03.14â€^^xsd:string? If not, why?\n\nAnswer:ä¸æ˜¯ï¼›è¿™æ˜¯å­—ç¬¦ä¸²å½¢å¼ï¼Œå­—ç¬¦ä¸²è¦è€ƒè™‘æ¯ä¸ªcharacterï¼Œæ˜æ˜¾ä¸¤ä¸ªå­—ç¬¦ä¸²ä¸ä¸€æ ·ã€‚\n\n\n2. OWL Equivalence between classes, individuals, and properties: ä¸€äº›ç­‰ä»·å…³ç³»\nexp:Athlete owl:equivalentClass exp:SportsPlayer . exp:obtain owl:equivalentProperty exp:acquire . exp:SportsPlayerA owl:sameAs exp:Thomas .\nDisjointness between classes: ç±»åˆ«ä¸ç›¸äº¤å…³ç³»\nexp:Man owl:disjointWith exp:Woman .\nIntersection of classes: äº¤é›†\nexp:Mother rdf:type owl:class ; \t\t   owl:intersectionOf (exp:Woman exp:Parent) .\n\nè¿™é‡Œæ‹¬å·é‡Œé¢å¯ä»¥æœ‰æ›´å¤šç±»åˆ«\n\nNegation of a class: ç±»åˆ«å–å\nexp:ABC rdf:type owl:class ; \t\towl:complementOf exp:Meat .\nProperty definitions: object property and data property.å¯¹å±æ€§çš„å®šä¹‰ï¼ˆè°“è¯ï¼‰\nex:friendOf rdf:type owl:ObjectProperty . ex:age rdf:type owl:DataProperty .\nTransitive property: ä¼ é€’æ€§\nexp:ancestor rdf:type owl:TransitiveProperty .\n\nGiven triples\n\nexp:Thmoas exp:ancestor exp:Jimmy . exp:Jimmy exp:ancestor exp:Michael .\n\nThen what can we infer from them?\n\nexp:Thmoas exp:ancestor exp:Michael .\nFunctional property:\nexp:hasMother rdf:type owl:FunctionalProperty .\n\nPlease explain using natural language:Everyone has only one mother.\n\nè°“è¯çš„å‡½æ•°ç‰¹æ€§è¡¨ç¤ºä»–çš„rangeå–å€¼åªèƒ½æœ‰ä¸€ä¸ª\n\n\ninverse functional property å…·æœ‰åå‡½æ•°ç‰¹æ€§\nexp:postgraduateSupervisor rdf:type owl:InverseFunctionalProperty .\n\nPlease explain using natural language:\n\nEach post-graduate student has only one supervisor.\n\nè¿™è¡¨ç¤ºè°“è¯­çš„å®šä¹‰åŸŸåªèƒ½æœ‰ä¸€ä¸ª\n\nSymmetric property\nexp:friendOf rdf:type owl:SymmetricProperty .\n\nGiven a triple\n\nexp:Thmoas exp:friendOf exp:Lisa .\n\nThen what can we infer from it?\n\nexp:Lisa exp:friendOf exp:Thmoas .\nInverse relations between properties\nexp:ancestor owl:inverseOf exp:descendant .\n\nGiven a triple\n\nexp:Thmoas exp:ancestor exp:Jimmy .\n\nThen what can we infer from it?\n\nexp:Jimmy exp:descendant exp:Thmoas .\nConstraints on properties: universal quantifier âˆ€ä»»æ„ï¼ˆè°“è¯é™å®šè¯ï¼‰\nexp:Person rdf:type owl:Restriction ; \t\t   owl:onProperty exp:hasMother ; #è¡¨ç¤ºPersonå¯ä»¥å……å½“hasMotherçš„ä¸»è¯­           owl:allValuesFrom exp:Women . #è¡¨ç¤ºå‰ä¸€å¥è°“è¯­çš„rangeçš„å–å€¼èŒƒå›´\n\nWhat do we know from the above triples?\nIf the subject of exp:hasMother comes from the class exp:Person, then the object can be only from the class exp:Women\n\nConstraints on properties: existential quantifier âˆƒ å­˜åœ¨\nexp:SemanticWebPapers rdf:type owl:Restriction ; \t\t\t\t\t  owl:onProperty exp:publishedIn ; \t\t\t\t\t  owl:someValuesFrom exp:AAAIPapers . #å­˜åœ¨ä¸€éƒ¨åˆ†çš„å‘è¡¨åœ¨AAAIPapers\n\nWhat do we know from the above triples?\nIf the subject of exp:publishedIn comes from the class exp:SemanticWebPapers, then the object may be (at least one) from the class exp:AAAIPapers.\n\nA part of the Semantic Web papers were published in AAAI.\n\n\nConstraints on properties: cardinalities \nexp:Person rdf:type owl:Restriction ; \t\t   owl:onProperty exp:hasParent ; \t\t   owl:cardinality â€œ2â€^^xsd:integer . #é™å®šhasParentçš„rangeåªèƒ½æœ‰ä¸¤ä¸ª\n\nPlease explain using natural language:\nEach person should have two parents.\n\ncardinalityä¹Ÿå¯ä»¥æ¢æˆowl:maxCardinality/ owl:minCardinalityï¼Œè¡¨ç¤ºæœ€å¤šæˆ–è€…æœ€å°‘\n\nGiraffe is a kind of animal which only eats leaves.\n\n\n@prefix sw: &lt;http://semanticweb.org/&gt; @prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; . @prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; . @prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; . sw:Giraffe rdfs:subClassOf _:x ._:x rdfs:subClassOf sw:Animal ; \trdf:type owl:Restriction ; \towl:onProperty sw:eat ; \towl:allValuesFrom sw:Leaf .\n\nPlease write the corresponding RDF triples (in Turtle) of the following sentence: â€œChildless Persons are the persons who are not parentsâ€. Note that classes â€œChildlessPersonâ€, â€œPersonâ€, â€œParentâ€ are defined in the namespace http://semanticweb.org/ with the prefix â€œSWâ€.\n\n_:x0 rdf:type owl:class;\t owl:complement owl:Parent._:x1 rdf:type owl:class;\t owl:intersectionOf (sw:Person _:x0);\t owl:equivalentClass sw:ChildlessPerson.\n\nExercise 1:The father of each person should be a man\n\nexp:Person rdf:type owl:Restriction ; \t\t   owl:onProperty exp:hasFather ;\t\t\t    \t\t   \t\t   owl:allValuesFrom exp:Men .\n\nPlease useRDF triples (in Turtle) to represent the following sentence: â€œEach human has only one biological mother who should be a womanâ€ with the classes: â€œHumanâ€and â€œWomenâ€, and the propertyâ€œbiologicalMotherOf â€. Each class or property can be defined in the namespace http://semanticweb.org/ with the prefix â€œSWâ€.\n\n@prefix sw: &lt;http://semanticweb.org/&gt; @prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; . @prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; . @prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; .sw:biologicalMotherOf rdfs:domain sw:Women ;                      rdfs:range  sw:Human ;                      rdf:type    owl:InverscFunctionalProperty .\n5) Please write the corresponding RDF triples (in Turtle) of the following sentence: â€œGrandpas are the men who are grandparentsâ€. Specific classes are defined in the namespace   http://semanticweb.org/. Prefixes are given as follows:   @prefix sw: http://semanticweb.org/ .   @prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# .   @prefix owl: http://www.w3.org/2002/07/owl# .\n_:x  rdf:type  owl:class  ;     owl:intersectionOf  (sw:Man  sw:Grandparent)  ;     owl:equivalentClass  sw:Grandpa .\n3. Propositional Logic\nExample: Natural Language: Nigiri is a type of Sushi which has ingredient Rice and Fish\n\n\nFOL:âˆ€x.[Nigiri(x) â†’ Sushi(x) âˆ§ âˆƒy.[hasIngredient(x,y) âˆ§ Rice(y)] âˆ§âˆƒz.[hasIngredient(x,z) âˆ§ Fish(z)]]\nAre the following valid OWL axioms? If not, why? (class: A,B,C,D, role: R)\nAâ¨…(Bâ¨† âˆƒR)\n(âˆ€R.Aâ¨†B)â¨…A\n(Aâ¨…B)Â¬Câ¨†D\n\n\n\nEverybody knowing some actor has only envious friends\n\nä¾‹1ï¼š$\\exists$knows.Actor $\\subseteq$â€‹ $\\forall$hasfriend.Envious\nç”¨ä¸€é˜¶é€»è¾‘æ¥æ”¹å†™ï¼š\n\nAll students that attend only master courses.\nä¾‹2ï¼šStudent âŠ“âˆ€attendsCourse.MasterCourse\nç”¨ä¸€é˜¶é€»è¾‘æ”¹å†™ï¼šâˆ€x (Student(x) âˆ§ âˆ€y(attendsCourse(x,y) âˆ§ MasterCourse(y)))\nä¾‹3ï¼šè‡ªç„¶è¯­è¨€è§£é‡Šï¼šAll students that attend at least one lecture.\nStudent âŠ‘âˆƒAttend.Lectureç”¨ä¸€é˜¶é€»è¾‘æ”¹å†™ï¼šâˆ€x (Student(x) â†’ âˆƒy(Attend(x,y) âˆ§ Lecture(y)))\nExample\n(1) Any student must attend at least one lecture.    Student âŠ‘ âˆƒAttend.Lecture(2) John is a brother of Mary.    Brother(John,Mary)(3) Parents are exactly those who are mothers or fathers.    *Parent â‰¡ Mother âŠ” Father\n\nExercise\n\n\nA Phd Student is a student who has a supervisor. \n\n\n\\text{Phd\\_student} \\subseteq \\text{student}\\ \\cap\\ \\exist\\text{Supervisedby.}\\ \\text{human} 2.Animals are not vegetables.\n\n\\text{Animal} \\subseteq\\ \\neg\\text{vegetable}\nExpress the following sentences in Description Logics.\n\nLi is a student of SEU. Any person who is enrolled in a university is a college student.\n\n\nExample: Â¬Feamale âŠ“ âˆƒhaschild.Human âŠ‘ Human\n\n\n\nModify:\n\n\n\n\nExercise:\n\nGive a model for the ontology:\n\n$\\text{PhD}_\\text{student} \\sqsubseteq \\text{Student}$â€‹\n$\\text{Student} \\sqsubseteq \\neg\\text{Employee}$â€‹â€‹, $\\text{PhD}_\\text{student}(\\text{John})$\n$\\text{Emploee}(\\text{Lisa}),\\text{Marriedto}(\\text{John},\\text{Lisa})$â€‹â€‹â€‹ \n\n\nAnswer:\n\n$\\Delta=\\{jo,l\\}$\n$I_I(\\text{John})=jo$â€‹â€‹\n$I_I(\\text{Lisa})=l$â€‹â€‹\n$I_C(\\text{Emploee})={l}$â€‹\n$I_C(\\text{PhD}_\\text{student})={jo}$â€‹â€‹\n$I_C(\\text{Student})={jo}$â€‹â€‹\n$I_R(\\text{Marriedto})={}$\n\n\nInconsistency is often caused by modeling errors. å¦‚æœä¸ä¸€è‡´ï¼Œå¸¸å¸¸éƒ½æ— æ³•æ‰¾åˆ°ä¸€ä¸ªmodel\n\nUnicorn(beauty) \nUnicorn âŠ‘ Fictitious\nUnicorn âŠ‘ Animal\nAnimal âŠ‘Â¬Fictitious\n\n\nA knowledge base is incoherent if a named class is equivalent to âŠ¥.\n\nIt usually also points to a modeling error. å³é€šè¿‡æ„é€ ç©ºé›†å¯ä»¥è¯æ˜modelçš„é”™è¯¯\n\nUnicorn âŠ‘ Fictitious\nUnicorn âŠ‘ Animal \nAnimal âŠ“ Fictitious âŠ‘ âŠ¥\n\n\nExpress the following sentences in Description Logic.\n\n\n\nEvery teacher must teach someoneTeacher $\\subseteq \\exists$ Teach. Human\nEvery finger is a bodypart and is a part-of hand.Finger $\\subseteq$ BodyPart $\\cap \\exists$ PartOf. Hand\nZhang is a teacher of SEUTeacher (Zhang), TeachIn(Zhang,SEU)\n\n\nGive a model of the following ontology:PhD $_{\\text {student }}$ U Undergraduatge $_{\\text {student }} \\sqsubseteq$ Student,PhD $_{\\text {student }}($ John $)$,Undergraduatge $_{\\text {student }}($ Jack $)$,Sister $($ Lisa,Jack $)$,Employee $($ Lisa $)$\n\n\\begin{array}{c}\\Delta=\\{j o, j a, l\\} \\\\ I_{I}(\\text { John })=j o \\\\ I_{I}(\\text { Jack })=j a \\\\ I_{I}(\\text { Lisa })=l \\\\ I_{C}(\\text { Employee })=\\{l\\}\\end{array}$I_{C}\\left(\\right.$ Undergraduatge $\\left._{\\text {student }}\\right)=\\{j a\\}$$I_{C}\\left(\\right.$ Phd $\\left._{\\text {student }}\\right)=\\{j o\\}$$I_{C}($ Student $)=\\{j o, j a\\}$$I_{R}($ Sister $)=\\{(l, j a)\\}$\n\nGive a model of the following ontology\n\nProfessorâŠ‘FacultyMember,\n\nProfessor(Guilin Qi),\n\nhasAffiliation(Guilin Qi, SEU),\n\nStudentOf(Zhang, Guilin Qi)\n\n\nA model: \n\nâˆ†={a,b,c}\nI(Guilin Qi)=a, I(SEU)=b, I(Zhang)=c\nI( Professor)={a}, I(FacultyMember)={a},\nI(hasAffiliation)={(a,b)},\nI(StudentOf)={(c,a)},\n\nGive a model of the following ontology\n\n\\begin{array}{l}\n\\text{Professor} \\sqsubseteq \\text{FacultyMember},\\\\\n\\text{Professor (Guilin Qi)},\\\\\n\\text{hasAffiliation (Guilin Qi, SEU)},\\\\\n\\text{StudentOf (Zhang, Guilin Qi)}\\\\\n\\end{array}\n\\begin{aligned}\n\\Delta &= \\{q,z,seu\\} \\\\\n\\mathrm{I}_{\\mathbf{I}}(\\text{Guilin Qi})&=q \\\\\n\\mathrm{I}_{\\mathbf{I}}(\\text{Zhang})&=z \\\\\n\\mathrm{I}_{\\mathbf{C}}(\\text{Professor})&=\\{q\\} \\\\\n\\mathrm{I}_{\\mathbf{C}}(\\text{FacultyMember})&=\\{q\\} \\\\\n\\mathrm{I}_{\\mathbf{R}}(\\text{hasAffiliation})&=\\{(q,seu)\\} \\\\\n\\mathrm{I}_{\\mathbf{R}}(\\text{StudentOf})&=\\{(z,q)\\} \\\\\n\\end{aligned}\n\n\n\nWrite the inferred axioms using description logic after conducting classification in forward reasoning on the following axioms.\nEndocarditis $\\sqsubseteq$ Heart DiseaseMiocardial Infarction $\\sqsubseteq$ Heart DiseaseHeart Disease $\\sqsubseteq$ DiseaseEnterococcal Endocarditis $\\sqsubseteq$ Endocarditis\n\nAnswer\nMiocardial_Infarction $\\sqsubseteq$â€‹â€‹â€‹â€‹ DiseaseEndocarditis $\\sqsubseteq$â€‹â€‹â€‹â€‹ DiseaseEnterococcal_Endocarditis $\\sqsubseteq$â€‹â€‹â€‹â€‹ Heart_DiseaseEnterococcal_Endocarditis $\\sqsubseteq$â€‹â€‹â€‹â€‹ Disease\n\n\n\n4. Knowledge Graph ReasoningExample1:\n\nExample2:\n\n\nSo what type of Endocarditis is?\n\n\nExample1:\n\n\nClassification is to compute all implicit subclass relations by applying rules on a TBox.\nåˆ©ç”¨TBoxçš„è§„åˆ™è®¡ç®—æ‰€æœ‰å­ç±»çš„ä¾èµ–å…³ç³»\n\n\nExample2:\n\nHighvalue_Company âŠ‘ âˆƒbeInvestedBy. Investment_Company\né«˜ä»·å€¼å…¬å¸ç”±æŠ•èµ„å…¬å¸æŠ•èµ„ã€‚\nInvestment_Company âŠ‘ Financial_Institute\næŠ•èµ„å…¬å¸å±äºé‡‘èæœºæ„\nâˆƒbeInvestedBy. Financial_Institute âŠ‘ Solvent_Company\nå€ŸåŠ©é‡‘èæœºæ„æŠ•èµ„çš„å…¬å¸éƒ½æ˜¯å…·å¤‡å¿è¿˜èƒ½åŠ›çš„ ä¼ä¸šã€‚\n\nAnswer:\n\nHighvalue_Company âŠ‘ âˆƒbeInvestedBy. Financial_Institute\nHighvalue_Company âŠ‘ Solvent_Company\n\nExample1:\n\nRule: If you are human, then you are mortal.\nHuman(x)â†’Mortal(x)\nQuestion: Is Socrates a mortal?\nSolution: Check whether Mortal(Scorates) or Human(Scorates) is true.\n\nExample2:\n\n\nQuery: Find all patients with heart diseases, i.e., Heart_Disease(x)\nRewriting: Endocarditis(x) â‹ Miocardial_Infarction(x) â‹ Coronary_disease(x)\nå¯ä»¥ç†è§£æˆé‡å†™é—®é¢˜\n\nGiven the following KG, use query rewriting on the query Person(x) (this query is used for checking whether x is a person) .\n\n\n\nExercizeï¼š\nFind all sports players with the following KG, i.e., rewrite the query Sports_Player(x).\n\n\nQuery: Find all sports players \nRewriting: SportsPlayer(x) â‹ BasketballPlayer(x) â‹ FootballPlayer(x) â‹ TennisPlayer(x) \n\nExample: \n\nPhDStudent âŠ‘ Student, \n\nPhDStudent âŠ‘ Employee, \n\nStudent âŠ‘ Â¬ Employee\n\nä»¥ä¸Šæœ€ç»ˆå¯ä»¥é€€å‡ºStudentå’ŒEmployeeéƒ½æ˜¯ç©ºé›†ï¼Œæ‰€ä»¥æ‰¾ä¸åˆ°ä¸€ä¸ªmodel\nInconsistent ontology: ontology without a model. \n\n\n\nExample: \n\nPhDStudent âŠ‘ Student, \n\nPhDStudent âŠ‘ Employee,\n\nStudent âŠ‘ Â¬ Employee, \n\nPhDStudent(John)\n\nè¿™é‡Œåˆ™äº§ç”Ÿäº†çŸ›ç›¾\n\n\n\nExample: DICE ontology:\n\nBrain $\\sqsubseteq$ CentralNervousSystem $\\sqcap$ $\\exists$systempart.NervousSystem $\\sqcap$ BodyPart $\\sqcap$ $\\exists$ region.HeadAndNeck $\\sqcap$ $\\forall$ region.HeadAndNeck\nCentralNervousSystem $\\sqsubseteq$â€‹â€‹â€‹ NervousSystem\nBodyPart $\\sqsubseteq \\neg$â€‹â€‹ NervousSystem    or   DisjointWith(BodyPart,NervousSystem)\nReasoning: \nBrain $\\sqsubseteq$â€‹â€‹â€‹ Bodypart $\\sqsubseteq$â€‹â€‹â€‹ $\\neg$â€‹â€‹ NervousSystem\nBrain $\\sqsubseteq$â€‹â€‹ CentralNervousSystem $\\sqsubseteq$â€‹â€‹ NervousSystem\nBrain = $\\emptyset$\n\n\nBrainæ˜¯ç©ºé›†\n\n\n\nExample from Foaf:\n\nPerson(timbl)\nHomepage(timbl, http://w3.org/)\nHomepage(w3c, http://w3c.org/)\nOrganization(w3c)\nInverseFunctionalProperty(Homepage) (Homepageçš„domainåªæœ‰ä¸€ä¸ªå€¼ï¼Œæ‰€ä»¥çŸ›ç›¾)\nDisjointWith(Organization, Person)\n\nExample from OpenCyc:\n\nArtifactualFeatureType(PopulatedPlace)\nExistingStuffType(PopulatedPlace)\nDisjointWith(ExistingobjectType,ExistingStuffType)\nArtifactualFeatureType $\\sqsubseteq$â€‹ ExistingObjectType\n\nExistingObjectTypeä¸ExistingStuddTypeä¸ç›¸äº¤ï¼Œä½†æ˜¯å´æ‹¥æœ‰ç›¸åŒçš„å®ä¾‹ï¼Œæ‰€ä»¥çŸ›ç›¾\n\n\nExerciseï¼šThe following ontology is inconsistent, and remove one axiom or assertion in it to make it consistent.\n\n\\begin{aligned}\n&\\operatorname{Ph} D_{\\text {student }} \\sqcup \\text { Undergraduatge }_{\\text {student }} \\sqsubseteq \\text { Student, } \\\\\n&\\text { Student } \\sqsubseteq \\neg \\text { Employee } \\\\\n&\\text { PhD }_{\\text {student }} \\text { (John), } \\\\\n&\\text { Employee(John), } \\\\\n&\\text { Marriedto(John, Lisa), } \\\\\n&\\text { Undergraduate(Jack) }\n\\end{aligned}\n$\\text { Student } \\sqsubseteq \\neg \\text { Employee }$ or $\\text { Employee(John)}$ or $\\text { PhD }_{\\text {student }} \\text { (John) }$\n\n%%Factsfriend(joe,sue) .friend(ann,sue) .friend(sue,max) .friend(max,ann) .%% Rulesfof(X,Y) :- friend(X,Y)fof(X,Z) :- friend(X,Y), fof(Y,Z)%%Quiery 1query(X) :- fof(X,ann)%%Answer:fof(sue,ann) .fof(max,ann) .fof(joe,ann) .fof(ann,ann) .\nExercise\n\nRuleï¼šfatherinlawOf(X,Z) :- wifeOf(X,Y), fatherOf(Y,Z)\n\nFactï¼š wifeOf (YaoMingï¼ŒYeLi)\n\nFactï¼š fatherOf (YeLiï¼ŒYeFa)\nWho is the father-in-law of Yao Mingï¼Ÿ\n\nfatherinlawOf(YaoMing, YeFa)\n\n\n5. Knowledge Graph Construction\n@base &lt;http://foo.example/DB/&gt; . @prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;. &lt;People/ID=7&gt; rdf:type &lt;People&gt; . #æŸæ¡è®°å½•çš„ç±»åˆ«&lt;People/ID=7&gt; &lt;People#ID&gt; &quot;7&quot; .  #å…·ä½“å±æ€§&lt;People/ID=7&gt; &lt;People#fname&gt; &quot;Bob&quot; . &lt;People/ID=7&gt; &lt;People#addr&gt; &quot;18&quot; . &lt;People/ID=7&gt; &lt;People#ref-addr&gt; &lt;Addresses/ID=18&gt; . #åˆ©ç”¨å¤–é”®å…³è”æ˜ å°„ä¸¤å¼ è¡¨çš„è®°å½•&lt;People/ID=8&gt; rdf:type &lt;People&gt; . &lt;People/ID=8&gt; &lt;People#ID&gt; &quot;8&quot; . &lt;People/ID=8&gt; &lt;People#fname&gt; &quot;Sue&quot; . &lt;Addresses/ID=18&gt; rdf:type &lt;Addresses&gt; . &lt;Addresses/ID=18&gt; &lt;Addresses#ID&gt; &quot;18&quot; . &lt;Addresses/ID=18&gt; &lt;Addresses#city&gt; &quot;Cambridge&quot; . &lt;Addresses/ID=18&gt; &lt;Addresses#state&gt; &quot;MA&quot; .\n\nPlease use direct mapping to map the following two relational tables to RDF triples with the base IRI http://foo.example/DB/ and prefix rdfï¼šhttp://www.w3.org/1999/02/22-rdf-syntax-ns# .\n\n\n@base &lt;http://foo.example/DB/&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;.&lt;Student/ID=001&gt; rdf:type &lt;Student&gt; .&lt;Student/ID=001&gt; &lt;Student#ID&gt; &quot;001&quot; .&lt;Student/ID=001&gt; &lt;Student#sname&gt; &quot;Zhang&quot; .&lt;Student/ID=001&gt; &lt;Student#major&gt; &quot;101&quot; .&lt;Student/ID=001&gt; &lt;Student#ref-major&gt; &lt;Major/ID=101&gt; .&lt;Major/ID=101&gt; rdf:type &lt;Major&gt; .&lt;Major/ID=101&gt; &lt;Major#ID&gt; &quot;101&quot; .&lt;Major/ID=101&gt; &lt;Major#mname&gt; &quot;CS&quot; .&lt;Major/ID=101&gt; &lt;Major#address&gt; &quot;CS_Building&quot; .\n\nExample: database view\n\n\nExample:@prefix rr: &lt;http:l//www.w3.org/ns/r2rml#&gt; .&lt;TriplesMap1&gt;a rr:TriplesMap;       #&lt;TriplesMap1&gt;å‰æ²¡æœ‰â€˜#â€™æ—¶è¦åŠ è¿™ä¸€å¥rr:logicalTable [rr:tableName &quot;Person&quot;];rr:subjectMap[\trr:template &quot;http://www.ex.com/Person/ID=&#123;ID&#125;&quot;;                 #ID=&#123;ID&#125;  ç›´æ¥&#123;ID&#125;éƒ½æ˜¯å¯ä»¥çš„  çœ‹ä½ è‡ªå·±æ€ä¹ˆå®šä¹‰template\trr:class &lt;http://www.ex.com/Person&gt;;#è¡¨ç¤ºä»urlæ‹¿class];rr:predicateObjectMap [\trr:predicate &lt;http:7/www.ex.com/Person#NAME&gt;; #è¡¨ç¤ºä»urlæ‹¿predicate    rr:objectMap [rr:column &quot;NAME&quot;]; #è¡¨ç¤ºä»dbä¸­å–].\n\n\n\nSet of RDF triples\n\n&lt;http://data.example.com/employee/7369&gt; rdf:type ex:Employee.&lt;http://data.example.com/employee/7369&gt; ex:name &quot;SMITH&quot;. &lt;http://data.example.com/employee/7369&gt; ex:department &lt;http://data.example.com/department/10&gt;.&lt;http://data.example.com/department/10&gt; rdf:type ex:Department.&lt;http://data.example.com/department/10&gt; ex:name &quot;APPSERVER&quot;.&lt;http://data.example.com/department/10&gt; ex:location &quot;NEW YORK&quot;.&lt;http://data.example.com/department/10&gt; ex:staff 1.\n\nR2RML\n\n@prefix rr: &lt;http://www.w3.org/ns/r2rml#&gt;.@prefix ex: &lt;http://example.com/ns#&gt;.&lt;#TriplesMap1&gt;rr:logicalTable [ rr:tableName &quot;EMP&quot; ];rr:subjectMap [\trr:template &quot;http://data.example.com/employee/&#123;EMPNO&#125;&quot;;\trr:class ex:Employee;];rr:predicateObjectMap [\trr:predicate ex:name;\trr:objectMap [ rr:column &quot;ENAME&quot; ];].rr:predicateObjectMap [\trr:predicate ex:department; #ä¸rdfå¯¹åº”\trr:objectMap [#å®šä¹‰å®¾è¯­æ˜ å°„ï¼Œåœ¨ç¬¬äºŒå¼ è¡¨æ‰¾\t\trr:parentTriplesMap &lt;#TriplesMap2&gt;; #å»map2å»æ‰¾subjectæ¥å½“å®¾è¯­\t\trr:joinCondition [#è¡¨ç¤ºè¿™äº›å±æ€§æ˜¯ç›¸åŒçš„\t\t\trr:child &quot;DEPTNO&quot;;#triple2å°±æ˜¯child\t\t\trr:parent &quot;DEPTNO&quot;;#triple1å°±æ˜¯parent\t\t];\t];].\n&lt;#TriplesMap2&gt; rr:logicalTable &lt;#DeptTableView&gt;;rr:subjectMap [     rr:template &quot;http://data.example.com/department/&#123;DEPTNO&#125;&quot;; \trr:class ex:Department; ]; rr:predicateObjectMap [ \trr:predicate ex:name; #å¯¹äºrdfçš„Property\trr:objectMap [ rr:column &quot;DNAME&quot; ]; ]; rr:predicateObjectMap [ \trr:predicate ex:location; \trr:objectMap [ rr:column &quot;LOC&quot; ]; ]; rr:predicateObjectMap [ \trr:predicate ex:staff; \trr:objectMap [ rr:column &quot;STAFF&quot; ]; ].\n\nPlease write the R2RML triples map to map the following relational database to RDF triples with prefix rr: http://www.w3.org/ns/r2rml# and prefix ex: http://example.com/ns#(for classes and properties).\n\n\n\nRDF Triples\n\n&lt;http://data.example.com/student/001&gt; ex:name &quot;Zhang&quot;. &lt;http://data.example.com/student/002&gt; ex:name &quot;Wang&quot;.\n@prefix rr:&lt;http://www.w3.org/ns/r2rml#&gt; .@prefix rr:&lt;http://example.com/ns#&gt; .&lt;#TriplesMap1&gt;\trr:logicalTable [rr:tabelName &quot;RDB&quot;];\trr:subjectMap[\t\trr:template &quot;http://data.example.com/student/&#123;ID&#125;&quot;;\t\trr:class ex:Student;\t];\trr:predicateObjectMap[\t\trr:predicate ex:name; \t\trr:objectMap [rr:column &quot;Name&quot;];\t].\n\nPlease use direct mapping to map the following three relational tables to RDF triples,\nGiven: \n@base http://foo.example/DB/ .\n\n\n@prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns#.\nAnswer:@base &lt;http://foo.example/DB/&gt; .@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;.&lt;Student/ID=001&gt; rdf:type &lt;Student&gt;.&lt;Student/ID=001&gt; &lt;Student#ID&gt; â€œ001â€.&lt;Student/ID=001&gt; &lt;Student#sname&gt; â€œWangâ€.&lt;Student/ID=001&gt; &lt;Student# major&gt; â€211â€.&lt;Student/ID=001&gt; &lt;Student#ref-major&gt; &lt;Major/ID=211&gt;.&lt;Course/ID=8&gt; rdf:type &lt;Course&gt;.&lt;Course/ID=8&gt; &lt;Course#ID&gt; â€œ8â€. &lt;Course/ID=8&gt; &lt;Course#cname&gt; â€œKGâ€.&lt;Course/ID=8&gt; &lt;Course#ref-major&gt; &lt;Major/ID=211&gt;.&lt;Course/ID=8&gt; &lt;Course#major&gt; â€œ211â€.&lt;Course/ID=8&gt; &lt;Course#ref-major&gt; &lt;Major/ID=211&gt;.&lt;Course/ID=9&gt; rdf:type &lt;Course&gt;.&lt;Course/ID=9&gt; &lt;Course#ID&gt; â€œ9â€. &lt;Course/ID=9&gt; &lt;Course#cname&gt; â€œNLPâ€.&lt;Course/ID=9&gt; &lt;Course#major&gt; â€œ211â€.&lt;Course/ID=9&gt; &lt;Course#ref-major&gt; &lt;Major/ID=211&gt;.&lt;Major/ID=211&gt; rdf:type &lt;Major&gt;.&lt;Major/ID=211&gt; &lt;Major#ID&gt; â€œ211â€.&lt;Major/ID=211&gt; &lt;Major#mname&gt; â€œAIâ€.&lt;Major/ID=211&gt; &lt;Major#address&gt; â€œCS_Buildingâ€.\n\\2) Given a relational database and RDF triples, please write corresponding R2RML triples maps which can map the given RDB to RDF.\n\nRDF Triples\n&lt;http://data.example.com/student/001&gt; rdf:type ex:Student ;\tex:id &quot;001&quot; ;\tfoaf:name &quot;Wang&quot; ;\tex:major &quot;211&quot; ;    ex:gender &quot;Male&quot;. &lt;http://data.example.com/student/002&gt; rdf:type ex:Student ;    ex:id &quot;002&quot; ;    foaf:name &quot;Wu&quot; ;    ex:major &quot;201&quot; ;    ex:gender &quot;Female&quot;.\nAnswer:@prefix rr: &lt;http:l//www.w3.org/ns/r2rml#&gt; .@prefix ex: &lt;http://example.com/ns#&gt;.@prefix foaf: &lt; http://w3.org/ff#&gt;.&lt;#TriplesMap1&gt;rr:logicalTable [rr:tableName â€œStudentâ€]rr:subjectMap[\trr:template â€œhttp://data.example.com/student/&#123;ID&#125;â€;\trr:class ex:Student;];rr:predicateObjectMap[\trr:predicate ex:id;\trr:objectMap [rr:column â€œIDâ€];];rr:predicateObjectMap[\trr:predicate foaf:name;\trr:objectMap [rr:column â€œsnameâ€];];rr:predicateObjectMap[\trr:predicate ex:mayjor;\trr:objectMap [rr:column â€œmajorâ€];];rr:predicateObjectMap[\trr:predicate ex:gender;\trr:objectMap [rr:column â€œgenderâ€];];\n\nGiven a relational database and RDF triples, please write corresponding R2RML triples maps which can map the given RDB to RDF.\n\n\n&lt;http://data.example.com/student/001&gt; rdf:type ex:Student ;\t\t\t\t\t\t\t\t\t  ex:id &quot;001&quot; ;                                      ex:name &quot;Wang&quot; ;                                      ex:major &lt;http://data.example.com/major/211&gt; .&lt;http://data.example.com/student/002&gt; rdf:type ex:Student ;                                      ex:id &quot;002&quot; ;                                      ex:name &quot;Wu&quot; .&lt;http://data.example.com/major/211&gt; rdf:type ex:Major ;                                                             ex:name &quot;AI&quot; .\n6. Triple Extraction from Relational Web Tables\n\n\nExercise\nCompute the Levenshtein distance between â€œkittenâ€ and â€œsittingâ€.\n1+1+1=3\n\n\nCompute the Jaccard similarity between â€œUniversity of California, Davisâ€ and â€œUniversity of California, Berkeleyâ€in word level.\n\n\nA\\cup B=\\{University, of, California, Davis, Berkeley\\}\nA\\cap B=\\{University, of, California\\}\nJ(A, B)=\\frac{|A\\cup B|}{|A\\cap B|}=\\frac{3}{5}\nCompute the Jaccard similarity between â€œEnglishâ€and â€œEnglandâ€based on character-level trigrams.\n\n\nA=\\{Eng, ngl, gli, lis, ish\\}\nB=\\{Eng, ngl, gla, lan, and\\}\nJ(A, B)=\\frac{|A\\cap B|}{|A\\cup B|}=\\frac{2}{8}=\\frac{1}{4}\nPlease compute the Levenshtein distance between two strings â€œSaturdayâ€ and â€œSundayâ€. \n\nAnswer:\nSaturdayâ†’Sturday (delete a)\nSturdayâ†’Surday (delete t)\nSurdayâ†’Sunday (replace r with n)\nThus, the Levenshtein distance is 3.\n\nPlease compute the Jaccard similarity between â€œFrenchâ€ and â€œFranceâ€ based on character-level bi-grams.\n\nAnswer:\nSegment â€œFrenchâ€ and â€œFranceâ€ into bi-grams as follows:\nFrench: {Fr, re, en, nc, ch}\nFrance: {Fr, ra, an, nc, ce}\nJaccardSimilarity=2/8=0.25\n\nPlease tell the difference between local disambiguation and global disambiguation in entity linking.\n\nAnswer:\nLocal disambiguation does not consider the effects of other referent entities in the same table/ document. With semantic associations between candidate referent entities, global disambiguation can correct mistakes of local disambiguation.\n\nWhy do we need candidate generation in entity linking?\n\nAnswer:\nCandidate generation can significantly reduce the number of comparison between mentions and entities so that we no longer require to iterate through all entities in the knowledge base for each mention. It does improve the efficiency of entity linking.\n7. Knowledge Graph Construction from Semi-Structured Data\n\n\nsubject: the article entity\nQiang Yang\n\n\npredicate: the target relation\nbirthOnDate\n\n\nobject: the string captured by the brackets of the regular expression\n1964 births\n\n\næå–å®Œä¹‹åéœ€è¦åšproperty\nNote: Domain and Range checking is necessary.\n\n\n\n\n\nIn the Wikipedia article page of â€œMo Yanâ€, the categories as follows. Please extract facts from them in turtle using YAGO category maps without domain and range checking, and clarify the subsequent validation steps on the extracted fact.\nYAGO category maps\n\n\n\n\n@prefix expr: &lt;http://www.example.org/resource/&gt;@prefix expp: &lt;http://www.example.org/property/&gt;expr: MoYan expp: bornOnDate &quot;1955&quot;;\t\t\texpp: hasWonPrice expr: Han Chinese Nobel,\t\t\t\t\t\t\t  expr: Nobel,\t\t\t\t\t\t\t  expr: Mao Dun Literature Prize.\n\néœ€è¦check propertyçš„ rangeå’Œdomain\ntype inference\n\nGiven the Wikipedia article page of â€œIntelliJ IDEAâ€, including the first sentence, categories, and the infobox. Please write correct types from them (directly use plain strings).\n\n\n\n\nç¬¬ä¸€å¥è¯ï¼šintegrated development environment(IDE)\ncategoriesï¼šFree integrated development environmentsï¼ŒIntegrated development environments, Java development toolsï¼ŒProducts, software\nInfoboxï¼šSoftware\n\n\nPlease extract a taxonomy from the following sentence (denote the answer as A is-a B):\n\nIBM, AMD, and Intel are High-tech companies using nanotechnology for several years.\nIBM is-a High-tech company\nAMD is-a High-tech company\nIntel is-a High-tech company\nHigh-tech company is-a company\nIBM is-a company\nAMD is-a company\nIntel is-a company\n\n8. Unstructured Data\n\n\nAssuming word with higher TF value and higher IDF value is more relevant to domain.\nTF: Term frequency.\n\n\n\n\n\\mathrm{TF}=\\frac{\\text { Number of certain word in a document }}{\\text { Number of all words in a document }}\nIDF: Inverse document frequency\n\n\n\\text{IDF}=\\log \\left(\\frac{\\text { Number of all documents in corpu }}{\\text { Number of documents containing the certain word }+1}\\right)Exerciseâ€”â€”TF-IDF\nSuppose there are 100 words in a document, and the word â€œcowâ€ appears three times. The word â€œcowâ€ has appeared in 1,000 documents, and the total number of documents is 10,000,000. What is the TF-IDF score of the word â€œcowâ€?\n\n\n\\begin{array}{ll}\n\\text{TF}=\\frac{3}{100}\\\\\n\\text{IDF}=\\log \\frac{10000000}{1000+1}=3.9996\\\\\nTF\\times IDF=0.119987\n\\end{array}\nä¾‹ï¼šå‡å®šã€Šäºšæ´²çš„ç½‘ç»œæŠ€æœ¯ã€‹ä¸€æ–‡é•¿åº¦ä¸º1000ä¸ªè¯ï¼Œâ€œäºšæ´²â€ã€â€œç½‘ç»œâ€ã€â€œæŠ€æœ¯â€å„å‡ºç°20æ¬¡ï¼Œåˆ™è¿™ä¸‰ä¸ªè¯çš„â€œè¯é¢‘â€ï¼ˆTFï¼‰éƒ½ä¸º0.02ã€‚ ç„¶åï¼Œæœç´¢Googleå‘ç°ï¼ŒåŒ…å«â€œçš„â€å­—çš„ç½‘é¡µå…±æœ‰250äº¿å¼ ï¼ˆå‡å®šè¿™å°±æ˜¯ä¸­æ–‡ç½‘é¡µæ€»æ•°ï¼‰ï¼ŒåŒ…å«â€œäºšæ´²â€çš„ç½‘é¡µå…±æœ‰62.3äº¿å¼ ï¼ŒåŒ…å«â€œç½‘ç»œâ€çš„ç½‘é¡µä¸º0.484äº¿å¼ ï¼ŒåŒ…å«â€œæŠ€æœ¯â€çš„ç½‘é¡µä¸º0.973äº¿å¼ ã€‚è®¡ç®—â€œäºšæ´²â€ã€â€œç½‘ç»œâ€ã€â€œæŠ€æœ¯â€çš„TF-IDFå€¼.\n\n\n\\begin{array}{ll}\n\\text{IDF(äºšæ´²)}=\\lg\\frac{250}{26.3}=0.603\\\\\n\\text{IDF(ç½‘ç»œ)}=\\lg\\frac{250}{0.484}=2.713\\\\\n\\text{IDF(æŠ€æœ¯)}=\\lg\\frac{250}{0.973}=2.410\\\\\n\\text{TF-IDF(äºšæ´²)}=0.603\\times 0.02=0.01206\\\\\n\\text{TF-IDF(ç½‘ç»œ)}=2.713\\times 0.02=0.05426\\\\\n\\text{TF-IDF(æŠ€æœ¯)}=2.410\\times 0.02=0.04820\\\\\n\\end{array}9. Knowledge Graph Alignment\n\nExample:\n\ntrigrams(nikon) $=\\{$ nik, iko, kon $\\}$\ntrigrams(nike) $=\\{$ nik, ike $\\}$\n$\\operatorname{sim}($â€‹ nikon, nike $)=1 / 4$â€‹\n\n\nCompute the trigram based similarity between two strings University and Universe\n\ntrigrams(University)={Uni,niv,ive,ver,ers,rsi,sit,ity}\n\ntrigrams(Universe)={Uni,niv,ive,ver,ers,rse}\n\n$\\text{sim(University,Universe)}=5/8$\n\nCompute the Jaccard similarity between the first-order neighbor classes of the classes Car and Automobile from different ontologies.\n\n\n\n\nStringSimilarity\nlen(book)=4,len(Textbook)=8\nsubstring(book, Textbook)=book\nlen(substring)=4\nstrIngSimilarity(book, Textbook)=4/4=1\nstrIngSimilarity(Textbook, book)=4/8=1/2\n\n\nNeighbor Class Set Similarity\nNeighbor(book)={literature,volume}\nNeighbor(Textbook)={volume,Engineering,Science}\nNeighbor Class Set Similarity(book, Textbook)=1/2\nNeighbor Class Set Similarity(Textbook, book)=1/3\n\n\nInstance Set Similarity\nInstance(book)={Red Sorghum,Introduction to Algorithm}\nInstance(Textbook)={Red Sorghum}\nInstance Set Similarity(book, Textbook)=1/2\nInstance Set Similarity(Textbook, book)=1\n\n\n\n\nQuestion: now we have String Similarity, Neighbor Class Set Similarity, Textual Context Similarity, and Instance Set Similarity, please tell which one belongs to the element-level matching techniques? Which one is a structure-level matching technique?\n\nString Similarity,Textual Context Similarity element-level matching techniques\n\nNeighbor Class Set Similarity, Instance Set Similarity structure-level matching technique\n\nCompute the Jaccard similarity between the instance set of class â€œBookâ€ and that of class â€œTextbookâ€.\n\n\n\n\n$A\\cup B$:{Red Sorghum, The Republic of Wine, Data Structure, Introduction to Algorithm, Operation System}\n$A\\cap B$:{Data Structure, Introduction to Algorithm}\nJaccard = $\\frac{|A\\cap B|}{|A\\cup B|}=\\frac{2}{5}$â€‹\n\nPlease tell the differences between the rdf:type relation and the general is-a relation.\n\ngeneral is-a relation be inter-class.\n\n\nGiven the Wikipedia article page of â€œNumPyâ€, including the first sentence, categories, and the infobox. Please write correct types from them (directly use plain strings).\n\n\n\n\n\n\nAnswer\n\nlibrary, software, Free mathematics software, Free science software, Numerical analysis software for Linux, Numerical analysis software for MacOS, Numerical analysis software for Windows, Numerical programming languages, Python (programming language) scientific libraries, Software using the BSD license.\n\n\nIn the Wikipedia article page of â€œTim Berners-Leeâ€, the categories are as follows. Please extract facts from them in turtle using YAGO category maps and the following prefixes without domain and range checking, and clarify the subsequent validation steps on the extracted fact.\n\n\n\n\n\n\nAnswer\n\nExtract facts\nexpr:Tim Berners-Lee\texpp:bornOnDate\t\t&quot;1955&quot; ;\t\t\t\t\t\texpp:hasWonPrize\texpr:Turing Award ;\t\t\t\t\t\texpp:hasWonPrize\texpr:Roval Medal ;\t\t\t\t\t\texpp:hasWonPrize\texpr:Medal ;\t\t\t\t\t\texpp:hasWonPrize\texpr:Webby Award ;\t\t\t\t\t\texpp:hasWonPrize\texpr:Award ;\n\nValidation\n\nCheck if expr:Tim Berners-Lee is in the domain of expp:bornOnDate and if &quot;1955&quot; is in the range of expp:bornOnDate;\nCheck if expr:Tim Berners-Lee is in the domain of expp:hasWonPrize and if expr:Turing Award expr:Roval Medal expr:Medal expr:Webby Award expr:Award is in the range of expp:hasWonPrize.\n\n\n\n\nExtract is-a relations form the following sentence, and derive all is-a relations using the transitivity of the is-a relation (in RDF Triple)\n\nWe have rules for keeping animals, such as horses and other farm animals, especially cows and chickens.\n\n\nAnswer\nfarm animal $\\to$ animal\nhorse $\\to$ animal\ncow $\\to$ animal\nchicken $\\to$ animal\ncow $\\to$ farm animal\nchicken $\\to$ animal\n\n\n\n\n\nCompute the TF-IDF values of knowledge, AI, Engineering with the statistics in the following tables, and rank them (Computing IDF using Ig).\n\n\\begin{aligned}\n&\\begin{array}{|l|l|}\n\\hline \\text { Doc1 } &  \\\\\n\\hline \\text { Term } & \\text { Count } \\\\\n\\hline \\text { Knowledge } & 3 \\\\\n\\hline \\text { Al } & 6 \\\\\n\\hline \\text { Engineering } & 4 \\\\\n\\hline\n\\end{array}\n&\\begin{array}{|l|l|}\n\\hline \\text { Doc2 } & \\\\\n\\hline \\text { Term } & \\text { Count } \\\\\n\\hline \\text { Knowledge } & 0 \\\\\n\\hline \\text { Al } & 5 \\\\\n\\hline \\text { Engineering } & 1 \\\\\n\\hline\n\\end{array}\n\\quad \\quad\n&\\begin{array}{|l|l|}\n\\hline \\text { Doc3 } &  \\\\\n\\hline \\text { Term } & \\text { Count } \\\\\n\\hline \\text { Knowledge } & 0 \\\\\n\\hline \\text { Ak } & 0 \\\\\n\\hline \\text { Engineering } & 5 \\\\\n\\hline\n\\end{array}\n\\end{aligned}\nAnswer\n\nDoc 1\n\n\n\\begin{array}{l}\nTF-IDF_{Knowledge} = \\frac{3}{13} \\times \\log (\\frac{3}{2}) = 0.0406 \\\\\nTF-IDF_{AI} = \\frac{6}{13} \\times \\log (\\frac{3}{3}) = 0 \\\\\nTF-IDF_{Engineering} = \\frac{4}{13} \\times \\log (\\frac{3}{4}) = -0.0384 \\\\\n\\end{array}\nDoc 2\n\n\\begin{array}{l}\nTF-IDF_{Knowledge} = 0\\\\\nTF-IDF_{AI} = \\frac{5}{6} \\times \\log (\\frac{3}{3}) = 0 \\\\\nTF-IDF_{Engineering} = \\frac{1}{6} \\times \\log (\\frac{3}{4}) = -0.0208 \\\\\n\\end{array}\nDoc 3\n\n\\begin{array}{l}\nTF-IDF_{Knowledge} = 0\\\\\nTF-IDF_{AI} = 0 \\\\\nTF-IDF_{Engineering} = \\frac{5}{5} \\times \\log (\\frac{3}{4}) = -0.1249 \\\\\n\\end{array}\n\n\n\n\n\nPlease compute the Levenshtein distance between two strings Saturday and Sunday.\n\nAnswer\n\nat \\to \\varnothing \\quad r \\to n \\\\\nLD = 3\n\n\n\nPlease compute the Jaccard similarity between â€œFrenchâ€ and â€œFranceâ€ based on character-level bi-grams.\nAnswer\n$\\text{French} = \\{Fr,re,en,nc,ch\\}$\n$\\text{French} = \\{Fr,ra,an,nc, ce\\}$\n$\\text{Jaccard Similarity} = \\frac{2}{5}$\n\n\n\n\n\nPlease tell the difference between local disambiguation and global disambiguation in entity linking.\nLocal Disambiguation (å±€éƒ¨æ¶ˆæ­§)\nOnly use the contextual information of the given mention and target entity for disambiguation without considering the effects of other referent entities in the same table.\n\n\nGlobal (Collective) Disambiguation (è”åˆæ¶ˆæ­§)\nLeverage the semantic associations between candidate referent entities to jointly disambiguate all entities for the mentions in a table.\n\n\n\n\n\n\n\nWhy do we need candidate generation in entity linking?\nIdentifying candidate referent entities of each string mention in table cells when given a knowledge base.\nSelect Top k entities for further disambiguation to accelerate.\n\n\n\n10. Knowledge Graph Querying\n\n\n\n\nPlease rewrite the following triple pattern by using the same subject only once.\n\n?a int:number 123789 .?a int:pair 34567.?a int:id 666777 .\n?a int:number 123789ï¼›   int:pair 34567ï¼›   int:id 666777 .\n\nPlease rewrite the following triple pattern by using the same subject and predicate only once.\n\n?a string:name â€˜Bobâ€™.?a string:name â€™Bobbyâ€™.?a string:name â€˜Boobâ€™.?a string:name â€˜Bob_â€™.\n?a string:name â€˜Bobâ€™,â€™Bobbyâ€™,â€˜Boobâ€™,â€˜Bob_â€™.\nExerciseGiven the dataset and the SPARQL query as follows, please write the query results.\n# Graph: http://example/addresses@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .&lt;http://example/president25&gt; foaf:givenName &quot;Bill&quot; .&lt;http://example/president25&gt; foaf:familyName &quot;McKinley&quot; .&lt;http://example/president27&gt; foaf:givenName &quot;Bill&quot; .&lt;http://example/president27&gt; foaf:familyName &quot;Taft&quot; .&lt;http://example/president42&gt; foaf:givenName &quot;Bill&quot; .&lt;http://example/president42&gt; foaf:familyName &quot;Clinton&quot; .\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;SELECT ?name ?familyWHERE &#123; ?x foaf:givenName ?name .?x foaf:familyName ?family .&#125;\n\n\n\n\nname\nfamily\n\n\n\n\nâ€œBillâ€\nâ€œMcKinleyâ€\n\n\nâ€œBillâ€\nâ€œTaftâ€\n\n\nâ€œBillâ€\nâ€œClintonâ€\n\n\n\n\n\n\nGiven the dataset and the SPARQL query as follows, please write the query results.\n\n# Graph: http://example/addresses@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .&lt;http://example/president25&gt; foaf:givenName &quot;Bill&quot; .&lt;http://example/president25&gt; foaf:familyName &quot;McKinley&quot; .&lt;http://example/president27&gt; foaf:givenName â€œBob&quot; .&lt;http://example/president27&gt; foaf:id 159486.&lt;http://example/president42&gt; foaf:givenName â€œMarry&quot; .&lt;http://example/president42&gt; foaf:familyName &quot;Clinton&quot; .\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;SELECT ?name ?familyWHERE &#123; ?x foaf:givenName ?name .?x foaf:familyName ?family .&#125;\n\n\n\n\nname\nfamily\n\n\n\n\nâ€œBillâ€\nâ€œMcKinleyâ€\n\n\nâ€œMarryâ€\nâ€œClintonâ€\n\n\n\n\n\nMatching RDF literals\n\n@prefix dt: &lt;http://example.org/datatype#&gt; .@prefix ns: &lt;http://example.org/ns#&gt; .@prefix : &lt;http://example.org/ns#&gt; .@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .:x ns:p &quot;cat&quot;@en .:y ns:p &quot;42&quot;^^xsd:integer .:z ns:p &quot;abc&quot;^^dt:specialDatatype .\n\nç¬¬ä¸€ç§æ˜¯æ‰¾ä¸åˆ°ç»“æœçš„ï¼Œå› ä¸ºä¸åŠ @æ˜¯ä¸ä¸€æ ·çš„æ„ä¹‰\n\n\n\n\n\n\n\n\n\nname\nfamily\n\n\n\n\nâ€œBillâ€\nâ€œMcKinleyâ€\n\n\n\n\n\n\nExercise\nGiven the dataset and the SPARQL query as follows, please write the query results.\n\n\n\n\n\nAnswer\n\n\n\n\n\nname\nfamily\n\n\n\n\nâ€œBillâ€\nâ€œMcKinleyâ€\n\n\nâ€œBobâ€\n\n\n\nâ€œMarryâ€\n\n\n\n\n\n\n\n\nPlease write the SPARQL query on â€œlist all volcanos located in Italy or Norwayâ€ given the following data.\n\ndepedia:Mount_Etna\trdf:type\tumbel-sc:Volcano;\t\t\t\t\trdfs:label \t&quot;Etna&quot;;\t\t\t\t\tp:location\tdbpedia:Italy.depedia:Mount_Baker\trdf:type\tumbel-sc:Volcano;\t\t\t\t\tp:location\tdbpedia:United_States.depedia:Beerenberg\trdf:type\tumbel-sc:Volcano;\t\t\t\t\trdfs:label\t&quot;Beerenberg&quot;@en;\t\t\t\t\tp:location\tdbpedia:Norway.\n\nAnswer\n\nSELECT ?volcano rdf:type umbel-sc:Volcano.WHERE &#123;    &#123;?Mount p:location dbpedia:Italy.&#125;    UNION &#123;?Mount p:location dbpedia:Norway.&#125;&#125;\n\n\n\n\nExercise\nGiven the dataset and the SPARQL query as follows, please write the query results.\nDataset\n\n# Default graph (stored at http://example.org/dft.ttl)@prefix dc: &lt;http://purl.org/dc/elements/1.1/&gt; .&lt;http://example.org/bob&gt; dc:publisher &quot;Bob Hacker&quot; .&lt;http://example.org/alice&gt; dc:publisher &quot;Alice Hacker&quot; .# Named graph: http://example.org/bob@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; ._:a foaf:name &quot;Bob&quot; ._:a foaf:mbox &lt;mailto:bob@oldcorp.example.org&gt; .# Named graph: http://example.org/alice@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; ._:a foaf:name &quot;Alice&quot; ._:a foaf:mbox &lt;mailto:alice@work.example.org&gt; .\n\nSPARQL query\nFROMNAMDå¯ä»¥çœç•¥ï¼Œå› ä¸ºæ ‡æ˜äº†GRAPH ?g\n\n\n\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt;SELECT ?who ?g ?mboxFROM &lt;http://example.org/dft.ttl&gt;FROM NAMED &lt;http://example.org/alice&gt;FROM NAMED &lt;http://example.org/bob&gt;WHERE&#123;?g dc:publisher ?who .GRAPH ?g &#123; ?x foaf:mbox ?mbox &#125;&#125;\n\nAnswer:\n\n\n\n\n\nwho\ng\nmbox\n\n\n\n\nâ€œBob Hackerâ€\n\\http://example.org/bob\n\\&#98;&#x6f;&#98;&#x40;&#x6f;&#x6c;&#x64;&#x63;&#x6f;&#x72;&#x70;&#x2e;&#x65;&#x78;&#x61;&#x6d;&#x70;&#108;&#x65;&#46;&#x6f;&#x72;&#x67;&#x5c;\n\n\nâ€œAlice Hackerâ€\n\\http://example.org/alice\n\n\n\n\n\n\n\n\n\n\n\n\nGiven the dataset and the SPARQL query as follows, please write the query results.\n\nQ1@prefix org: &lt;http://example.com/ns#&gt; ._:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 ._:b org:employeeName &quot;Bob&quot; ._:b org:employeeId 67890 .\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;PREFIX org: &lt;http://example.com/ns#&gt;DELETE &#123;?person ?p ?o .&#125;where &#123;?person org:employeeId ?id .FILTER (?id &gt; 50000)?person ?p ?o .&#125;\n\nåˆ é™¤åï¼š\n\n_:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 .\n2. Q2@prefix org: &lt;http://example.com/ns#&gt; .# Graph: http://person_:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 ._:b org:employeeName &quot;Bob&quot; ._:b org:employeeId 67890 .# Graph: http://person2_:c org:employeeId 13579\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;PREFIX org: &lt;http://example.com/ns#&gt;INSERT &#123;GRAPH &lt;http://person2&gt; &#123;?person ?p ?o .&#125;&#125;where &#123;Graph: &lt;http://person&gt;&#123;?person org:employeeId ?id .FILTER (?id &lt; 50000)?person ?p ?o .&#125;&#125;\n@prefix org: &lt;http://example.com/ns#&gt; .# Graph: http://person_:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 ._:b org:employeeName &quot;Bob&quot; ._:b org:employeeId 67890 .# Graph: http://person2_:c org:employeeId 13579 ._:a org:employeeName &quot;Alice&quot; ._:a org:employeeId 12345 .\n\n\n\n\n\n\nOrder the results.\n\n\n\nASC for ascending (default) and DESC (e.g., DESC(?name)) for descending.\n\n\nLIMIT\nlimits the number of result:\nåªè¿”å›5ä¸ª\n\n\n\n\nOFFSET\nposition/index of the first reported results:\n\n\n\nOrder of the result should be predictable (combine with ORDER BY)\n\nBINDINGS\n\n\nVALUE\nadd data to the query directly.\nå¢åŠ é™åˆ¶\n\n\n\n\nAGGREGATES\n\nQuestion: Please use natural language to explain this SPARQL query!\næŸ¥é€‰è¯¾äººæ•°è¶…è¿‡5äººçš„è¯¾\n\n\n\n\n\nQuestion: Please use natural language to explain the above SPARQL queries!\n\n\nTranslate the following natural language sentences into SPARQL.\n\nWhat are all the countries and their capitals in Africa?\n# Givenhttp://dbpedia.org/property/continent,http://dbpedia.org/resource/Africa,http://dbpedia.org/ontology/Country,http://dbpedia.org/ontology/capital.\nPREFIX dbp: &lt;http://dbpedia.org/&gt;PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;SELECT ?x ?yWHERE&#123;    ?x \trdf:type\tdbp:ontology/Country .    ?x \tdbp:property/continent\tdbp:resource/Africa .    ?x \tdbp:ontology/capital\t?y .&#125;\n\nWhat are the devices whose manufacturers are in Korea or Japan?\n#Givenhttp://dbpedia.org/property/locationCountry,http://dbpedia.org/resource/Korea,http://dbpedia.org/resource/Japan,http://dbpedia.org/ontology/manufactury,http://dbpedia.org/ontology/Device.\nPREFIX dbp: &lt;http://dbpedia.org/&gt;PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;SELECT ?deviceWHERE&#123;    ?device \trdf:type\tdbp:ontology/Device .    ?device \tdbp:ontology/manufacturer\t?location .    &#123;?location \tdbp:property/locationCountry\tdbp:resource/Japan .&#125;    UNION &#123;?location \tdbp:property/locationCountry\tdbp:resource/Korea .&#125;&#125;\n\n\n\nFrom the following RDF triples and the result of query, construct a SPARQL query.\n@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; . @prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; . _:a \trdf:type \tfoaf:Person . _:a \tfoaf:name \t&quot;Alice&quot; . _:a \tfoaf:mbox \t&lt;mailto:alice@example.com&gt; . _:a \tfoaf:mbox \t&lt;mailto:alice@work.example&gt; . _:b \trdf:type \tfoaf:Person . _:b \tfoaf:name \t&quot;Bob&quot; .\n| name    | mbox                                                   || :â€”â€”â€” | :â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”- || â€œAliceâ€ | mailto:alice@example.com   || â€œAliceâ€ | mailto:alice@work.example || â€œBobâ€   |                                                        |\n\nAnswer\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;SELECT ?name, ?mboxWHERE&#123;    ?x \trdf:type\tfoaf:Person ;    \tfoaf:name   ?name .    OPTIONAL &#123;?x\t\tfoaf:mbox\t?mbox .&#125;&#125;\n\n\n\nGiven the dataset and query results as follows, please write the corresponding SPARQL Query.\n# Datasetdbpedia:Mount_Etna \t\trdf:type \tumbel-sc:Volcano ;\t\t\t\t\t\trdfs:label \t&quot;Etna&quot; ;\t\t\t\t\t\tp:location \tdbpedia:Italy .dbpedia:Mount_Xiqiao \trdf:type \tumbel-sc:Volcano ;\t\t\t\t\t\trdfs:label \t&quot;Mount_Xiqiao&quot; ;\t\t\t\t\t\tp:location \tdbpedia:China .dbpedia:Beerenberg \t\trdf:type \tumbel-sc:Volcano .\t\t\t\t\t\trdfs:label \t&quot;Beerenberg&quot;@en ;\t\t\t\t\t\tp:location \tdbpedia:Norway .# SPARQL Resultsdbpedia:Mount_Etna \t\trdfs:label \t&quot;Etna&quot; ;\t\t\t\t\t\trdf:type \tmyTypes:VolcanosOutsideChina.dbpedia:Beerenberg \t\trdfs:label \t&quot;Beerenberg&quot;@en;\t\t\t\t\t\trdf:type \tmyTypes:VolcanosOutsideChina.\n\nAnswer TODO\nCONSTRUCT &#123;    ?v \trdfs:label\t?name ;        rdf:type\tmyTypes:VolcanosOutsideChina .&#125;WHERE &#123;    ?v\trdf:type\tumbel-sc:Volcano;        rdfs:label\t?name.    OPTIONAL &#123;        ?v\tp:location\t?l . FILTER (?l = dbpedia:China)    &#125; FILTER (!BOUND(?l))&#125;\n\nFrom the following RDF triples and the result of query, construct a SPARQL query.\n@prefix foaf: http://xmlns.com/foaf/0.1/ . \n@prefix rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# . \n_:a rdf:type foaf:Person . \n_:a foaf:name â€œAliceâ€ . \n_:a foaf:mbox &#x61;&#x6c;&#x69;&#x63;&#101;&#64;&#101;&#x78;&#97;&#x6d;&#112;&#x6c;&#101;&#x2e;&#x63;&#111;&#x6d; . \n_:a foaf:mbox &#x61;&#x6c;&#x69;&#x63;&#101;&#64;&#x77;&#111;&#114;&#107;&#46;&#101;&#120;&#97;&#x6d;&#112;&#x6c;&#x65; . \n_:b rdf:type foaf:Person . \n_:b foaf:name â€œBobâ€ . \n\n\n\n10. Cypher\n\nCREATE(\tnode:Movie\t&#123;\t\ttitle:&quot;The American President&quot;\t&#125;)\n\n\nCreate the relationship using cypher.\n\n\nCREATE\t(n1:Person &#123;name:&#x27;Oliver Stone&#x27;&#125;)\t-[r:DIRECTED]\t-&gt;(N2:Movie&#123;title:&quot;Wall Street&quot;&#125;)\n\næŸ¥è¯¢æ‰€æœ‰èŠ‚ç‚¹\n\nMATCH (n) RETURN n\n\næŸ¥è¯¢æ‰€æœ‰ç”µå½±title\n\nMATCH (movie:Movie)RETURN movie.title\n\nåå«Oliver Stoneç›¸å…³è”çš„äº‹ç‰©æ ‡é¢˜\n\nMATCH (director &#123;name: &#x27;Oliver Stone&#x27;&#125;)--(movie) RETURN movie.title\n\nä¸äººç‰©Oliver Stoneç›¸å…³è”çš„ç”µå½±æ ‡é¢˜\n\nMATCH (:Person &#123;name: &#x27;Oliver Stone&#x27;&#125;)--(movie:Movie) RETURN movie.title\n\nä¸äººç‰©Oliver Stoneç›¸å…³è”çš„å…³ç³»ç±»å‹\n\nMATCH (:Person &#123;name: &#x27;Oliver Stone&#x27;&#125;)-[r]-(movie) RETURN type(r)\n\nå‡ºæ¼”åä¸ºâ€˜Wall Streetâ€™ç”µå½±çš„æ¼”å‘˜å§“å\n\nMATCH (wallstreet:Movie &#123;title: &#x27;Wall Street&#x27;&#125;)&lt;-[:ACTED_IN]-(actor) RETURN actor.name\n\nå‚æ¼”æˆ–å¯¼æ¼”åä¸ºWall Streetçš„ç”µå½±çš„æ‰€æœ‰äººç‰©\n\nMATCH (wallstreet:Movie &#123;title: &#x27;Wall Street&#x27;&#125;)&lt;-[:ACTED_IN|:DIRECTED]-(person:Person) RETURN person.name\n\nåä¸ºWall Streetçš„ç”µå½±çš„ä¸­æ‰€æœ‰çš„è§’è‰²\n\nMATCH (wallstreet:Movie &#123;title: &#x27;Wall Street&#x27;&#125;)&lt;-[r:ACTED_IN]-(actor) RETURN r.role\n\nwhen nodes already exist, we can use MATCH first, then CREATE\n\n\nMATCH \t(charlie:Person &#123;name: &#x27;Charlie Sheen&#x27;&#125;),     (rob:Person &#123;name: &#x27;Rob Reiner&#x27;&#125;) CREATE     (rob)-[:TYPE INCLUDING A SPACE]-&gt;(charlie)\n\næŸ¥è¯¢å‚æ¼”åä¸ºâ€˜The American Presidentâ€™çš„æ‰€æœ‰æ¼”å‘˜å§“å\n\n\nMATCH\t(person:Person)-[:ACTED_IN]\t-&gt;(movie:Movie&#123;title:&quot;The American President&quot;&#125;)RETURN person.name\n\næŸ¥è¯¢åŒ…å«è§’è‰²â€™Card Foxâ€™çš„ç”µå½±å\n\n\nMATCH\t(actor)-[:ACTED_&#123;role:&quot;Card Fox&quot;&#125;]\t-&gt;(movie:Movie)RETURN movie.title\n\n\nåˆ é™¤åä¸ºUNKNOWNçš„èŠ‚ç‚¹\n\nMATCH (n:Person &#123;name: &#x27;UNKNOWNâ€™&#125;) DELETE n\n\nåˆ é™¤æ•°æ®åº“ä¸­æ‰€æœ‰èŠ‚ç‚¹åŠä¸å…¶ç›¸è¿çš„å…³ç³»\n\nMATCH (n) DETACH DELETE n\n\nåˆ é™¤åä¸ºAndyçš„èŠ‚ç‚¹å’Œä¸å…¶ç›¸è¿çš„æ‰€æœ‰å…³ç³»\n\nMATCH (n &#123;name: &#x27;Andyâ€™&#125;) DETACH DELETE n\n\nåˆ é™¤Andyçš„æ‰€æœ‰KNOWSå…³ç³»\n\nMATCH (n &#123;name: &#x27;Andy&#x27;&#125;)-[r:KNOWS]-&gt;() DELETE r\n\nåˆ é™¤äººç‰©å¹´é¾„ä¸º34å²çš„æ‰€æœ‰å…³ç³»\n\n\nMATCH (person:Person &#123;age:34&#125;)-[r]-&gt;()DELETE r\n\nUpdate a property\n\nMATCH (n &#123;name: &#x27;Andy&#x27;&#125;) SET n.age = toString(n.age) RETURN n.name, n.age\n\nMATCH (n &#123;name: &#x27;Andy&#x27;&#125;) SET n.position = &#x27;Developer&#x27;, n.surname = &#x27;Taylor&#x27;\nMATCH (p &#123;name: &#x27;Peter&#x27;&#125;) SET p = &#123;name: &#x27;Peter Smithâ€™, \tposition: &#x27;Entrepreneur&#x27;&#125; RETURN p.name, p.age, p.position\n\næ›´æ–°Georgeçš„å¹´é¾„ä¸º28\n\n\nMATCH (p &#123;name:&#x27;George&#x27;&#125;)SET p = &#123;name: &#x27;George&#x27;\tage: 28&#125;\n\n\nWrite cypher to get the second graph\n\nMATCH \t(actor1:Actor &#123;name: &#x27;Anthony Hopkins&#x27;&#125;),\t(actor2:Actor &#123;name: &#x27;Hitchcock&#x27;&#125;),\t(movie:Movie &#123;title: &#x27;Hitechcock&#x27;&#125;)CREATE\t(actor1)-[r:ACTS_IN]\t-&gt;(movie)DELETE actor2\n\nQuery all relationship types connected by actor Anthony Hopkins\n\nMATCH\t(actor:Actor &#123;name: &#x27;Anthony Hopkins&#x27;&#125;)-[r]-()RETURN type(r)\n\nGiven the dataset and natural language query as follows, please write the corresponding Cypher Query.\nReturn the movie name containing the role â€œBud Foxâ€\n\n\n\n\n\nAnswer\nMATCH (actor) - [:ACTED_IN &#123;role:&#x27;Bud Fox&#x27;&#125;] -&gt; (movie:Movie)RETURN movie.title\n\n\n\n\nDelete all the relationships on the person who is 34 years old using Cypher.\n\n\nAnswer\nMATCH (n:Person &#123;age: 34&#125;) - [r] -&gt; ()DELETE r\n\n\n","categories":["KnowledgeEngineering"]}]